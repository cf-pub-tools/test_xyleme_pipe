---
title: Ambari 1.7.0 Documentation Suite
---
<!DOCTYPE html><html xmlns:xy="http://xyleme.com/xylink">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Ambari 1.7.0 Documentation Suite</title>
<link href="http://docs.pivotal.io/stylesheets/master.css" rel="stylesheet" type="text/css" media="screen,print">
<link href="../../xyleme.css" rel="stylesheet" type="text/css" media="screen, print">
</head>
<body><div class="viewport"><div class="wrap">
<div class="container">
<header></header><main class="content content-layout" id="js-content" role="main"><a id="top"></a><h1 class="bold horton-blue">Ambari 1.7.0 Documentation Suite</h1>
<h2 class="small-title thin">Ambari 1.7.0</h2>
<div class="lessons">
    
      <h2 class="horton-green bold">Ambari User's Guide</h2>
      
        <h3 class="horton-blue bold" id="ref-5ed795d7-60ee-45f1-b2af-ed6b16cd9c5a">Overview</h3>
        
          <p>Hadoop is a large-scale, distributed data storage and processing infrastructure using clusters of
            commodity hosts networked together. Monitoring and managing such complex distributed systems is a
            non-trivial task. To help you manage the complexity, Apache Ambari collects a wide range of information from
            the cluster's nodes and services and presents it to you in an easy-to-read and use, centralized web
            interface, Ambari Web.

            Ambari Web displays information such as service-specific summaries, graphs, and alerts. You use Ambari Web
            to create and manage your HDP cluster and to perform basic operational tasks such as starting and stopping
            services, adding hosts to your cluster, and updating service configurations. You also use Ambari Web to
            perform administrative tasks for your cluster, such as managing users and groups and deploying Ambari Views.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-79682e24-8cfc-49c2-bdd3-b87df97dc875">Architecture</h3>
        
          <p>The Ambari Server serves as the collection point for data from across your cluster. Each host has a
            copy of the Ambari Agent - either installed automatically by the Install wizard or manually - which allows
            the Ambari Server to control each host. In addition, each host has a copy of Ganglia Monitor (<code>
              gmond</code>), which collects metric information that is passed to the Ganglia Connector, and then
            on to the Ambari Server.
          </p>
          <div class="figure">
            
              <p class="italic">Figure - Ambari Server Architecture</p>
              
                
                <img src="01-RawContent/Ambari/architecture_no_gang.png" width="25">
              
            
          </div>
        
        
          <h4 class="bold">Sessions</h4>
          
            <p>Ambari Web is a client-side JavaScript application, which calls the Ambari REST API (accessible
              from the Ambari Server) to access cluster information and perform cluster operations. After authenticating
              to Ambari Web, the application authenticates to the Ambari Server. Communication between the browser and
              server occurs asynchronously via the REST API.
            </p>
            <p>
              Ambari Web sessions do not time out. The Ambari Server application constantly accesses the Ambari REST
              API, which resets the session timeout. During any period of Ambari Web inactivity, the Ambari Web user
              interface (UI) refreshes automatically. You must explicitly sign out of the Ambari Web UI to destroy the
              Ambari session with the server.
            </p>
            <div class="figure">
              
                
                  
                  <img src="01-RawContent/Ambari/signout.png" width="25">
                
              
            </div>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-38a30991-3a39-483c-b7b0-a6676a1737fc">Accessing Ambari Web</h3>
        
          <p>Typically, you start the Ambari Server and Ambari Web as part of the installation process. If Ambari
            Server is stopped, you can start it using a command line editor on the Ambari Server host machine. Enter the
            following command:
          </p>
          <p>
            <code>ambari-server start</code>
          </p>
          <p>
            To access Ambari Web, open a supported browser and enter the Ambari Web URL:
          </p>
          <p>
            <code>http://&lt;your.ambari.server&gt;:8080</code>
          </p>
          <p>
            Enter your user name and password. If this is the first time Ambari Web is accessed, use the default values,
            <code>admin/admin</code>.

            These values can be changed, and new users provisioned, using the
            <code>Manage Ambari</code>
            option.
          </p>
          <div class="figure">
            
              
                
                <img src="01-RawContent/Ambari/manage_ambari_option_full_width_arrow.png" width="50">
              
            
          </div>
          <p>
            For more information about managing users and other administrative tasks, see<a href="#ref-c016ce20-4136-4813-941b-dfa8ec05b5aa">Administering Ambari</a>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-09419997-e1b4-4788-a11a-5b02cdfedd90">Monitoring and Managing your HDP Cluster with Ambari</h3>
        
          <p>This topic describes how to use Ambari Web features to monitor and manage your HDP cluster. To
            navigate, select one of the following feature tabs located at the top of the Ambari main window. The
            selected tab appears white.
          </p>
          <div class="figure">
            
              
                
                <img src="01-RawContent/Ambari/navheader3.png" width="25">
              
            
          </div>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-7db492c4-fef5-4686-b19d-acf0a1bd39a9">Viewing</a>
                  <a href="#ref-7db492c4-fef5-4686-b19d-acf0a1bd39a9">Metrics on the Dashboard</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-a395d3b3-f835-4033-8176-d5ccee6830e5">Monitoring and Managing Services</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-e98ea9e6-e031-46ef-bde7-6680d0bdf153">Managing Hosts</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-3725b276-e557-4c69-858d-3cda866960f5">Administering the Cluster</a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-7db492c4-fef5-4686-b19d-acf0a1bd39a9">Viewing Metrics on the Dashboard</h3>
        
          <p>Ambari Web displays the
            <strong>Dashboard</strong>
            page as the home page. Use the
            <strong>Dashboard</strong>
            to view the operating status of your cluster in the following three ways:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-61c72883-e9b3-49d0-9ada-e74d91bceec2">Scanning System Metrics</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-ac23e281-be1d-4955-86c1-33c1adb97a5c">Scanning Status</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-fb656590-d257-4e91-b2cc-67c98c962c11">Viewing Heatmaps</a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Scanning System Metrics</h4>
          
            <p>View
              <strong>Metrics</strong>
              that indicate the operating status of your cluster on the Ambari Dashboard. Each metrics widget displays
              status information for a single service in your HDP cluster. The Ambari Dashboard displays all metrics for
              the HDFS, YARN, HBase, and Storm services, and cluster-wide metrics by default.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>Metrics data for Storm is buffered and sent as a batch to Ambari every five minutes. After
                  adding the Storm service, anticipate a five-minute delay for Storm metrics to appear.
                </p>
              </div>
            </aside>
            <p>You can add and remove individual widgets, and rearrange the dashboard by dragging and dropping
              each widget to a new location in the dashboard.
            </p>
            <div class="figure">
              
                
                  
                  <img src="01-RawContent/Ambari/allwidgets2.png" width="50">
                
              
            </div>
            <p>Status information appears as simple pie and bar charts, more complex charts showing usage and
              load, sets of links to additional data sources, and values for operating parameters such as uptime and
              average RPC queue wait times. Most widgets display a single fact by default. For example, HDFS Disk Usage
              displays a load chart and a percentage figure. The Ambari Dashboard includes metrics for the following
              services:
            </p>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">Ambari Service Metrics and Descriptions</p>
              
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Metric:</p>
                    </th>
                    <th rowspan="1">
                      <p>Description:</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>HDFS</p>
                    </td>
                    <td rowspan="1">
                      <p></p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HDFS Disk Usage</p>
                    </td>
                    <td rowspan="1">
                      <p>The Percentage of DFS used, which is a combination of DFS and non-DFS used.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Data Nodes Live</p>
                    </td>
                    <td rowspan="1">
                      <p>The number of DataNodes live, as reported from the NameNode.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>NameNode Heap</p>
                    </td>
                    <td rowspan="1">
                      <p>The percentage of NameNode JVM Heap used.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>NameNode RPC</p>
                    </td>
                    <td rowspan="1">
                      <p>The average RPC queue latency.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>NameNode CPU WIO</p>
                    </td>
                    <td rowspan="1">
                      <p>The percentage of CPU Wait I/O.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>NameNode Uptime</p>
                    </td>
                    <td rowspan="1">
                      <p>The NameNode uptime calculation.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>YARNHDP 2.0 and 2.1 Stacks</p>
                    </td>
                    <td rowspan="1">
                      <p></p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>ResourceManager Heap</p>
                    </td>
                    <td rowspan="1">
                      <p>The percentage of ResourceManager JVM Heap used.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>ResourceManager Uptime</p>
                    </td>
                    <td rowspan="1">
                      <p>The ResourceManager uptime calculation.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>NodeManagers Live</p>
                    </td>
                    <td rowspan="1">
                      <p>The number of DataNodes live, as reported from the ResourceManager.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>YARN Memory</p>
                    </td>
                    <td rowspan="1">
                      <p>The percentage of available YARN memory (used vs. total available).</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase</p>
                    </td>
                    <td rowspan="1">
                      <p></p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase Master Heap</p>
                    </td>
                    <td rowspan="1">
                      <p>The percentage of NameNode JVM Heap used.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase Ave Load</p>
                    </td>
                    <td rowspan="1">
                      <p>The average load on the HBase server.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase Master Uptime</p>
                    </td>
                    <td rowspan="1">
                      <p>The HBase Master uptime calculation.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Region in Transition</p>
                    </td>
                    <td rowspan="1">
                      <p>The number of HBase regions in transition.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>StormHDP 2.1 Stack</p>
                    </td>
                    <td rowspan="1">
                      <p></p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Supervisors Live</p>
                    </td>
                    <td rowspan="1">
                      <p>The number of Supervisors live, as reported from the Nimbus server.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>MapReduceHDP 1.3 Stack</p>
                    </td>
                    <td rowspan="1">
                      <p></p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>JobTracker Heap</p>
                    </td>
                    <td rowspan="1">
                      <p>The percentage of JobTracker JVM Heap used.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>TaskTrackers Live</p>
                    </td>
                    <td rowspan="1">
                      <p>The number of TaskTrackers live, as reported from the JobTracker.</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
          
            <h4 class="bold">Drilling Into Metrics for a Service</h4>
            
              <ul class="bullet-list">
                
                  <li>
                    <p>To see more detailed information about a service, hover your cursor over a Metrics
                      widget.
                    </p>
                    <p>More detailed information about the service displays, as shown in the following example:
                    </p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/reversedwidget2.png" width="50">
                        
                      
                    </div>
                  </li>
                  <li>
                    <p>To remove a widget from the mashup, click the white X.</p>
                  </li>
                  <li>
                    <p>To edit the display of information in a widget, click the pencil icon. For more
                      information about editing a widget, see<a href="#ref-65141f6f-a2ae-44a9-86d8-851eb918b178">Customizing Metrics Display</a>.
                    </p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Viewing Cluster-Wide Metrics</h4>
            
              <p>Cluster-wide metrics display information that represents your whole cluster. The Ambari
                Dashboard shows the following cluster-wide metrics:
              </p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/cluster_wide_metrics_2.png" width="50">
                  
                
              </div>
              <div class="xyleme-table"><table border="1">
                <p class="italic bold">Ambari Cluster-Wide Metrics and Descriptions</p>
                
                  
                  
                  <thead>
                    <tr>
                      <th rowspan="1">
                        <p>Metric:</p>
                      </th>
                      <th rowspan="1">
                        <p>Description:</p>
                      </th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td rowspan="1">
                        <p>Memory Usage</p>
                      </td>
                      <td rowspan="1">
                        <p>The cluster-wide memory utilization, including memory cached, swapped, used, shared.
                        </p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p>Network Usage</p>
                      </td>
                      <td rowspan="1">
                        <p>The cluster-wide network utilization, including in-and-out.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p>CPU Usage</p>
                      </td>
                      <td rowspan="1">
                        <p>Cluster-wide CPU information, including system, user and wait IO.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p>Cluster Load</p>
                      </td>
                      <td rowspan="1">
                        <p>Cluster-wide Load information, including total number of nodes. total number of CPUs,
                          number of running processes and 1-min Load.
                        </p>
                      </td>
                    </tr>
                  </tbody>
                  
                
              </table></div>
              <ul class="bullet-list">
                
                  <li>
                    <p>To remove a widget from the dashboard, click the white X.</p>
                  </li>
                  <li>
                    <p>Hover your cursor over each cluster-wide metric to magnify the chart or itemize the widget
                      display.
                    </p>
                  </li>
                  <li>
                    <p>To remove or add metric items from each cluster-wide metric widget, select the item on the
                      widget legend.
                    </p>
                  </li>
                  <li>
                    <p>To see a larger view of the chart, select the magnifying glass icon.</p>
                    <p>Ambari displays a larger version of the widget in a pop-out window, as shown in the
                      following example:
                    </p>
                  </li>
                
              </ul>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/popoutchart.png" width="50">
                  
                
              </div>
              <p>Use the pop-up window in the same ways that you use cluster-wide metric widgets on the
                dashboard.
              </p>
              <p>To close the widget pop-up window, choose OK.</p>
            
          
          
            <h4 class="bold">Adding a Widget to the Dashboard</h4>
            
              <p>To replace a widget that has been removed from the dashboard:</p>
              <ul class="number-list">
                
                  <li>
                    <p>Select the Metrics drop-down, as shown in the following example:</p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/add_a_widget.png" width="50">
                        
                      
                    </div>
                  </li>
                  <li>
                    <p>Choose Add.</p>
                  </li>
                  <li>
                    <p>Select a metric, such as Region in Transition.</p>
                  </li>
                  <li>
                    <p>Choose Apply.</p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Resetting the Dashboard</h4>
            
              <p>To reset all widgets on the dashboard to display default settings:</p>
              <ul class="number-list">
                
                  <li>
                    <p>Select the Metrics drop-down, as shown in the following example:</p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/edit_widget_dashboard.png" width="50">
                        
                      
                    </div>
                  </li>
                  <li>
                    <p>Choose Edit.</p>
                  </li>
                  <li>
                    <p>Choose Reset all widgets to default.</p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Viewing Metrics in Ganglia</h4>
            
              <p>To view metrics for your cluster using the Ganglia UI:</p>
              <ul class="number-list">
                
                  <li>
                    <p>Select the Metrics drop-down:</p>
                  </li>
                  <li>
                    <p>Choose Edit.</p>
                  </li>
                  <li>
                    <p>Choose View Metrics in Ganglia.</p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Customizing Metrics Display</h4>
            
              <p>To customize the way a service widget displays metrics information:</p>
              <ul class="number-list">
                
                  <li>
                    <p>Hover your cursor over a service widget.</p>
                  </li>
                  <li>
                    <p>Select the pencil-shaped, edit icon that appears in the upper-right corner.</p>
                    <p>The Customize Widget pop-up window displays properties that you can edit, as shown in the
                      following example.
                    </p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/customizewidget.png" width="50">
                        
                      
                    </div>
                  </li>
                  <li>
                    <p>Follow the instructions in the Customize Widget pop-up to customize widget appearance.
                    </p>
                    <p>In this example, you can adjust the thresholds at which the HDFS Capacity bar chart
                      changes color, from green to orange to red.
                    </p>
                  </li>
                  <li>
                    <p>To save your changes and close the editor, choose<code>
                      Apply</code>.
                    </p>
                  </li>
                  <li>
                    <p>To close the editor without saving any changes, choose<code>
                      Cancel</code>.
                    </p>
                  </li>
                
              </ul>
              <aside class="custom-note">
                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                <div class="simple-block">
                  <p>Not all widgets support editing.</p>
                </div>
              </aside>
            
          
          
            <h4 class="bold">Viewing More Metrics for your HDP Stack</h4>
            
              <p>The HDFS Links and HBase Links widgets list HDP components for which links to more metrics
                information, such as thread stacks, logs and native component UIs are available. For example, you can
                link to NameNode, Secondary NameNode, and DataNode components for HDFS, using the links shown in the
                following example:
              </p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/more_widget_links.png" width="50">
                  
                
              </div>
              <p>Choose the
                <code>More</code>
                drop-down to select from the list of links available for each service. The Ambari Dashboard includes
                additional links to metrics for the following services:
              </p>
              <div class="xyleme-table"><table border="1">
                <p class="italic bold">Links to More Metrics for HDP Services</p>
                
                  
                  
                  
                  <thead>
                    <tr>
                      <th rowspan="1">
                        <p>Service:</p>
                      </th>
                      <th rowspan="1">
                        <p>Metric:</p>
                      </th>
                      <th rowspan="1">
                        <p>Description:</p>
                      </th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td rowspan="1">
                        <p>HDFS</p>
                      </td>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p></p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>NameNode UI</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to the NameNode UI.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>NameNode Logs</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to the NameNode logs.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>NameNode JMX</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to the NameNode JMX servlet.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>Thread Stacks</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to the NameNode thread stack traces.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p>HBase</p>
                      </td>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p></p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>HBase Master UI</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to the HBase Master UI.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>HBase Logs</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to the HBase logs.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>ZooKeeper Info</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to ZooKeeper information.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>HBase Master JPX</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to the HBase Master JMX servlet.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>Debug Dump</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to debug information.</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p></p>
                      </td>
                      <td rowspan="1">
                        <p>Thread Stacks</p>
                      </td>
                      <td rowspan="1">
                        <p>Links to the HBase Master thread stack traces.</p>
                      </td>
                    </tr>
                  </tbody>
                  
                
              </table></div>
            
          
        
        
          <h4 class="bold">Viewing Heatmaps</h4>
          
            <p>
              <strong>Heatmaps</strong>
              provides a graphical representation of your overall cluster utilization using simple color coding.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/secondlargeheatmap2.png" width="50">
                
              
            </div>
            <p>A colored block represents each host in your cluster. To see more information about a specific
              host, hover over the block representing the host in which you are interested. A pop-up window displays
              metrics about HDP components installed on that host. Colors displayed in the block represent usage in a
              unit appropriate for the selected set of metrics. If any data necessary to determine state is not
              available, the block displays "Invalid Data". Changing the default maximum values for the heatmap lets you
              fine tune the representation. Use the Select Metric drop-down to select the metric type.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/heatmapspopup2.png" width="75">
                
              
            </div>
            <p>
              <strong>Heatmaps</strong>
              supports the following metrics:
            </p>
            <div class="xyleme-table"><table border="1">
              
                
                
                <thead></thead>
                <tbody>
                  <tr>
                    <th rowspan="1">
                      <p>Metric</p>
                    </th>
                    <th rowspan="1">
                      <p>Uses</p>
                    </th>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Host/Disk Space Used %</p>
                    </td>
                    <td rowspan="1">
                      <p>disk.disk_free and disk.disk_total</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Host/Memory Used %</p>
                    </td>
                    <td rowspan="1">
                      <p>memory.mem_free and memory.mem_total</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Host/CPU Wait I/O %</p>
                    </td>
                    <td rowspan="1">
                      <p>cpu.cpu_wio</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HDFS/Bytes Read</p>
                    </td>
                    <td rowspan="1">
                      <p>dfs.datanode.bytes_read</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HDFS/Bytes Written</p>
                    </td>
                    <td rowspan="1">
                      <p>dfs.datanode.bytes_written</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HDFS/Garbage Collection Time</p>
                    </td>
                    <td rowspan="1">
                      <p>jvm.gcTimeMillis</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HDFS/JVM Heap MemoryUsed</p>
                    </td>
                    <td rowspan="1">
                      <p>jvm.memHeapUsedM</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>YARN/Garbage Collection Time</p>
                    </td>
                    <td rowspan="1">
                      <p>jvm.gcTimeMillis</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>YARN / JVM Heap Memory Used</p>
                    </td>
                    <td rowspan="1">
                      <p>jvm.memHeapUsedM</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>YARN / Memory used %</p>
                    </td>
                    <td rowspan="1">
                      <p>UsedMemoryMB and AvailableMemoryMB</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase/RegionServer read request count</p>
                    </td>
                    <td rowspan="1">
                      <p>hbase.regionserver.readRequestsCount</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase/RegionServer write request count</p>
                    </td>
                    <td rowspan="1">
                      <p>hbase.regionserver.writeRequestsCount</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase/RegionServer compaction queue size</p>
                    </td>
                    <td rowspan="1">
                      <p>hbase.regionserver.compactionQueueSize</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase/RegionServer regions</p>
                    </td>
                    <td rowspan="1">
                      <p>hbase.regionserver.regions</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase/RegionServer memstore sizes</p>
                    </td>
                    <td rowspan="1">
                      <p>hbase.regionserver.memstoreSizeMB</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
        
        
          <h4 class="bold">Scanning Status</h4>
          
            <p>Notice the color of the dot appearing next to each component name in a list of components,
              services or hosts. The dot color and blinking action indicates operating status of each component,
              service, or host. For example, in the<a href="#ref-cd8177dd-d8f0-4b93-8473-503d6711e546">Summary
                View</a>, notice green dot next to each service name. The following colors and actions indicate
              service status:
            </p>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">Status Indicators</p>
              
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Color</p>
                    </th>
                    <th rowspan="1">
                      <p>Status</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>Solid Green</p>
                    </td>
                    <td rowspan="1">
                      <p>All masters are running</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Blinking Green</p>
                    </td>
                    <td rowspan="1">
                      <p>Starting up</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Solid Red</p>
                    </td>
                    <td rowspan="1">
                      <p>At least one master is down</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Blinking Red</p>
                    </td>
                    <td rowspan="1">
                      <p>Stopping</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <p>Click the service name to open the
              <strong>Services</strong>
              screen, where you can see more detailed information on each service.
            </p>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-e98ea9e6-e031-46ef-bde7-6680d0bdf153">Managing Hosts</h3>
        
          <p>Use Ambari Hosts to manage multiple HDP components such as DataNodes, NameNodes, TaskTrackers and
            RegionServers, running on hosts throughout your cluster. For example, you can restart all DataNode
            components, optionally controlling that task with rolling restarts. Ambari Hosts supports filtering your
            selection of host components, based on operating status, host health, and defined host groupings.
          </p>
        
        
          <h4 class="bold">Working with Hosts</h4>
          
            <p>Use Hosts to view hosts in your cluster on which Hadoop services run. Use options on
              <strong>Actions</strong>
              to perform actions on one or more hosts in your cluster.
            </p>
            <p>View individual hosts, listed by fully-qualified domain name, on the Hosts landing page.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/hosts_home.png" width="50">
                
              
            </div>
          
        
        
          <h4 class="bold">Determining Host Status</h4>
          
            <p>A colored dot beside each host name indicates operating status of each host, as follows:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>Red - At least one master component on that host is down. Hover to see a tooltip that lists
                    affected components.
                  </p>
                </li>
                <li>
                  <p>Orange - At least one slave component on that host is down. Hover to see a tooltip that
                    lists affected components.
                  </p>
                </li>
                <li>
                  <p>Yellow - Ambari Server has not received a heartbeat from that host for more than 3
                    minutes.
                  </p>
                </li>
                <li>
                  <p>Green - Normal running state.</p>
                </li>
              
            </ul>
            <p>A red condition flag overrides an orange condition flag, which overrides a yellow condition flag.
              In other words, a host having a master component down may also have other issues. The following example
              shows three hosts, one having a master component down, one having a slave component down, and one healthy.
              Warning indicators appear next to hosts having a component down.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/hosts_3status_8wrngs.png" width="50">
                
              
            </div>
          
        
        
          <h4 class="bold">Filtering the Hosts List</h4>
          
            <p>Use Filters to limit listed hosts to only those having a specific operating status. The number of
              hosts in your cluster having a listed operating status appears after each status name, in parenthesis. For
              example, the following cluster has one host having healthy status and three hosts having Maintenance Mode
              turned on.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/hosts_filter_Baikal_icons.png" width="50">
                
              
            </div>
            <p>For example, to limit the list of hosts appearing on Hosts home to only those with Healthy status,
              select Filters, then choose the Healthy option. In this case, one host name appears on Hosts home.
              Alternatively, to limit the list of hosts appearing on Hosts home to only those having Maintenance Mode
              on, select Filters, then choose the Maintenance Mode option. In this case, three host names appear on
              Hosts home.
            </p>
            <p>Use the general filter tool to apply specific search and sort criteria that limits the list of
              hosts appearing on the Hosts page.
            </p>
          
        
        
          <h4 class="bold">Performing Host-Level Actions</h4>
          
            <p>Use Actions to act on one, or multiple hosts in your cluster. Actions performed on multiple hosts
              are also known as bulk operations.
            </p>
            <p>Actions comprises three menus that list the following options types:</p>
            <ul class="bullet-list">
              
                <li>
                  <p>Hosts - lists selected, filtered or all hosts options, based on your selections made using
                    Hosts home and Filters.
                  </p>
                </li>
                <li>
                  <p>Objects - lists component objects that match your host selection criteria.</p>
                </li>
                <li>
                  <p>Operations - lists all operations available for the component objects you selected.
                  </p>
                </li>
              
            </ul>
            <p>For example, to restart DataNodes on one host:</p>
            <ul class="number-list">
              
                <li>
                  <p>In Hosts, select a host running at least one DataNode.</p>
                </li>
                <li>
                  <p>In Actions, choose<code>Selected Hosts &gt; DataNodes &gt;
                    Restart</code>, as shown in the following image.
                  </p>
                  <div class="figure">
                    
                      
                        <img src="01-RawContent/Ambari/Host_datanode_restart.png" width="50">
                      
                    
                  </div>
                </li>
                <li>
                  <p>Choose OK to confirm starting the selected operation.</p>
                </li>
                <li>
                  <p>Optionally, use
                    <a href="#ref-23aca095-e95c-4345-ad8a-c90ca83a80ec">Monitoring Background Operations</a>
                    to follow, diagnose or troubleshoot the restart operation.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Viewing Components on a Host</h4>
          
            <p>To manage components running on a specific host, choose a FQDN on the Hosts page. For example,
              choose c6403.ambari.apache.org in the default example shown. Summary-Components lists all components
              installed on that host.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/Components_on_host3.png" width="50">
                
              
            </div>
            <p>Choose options in<code>Host Actions</code>, to start, stop, restart,
              delete, or turn on maintenance mode for all components installed on the selected host.
            </p>
            <p>Alternatively, choose action options from the drop-down menu next to an individual component on a
              host. The drop-down menu shows current operation status for each component, For example, you can
              decommission, restart, or stop the DataNode component (started) for HDFS, by selecting one of the options
              shown in the following example:
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/host_components_actions.png" width="70">
                
              
            </div>
          
        
        
          <h4 class="bold">Decommissioning Masters and Slaves</h4>
          
            <p>Decommissioning is a process that supports removing a component from the cluster. You must
              decommission a master or slave running on a host before removing the component or host from service.
              Decommissioning helps prevent potential loss of data or service disruption. Decommissioning is available
              for the following component types:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>DataNodes</p>
                </li>
                <li>
                  <p>NodeManagers</p>
                </li>
                <li>
                  <p>TaskTrackers</p>
                </li>
                <li>
                  <p>RegionServers</p>
                </li>
              
            </ul>
            <p>Decommissioning executes the following tasks:</p>
            <ul class="bullet-list">
              
                <li>
                  <p>For DataNodes, safely replicates the HDFS data to other DataNodes in the cluster.</p>
                </li>
                <li>
                  <p>For NodeManagers and TaskTrackers, stops accepting new job requests from the masters and
                    stops the component.
                  </p>
                </li>
                <li>
                  <p>For RegionServers, turns on drain mode and stops the component.</p>
                </li>
              
            </ul>
          
          
            <h4 class="bold">How to Decommission a Component</h4>
            
              <p>To decommission a component using Ambari Web, browse
                <strong>Hosts</strong>
                to find the host FQDN on which the component resides.
              </p>
              <p>Using<strong>Actions</strong>, select<strong>HostsComponent Type</strong>, then choose<strong>
                Decommission</strong>.
              </p>
              <p>For example:</p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/decommission_dnode.png" width="50">
                  
                
              </div>
              <p>The UI shows "Decommissioning" status while steps process, then "Decommissioned" when
                complete.
              </p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/decomissioning_masters.png" width="75">
                  
                
              </div>
            
          
          
            <h4 class="bold">How to Delete a Component</h4>
            
              <p>To delete a component using Ambari Web, on
                <code>Hosts</code>
                choose the host FQDN on which the component resides.
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>In<code>Components</code>, find a decommissioned component.
                    </p>
                  </li>
                  <li>
                    <p>Stop the component, if necessary.</p>
                    <aside class="custom-note">
                      <div class="icon"><img src="Icons/Note.png" width="50"></div>
                      <div class="simple-block">
                        <p>A decommissioned slave component may restart in the decommissioned state.</p>
                      </div>
                    </aside>
                  </li>
                  <li>
                    <p>For a decommissioned component, choose
                      <strong>Delete</strong>
                      from the component drop-down menu.
                    </p>
                  </li>
                  <li>
                    <p>Restart the Ganglia and Nagios services.</p>
                    <aside class="custom-note">
                      <div class="icon"><img src="Icons/Note.png" width="50"></div>
                      <div class="simple-block">
                        <p>Restarting services enables Ambari to recognize and monitor the correct number of
                          components.
                        </p>
                      </div>
                    </aside>
                    <p>Deleting a slave component, such as a DataNode does not automatically inform a master
                      component, such as a NameNode to remove the slave component from its exclusion list. Adding a
                      deleted slave component back into the cluster presents the following issue; the added slave
                      remains decommissioned from the master's perspective. Restart the master component, as a
                      work-around.
                    </p>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Deleting a Host from a Cluster</h4>
          
            <p>Deleting a host removes the host from the cluster. Before deleting a host, you must complete the
              following prerequisites:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>Stop all components running on the host.</p>
                </li>
                <li>
                  <p>Decommission any DataNodes running on the host.</p>
                </li>
                <li>
                  <p>Move from the host any master components, such as NameNode or ResourceManager, running on
                    the host.
                  </p>
                </li>
                <li>
                  <p>Turn Off Maintenance Mode, if necessary, for the host.</p>
                </li>
              
            </ul>
          
          
            <h4 class="bold">How to Delete a Host from a Cluster</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>In Hosts, click on a host name.</p>
                  </li>
                  <li>
                    <p>On the Host-Details page, select Host Actions drop-down menu.</p>
                  </li>
                  <li>
                    <p>Choose Delete.</p>
                  </li>
                
              </ul>
              <p>If you have not completed prerequisite steps, a warning message similar to the following one
                appears:
              </p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/Unable_to_delete_host_msg.png" width="50">
                  
                
              </div>
            
          
        
        
          <h4 class="bold">Setting Maintenance Mode</h4>
          
            <p>Maintenance Mode supports suppressing alerts and skipping bulk operations for specific services,
              components and hosts in an Ambari-managed cluster. You typically turn on Maintenance Mode when performing
              hardware or software maintenance, changing configuration settings, troubleshooting, decommissioning, or
              removing cluster nodes. You may place a service, component, or host object in Maintenance Mode before you
              perform necessary maintenance or troubleshooting tasks.
            </p>
            <p>Maintenance Mode affects a service, component, or host object in the following two ways:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>Maintenance Mode suppresses alerts, warnings and status change indicators generated for the
                    object
                  </p>
                </li>
                <li>
                  <p>Maintenance Mode exempts an object from host-level or service-level bulk operations
                  </p>
                </li>
              
            </ul>
            <p>Explicitly turning on Maintenance Mode for a service implicitly turns on Maintenance Mode for
              components and hosts that run the service. While Maintenance Mode On prevents bulk operations being
              performed on the service, component, or host, you may explicitly start and stop a service, component, or
              host having Maintenance Mode On.
            </p>
          
          
            <h4 class="bold">Setting Maintenance Mode for Services, Components, and Hosts</h4>
            
              <p>For example, examine using Maintenance Mode in a 3-node, Ambari-managed cluster installed using
                default options. This cluster has one data node, on host c6403. This example describes how to explicitly
                turn on Maintenance Mode for the HDFS service, alternative procedures for explicitly turning on
                Maintenance Mode for a host, and the implicit effects of turning on Maintenance Mode for a service, a
                component and a host.
              </p>
            
            
              <h4 class="bold">How to Turn On Maintenance Mode for a Service</h4>
              
                <ul class="number-list">
                  
                    <li>
                      <p>Using Services, select<code>HDFS</code>.
                      </p>
                    </li>
                    <li>
                      <p>Select Service Actions, then choose<code>Turn On Maintenance
                        Mode</code>.
                      </p>
                    </li>
                    <li>
                      <p>Choose OK to confirm.</p>
                      <p>
                        Notice, on Services Summary that Maintenance Mode turns on for the NameNode and SNameNode
                        components.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">How to Turn On Maintenance Mode for a Host</h4>
              
                <ul class="number-list">
                  
                    <li>
                      <p>Using Hosts, select c6401.ambari.apache.org.</p>
                    </li>
                    <li>
                      <p>Select<code>Host Actions</code>, then choose
                        <code>Turn On Maintenance Mode</code>.
                      </p>
                    </li>
                    <li>
                      <p>Choose OK to confirm.</p>
                      <p>
                        Notice on Components, that Maintenance Mode turns on for all components.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">How to Turn On Maintenance Mode for a Host (alternative using filtering for hosts)</h4>
              
                <ul class="number-list">
                  
                    <li>
                      <p>Using Hosts, select c6403.ambari.apache.org.</p>
                    </li>
                    <li>
                      <p>In
                        <code>Actions &gt; Selected Hosts &gt; Hosts</code>
                        choose<code>Turn On Maintenance Mode</code>.
                      </p>
                    </li>
                    <li>
                      <p>Choose
                        <code>OK</code>
                        to confirm.
                      </p>
                      <p>
                        Notice that Maintenance Mode turns on for host c6403.ambari.apache.org.
                      </p>
                    </li>
                  
                </ul>
                <p>
                  Your list of Hosts now shows Maintenance Mode On for hosts c6401 and c6403.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/MM_hosts_components.png" width="50">
                    
                  
                </div>
                <ul class="bullet-list">
                  
                    <li>
                      <p>Hover your cursor over each Maintenance Mode icon appearing in the Hosts list.
                      </p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>Notice that hosts c6401 and c6403 have Maintenance Mode On.</p>
                          </li>
                          <li>
                            <p>Notice that on host c6401; Ganglia Monitor, HbaseMaster, HDFS client, NameNode,
                              and Zookeeper Server have Maintenance Mode turned On.
                            </p>
                          </li>
                          <li>
                            <p>Notice on host c6402, that HDFS client and Secondary NameNode have Maintenance
                              Mode On.
                            </p>
                          </li>
                          <li>
                            <p>Notice on host c6403, that 15 components have Maintenance Mode On.</p>
                          </li>
                        
                      </ul>
                    </li>
                    <li>
                      <p>The following behavior also results:</p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>Alerts are suppressed for the DataNode.</p>
                          </li>
                          <li>
                            <p>DataNode is skipped from HDFS Start/Stop/Restart All, Rolling Restart.</p>
                          </li>
                          <li>
                            <p>DataNode is skipped from all Bulk Operations except Turn Maintenance Mode
                              ON/OFF.
                            </p>
                          </li>
                          <li>
                            <p>DataNode is skipped from Start All and / Stop All components.</p>
                          </li>
                          <li>
                            <p>DataNode is skipped from a host-level restart/restart all/stop all/start.
                            </p>
                          </li>
                        
                      </ul>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Maintenance Mode Use Cases</h4>
              
                <p>Four common Maintenance Mode Use Cases follow:</p>
                <ul class="number-list">
                  
                    <li>
                      <p>You want to perform hardware, firmware, or OS maintenance on a host.</p>
                      <p>
                        You want to:
                      </p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>Prevent alerts generated by all components on this host.</p>
                          </li>
                          <li>
                            <p>Be able to stop, start, and restart each component on the host.</p>
                          </li>
                          <li>
                            <p>Prevent host-level or service-level bulk operations from starting, stopping, or
                              restarting components on this host.
                            </p>
                          </li>
                        
                      </ul>
                      <p>
                        To achieve these goals, turn On Maintenance Mode explicitly for the host. Putting a host in
                        Maintenance Mode implicitly puts all components on that host in Maintenance Mode.
                      </p>
                    </li>
                    <li>
                      <p>You want to test a service configuration change. You will stop, start, and restart the
                        service using a rolling restart to test whether restarting picks up the change.
                      </p>
                      <p>
                        You want:
                      </p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>No alerts generated by any components in this service.</p>
                          </li>
                          <li>
                            <p>To prevent host-level or service-level bulk operations from starting, stopping, or
                              restarting components in this service.
                            </p>
                          </li>
                        
                      </ul>
                      <p>
                        To achieve these goals, turn on Maintenance Mode explicitly for the service. Putting a service
                        in Maintenance Mode implicitly turns on Maintenance Mode for all components in the service.
                      </p>
                    </li>
                    <li>
                      <p>You turn off a service completely.</p>
                      <p>
                        You want:
                      </p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>The service to generate no warnings.</p>
                          </li>
                          <li>
                            <p>To ensure that no components start, stop, or restart due to host-level actions or
                              bulk operations.
                            </p>
                          </li>
                        
                      </ul>
                      <p>
                        To achieve these goals, turn On Maintenance Mode explicitly for the service. Putting a service
                        in Maintenance Mode implicitly turns on Maintenance Mode for all components in the service.
                      </p>
                    </li>
                    <li>
                      <p>A host component is generating alerts.</p>
                      <p>
                        You want to:
                      </p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>Check the component.</p>
                          </li>
                          <li>
                            <p>Assess warnings and alerts generated for the component.</p>
                          </li>
                          <li>
                            <p>Prevent alerts generated by the component while you check its condition.
                            </p>
                          </li>
                        
                      </ul>
                    </li>
                  
                </ul>
                <p>
                  To achieve these goals, turn on Maintenance Mode explicitly for the host component. Putting a host
                  component in Maintenance Mode prevents host-level and service-level bulk operations from starting or
                  restarting the component. You can restart the component explicitly while Maintenance Mode is on.
                </p>
              
            
          
        
        
          <h4 class="bold">Adding Hosts to a Cluster</h4>
          
            <p>To add new hosts to your cluster, browse to the Hosts page and select
              <code>Actions &gt;</code>
              <code>+Add New Hosts</code>. The
              <code>Add Host Wizard</code>
              provides a sequence of prompts similar to those in the Ambari Install Wizard. Follow the prompts,
              providing information similar to that provided to define the first set of hosts in your cluster.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/addhosts.png" width="50">
                
              
            </div>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-a395d3b3-f835-4033-8176-d5ccee6830e5">Managing Services</h3>
        
          <p>Use
            <code>Services</code>
            to monitor and manage selected services running in your Hadoop cluster.
          </p>
          <p>All services installed in your cluster are listed in the leftmost
            <code>Services</code>
            panel.
          </p>
          <div class="figure">
            
              
                <img src="01-RawContent/Ambari/Services_hdp22_amb170.png" width="50">
              
            
          </div>
          <p>Services supports the following tasks:</p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-1b6faf72-d530-448d-b7da-1c863aaf8e2c">Starting and Stopping All Services</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-229fb7c2-31ed-4a90-aba6-9d00ce5f32ce">Selecting a Service</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-cd8177dd-d8f0-4b93-8473-503d6711e546">Viewing Summary, Alert, and Health
                    Information
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-f6634232-8199-4010-b67d-c18563e7fa11">Editing Service Config Properties</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-33b1ba5b-14d6-4fd8-a405-fde772168b2b">Rolling Restarts</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-4c1204bd-2364-41e7-bca6-fd415f8f696e">Using Quick Links</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-275969b0-5b20-4fde-8837-8a527032f0c5">Analyzing Service Metrics</a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Starting and Stopping All Services</h4>
          
            <p>To start or stop all listed services at once, select<code>
              Actions</code>, then choose
              <code>Start All</code>
              or<code>Stop All</code>, as shown in the following example:
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/services_stop_all.png" width="50">
                
              
            </div>
          
        
        
          <h4 class="bold">Selecting a Service</h4>
          
            <p>Selecting a service name from the list shows current summary, alert, and health information for
              the selected service. To refresh the monitoring panels and show information about a different service,
              select a different service name from the list.
            </p>
            <p>Notice the colored dot next to each service name, indicating service operating status and a small,
              red, numbered rectangle indicating any alerts generated for the service.
            </p>
          
          
            <h4 class="bold">Adding a Service</h4>
            
              <p>The Ambari install wizard installs all available Hadoop services by default. You may choose to
                deploy only some services initially, then add other services at later times. For example, many customers
                deploy only core Hadoop services initially.
                <code>Add Service</code>
                supports deploying additional services without interrupting operations in your Hadoop cluster. When you
                have deployed all available services,
                <code>Add Service</code>
                displays disabled.
              </p>
              <p>
                For example, if you are using HDP 2.2 Stack and did not install Falcon or Storm, you can use the
                <code>Add Service</code>
                capability to add those services to your cluster.
              </p>
              <aside class="custom-note">
                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                <div class="simple-block">
                  <p>After installing Storm via Ambari, you should configure the Storm service to run as a
                    supervised service.
                  </p>
                  <p>For more information, see<a href="#ref-803898d1-8f94-4980-9b9f-9b110361a6a3">
                    Configuring Storm for Supervision</a>.
                  </p>
                </div>
              </aside>
              <p>To add a service, select<code>Actions &gt; Add Service</code>,
                then complete the following procedure using the Add Service Wizard.
              </p>
            
            
              <h4 class="bold">Adding a Service to your Hadoop cluster</h4>
              
                <p>This example shows the Falcon service selected for addition.</p>
                <ul class="number-list">
                  
                    <li>
                      <p>Choose<code>Services</code>.
                      </p>
                      <p>
                        Choose an available service. Alternatively, choose all to add all available services to your
                        cluster. Then, choose Next. The Add Service wizard displays installed services highlighted green
                        and check-marked, not available for selection.
                      </p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/SelectService75.png" width="60">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>In<code>Assign Masters</code>, confirm the default host
                        assignment. Alternatively, choose a different host machine to which master components for your
                        selected service will be added. Then, choose Next.
                      </p>
                      <p>
                        The Add Services Wizard indicates hosts on which the master components for a chosen service will
                        be installed. A service chosen for addition shows a grey check mark.

                        Using the drop-down, choose an alternate host name, if necessary.
                      </p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>A green label located on the host to which its master components will be added,
                              or
                            </p>
                          </li>
                          <li>
                            <p>An active drop-down list on which available host names appear.</p>
                          </li>
                        
                      </ul>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/AssignMasters.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>In<code>Assign Slaves and Clients</code>, accept the
                        default assignment of slave and client components to hosts. Then, choose Next.
                      </p>
                      <p>
                        Alternatively, select hosts on which you want to install slave and client components. You must
                        select at least one host for the slave of each service being added.
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          <thead>
                            <tr>
                              <th rowspan="1">
                                <p>Service Added</p>
                              </th>
                              <th rowspan="1">
                                <p>Host Role Required</p>
                              </th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td rowspan="1">
                                <p>MapReduce</p>
                              </td>
                              <td rowspan="1">
                                <p>TaskTracker</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>YARN</p>
                              </td>
                              <td rowspan="1">
                                <p>NodeManager</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>HBase</p>
                              </td>
                              <td rowspan="1">
                                <p>RegionServer</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                        Host Roles Required for Added Services
                      </table></div>
                      <p>The Add Service Wizard skips and disables the Assign Slaves and Clients step for a
                        service requiring no slave nor client assignment.
                      </p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/AssignSlavesnClients.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>In<code>Customize Services</code>, accept the default
                        configuration properties.
                      </p>
                      <p>
                        Alternatively, edit the default values for configuration properties, if necessary. Choose
                        Override to create a configuration group for this service. Then, choose Next.
                      </p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/CustomizeServices.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>In Review, make sure the configuration settings match your intentions. Then, choose
                        Deploy.
                      </p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/ReviewServiceConfig.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>Monitor the progress of installing, starting, and testing the service. When the service
                        installs and starts successfully, choose Next.
                      </p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/AddServiceISTsuccess.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>Summary displays the results of installing the service. Choose Complete.</p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/AddServiceSummary.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>Restart the Nagios service and any other components having stale configurations.
                      </p>
                    </li>
                  
                </ul>
                <p>If you do not restart Nagios service after completing the Add Service Wizard, alerts and
                  notifications may not work properly.
                </p>
              
            
          
        
        
          <h4 class="bold">Viewing Summary, Alert, and Health Information</h4>
          
            <p>After you select a service, the
              <code>Summary</code>
              tab displays basic information about the selected service.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/services_summary.png" width="50">
                
              
            </div>
            <p>Select one of the
              <code>View Host</code>
              links, as shown in the following example, to view components and the host on which the selected service is
              running.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/view_hosts_links.png" width="50">
                
              
            </div>
          
          
            <h4 class="bold">Alerts and Health Checks</h4>
            
              <p>View results of the health checks performed on your cluster by Nagios in<code>
                Alerts and Health Checks</code>. Alerts and Health Checks displays a list of each issue
                and its rating, sorted first by descending severity, then by descending time. To access more detailed
                information, select the native Nagios GUI link located at the upper right corner of the panel. Use the
                Nagios credentials you set up during installation to log in to Nagios.
              </p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/services_alerts_health_checks.png" width="50">
                  
                
              </div>
            
          
        
        
          <h4 class="bold">Editing Service Config Properties</h4>
          
            <p>Select a service, then select
              <code>Configs</code>
              to view and update configuration properties for the selected service. For example, select MapReduce2, then
              select Configs. Expand a config category to view configurable service properties. For example, select
              General to configure Default virtual memory for a job's map task.
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/Configs_MR2_stale.png" width="50">
                
              
            </div>
          
          
            <h4 class="bold">Performing Service Actions</h4>
            
              <p>Manage a selected service on your cluster by performing service actions. In<code>
                Services</code>, select the
                <code>Service Actions</code>
                drop-down menu, then choose an option. Available options depend on the service you have selected. For
                example, HDFS service action options include:
              </p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/Service_Actions_DataNode.png" width="75">
                  
                
              </div>
              <p>Optionally, choose
                <code>Turn On Maintenance Mode</code>
                to suppress alerts generated by a service before performing a service action. Maintenance Mode
                suppresses alerts and status indicator changes generated by the service, while allowing you to start,
                stop, restart, move, or perform maintenance tasks on the service. For more information about how
                Maintenance Mode affects bulk operations for host components, see<a href="#ref-0ec3f7a2-f562-45be-a550-63d63861558d">Maintenance Mode</a>.
              </p>
            
          
          
            <h4 class="bold">Rolling Restarts</h4>
            
              <p>When you restart multiple services, components, or hosts, use rolling restarts to distribute the
                task; minimizing cluster downtime and service disruption. A rolling restart stops, then starts multiple,
                running slave components such as DataNodes, TaskTrackers, NodeManagers, RegionServers, or Supervisors,
                using a batch sequence. You set rolling restart parameter values to control the number of, time between,
                tolerance for failures, and limits for restarts of many components across large clusters.
              </p>
              <p>To run a rolling restart:</p>
              <ul class="number-list">
                
                  <li>
                    <p>Select a Service, then link to a lists of specific components or hosts that Require
                      Restart.
                    </p>
                  </li>
                  <li>
                    <p>Select Restart, then choose a slave component option.</p>
                  </li>
                  <li>
                    <p>Review and set values for Rolling Restart Parameters.</p>
                  </li>
                  <li>
                    <p>Optionally, reset the flag to only restart components with changed configurations.
                    </p>
                  </li>
                  <li>
                    <p>Choose Trigger Restart.</p>
                  </li>
                
              </ul>
              <p>Use
                <a href="#ref-23aca095-e95c-4345-ad8a-c90ca83a80ec">Monitor Background Operations</a>
                to monitor progress of rolling restarts.
              </p>
            
            
              <h4 class="bold">Setting Rolling Restart Parameters</h4>
              
                <p>When you choose to restart slave components, use parameters to control how restarts of
                  components roll. Parameter values based on ten percent of the total number of components in your
                  cluster are set as default values. For example, default settings for a rolling restart of components
                  in a 3-node cluster restarts one component at a time, waits two minutes between restarts, will proceed
                  if only one failure occurs, and restarts all existing components that run this service.
                </p>
                <p>
                  If you trigger a rolling restart of components, Restart components with stale configs defaults to
                  true. If you trigger a rolling restart of services, Restart services with stale configs defaults to
                  false.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/RlgRestart_DataNodes.png" width="70">
                    
                  
                </div>
                <p>Rolling restart parameter values must satisfy the following criteria:</p>
                <div class="xyleme-table"><table border="1">
                  <p class="italic bold">Validation Rules for Rolling Restart Parameters</p>
                  
                    
                    
                    
                    
                    <thead>
                      <tr>
                        <th rowspan="1">
                          <p>Parameter</p>
                        </th>
                        <th rowspan="1">
                          <p>Required</p>
                        </th>
                        <th rowspan="1">
                          <p>Value</p>
                        </th>
                        <th rowspan="1">
                          <p>Description</p>
                        </th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td rowspan="1">
                          <p>Batch Size</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Must be an integer &gt; 0</p>
                        </td>
                        <td rowspan="1">
                          <p>Number of components to include in each restart batch.</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Wait Time</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Must be an integer &gt; = 0</p>
                        </td>
                        <td rowspan="1">
                          <p>Time (in seconds) to wait between queuing each batch of components.</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Tolerate up to x failures</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Must be an integer &gt; = 0</p>
                        </td>
                        <td rowspan="1">
                          <p>Total number of restart failures to tolerate, across all batches, before halting the
                            restarts and not queuing batches.
                          </p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              
            
            
              <h4 class="bold">Aborting a Rolling Restart</h4>
              
                <p>To abort future restart operations in the batch, choose Abort Rolling Restart.</p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/abort_rllng_restart_option.png" width="50">
                    
                  
                </div>
              
            
          
          
            <h4 class="bold">Enabling NameNode High Availability</h4>
            
              <aside class="custom-note">
                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                <div class="simple-block">
                  <p>This feature is available with HDP Stack (2.0 or later)</p>
                </div>
              </aside>
              <p>
                To ensure that a NameNode in your cluster is always available if the primary NameNode host fails, enable
                and set up NameNode High Availability on your cluster using Ambari Web.

                In Ambari Web, browse to<code>Services &gt; HDFS &gt; Summary</code>,
                select
                <code>Service Actions</code>
                and then choose<code>Enable NameNode HA</code>. Follow the steps in the
                Enable NameNode HA Wizard.

                For more information about using the Enable NameNode HA Wizard to set up NameNode High Availability, see
                <a href="#ref-96b6ea9c-9bf5-4a1b-a4fd-85eec215621e">Configuring NameNode High
                  Availability</a>.
              </p>
            
          
          
            <h4 class="bold">Enabling Resource Manager High Availability</h4>
            
              <aside class="custom-note">
                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                <div class="simple-block">
                  <p>This feature is available with HDP Stack (2.1 or later)</p>
                </div>
              </aside>
              <p>To ensure that a ResourceManager in your cluster is always available if the primary
                ResourceManager host fails, enable and set up ResourceManager High Availability on your cluster using
                Ambari Web.

                In Ambari Web, browse to<code>Services &gt; YARN &gt; Summary</code>,
                select Service Actions and then choose Enable ResourceManager HA. Follow the steps in the Enable
                ResourceManager HA Wizard.

                For more information about using the Enable ResourceManager HA Wizard to set up ResourceManager High
                Availability, see<a href="#ref-edbf1cf0-b3cd-42fb-959c-fdb13bc5e02f">Configuring
                  ResourceManager High Availability</a>.
              </p>
            
          
          
            <h4 class="bold">Monitoring Background Operations</h4>
            
              <p>Optionally, use Background Operations to monitor progress and completion of bulk operations such
                as rolling restarts.
              </p>
              <p>
                Background Operations opens by default when you run a job that executes bulk operations.
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>Select the right-arrow for each operation to show restart operation progress on each
                      host.
                    </p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/RlgRestart_DNds_NdMgrs.png" width="50">
                        
                      
                    </div>
                  </li>
                  <li>
                    <p>After restarts complete, Select the right-arrow, or a host name, to view log files and any
                      error messages generated on the selected host.
                    </p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/Background_Ops_hosts.png" width="50">
                        
                      
                    </div>
                  </li>
                  <li>
                    <p>Select links at the upper-right to copy or open text files containing log and error
                      information.
                    </p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/Background_Ops_logs.png" width="50">
                        
                      
                    </div>
                  </li>
                
              </ul>
              <p>Optionally, select the option to not show the bulk operations dialog.</p>
            
          
          
            <h4 class="bold">Using Quick Links</h4>
            
              <p>Select
                <code>Quick Links</code>
                options to access additional sources of information about a selected service. For example, HDFS Quick
                Links options include the native NameNode GUI, NameNode logs, the NameNode JMX output, and thread stacks
                for the HDFS service. Quick Links are not available for every service.
              </p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/quicklinks.png" width="50">
                  
                
              </div>
            
          
          
            <h4 class="bold">Analyzing Service Metrics</h4>
            
              <p>Review visualizations in
                <code>Metrics</code>
                that chart common metrics for a selected service.
                <code>Services &gt; Summary</code>
                displays metrics widgets for HDFS, HBase, Storm services. For more information about using metrics
                widgets, see<a href="#ref-61c72883-e9b3-49d0-9ada-e74d91bceec2">Scanning System Metrics</a>.
                To see more metrics information, select the link located at the upper right of the Metrics panel that
                opens the native Ganglia GUI.
              </p>
            
          
        
        
          <h4 class="bold">Managing Configurations</h4>
          
            <p>Use Ambari Web to manage your HDP component configurations. Select any of the following topics:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>
                    <a href="#ref-03c39d95-af1d-4f7c-bc13-9790c002a53a">Configuring Services</a>
                  </p>
                </li>
                <li>
                  <p>
                    <a href="#ref-0c1ccfaa-3cec-4542-aeee-815e651a15c2">Using Host Config Groups</a>
                  </p>
                </li>
                <li>
                  <p>
                    <a href="#ref-bf3b7cb1-32dd-4b4a-8e12-ffcc44be2771">Customizing Log Settings</a>
                  </p>
                </li>
                <li>
                  <p>
                    <a href="#ref-024243f8-734e-4882-a936-132de0d2111b">Downloading Client Configs</a>
                  </p>
                </li>
                <li>
                  <p>
                    <a href="#ref-c448b293-0e9b-42a1-bfef-076dd1fef3df">Service Configuration Versions</a>
                  </p>
                </li>
              
            </ul>
          
          
            <h4 class="bold">Configuring Services</h4>
            
              <p>Select a service, then select
                <code>Configs</code>
                to view and update configuration properties for the selected service. For example, select MapReduce2,
                then select Configs. Expand a config category to view configurable service properties.
              </p>
            
            
              <h4 class="bold">Updating Service Properties</h4>
              
                <ul class="number-list">
                  
                    <li>
                      <p>Expand a configuration category.</p>
                    </li>
                    <li>
                      <p>Edit values for one or more properties that have the Override option.</p>
                      <p>
                        Edited values, also called stale configs, show an Undo option.
                      </p>
                    </li>
                    <li>
                      <p>Choose Save.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Restarting components</h4>
              
                <p>After editing and saving a service configuration, Restart indicates components that you must
                  restart.

                  Select the Components or Hosts links to view details about components or hosts requiring a restart.

                  Then, choose an option appearing in Restart. For example, options to restart YARN components include:
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/restart_options.png" width="70">
                    
                  
                </div>
              
            
          
          
            <h4 class="bold">Using Host Config Groups</h4>
            
              <p>Ambari initially assigns all hosts in your cluster to one, default configuration group for each
                service you install. For example, after deploying a three-node cluster with default configuration
                settings, each host belongs to one configuration group that has default configuration settings for the
                HDFS service. In Configs, select<code>Manage Config Groups</code>, to
                create new groups, re-assign hosts, and override default settings for host components you assign to each
                group.
              </p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/MngCnfgGrps.png" width="50">
                  
                
              </div>
              <p>To create a Configuration Group:</p>
              <ul class="number-list">
                
                  <li>
                    <p>Choose<code>Add New Configuration Group</code>.
                    </p>
                  </li>
                  <li>
                    <p>Name and describe the group, then choose Save.</p>
                  </li>
                  <li>
                    <p>Select a Config Group, then choose Add Hosts to Config Group.</p>
                  </li>
                  <li>
                    <p>Select Components and choose from available Hosts to add hosts to the new group.
                    </p>
                    <p>
                      Select Configuration Group Hosts enforces host membership in each group, based on installed
                      components for the selected service.
                    </p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/SelectCnfgGrpHosts.png" width="50">
                        
                      
                    </div>
                  </li>
                  <li>
                    <p>Choose OK.</p>
                  </li>
                  <li>
                    <p>In Manage Configuration Groups, choose Save.</p>
                  </li>
                
              </ul>
              <p>
                To edit settings for a configuration group:
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>In Configs, choose a Group.</p>
                  </li>
                  <li>
                    <p>Select a Config Group, then expand components to expose settings that allow Override.
                    </p>
                  </li>
                  <li>
                    <p>Provide a non-default value, then choose Override or Save.</p>
                    <p>Configuration groups enforce configuration properties that allow override, based on
                      installed components for the selected service and group.
                    </p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/EditCnfgGrpProperty.png" width="50">
                        
                      
                    </div>
                  </li>
                  <li>
                    <p>Override prompts you to choose one of the following options:</p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/override_config.png" width="50">
                        
                      
                    </div>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Select an existing configuration group (to which the property value override
                            provided in step 3 will apply), or
                          </p>
                        </li>
                        <li>
                          <p>Create a new configuration group (which will include default properties, plus the
                            property override provided in step 3).
                          </p>
                        </li>
                        <li>
                          <p>Then, choose<code>OK</code>.
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>In Configs, choose Save.</p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Customizing Log Settings</h4>
            
              <p>Ambari Web displays default logging properties in<code>Service Configs &gt;
                Custom log 4j Properties</code>. Log 4j properties control logging activities for the
                selected service.
              </p>
              <div class="figure">
                
                  
                    <img src="01-RawContent/Ambari/edit_log4jprops.png" width="60">
                  
                
              </div>
              <p>
                Restarting components in the service pushes the configuration properties displayed in Custom log 4j
                Properties to each host running components for that service. If you have customized logging properties
                that define how activities for each service are logged, you will see refresh indicators next to each
                service name after upgrading to Ambari 1.5.0 or higher. Make sure that logging properties displayed in
                Custom log 4j Properties include any customization. Optionally, you can create configuration groups that
                include custom logging properties. For more information about saving and overriding configuration
                settings, see<a href="#ref-03c39d95-af1d-4f7c-bc13-9790c002a53a">Configuring Services</a>.
              </p>
            
          
          
            <h4 class="bold">Downloading Client Configs</h4>
            
              <p>For Services that include client components (for example Hadoop Client or Hive Client), you can
                download the client configuration files associated with that client from Ambari.
              </p>
              <ul class="bullet-list">
                
                  <li>
                    <p>In Ambari Web, browse to the Service with the client for which you want the
                      configurations.
                    </p>
                  </li>
                  <li>
                    <p>Choose<code>Service Actions</code>.
                    </p>
                  </li>
                  <li>
                    <p>Choose<code>Download Client Configs</code>. You are prompted
                      for a location to save the client configs bundle.
                    </p>
                    <div class="figure">
                      
                        
                          <img src="01-RawContent/Ambari/Dwnld_clnt_cnfgs.png" width="50">
                        
                      
                    </div>
                  </li>
                  <li>
                    <p>Save the bundle.</p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Service Configuration Versions</h4>
            
              <p>Ambari provides the ability to manage configurations associated with a Service. You can make
                changes to configurations, see a history of changes, compare + revert changes and push configuration
                changes to the cluster hosts.
              </p>
              <ul class="bullet-list">
                
                  <li>
                    <p>
                      <a href="#ref-32d5e0fe-390f-4382-a31f-4aa0eabe81a0">Basic Concepts</a>
                    </p>
                  </li>
                  <li>
                    <p>
                      <a href="#ref-56bf9d96-e835-4ea0-8084-b3013c74f267">Terminology</a>
                    </p>
                  </li>
                  <li>
                    <p>
                      <a href="#ref-fb2a6656-b1b0-4a6e-8a16-6ef8e7e7d391">Saving a Change</a>
                    </p>
                  </li>
                  <li>
                    <p>
                      <a href="#ref-94bce554-5cb9-48e3-b0de-d139d5278f31">Viewing History</a>
                    </p>
                  </li>
                  <li>
                    <p>
                      <a href="#ref-796ae133-58ae-4103-9de9-b5b05e8eef0e">Comparing Versions</a>
                    </p>
                  </li>
                  <li>
                    <p>
                      <a href="#ref-e2b71304-1b66-49b5-ad1e-c9edc13f2e97">Reverting a Change</a>
                    </p>
                  </li>
                  <li>
                    <p>
                      <a href="#ref-374297e8-ae0e-4336-969f-592281d2f6ac">Versioning and Host Config Groups
                      </a>
                    </p>
                  </li>
                
              </ul>
            
            
              <h4 class="bold">Basic Concepts</h4>
              
                <p>It’s important to understand how service configurations are organized and stored in Ambari.
                  Properties are grouped into Configuration Types (config types). A set of config types makes up the set
                  of configurations for a service.

                  For example, the HDFS Service includes the following config types: hdfs-site, core-site, hdfs-log4j,
                  hadoop-env, hadoop-policy. If you browse to<code>Services &gt; HDFS &gt;
                    Configs</code>, the configuration properties for these config types are available for
                  edit.

                  Versioning of configurations is performed at the service-level. Therefore, when you modify a
                  configuration property in a service, Ambari will create a Service Config Version. The figure below
                  shows V1 and V2 of a Service Configuration Version with a change to a property in Config Type A. After
                  making the property change to Config Type A in V1, V2 is created.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Svc_Cnfg_Vrsn_Cncpt.png" width="50">
                    
                  
                </div>
              
            
            
              <h4 class="bold">Terminology</h4>
              
                <p>The following table lists configuration versioning terms and concepts that you should know.
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    <thead>
                      <tr>
                        <th rowspan="1">
                          <p>Term</p>
                        </th>
                        <th rowspan="1">
                          <p>Description</p>
                        </th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td rowspan="1">
                          <p>Configuration Property</p>
                        </td>
                        <td rowspan="1">
                          <p>Configuration property managed by Ambari, such as NameNode heapsize or replication
                            factor.
                          </p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Configuration Type (Config Type)</p>
                        </td>
                        <td rowspan="1">
                          <p>Group of configuration properties. For example: hdfs-site is a Config Type.
                          </p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Service Configurations</p>
                        </td>
                        <td rowspan="1">
                          <p>Set of configuration types for a particular service. For example: hdfs-site and
                            core-site Config Types are part of the HDFS Service Configuration.
                          </p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Change Notes</p>
                        </td>
                        <td rowspan="1">
                          <p>Optional notes to save with a service configuration change.</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Service Config Version (SCV)</p>
                        </td>
                        <td rowspan="1">
                          <p>Particular version of configurations for a specific service. Ambari saves a history
                            of service configuration versions.
                          </p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Host Config Group (HCG)</p>
                        </td>
                        <td rowspan="1">
                          <p>Set of configuration properties to apply to a specific set of hosts. Each service
                            has a default Host Config Group, and custom config groups can be created on top of the
                            default configuration group to target property overrides to one or more hosts in the
                            cluster. See Managing Configuration Groups for more information.
                          </p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              
            
            
              <h4 class="bold">Saving a Change</h4>
              
                <ul class="number-list">
                  
                    <li>
                      <p>Make the configuration property change.</p>
                    </li>
                    <li>
                      <p>Choose Save.</p>
                    </li>
                    <li>
                      <p>You are prompted to enter notes that describe the change.</p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/Save_Config_Changes.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>Click Save to confirm your change. Cancel will not save but instead returns you to the
                        configuration page to continuing editing.
                      </p>
                      <p>
                        To revert the changes you made and not save, choose Discard.

                        To return to the configuration page and continue editing without saving changes, choose Cancel.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Viewing History</h4>
              
                <p>Service Config Version history is available from Ambari Web in two places: On the Dashboard
                  page under the Config History tab; and on each Service page under the Configs tab.

                  The
                  <code>Dashboard &gt; Config History</code>
                  tab shows a list of all versions across services with each version number and the date and time the
                  version was created. You can also see which user authored the change with the notes entered during
                  save. Using this table, you can filter, sort and search across versions.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Cnfig_Hstry_1.png" width="50">
                    
                  
                </div>
              
              
                <p>The most recent configuration changes are shown on the
                  <code>Service &gt; Configs</code>
                  tab. Users can navigate the version scrollbar left-right to see earlier versions. This provides a
                  quick way to access the most recent changes to a service configuration.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Cnfig_Hstry_2.png" width="50">
                    
                  
                </div>
                <p>Click on any version in the scrollbar to view, and hover to display an option menu which
                  allows you compare versions and perform a revert. Performing a revert makes any config version that
                  you select the current version.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Cnfig_Hstry_3.png" width="50">
                    
                  
                </div>
              
            
            
              <h4 class="bold">Comparing Versions</h4>
              
                <p>When navigating the version scroll area on the
                  <code>Services &gt; Configs</code>
                  tab, you can hover over a version to display options to view, compare or revert.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Cmpare_vrsns_1.png" width="50">
                    
                  
                </div>
                <ul class="number-list">
                  To perform a compare between two service configuration versions:
                  
                    <li>
                      <p>Navigate to a specific configuration version. For example “V6”.</p>
                    </li>
                    <li>
                      <p>Using the version scrollbar, find the version would you like to compare against “V6”.
                        For example, if you want to compare V6 to V2, find V2 in the scrollbar.
                      </p>
                    </li>
                    <li>
                      <p>Hover over the version to display the option menu. Click “Compare”.</p>
                    </li>
                    <li>
                      <p>Ambari displays a comparison of V6 to V2, with an option to revert to V2.</p>
                    </li>
                    <li>
                      <p>Ambari also filters the display by only “Changed properties”. This option is available
                        under the Filter control.
                      </p>
                    </li>
                  
                </ul>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Cmpare_vrsns_2.png" width="50">
                    
                  
                </div>
              
            
            
              <h4 class="bold">Reverting a Change</h4>
              
                <p>You can revert to an older service configuration version by using the “Make Current” feature.
                  The “Make Current” will actually create a new service configuration version with the configuration
                  properties from the version you are reverting -- it is effectively a “clone”. After initiating the
                  Make Current operation, you are prompted to enter notes for the new version (i.e. the clone) and save.
                  The notes text will include text about the version being cloned.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/revert_change_1.png" width="50">
                    
                  
                </div>
                <p>There are multiple methods to revert to a previous configuration version:</p>
                <ul class="bullet-list">
                  
                    <li>
                      <p>View a specific version and click the “Make V* Current” button.</p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/revert_change_tabl_1.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>Use the version navigation dropdown and click the “Make Current” button.</p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/revert_change_tabl_2.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>Hover on a version in the version scrollbar and click the “Make Current” button.
                      </p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/revert_change_tabl_3.png" width="50">
                          
                        
                      </div>
                    </li>
                    <li>
                      <p>Perform a comparison and click the “Make V* Current” button.</p>
                      <div class="figure">
                        
                          
                            <img src="01-RawContent/Ambari/revert_change_tabl_4.png" width="50">
                          
                        
                      </div>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Versioning and Host Config Groups</h4>
              
                <p>Service configuration versions are scoped to a host config group. For example, changes made in
                  the default group can be compared and reverted in that config group. Same with custom config groups.
                </p>
              
              
                <p>The following example describes a flow where you have multiple host config groups and create
                  service configuration versions in each config group.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Svc_Config_Vrsn-01.png" width="50">
                    
                  
                </div>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Svc_Config_Vrsn-02.png" width="50">
                    
                  
                </div>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Svc_Config_Vrsn-03.png" width="50">
                    
                  
                </div>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Svc_Config_Vrsn-04.png" width="50">
                    
                  
                </div>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/Svc_Config_Vrsn-05.png" width="50">
                    
                  
                </div>
                <ul class="bullet-list">
                  
                    <li>
                      <p></p>
                    </li>
                    <li>
                      <p></p>
                    </li>
                    <li>
                      <p></p>
                    </li>
                    <li>
                      <p></p>
                    </li>
                    <li>
                      <p></p>
                    </li>
                    <li>
                      <p></p>
                    </li>
                  
                </ul>
              
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-3725b276-e557-4c69-858d-3cda866960f5">Administering the Cluster</h3>
        
          <p>Use
            <code>Admin</code>
            options to view repositories and service accounts for your cluster and to enable or disable Kerberos
            security for your cluster.
          </p>
          <div class="figure">
            
              
                <img src="01-RawContent/Ambari/Amb_Admin_optns_170.png" width="50">
              
            
          </div>
          <p>For more information about administering your cluster, see<a href="#ref-c016ce20-4136-4813-941b-dfa8ec05b5aa">Administering Ambari</a>.
          </p>
        
        
          <h4 class="bold">Viewing Cluster Stack Version and Repository URLs</h4>
          
            <p>To view the version of each Service version installed in your HDP cluster and the base repository
              path, choose<code>Admin &gt; Repositories</code>. Version and repository
              information for the HDP 2.2 Stack is shown in the following example:
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/Repo_versions_22_stack.png" width="50">
                
              
            </div>
          
        
        
          <h4 class="bold">Viewing Service Users and Groups</h4>
          
            <p>To view Service Accounts defined in your HDP cluster, choose<code>Admin &gt;
              Serrvice Accounts</code>. Default Service User and Group information for the HDP 2.2 Stack
              is shown in the following example:
            </p>
            <div class="figure">
              
                
                  <img src="01-RawContent/Ambari/Service_Accounts_22_Stack.png" width="50">
                
              
            </div>
          
        
        
          <h4 class="bold">Enabling Kerberos Security</h4>
          
            <p>Ambari supports the Kerberos protocol which allows nodes in your cluster to prove their
              identities, or authenticate, in a secure manner. To enable Kerberos security you must:
            </p>
            <ul class="number-list">
              
                <li>
                  <p>Set up Kerberos for your cluster. For more information on setting up Kerberos, see<a href="#ref-4a8722b7-505e-4aa1-9256-9fff03c0d000">Preparing Kerberos for Hadoop</a>.
                  </p>
                </li>
                <li>
                  <p>Choose
                    <code>Enable Security</code>
                    and follow the Enable Security Wizard.
                  </p>
                  <div class="figure">
                    
                      
                        <img src="01-RawContent/Ambari/newkerb_2x.png" width="80">
                      
                    
                  </div>
                </li>
              
            </ul>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-9200c433-12d8-4055-b458-ae8808920ff8">Monitoring and Alerts</h3>
        
          <p>Nagios is an open source network monitoring system designed to monitor all aspects of your Hadoop
            cluster (such as hosts, services, and so forth) over the network. It can monitor many facets of your
            installation, ranging from operating system attributes like CPU and memory usage to the status of
            applications, files, and more.
          </p>
          <p>Nagios is primarily used for the following kinds of tasks:</p>
          <ul class="bullet-list">
            
              <li>
                <p>Getting instant information about your organization's Hadoop infrastructure</p>
              </li>
              <li>
                <p>Detecting and repairing problems, and mitigating future issues, before they affect end-users
                  and customers
                </p>
              </li>
              <li>
                <p>Leveraging Nagios’ event monitoring capabilities to receive alerts for potential problem
                  areas
                </p>
              </li>
              <li>
                <p>Analyzing specific trends; for example: what is the CPU usage for a particular Hadoop service
                  weekdays between 2 p.m. and 5 p.m?
                </p>
              </li>
            
          </ul>
          <p>For more information, see the Nagios website at<a href="http://www.nagios.org">
            http://www.nagios.org</a>.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>Nagios is an optional component of Ambari. During cluster install you can choose to install and
                configure Nagios. When selected, out-of-the-box Ambari provides a set of Nagios plug-ins specially
                designed for monitoring important aspects of your Hadoop cluster, based on your Stack selection.
              </p>
            </div>
          </aside>
        
      
      
        <h3 class="horton-blue bold" id="ref-4a81c823-8559-4b90-9015-7fbf39b1b7a0">Basic Nagios Architecture</h3>
        
          <p>Using the open source monitoring system Nagios, Ambari gathers information on the status of both of
            the hosts and the services that run on them.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p><strong>Host and System Information</strong>: Ambari monitors basic host and system information
                  such as CPU utilization, disk I/O bandwidth and operations per second, average memory and swap space
                  utilization, and average network latency.
                </p>
              </li>
              <li>
                <p><strong>Service Information</strong>: Ambari monitors the health and performance status of each
                  service by presenting information generated by that service. Because services that run in master/slave
                  configurations (HDFS, MapReduce, and HBase) are fault tolerant in regard to service slaves, master
                  information is presented individually, whereas slave information is presented largely in aggregate.
                </p>
              </li>
              <li>
                <p><strong>Alert Information</strong>: Using Nagios with Hadoop-specific plug-ins and configurations,
                  Ambari Web can issue alerts based on service states defined on the following basic levels:
                </p>
                <ul class="Bullet">
                  
                    <li>
                      <p>OK</p>
                    </li>
                    <li>
                      <p>Warning</p>
                    </li>
                    <li>
                      <p>Critical</p>
                      <p>
                        The thresholds for these alerts can be tuned using configuration files, and new alerts can be
                        added. For more details on Nagios architecture, see the Nagios Overview at at<a href="http://www.nagios.org">http://www.nagios.org</a>.
                      </p>
                    </li>
                  
                </ul>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-621ddc71-a848-489c-9286-acf9f5caefcd">Installing Nagios</h3>
        
          <p>The Ambari Installation Wizard gives you the option of installing and configuring Nagios, including
            the out-of-the-box plug-ins for Hadoop-specific alerts. The Nagios server, Nagios plug-ins, and the
            web-based user interface are installed on the Nagios server host, as specified during the installation
            procedure.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-afd46a44-a34a-48bd-ae68-e12918c31f22">Configuration File Locations</h3>
        
          <p>All Hadoop-specific configurations are added to Nagios through files prefixed with “hadoop-“ located
            in the
            <code>/etc/nagios/objects</code>
            directory of the Nagios Server host. The default general Nagios configuration file,
            <code>nagios.cfg</code>
            (in<code>/etc/nagios</code>), is set up to pick up the new Hadoop specific configurations from
            this directory.
          </p>
          <p>
            Hadoop-specific plug-ins are stored in the Nagios plug-ins directory,<code>
            /usr/lib64/nagios/plug-ins/</code>.
          </p>
          <p>
            By default, the Nagios server runs as a user named “nagios” which is in a group also named “nagios”. The
            user and group can be customized during the Ambari Cluster Install (<code>Cluster Install
            Wizard &gt; Customize Services &gt; Misc</code>). After you install Nagios, use Ambari Web to
            start and stop the Nagios server.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-f203efa1-d112-4f5b-94a7-41a73fc7dad1">Configuring Nagios Alerts For Hadoop Services</h3>
        
          <p>For each alert, the out-of-the-box Hadoop Nagios configuration file defines default values for the
            following Nagios directives:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>Warning threshold</p>
                <p>
                  The value that produces a warning alert.
                </p>
              </li>
              <li>
                <p>Critical threshold</p>
                <p>
                  The value that produces a critical alert.
                </p>
              </li>
              <li>
                <p>Check interval</p>
                <p>
                  The number of minutes between regularly scheduled checks on the host, if the check does not change the
                  state.
                </p>
              </li>
              <li>
                <p>Retry interval</p>
                <p>
                  The number of minutes between “retries”, when a service changes state, Nagios can confirm that state
                  change by retrying the check multiple times. This retry interval can be different than the original
                  check interval.
                </p>
              </li>
              <li>
                <p>Maximum number of check attempts</p>
                <p>
                  The maximum number of retry attempts. Usually when the state of a service changes, this change is
                  considered “soft” until multiple retries confirm it. Once the state change is confirmed, it is
                  considered “hard”. Ambari Web displays hard states for all the Nagios Hadoop specific checks.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-7a990a51-50a7-4b82-99a4-4588403a91d9">Nagios Alerts For Hadoop Services</h3>
        
          <p>This topic provides more information about Hadoop alerts provided by Ambari. All these alerts are
            displayed in Ambari Web and in the native Nagios web interface.
          </p>
          <p>Ambari provides two types of alerts configured out-of-the-box:</p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <strong>Host-level Alerts</strong>
                </p>
                <p>
                  These alerts refer to a specific host and specific component running on that host. These alerts check
                  a component and system-level metrics to determine health of the host.
                </p>
              </li>
              <li>
                <p>
                  <strong>Service-level Alerts</strong>
                </p>
                <p>
                  These alerts refer to a Hadoop Service and do not refer to a specific host. These alerts check one or
                  more components of a service as well as system-level metrics to determine overall health of a Hadoop
                  Service.
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">HDFS Service Alerts</h4>
          
            <p>These alerts are used to monitor the HDFS service.</p>
          
          
            <h4 class="bold">Blocks health</h4>
            
              <p>This service-level alert is triggered if the number of corrupt or missing blocks exceeds the
                configured critical threshold. This alert uses the
                <code>check_hdfs_blocks</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Some DataNodes are down and the replicas that are missing blocks are only on those
                        DataNodes.
                      </p>
                    </li>
                    <li>
                      <p>The corrupt/missing blocks are from files with a replication factor of 1. New replicas
                        cannot be created because the only replica of the block is missing.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>For critical data, use a replication factor of 3.</p>
                    </li>
                    <li>
                      <p>Bring up the failed DataNodes with missing or corrupt blocks.</p>
                    </li>
                    <li>
                      <p>Identify the files associated with the missing or corrupt blocks by running the Hadoop
                        <code>fsck</code>
                        command.
                      </p>
                    </li>
                    <li>
                      <p>Delete the corrupt files and recover them from backup, if it exists.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">NameNode process</h4>
            
              <p>This host-level alert is triggered if the NameNode process cannot be confirmed to be up and
                listening on the network for the configured critical threshold, given in seconds. It uses the Nagios
                <code>check_tcp</code>
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The NameNode process is down on the HDFS master host.</p>
                    </li>
                    <li>
                      <p>The NameNode process is up and running but not listening on the correct network port.
                        The default port is 8201.
                      </p>
                    </li>
                    <li>
                      <p>The Nagios server cannot connect to the HDFS master through the network.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check for any errors in the logs, located at<code>
                        /var/log/hadoop/hdfs/</code>. Then restart the NameNode host/process using the
                        <code>HMC Manage Services</code>
                        tab.
                      </p>
                    </li>
                    <li>
                      <p>Run the
                        <code>netstat-tuplpn</code>
                        command to check if the NameNode process is bound to the correct network port.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios server and the NameNode.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">DataNode space</h4>
            
              <p>This host-level alert is triggered if storage capacity if full on the DataNode (90% critical).
                It uses the
                <code>check_datanode_storage.php</code>
                plug-in which checks the DataNode JMX Servlet for the
                <code>Capacity</code>
                and
                <code>Remaining</code>
                properties.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Cluster storage is full.</p>
                    </li>
                    <li>
                      <p>If cluster storage is not full, DataNode is full.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>If the cluster has available storage, use Balancer to distribute the data to relatively
                        less-used datanodes.
                      </p>
                    </li>
                    <li>
                      <p>If the cluster is full, delete unnecessary data or add additional storage by adding
                        either more DataNodes or more or larger disks to the DataNodes. After adding more storage run
                        Balancer.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">DataNode process</h4>
            
              <p>This host-level alert is triggered if the individual DataNode processes cannot be established to
                be up and listening on the network for the configured critical threshold, given in seconds. It uses the
                Nagios
                <code>check_tcp</code>
                plugin.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>DataNode process is down or not responding.</p>
                    </li>
                    <li>
                      <p>DataNode is not down, but is not listening to the correct network port/address.
                      </p>
                    </li>
                    <li>
                      <p>Nagios server cannot connect to the DataNodes.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check for dead DataNodes in Ambari Web.</p>
                    </li>
                    <li>
                      <p>Check for any errors in the DataNode logs, located at<code>
                        /var/log/hadoop/hdfs</code>. Then, restart the DataNode, if necessary.
                      </p>
                    </li>
                    <li>
                      <p>Run the
                        <code>netstat-tuplpn</code>
                        command to check if the DataNode process is bound to the correct network port.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios server and the DataNode.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">NameNode host CPU utilization</h4>
            
              <p>This host-level alert is triggered if CPU utilization of the NameNode exceeds certain thresholds
                (200% warning, 250% critical). It uses the
                <code>check_cpu.php</code>
                plug-in which checks the NameNode JMX Servlet for the
                <strong>SystemCPULoad</strong>
                property. This information is only available if you are running JDK 1.7.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Unusually high CPU utilization: Can be caused by a very unusual job/query workload; but
                        this is generally due to an issue in the daemon.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Use the
                        <code>top</code>
                        command to determine which processes are consuming excess CPU.
                      </p>
                    </li>
                    <li>
                      <p>Reset the offending process.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">NameNode edit logs directory status</h4>
            
              <p>This host-level alert is triggered if the NameNode cannot write to one of its configured edit
                log directories.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>At least one of the multiple edit log directories is mounted over NFS and has become
                        unreachable.
                      </p>
                    </li>
                    <li>
                      <p>The permissions on at least one of the multiple edit log directories is set to
                        Read-only.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check permissions on all edit log directories.</p>
                    </li>
                    <li>
                      <p>Use the
                        <code>dfs.name.dir</code>
                        parameter in the
                        <code>hdfs-site.xml</code>
                        file on the NameNode to identify the locations of all the edit log directories for the NameNode.
                        Check whether the NameNode can reach all those locations.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">NameNode Web UI</h4>
            
              <p>This host-level alert is triggered if the NameNode Web UI is unreachable.</p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The NameNode Web UI is unreachable from the Nagios Server.</p>
                    </li>
                    <li>
                      <p>The NameNode process is not running.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check whether the NameNode process is running.</p>
                    </li>
                    <li>
                      <p>Check whether the Nagios Server can ping the NameNode server.</p>
                    </li>
                    <li>
                      <p>Using a browser, check whether the Nagios Server can reach the NameNode Web UI.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">Percent DataNodes with space available</h4>
            
              <p>This service-level alert is triggered if the storage if full on a certain percentage of
                DataNodes (10% warn, 30% critical). It uses the
                <code>check_aggregate.php</code>
                plug-in which aggregates the result from the
                <code>check_datanode_storage.php</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Cluster storage is full.</p>
                    </li>
                    <li>
                      <p>If cluster storage is not full, DataNode is full.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>If cluster still has storage, use Balancer to distribute the data to relatively
                        less-used DataNodes.
                      </p>
                    </li>
                    <li>
                      <p>If the cluster is full, delete unnecessary data or add additional storage by adding
                        either more DataNodes or more or larger disks to the DataNodes. After adding more storage run
                        Balancer.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">Percent DataNodes live</h4>
            
              <p>This alert is triggered if the number of down DataNodes in the cluster is greater than the
                configured critical threshold. It uses the
                <code>check_aggregate</code>
                plug-in to aggregate the results of
                <code>Data node process</code>
                checks.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>DataNodes are down.</p>
                    </li>
                    <li>
                      <p>DataNodes are not down but are not listening to the correct network port/address.
                      </p>
                    </li>
                    <li>
                      <p>Nagios server cannot connect to one or more DataNodes.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check for dead DataNodes in Ambari Web.</p>
                    </li>
                    <li>
                      <p>Check for any errors in the DataNode logs, located at<code>
                        /var/log/hadoop/hdfs</code>. Then, restart the DataNode hosts/processes.
                      </p>
                    </li>
                    <li>
                      <p>Run the
                        <code>netstat-tuplpn</code>
                        command to check if the DataNode process is bound to the correct network port.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios server and the DataNodes.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">NameNode RPC latency</h4>
            
              <p>This host-level alert is triggered if the NameNode operations RPC latency exceeds the configured
                critical threshold. Typically an increase in the RPC processing time increases the RPC queue length,
                causing the average queue wait time to increase for NameNode operations. It uses the Nagios
                <code>check_rpcq_latency</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>A job or an application is performing too many NameNode operations.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Review the job or the application for potential bugs causing it to perform too many
                        NameNode operations.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">HDFS capacity utilization</h4>
            
              <p>This service-level alert is triggered if the HDFS capacity utilization exceeds the configured
                critical threshold (80% warn, 90% critical). It uses the
                <code>check_hdfs_capacity.php</code>
                plug-in which checks the
                <code>NameNode JMX Servlet</code>
                for the
                <code>CapacityUsed</code>
                and
                <code>CapacityRemaining</code>
                properties.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Cluster storage is full.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Delete unnecessary data.</p>
                    </li>
                    <li>
                      <p>Archive unused data.</p>
                    </li>
                    <li>
                      <p>Add more DataNodes.</p>
                    </li>
                    <li>
                      <p>Add more or larger disks to the DataNodes.</p>
                    </li>
                    <li>
                      <p>After adding more storage, run Balancer.</p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">NameNode HA Alerts (Hadoop 2 only)</h4>
          
            <p>These alerts are available only when you are using Hadoop 2.x and you have enabled NameNode HA.
            </p>
          
          
            <h4 class="bold">JournalNode process</h4>
            
              <p>This host-level alert is triggered if the individual JournalNode process cannot be established
                to be up and listening on the network for the configured critical threshold, given in seconds. It uses
                the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The JournalNode process is down or not responding.</p>
                    </li>
                    <li>
                      <p>The JournalNode is not down, but is not listening to the correct network port/address.
                      </p>
                    </li>
                    <li>
                      <p>The Nagios server cannot connect to the JournalNode.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check if the JournalNode process is dead.</p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios server and the JournalNode host.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">NameNode HA Healthy process</h4>
            
              <p>This service-level alert is triggered if either the Active NameNode or Standby NameNode are not
                running.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The Active, Standby or both NameNode processes are down.</p>
                    </li>
                    <li>
                      <p>The Nagios Server cannot connect to one or both NameNode hosts.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>On each host running NameNode, check for any errors in the logs, located at<code>
                        /var/log/hadoop/hdfs/</code>. Then, restart the NameNode host/process using Ambari Web.
                      </p>
                    </li>
                    <li>
                      <p>On each host running NameNode, run the
                        <code>netstat-tuplpn</code>
                        command to check if the NameNode process is bound to the correct network port.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios server and the hosts running NameNode.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">YARN Alerts (Hadoop 2 only)</h4>
          
            <p>
              These alerts are used to monitor YARN.
            </p>
          
          
            <h4 class="bold">ResourceManager process</h4>
            
              <p>This host-level alert is triggered if the individual ResourceManager process cannot be
                established to be up and listening on the network for the configured critical threshold, given in
                seconds. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The ResourceManager process is down or not responding.</p>
                    </li>
                    <li>
                      <p>The ResourceManager is not down, but is not listening to the correct network
                        port/address.
                      </p>
                    </li>
                    <li>
                      <p>Nagios Server cannot connect to the ResourceManager.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check for a dead ResourceManager.</p>
                    </li>
                    <li>
                      <p>Check for any errors in the ResourceManager logs, located at<code>
                        /var/log/hadoop/yarn</code>. Then, restart the ResourceManager, if necessary.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios Server and the ResourceManager host.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">Percent NodeManagers live</h4>
            
              <p>This alert is triggered if the number of down NodeManagers in the cluster is greater than the
                configured critical threshold. It uses the
                <code>check_aggregate</code>
                plug-in to aggregate the results of DataNode process alert checks.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>NodeManagers are down.</p>
                    </li>
                    <li>
                      <p>NodeManagers are not down but are not listening to the correct network port/address.
                      </p>
                    </li>
                    <li>
                      <p>Nagios server cannot connect to one or more NodeManagers.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check for dead NodeManagers.</p>
                    </li>
                    <li>
                      <p>Check for any errors in the NodeManager logs, located at<code>
                        /var/log/hadoop/yarn</code>. Then, restart the NodeManagers hosts/processes, as necessary.
                      </p>
                    </li>
                    <li>
                      <p>Run the
                        <code>netstat-tuplpn</code>
                        command to check if the NodeManager process is bound to the correct network port.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios Server and the NodeManagers host.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">ResourceManager Web UI</h4>
            
              <p>This host-level alert is triggered if the ResourceManager Web UI is unreachable.</p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The ResourceManager Web UI is unreachable from the Nagios Server.</p>
                    </li>
                    <li>
                      <p>The ResourceManager process is not running.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check if the ResourceManager process is running.</p>
                    </li>
                    <li>
                      <p>Check whether the Nagios Server can ping the ResourceManager server.</p>
                    </li>
                    <li>
                      <p>Using a browser, check whether the Nagios Server can reach the ResourceManager Web UI.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">ResourceManager RPC latency</h4>
            
              <p>This host-level alert is triggered if the ResourceManager operations RPC latency exceeds the
                configured critical threshold. Typically an increase in the RPC processing time increases the RPC queue
                length, causing the average queue wait time to increase for ResourceManager operations. It uses the
                Nagios
                <code>check_rpcq_latency</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>A job or an application is performing too many ResourceManager operations.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Review the job or the application for potential bugs causing it to perform too many
                        ResourceManager operations.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">ResourceManager CPU utilization</h4>
            
              <p>This host-level alert is triggered if CPU utilization of the ResourceManager exceeds certain
                thresholds (200% warning, 250% critical). It uses the
                <code>check_cpu.php</code>
                plug-in which checks the ResourceManager JMX Servlet for the
                <code>SystemCPULoad</code>
                property. This information is only available if you are running JDK 1.7.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Unusually high CPU utilization: Can be caused by a very unusual job/query workload, but
                        this is generally the sign of an issue in the daemon.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Use the
                        <code>top</code>
                        command to determine which processes are consuming excess CPU.
                      </p>
                    </li>
                    <li>
                      <p>Reset the offending process.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">NodeManager process</h4>
            
              <p>This host-level alert is triggered if the NodeManager process cannot be established to be up and
                listening on the network for the configured critical threshold, given in seconds. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>NodeManager process is down or not responding.</p>
                    </li>
                    <li>
                      <p>NodeManager is not down but is not listening to the correct network port/address.
                      </p>
                    </li>
                    <li>
                      <p>Nagios Server cannot connect to the NodeManager</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check if the NodeManager is running.</p>
                    </li>
                    <li>
                      <p>Check for any errors in the NodeManager logs (<code>
                        /var/log/hadoop/yarn</code>) and restart the NodeManager, if necessary.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios Server and the NodeManager host.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">NodeManager health</h4>
            
              <p>This host-level alert checks the node health property available from the NodeManager
                component.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Node Health Check script reports issues or is not configured.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check in the NodeManager logs (<code>/var/log/hadoop/yarn</code>) for health
                        check errors and restart the NodeManager, and restart if necessary.
                      </p>
                    </li>
                    <li>
                      <p>Check in the ResourceManager UI logs (<code>/var/log/hadoop/yarn</code>) for
                        health check errors.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">MapReduce2 Alerts (Hadoop 2 only)</h4>
          
            <p>These alerts are used to monitor MR2.</p>
          
          
            <h4 class="bold">HistoryServer Web UI</h4>
            
              <p>This host-level alert is triggered if the HistoryServer Web UI is unreachable.</p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The HistoryServer Web UI is unreachable from the Nagios Server.</p>
                    </li>
                    <li>
                      <p>The HistoryServer process is not running.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check if the HistoryServer process is running.</p>
                    </li>
                    <li>
                      <p>Check whether the Nagios Server can ping the HistoryServer server.</p>
                    </li>
                    <li>
                      <p>Using a browser, check whether the Nagios Server can reach the HistoryServer Web UI.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">HistoryServer RPC latency</h4>
            
              <p>This host-level alert is triggered if the HistoryServer operations RPC latency exceeds the
                configured critical threshold. Typically an increase in the RPC processing time increases the RPC queue
                length, causing the average queue wait time to increase for NameNode operations. It uses the Nagios
                <code>check_rpcq_latency</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>A job or an application is performing too many HistoryServer operations.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Review the job or the application for potential bugs causing it to perform too many
                        HistoryServer operations.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">HistoryServer CPU utilization</h4>
            
              <p>This host-level alert is triggered if the percent of CPU utilization on the HistoryServer
                exceeds the configured critical threshold. This alert uses the Nagios
                <code>check_snmp_load</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Unusually high CPU utilization: Can be caused by a very unusual job/query workload, but
                        this is generally the sign of an issue in the daemon.
                      </p>
                    </li>
                    <li>
                      <p>A down SNMP daemon on the HistoryServer node, producing an unknown status.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Use the
                        <code>top</code>
                        command to determine which processes are consuming excess CPU.
                      </p>
                    </li>
                    <li>
                      <p>Reset the offending process.</p>
                    </li>
                    <li>
                      <p>Check the status of the SNMP daemon.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">HistoryServer process</h4>
            
              <p>This host-level alert is triggered if the HistoryServer process cannot be established to be up
                and listening on the network for the configured critical threshold, given in seconds. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>HistoryServer process is down or not responding.</p>
                    </li>
                    <li>
                      <p>HistoryServer is not down but is not listening to the correct network port/address.
                      </p>
                    </li>
                    <li>
                      <p>Nagios Server cannot connect to the HistoryServer.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check the HistoryServer is running.</p>
                    </li>
                    <li>
                      <p>Check for any errors in the HistoryServer logs, located at<code>
                        /var/log/hadoop/mapred.</code>Then, restart the HistoryServer, if necessary.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios Server and the HistoryServer host.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">MapReduce Service Alerts (Hadoop 1 only)</h4>
          
            <p>These alerts are used to monitor the MapReduce service.</p>
          
          
            <h4 class="bold">JobTracker RPC latency alert</h4>
            
              <p>This host-level alert is triggered if the JobTracker operations RPC latency exceeds the
                configured critical threshold. Typically an increase in the RPC processing time increases the RPC queue
                length, causing the average queue wait time to increase for JobTracker operations. This alert uses the
                Nagios
                <code>check_rpcq_latency</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>A job or an application is performing too many JobTracker operations.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Review the job or the application for potential bugs causing it to perform too many
                        JobTracker operations.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">JobTracker process</h4>
            
              <p>This host-level alert is triggered if the individual JobTracker process cannot be confirmed to
                be up and listening on the network for the configured critical threshold, given in seconds. It uses the
                Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>JobTracker process is down or not responding.</p>
                    </li>
                    <li>
                      <p>JobTracker is not down but is not listening to the correct network port/address.
                      </p>
                    </li>
                    <li>
                      <p>The Nagios server cannot connect to the JobTracker</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check if the JobTracker process is running.</p>
                    </li>
                    <li>
                      <p>Check for any errors in the JobTracker logs, located at<code>
                        /var/log/hadoop/mapred</code>. Then, restart the JobTracker, if necessary
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios Server and the JobTracker host.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">JobTracker Web UI</h4>
            
              <p>This Host-level alert is triggered if the JobTracker Web UI is unreachable.</p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The JobTracker Web UI is unreachable from the Nagios Server.</p>
                    </li>
                    <li>
                      <p>The JobTracker process is not running.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check if the JobTracker process is running.</p>
                    </li>
                    <li>
                      <p>Check whether the Nagios Server can ping the JobTracker server.</p>
                    </li>
                    <li>
                      <p>Using a browser, check whether the Nagios Server can reach the JobTracker Web UI.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">JobTracker CPU utilization</h4>
            
              <p>This host-level alert is triggered if CPU utilization of the JobTracker exceeds certain
                thresholds (200% warning, 250% critical). It uses the
                <code>check_cpu.php</code>
                plug-in which checks the JobTracker JMX Servlet for the
                <code>SystemCPULoad</code>
                property. This information is only available if you are running JDK 1.7.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Unusually high CPU utilization: Can be caused by a very unusual job/query workload, but
                        this is generally the sign of an issue in the daemon.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Use the
                        <code>top</code>
                        command to determine which processes are consuming excess CPU.
                      </p>
                    </li>
                    <li>
                      <p>Reset the offending processor.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">HistoryServer Web UI</h4>
            
              <p>This host-level alert is triggered if the HistoryServer Web UI is unreachable.</p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The HistoryServer Web UI is unreachable from the Nagios Server.</p>
                    </li>
                    <li>
                      <p>The HistoryServer process is not running.</p>
                    </li>
                    <li>
                      <p>Using a browser, check whether the Nagios Server can reach the HistoryServer Web UI.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check the HistoryServer process is running.</p>
                    </li>
                    <li>
                      <p>Check whether the Nagios Server can ping the HistoryServer server.</p>
                    </li>
                    <li>
                      <p>Check the status of the SNMP daemon.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">HistoryServer process</h4>
            
              <p>This host-level alert is triggered if the HistoryServer process cannot be established to be up
                and listening on the network for the configured critical threshold, given in seconds. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The HistoryServer process is down or not responding.</p>
                    </li>
                    <li>
                      <p>The HistoryServer is not down but is not listening to the correct network
                        port/address.
                      </p>
                    </li>
                    <li>
                      <p>The Nagios Server cannot connect to the HistoryServer.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check for any errors in the HistoryServer logs located at<code>
                        /var/log/hadoop/mapred</code>. Then, restart the HistoryServer, if necessary.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios Server and the HistoryServer host.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">HBase Service Alerts</h4>
          
            <p>These alerts are used to monitor the HBase service.</p>
          
          
            <h4 class="bold">Percent RegionServers live</h4>
            
              <p>This service-level alert is triggered if the configured percentage of Region Server processes
                cannot be determined to be up and listening on the network for the configured critical threshold. The
                default setting is 10% to produce a WARN alert and 30% to produce a CRITICAL alert. It uses the
                <code>check_aggregate</code>
                plug-in to aggregate the results of
                <code>RegionServer process down</code>
                checks.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Misconfiguration or less-than-ideal configuration caused the RegionServers to crash.
                      </p>
                    </li>
                    <li>
                      <p>Cascading failures brought on by some workload caused the RegionServers to crash.
                      </p>
                    </li>
                    <li>
                      <p>The RegionServers shut themselves down because there were problems in the dependent
                        services, ZooKeeper, or HDFS.
                      </p>
                    </li>
                    <li>
                      <p>GC paused the RegionServer for too long and the RegionServers lost contact with
                        ZooKeeper.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check the dependent services to make sure they are operating correctly.</p>
                    </li>
                    <li>
                      <p>Look at the RegionServer log files, usually located at
                        <code>/var/log/hbase/*.log</code>
                        for further information.
                      </p>
                    </li>
                    <li>
                      <p>Look at the configuration files located at
                        <code>/etc/hbase/conf.</code>
                      </p>
                    </li>
                    <li>
                      <p>If the failure was associated with a particular workload, try to better understand the
                        workload.
                      </p>
                    </li>
                    <li>
                      <p>Restart the RegionServers.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">HBase Master process</h4>
            
              <p>This alert is triggered if the HBase master processes cannot be confirmed to be up and listening
                on the network for the configured critical threshold, given in seconds. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The HBase master process is down.</p>
                    </li>
                    <li>
                      <p>The HBase master has shut itself down because there were problems in the dependent
                        services, ZooKeeper, or HDFS.
                      </p>
                    </li>
                    <li>
                      <p>The Nagios server cannot connect to the HBase master through the network.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check the dependent services.</p>
                    </li>
                    <li>
                      <p>Look at the master log files, usually located at
                        <code>/var/log/hbase/*.log,</code>
                        for further information.
                      </p>
                    </li>
                    <li>
                      <p>Look at the configuration files in
                        <code>/etc/hbase/conf.</code>
                      </p>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios server and the HBase master.
                      </p>
                    </li>
                    <li>
                      <p>Restart the master.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">HBase Master Web UI</h4>
            
              <p>This host-level alert is triggered if the HBase Master Web UI is unreachable.</p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The HBase Master Web UI is unreachable from the Nagios Server.</p>
                    </li>
                    <li>
                      <p>The HBase Master process is not running.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check if the Master process is running.</p>
                    </li>
                    <li>
                      <p>Check whether the Nagios Server can ping the HBase Master server.</p>
                    </li>
                    <li>
                      <p>Using a browser, check whether the Nagios Server can reach the HBase Master Web UI.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">HBase Master CPU utilization</h4>
            
              <p>This host-level alert is triggered if CPU utilization of the HBase Master exceeds certain
                thresholds (200% warning, 250% critical). It uses the
                <code>check_cpu.php</code>
                plug-in which checks the HBase Master JMX Servlet for the
                <code>SystemCPULoad</code>
                property. This information is only available if you are running JDK 1.7.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Unusually high CPU utilization. Can be caused by a very unusual job/query workload, but
                        this is generally the sign of an issue in the daemon.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Use the
                        <code>top</code>
                        command to determine which processes are consuming excess CPU.
                      </p>
                    </li>
                    <li>
                      <p>Reset the offending process.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">RegionServer process</h4>
            
              <p>This host-level alert is triggered if the RegionServer processes cannot be confirmed to be up
                and listening on the network for the configured critical threshold, given in seconds. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The RegionServer process is down on the host.</p>
                    </li>
                    <li>
                      <p>The RegionServer process is up and running but not listening on the correct network port
                        (default 60030).
                      </p>
                    </li>
                    <li>
                      <p>The Nagios server cannot connect to the RegionServer through the network.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check for any errors in the logs, located at<code>/var/log/hbase/</code>.
                        Then, restart the RegionServer process using Ambari Web.
                      </p>
                    </li>
                    <li>
                      <p>Run the
                        <code>netstat-tuplpn</code>
                        command to check if the RegionServer process is bound to the correct network port.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the NagiosServer and the RegionServer.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">Hive Alerts</h4>
          
            <p>These alerts are used to monitor the Hive service.</p>
          
          
            <h4 class="bold">Hive-Metastore status</h4>
            
              <p>This host-level alert is triggered if the Hive Metastore process cannot be determined to be up
                and listening on the network for the configured critical threshold, given in seconds. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The Hive Metastore service is down.</p>
                    </li>
                    <li>
                      <p>The database used by the Hive Metastore is down.</p>
                    </li>
                    <li>
                      <p>The Hive Metastore host is not reachable over the network.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Using<strong>Ambari Web</strong>, stop the Hive service and then restart it.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios server and the Hive Metastore server.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">WebHCat Alerts</h4>
          
            <p>These alerts are used to monitor the WebHCat service.</p>
          
          
            <h4 class="bold">WebHCat Server status</h4>
            
              <p>This host-level alert is triggered if the WebHCat server cannot be determined to be up and
                responding to client requests.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The WebHCat server is down.</p>
                    </li>
                    <li>
                      <p>The WebHCat server is hung and not responding.</p>
                    </li>
                    <li>
                      <p>The WebHCat server is not reachable over the network.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Restart the WebHCat server using Ambari Web.</p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">Oozie Alerts</h4>
          
            <p>These alerts are used to monitor the Oozie service.</p>
          
          
            <h4 class="bold">Oozie status</h4>
            
              <p>This host-level alert is triggered if the Oozie server cannot be determined to be up and
                responding to client requests.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The Oozie server is down.</p>
                    </li>
                    <li>
                      <p>The Oozie server is hung and not responding.</p>
                    </li>
                    <li>
                      <p>The Oozie server is not reachable over the network.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Restart the Oozie service using Ambari Web.</p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">Ganglia Alerts</h4>
          
            <p>These alerts are used to monitor the Ganglia service.</p>
          
          
            <h4 class="bold">Ganglia Server status</h4>
            
              <p>This host-level alert determines if the Ganglia server is running and listening on the network
                port. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The Ganglia server process is down.</p>
                    </li>
                    <li>
                      <p>The Ganglia server process is hung and not responding.</p>
                    </li>
                    <li>
                      <p>The network connection between the Nagios and Ganglia servers is down.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check the Ganglia server,
                        <code>gmetad</code>
                        related log, located at
                        <code>/var/log/messages</code>
                        for any errors.
                      </p>
                    </li>
                    <li>
                      <p>Restart the Ganglia server.</p>
                    </li>
                    <li>
                      <p>Check if
                        <code>ping</code>
                        works between Nagios and Ganglia servers.
                      </p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">Ganglia Monitor process</h4>
            
              <p>These host-level alerts check if the Ganglia monitor daemons,
                <code>gmond,</code>
                on the Ganglia server are running and listening on the network port. This alert uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
              <p>Ganglia Monitoring daemons run for the following collections:</p>
              <ul class="bullet-list">
                
                  <li>
                    <p>Slaves</p>
                  </li>
                  <li>
                    <p>NameNode</p>
                  </li>
                  <li>
                    <p>HBase Master</p>
                  </li>
                  <li>
                    <p>JobTracker (Hadoop 1 only)</p>
                  </li>
                  <li>
                    <p>ResourceManager (Hadoop 2 only)</p>
                  </li>
                  <li>
                    <p>HistoryServer (Hadoop 2 only)</p>
                  </li>
                
              </ul>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>A
                        <code>gmond</code>
                        process is down.
                      </p>
                    </li>
                    <li>
                      <p>A
                        <code>gmond</code>
                        process is hung and not responding.
                      </p>
                    </li>
                    <li>
                      <p>The network connection is down between the Nagios and Ganglia servers.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check the
                        <code>gmond</code>
                        related log, located at
                        <code>/var/log/messages</code>
                        for any errors.
                      </p>
                    </li>
                    <li>
                      <p>Check if
                        <code>ping</code>
                        works between Nagios and Ganglia servers.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">Nagios Alerts</h4>
          
            <p>These alerts are used to monitor the Nagios service.</p>
          
          
            <h4 class="bold">Nagios status log freshness</h4>
            
              <p>This host-level alert determines if the Nagios server is updating its status log regularly.
                Ambari depends on the status log located at
                <code>/var/nagios/status.dat</code>
                to receive all the Nagios alerts.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The Nagios server is hanging and therefore not scheduling new alerts.</p>
                    </li>
                    <li>
                      <p>The file
                        <code>/var/nagios/status.dat</code>
                        does not have appropriate write permissions for the Nagios user.
                      </p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Restart the Nagios server.</p>
                    </li>
                    <li>
                      <p>Check the permissions on<code>/var/nagios/status.dat</code>.
                      </p>
                    </li>
                    <li>
                      <p>Check
                        <code>/var/log/messages</code>
                        for any related errors.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">ZooKeeper Alerts</h4>
          
            <p>These alerts are used to monitor the Zookeeper service.</p>
          
          
            <h4 class="bold">Percent ZooKeeper servers live</h4>
            
              <p>This service-level alert is triggered if the configured percentage of ZooKeeper processes cannot
                be determined to be up and listening on the network for the configured critical threshold, given in
                seconds. It uses the
                <code>check_aggregate</code>
                plug-in to aggregate the results of
                <code>Zookeeper process</code>
                checks.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The majority of your ZooKeeper servers are down and not responding.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check the dependent services to make sure they are operating correctly.</p>
                    </li>
                    <li>
                      <p>Check the ZooKeeper log files located at
                        <code>/var/log/hadoop/zookeeper.log</code>
                        for further information.
                      </p>
                    </li>
                    <li>
                      <p>If the failure was associated with a particular workload, try to better understand the
                        workload.
                      </p>
                    </li>
                    <li>
                      <p>Restart the ZooKeeper servers, using Ambari Web.</p>
                    </li>
                  
                </ul>
              
            
          
          
            <h4 class="bold">Zookeeper Server process</h4>
            
              <p>This host-level alert is triggered if the ZooKeeper server process cannot be determined to be up
                and listening on the network for the configured critical threshold, given in seconds. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The ZooKeeper server process is down on the host.</p>
                    </li>
                    <li>
                      <p>The ZooKeeper server process is up and running but not listening on the correct network
                        port (default 2181).
                      </p>
                    </li>
                    <li>
                      <p>The Nagios server cannot connect to the ZooKeeper server through the network.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check for any errors in the ZooKeeper logs located at<code>
                        /var/log/hbase/</code>. Then, restart the ZooKeeper process using Ambari Web.
                      </p>
                    </li>
                    <li>
                      <p>Run the
                        <code>netstat-tuplpn</code>
                        command to check if the ZooKeeper server process is bound to the correct network port.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Nagios server and the ZooKeeper server.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
        
          <h4 class="bold">Ambari Alerts</h4>
          
            <p>This alert is used to monitor the Ambari Agent service.</p>
          
          
            <h4 class="bold">Ambari Agent process</h4>
            
              <p>This host-level alert is triggered if the Ambari Agent process cannot be confirmed to be up and
                listening on the network for the configured critical threshold, given in seconds. It uses the Nagios
                <code>check_tcp</code>
                plug-in.
              </p>
            
            
              <h4 class="bold">Potential causes</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>The Ambari Agent process is down on the host.</p>
                    </li>
                    <li>
                      <p>The Ambari Agent process is up and running but heartbeating to the Ambari Server.
                      </p>
                    </li>
                    <li>
                      <p>The Ambari Agent process is up and running but is unreachable through the network from
                        the Nagios Server.
                      </p>
                    </li>
                    <li>
                      <p>The Ambari Agent cannot connect to the Ambari Server through the network.</p>
                    </li>
                  
                </ul>
              
            
            
              <h4 class="bold">Possible remedies</h4>
              
                <ul class="bullet-list">
                  
                    <li>
                      <p>Check for any errors in the logs located at<code>
                        /var/log/ambari-agent/ambari-agent.log</code>. Then, restart the Ambari Agent process.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>ping</code>
                        to check the network connection between the Ambari Agent host and the Ambari Servers.
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
      
    
    
      <h2 class="horton-green bold">Installing HDP Using Ambari</h2>
      
        
          <p>This section describes the information and materials you should get ready to install a HDP cluster
            using Ambari. Ambari provides an end-to-end management and monitoring solution for your HDP cluster. Using
            the Ambari Web UI and REST APIs, you can deploy, operate, manage configuration changes, and monitor services
            for all nodes in your cluster from a central point.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-06bea357-b482-4449-ba95-0744384f3146">Determine Stack Compatibility</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-847d0ef5-fa6e-4e75-bdb5-a4ec20141189">Meet Minimum System Requirements</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-50c9d54d-6862-497c-9e26-bdb3be3180e1">Collect Information</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-b5f4ad84-c530-47b5-a963-ef871697c278">Prepare the Environment</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-28d7e1f2-0adb-436a-a4b1-65b522fdcdf2">Optional: Configure Local Repositories
                    for Ambari
                  </a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-06bea357-b482-4449-ba95-0744384f3146">Determine Stack Compatibility</h3>
        
          <p>Use this table to determine whether your Ambari and HDP stack versions are compatible.</p>
          <div class="xyleme-table"><table border="1">
            
              
              
              
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>Ambari</p>
                  </th>
                  <th rowspan="1">
                    <p>HDP 2.2
                      <a href="#footnote-1" class="footnote-anchor">[1]</a>
                    </p>
                  </th>
                  <th rowspan="1">
                    <p>HDP 2.1
                      <a href="#footnote-2" class="footnote-anchor">[2]</a>
                    </p>
                  </th>
                  <th rowspan="1">
                    <p>HDP 2.0
                      <a href="#footnote-3" class="footnote-anchor">[3]</a>
                    </p>
                  </th>
                  <th rowspan="1">
                    <p>HDP1.3</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>1.7.0</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.6.1</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.6.0</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.5.1</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.5.0</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.4.4.23</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.4.3.38</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.4.2.104</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.4.1.61</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.4.1.25</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>1.2.5.17</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>x</p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
          <p>For more information about Installing Accumulo, Hue, Knox, Ranger, and Solr services, see<a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.0/HDP_Man_Install_v22/index.html#Item1.1">
            Installing HDP Manually</a>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-847d0ef5-fa6e-4e75-bdb5-a4ec20141189">Meet Minimum System Requirements</h3>
        
          <p>To run Hadoop, your system must meet the following minimum requirements:</p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-27a5555d-a678-4ecf-a524-b4d31230c087">Hardware Recommendations</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-5f6ff954-2e7e-4900-b94b-b4728f977ebe">Operating S</a>
                  <a href="#ref-5f6ff954-2e7e-4900-b94b-b4728f977ebe">ystems Requirements</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-0e5f4540-a5d4-4802-8104-84388d0addc3">Browser Requirements</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-2552631c-22d0-42d6-963f-c9453a62e537">Software Requirements</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-c81d7e9a-dc5d-4ab4-a12c-34428c1f13dc">JDK Requirements</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-f35b0203-6267-4533-9e88-652452ece5f5">Database Requirements</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-e00c3b09-113c-4972-ad44-b1d221c11d6b">Recommended Maximum Open File
                    Descriptors
                  </a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Hardware Recommendations</h4>
          
            <p>There is no single hardware requirement set for installing Hadoop.</p>
            <p>For more information about hardware components that may affect your installation, see<a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.0/Cluster_Plan_Gd_v22/index.html#Item1.8">
              Hardware Recommendations For Apache Hadoop</a>.
            </p>
          
        
        
          <h4 class="bold">Operating Systems Requirements</h4>
          
            <p>The following, 64-bit operating systems are supported:</p>
            <ul class="bullet-list">
              
                <li>
                  <p>Red Hat Enterprise Linux (RHEL) v6.x</p>
                </li>
                <li>
                  <p>Red Hat Enterprise Linux (RHEL) v5.x (deprecated)</p>
                </li>
                <li>
                  <p>CentOS v6.x</p>
                </li>
                <li>
                  <p>CentOS v5.x (deprecated)</p>
                </li>
                <li>
                  <p>Oracle Linux v6.x</p>
                </li>
                <li>
                  <p>Oracle Linux v5.x (deprecated)</p>
                </li>
                <li>
                  <p>SUSE Linux Enterprise Server (SLES) v11, SP1 and SP3</p>
                </li>
                <li>
                  <p>Ubuntu Precise v12.04</p>
                </li>
              
            </ul>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>If you plan to install HDP Stack on SLES 11 SP3, be sure to refer to Configuring Repositories
                  in the HDP documentation for the HDP repositories specific for SLES 11 SP3. Or, if you plan to perform
                  a Local Repository install, be sure to use the SLES 11 SP3 repositories.
                </p>
              </div>
            </aside>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Important.png" width="50"></div>
              <div class="simple-block">
                <p>The installer pulls many packages from the base OS repositories. If you do not have a complete
                  set of base OS repositories available to all your machines at the time of installation you may run
                  into issues.
                </p>
                <p>If you encounter problems with base OS repositories being unavailable, please contact your
                  system administrator to arrange for these additional repositories to be proxied or mirrored. For more
                  information see<a href="#ref-28d7e1f2-0adb-436a-a4b1-65b522fdcdf2">Optional: Configure the
                    Local Repositories</a>.
                </p>
              </div>
            </aside>
          
        
        
          <h4 class="bold">Browser Requirements</h4>
          
            <p>The Ambari Install Wizard runs as a browser-based Web application. You must have a machine capable
              of running a graphical browser to use this tool.
              The minimum required browser versions are:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>Windows (Vista, 7)</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Internet Explorer 9.0</p>
                      </li>
                      <li>
                        <p>Firefox 18</p>
                      </li>
                      <li>
                        <p>Google Chrome 26</p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Mac OS X (10.6 or later)</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Firefox 18</p>
                      </li>
                      <li>
                        <p>Safari 5</p>
                      </li>
                      <li>
                        <p>Google Chrome 26</p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Linux (RHEL, CentOS, SLES, Oracle Linux, UBUNTU)</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Firefox 18</p>
                      </li>
                      <li>
                        <p>Google Chrome 26</p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
            <p>On any platform, we recommend updating your browser to the latest, stable version.</p>
          
        
        
          <h4 class="bold">Software Requirements</h4>
          
            <p>On each of your hosts:</p>
            <ul class="bullet-list">
              
                <li>
                  <p>yum and rpm (RHEL/CentOS/Oracle Linux)</p>
                </li>
                <li>
                  <p>zypper and php_curl (SLES)</p>
                </li>
                <li>
                  <p>apt (Ubuntu)</p>
                </li>
                <li>
                  <p>scp, curl, unzip, tar, and wget</p>
                </li>
                <li>
                  <p>OpenSSL (v1.01, build 16 or later)</p>
                </li>
                <li>
                  <p>python (v2.6 or later)</p>
                </li>
              
            </ul>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Important.png" width="50"></div>
              <div class="simple-block">
                <p>The Python version shipped with SUSE 11, 2.6.0-8.12.2, has a critical bug that may cause the
                  Ambari Agent to fail within the first 24 hours. If you are installing on SUSE 11, please update all
                  your hosts to Python version 2.6.8-0.15.1.
                </p>
              </div>
            </aside>
          
        
        
          <h4 class="bold">JDK Requirements</h4>
          
            <p>The following Java runtime environments are supported:</p>
            <ul class="bullet-list">
              
                <li>
                  <p>Oracle JDK 1.7_67 64-bit (default)</p>
                </li>
                <li>
                  <p>Oracle JDK 1.6_31 64-bit (DEPRECATED)</p>
                </li>
                <li>
                  <p>OpenJDK 7 64-bit (not supported on SLES)
                    To install OpenJDK 7 for RHEL, run the following command on all hosts:
                  </p>
                  <p>
                    <code>yum install java-1.7.0-openjdk</code>
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Database Requirements</h4>
          
            <p>Ambari requires a relational database to store information about the cluster configuration and
              topology. If you install HDP Stack with Hive or Oozie, they also require a relational database. The
              following table outlines these database requirements:
            </p>
            <div class="xyleme-table"><table border="1">
              
                
                
                <thead></thead>
                <tbody>
                  <tr>
                    <th rowspan="1">
                      <p>Component</p>
                    </th>
                    <th rowspan="1">
                      <p>Description</p>
                    </th>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ambari</p>
                    </td>
                    <td rowspan="1">
                      <p>By default, will install an instance of PostgreSQL on the Ambari Server host.
                        Optionally, to use an existing instance of PostgreSQL, MySQL or Oracle. For further information,
                        see<a href="#ref-6db1b3ae-7e80-4a7c-a73d-20f11379078f">Using Non-Default Databases for
                          Ambari</a>.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Hive</p>
                    </td>
                    <td rowspan="1">
                      <p>By default (on RHEL/CentOS/Oracle Linux 6), Ambari will install an instance of MySQL on
                        the Hive Metastore host. Otherwise, you need to use an existing instance of PostgreSQL, MySQL or
                        Oracle. See
                        <a href="#ref-5010f1c4-fc32-44cd-94f5-fe557eefcd6d">Using Non-Default Databases for
                          Hive
                        </a>
                        for more information.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Oozie</p>
                    </td>
                    <td rowspan="1">
                      <p>By default, Ambari will install an instance of Derby on the Oozie Server host.
                        Optionally, to use an existing instance of PostgreSQL, MySQL or Oracle, see
                        <a href="#ref-b9803b8c-5f91-40d5-bdc4-da481581efbf">Using Non-Default Databases for
                          Oozie
                        </a>
                        for more information.
                      </p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
          
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>For the Ambari database, if you use an existing Oracle database, make sure the Oracle listener
                  runs on a port other than 8080 to avoid conflict with the default Ambari port.
                </p>
              </div>
            </aside>
          
        
        
          <h4 class="bold">Check the Maximum Open File Descriptors</h4>
          
            <p>The recommended maximum number of open file descriptors is 10000, or more.
              To check the current value set for the maximum number of open file descriptors, execute the following
              shell commands on each host:
              <code>ulimit -Sn
                ulimit -Hn
              </code>
            </p>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-50c9d54d-6862-497c-9e26-bdb3be3180e1">Collect Information</h3>
        
          <p>Before deploying an HDP cluster, you should collect the following information:</p>
          <ul class="bullet-list">
            
              <li>
                <p>The fully qualified domain name (FQDN) of each host in your system.
                  The Ambari install wizard supports using IP addresses. You can use
                  <code>hostname -f</code>
                  to check or verify the FQDN of a host.
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>Deploying all HDP components on a single host is possible, but is appropriate only for
                      initial evaluation purposes. Typically, you set up at least three hosts; one master host and two
                      slaves, as a minimum cluster. For more information about deploying HDP components, see the
                      descriptions for
                      <a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.0/Getting_Started_v22/index.html#Item1.4">
                        a
                      </a>
                      <a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.0/Getting_Started_v22/index.html#Item1.4">
                        Typical Hadoop Cluster</a>.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>A list of components you want to set up on each host.</p>
              </li>
              <li>
                <p>The base directories you want to use as mount points for storing:</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>NameNode data</p>
                    </li>
                    <li>
                      <p>DataNodes data</p>
                    </li>
                    <li>
                      <p>Secondary NameNode data</p>
                    </li>
                    <li>
                      <p>Oozie data</p>
                    </li>
                    <li>
                      <p>MapReduce data (Hadoop version 1.x)</p>
                    </li>
                    <li>
                      <p>YARN data (Hadoop version 2.x)</p>
                    </li>
                    <li>
                      <p>ZooKeeper data, if you install ZooKeeper</p>
                    </li>
                    <li>
                      <p>Various log, pid, and db files, depending on your install type</p>
                    </li>
                  
                </ul>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>You must use base directories that provide persistent storage locations for your HDP
                      components and your Hadoop data. Installing HDP components in locations that may be removed from a
                      host may result in cluster failure or data loss.
                      For example: Do Not use
                      <code>/tmp</code>
                      in a base directory path.
                    </p>
                  </div>
                </aside>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-b5f4ad84-c530-47b5-a963-ef871697c278">Prepare the Environment</h3>
        
          <p>To deploy your Hadoop instance, you need to prepare your deployment environment:</p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-a45c8e9e-e707-48bc-ba61-9d31349b17de">Check Existing Package Versions</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-88addfc9-ec6c-4dcb-b2dd-75b4331d2809">Set up Password-less SSH</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-9b90a5d6-c93b-4fc5-99dc-846c33632143">Set up Service User Accounts</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-5ec591f7-ecd5-4e03-a1f4-5bfbd23c89ce">Enable NTP on the Cluster</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-96c2019f-12bd-46db-b00c-c7e93e1acf0f">Check DNS</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-1ae25403-3cb6-435d-a1af-0592f866e255">Configure iptables</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-eaf82ef6-fbb9-42b6-bb25-ff033772a8a2">Disable SELinux, PackageKit and Check
                    umask Value
                  </a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Check Existing Package Versions</h4>
          
            <p>During installation, Ambari overwrites current versions of some packages required by Ambari to
              manage a Hadoop cluster. Package versions other than those that Ambari installs can cause problems running
              the installer. Remove any package versions that do not match the following ones:
            </p>
            <div class="tabs">
              
              <div class="tab">
                <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                <div class="tab-content">
                  <div class="xyleme-table"><table border="1">
                    
                      
                      
                      <thead></thead>
                      <tbody>
                        <tr>
                          <th rowspan="1">
                            <p>
                              <strong>Component - Description</strong>
                            </p>
                          </th>
                          <th rowspan="1">
                            <p>
                              <strong>Files and Versions</strong>
                            </p>
                          </th>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Server Database</p>
                          </td>
                          <td rowspan="1">
                            <p>postgresql 8.4.13-1.el6_3, postgresql-libs 8.4.13-1.el6_3, postgresql-server
                              8.4.13-1.el6_3
                            </p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Agent - Installed on each host in your cluster. Communicates with the
                              Ambari Server to execute commands.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>None</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Nagios Server - The host that runs the Nagios server.</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios 3.5.0-99, nagios-devel 3.5.0-99, nagios-www 3.5.0-99, nagios-plugins
                              1.4.9-1
                            </p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ganglia Server - The host that runs the Ganglia Server.</p>
                          </td>
                          <td rowspan="1">
                            <p>ganglia-gmetad 3.5.0-99, ganglia-devel 3.5.0-99, libganglia 3.5.0-99, ganglia-web
                              3.5.7-99, rrdtool 1.4.5-1.el6
                            </p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ganglia Monitor - Installed on each host in the cluster. Sends metrics data to the
                              Ganglia Collector.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>ganglia-gmond 3.5.0-99, libganglia 3.5.0-99</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                </div>
              </div>
              <div class="tab">
                <p class="bold">SLES 11</p>
                <div class="tab-content">
                  <div class="xyleme-table"><table border="1">
                    
                      
                      
                      <thead></thead>
                      <tbody>
                        <tr>
                          <th rowspan="1">
                            <p>
                              <strong>Component - Description</strong>
                            </p>
                          </th>
                          <th rowspan="1">
                            <p>
                              <strong>Files and Versions</strong>
                            </p>
                          </th>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Server Database</p>
                          </td>
                          <td rowspan="1">
                            <p>postgresql 8.3.5-1, postgresql-server 8.3.5-1, postgresql-libs 8.3.5-1</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Agent - Installed on each host in your cluster. Communicates with the
                              Ambari Server to execute commands.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>None</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Nagios Server - The host that runs the Nagios server.</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios 3.5.0-99, nagios-devel 3.5.0-99, nagios-www 3.5.0-99, nagios-plugins
                              1.4.9-1
                            </p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ganglia Server - The host that runs the Ganglia Server.</p>
                          </td>
                          <td rowspan="1">
                            <p>ganglia-gmetad 3.5.0-99 ganglia-devel 3.5.0-99 libganglia 3.5.0-99 ganglia-web
                              3.5.7-99 rrdtool 1.4.5-4.5.1
                            </p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ganglia Monitor - Installed on each host in the cluster. Sends metrics data to the
                              Ganglia Collector.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>ganglia-gmond 3.5.0-99, libganglia 3.5.0-99</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                </div>
              </div>
              <div class="tab">
                <p class="bold">UBUNTU 12</p>
                <div class="tab-content">
                  <div class="xyleme-table"><table border="1">
                    
                      
                      
                      <thead></thead>
                      <tbody>
                        <tr>
                          <th rowspan="1">
                            <p>
                              <strong>Component - Description</strong>
                            </p>
                          </th>
                          <th rowspan="1">
                            <p>
                              <strong>Files and Versions</strong>
                            </p>
                          </th>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Server Database</p>
                          </td>
                          <td rowspan="1">
                            <p><i></i>libpq5 postgresql postgresql-9.1 postgresql-client-9.1
                              postgresql-client-common postgresql-common ssl-cert
                            </p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Agent - Installed on each host in your cluster. Communicates with the
                              Ambari Server to execute commands.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>zlibc_0.9k-4.1_amd64</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Nagios Server - The host that runs the Nagios Server.</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios3</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ganglia Server - The host that runs the Ganglia Server.</p>
                          </td>
                          <td rowspan="1">
                            <p>gmetad ganglia-webfrontend ganglia-monitor-python rrdcached</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ganglia Monitor - Installed on each host in the cluster. Sends metrics data to the
                              Ganglia Collector.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>gmetad ganglia-webfrontend ganglia-monitor-python rrdcached</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                </div>
              </div>
              <div class="tab">
                <p class="bold">RHEL/CentOS/Oracle Linux 5</p>
                <div class="tab-content">
                  <div class="xyleme-table"><table border="1">
                    
                      
                      
                      <thead></thead>
                      <tbody>
                        <tr>
                          <th rowspan="1">
                            <p>
                              <strong>Component - Description</strong>
                            </p>
                          </th>
                          <th rowspan="1">
                            <p>
                              <strong>Files and Versions</strong>
                            </p>
                          </th>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Server Database</p>
                          </td>
                          <td rowspan="1">
                            <p>libffi 3.0.5-1.el5, python26 2.6.8-2.el5, python26-libs 2.6.8-2.el5, postgresql
                              8.4.13-1.el6_3, postgresql-libs 8.4.13-1.el6_3, postgresql-server 8.4.13-1.el6_3
                            </p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Agent - Installed on each host in your cluster. Communicates with the
                              Ambari Server to execute commands.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>libffi 3.0.5-1.el5, python26 2.6.8-2.el5, python26-libs 2.6.8-2.el5</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Nagios Server - The host that runs the Nagios server.</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios 3.5.0-99, nagios-devel 3.5.0-99, nagios-www 3.5.0-99, nagios-plugins
                              1.4.9-1
                            </p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ganglia Server - The host that runs the Ganglia Server.</p>
                          </td>
                          <td rowspan="1">
                            <p>ganglia-gmetad 3.5.0-99, ganglia-devel 3.5.0-99, libganglia 3.5.0-99, ganglia-web
                              3.5.7-99, rrdtool 1.4.5-1.el5
                            </p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ganglia Monitor - Installed on each host in the cluster. Sends metrics data to the
                              Ganglia Collector.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>ganglia-gmond 3.5.0-99, libganglia 3.5.0-99</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                </div>
              </div>
            </div>
          
          
            <div class="xyleme-table"><table border="1">
              
                
                
                <thead></thead>
                <tbody>
                  <tr>
                    <th rowspan="1">
                      <p>
                        <strong>Component - Description</strong>
                      </p>
                    </th>
                    <th rowspan="1">
                      <p>
                        <strong>Files and Versions</strong>
                      </p>
                    </th>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ambari Server Database</p>
                    </td>
                    <td rowspan="1">
                      <p>postgresql 8.4.13-1.el6_3, postgresql-libs 8.4.13-1.el6_3, postgresql-server
                        8.4.13-1.el6_3
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ambari Agent - Installed on each host in your cluster. Communicates with the Ambari
                        Server to execute commands.
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>None</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Nagios Server - The host that runs the Nagios server.</p>
                    </td>
                    <td rowspan="1">
                      <p>nagios 3.5.0-99, nagios-devel 3.5.0-99, nagios-www 3.5.0-99, nagios-plugins 1.4.9-1
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia Server - The host that runs the Ganglia Server.</p>
                    </td>
                    <td rowspan="1">
                      <p>ganglia-gmetad 3.5.0-99, ganglia-devel 3.5.0-99, libganglia 3.5.0-99, ganglia-web
                        3.5.7-99, rrdtool 1.4.5-1.el6
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia Monitor - Installed on each host in the cluster. Sends metrics data to the
                        Ganglia Collector.
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>ganglia-gmond 3.5.0-99, libganglia 3.5.0-99</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <div class="xyleme-table"><table border="1">
              
                
                
                <thead></thead>
                <tbody>
                  <tr>
                    <th rowspan="1">
                      <p>
                        <strong>Component - Description</strong>
                      </p>
                    </th>
                    <th rowspan="1">
                      <p>
                        <strong>Files and Versions</strong>
                      </p>
                    </th>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ambari Server Database</p>
                    </td>
                    <td rowspan="1">
                      <p>postgresql 8.3.5-1, postgresql-server 8.3.5-1, postgresql-libs 8.3.5-1</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ambari Agent - Installed on each host in your cluster. Communicates with the Ambari
                        Server to execute commands.
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>None</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Nagios Server - The host that runs the Nagios server.</p>
                    </td>
                    <td rowspan="1">
                      <p>nagios 3.5.0-99, nagios-devel 3.5.0-99, nagios-www 3.5.0-99, nagios-plugins 1.4.9-1
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia Server - The host that runs the Ganglia Server.</p>
                    </td>
                    <td rowspan="1">
                      <p>ganglia-gmetad 3.5.0-99 ganglia-devel 3.5.0-99 libganglia 3.5.0-99 ganglia-web 3.5.7-99
                        rrdtool 1.4.5-4.5.1
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia Monitor - Installed on each host in the cluster. Sends metrics data to the
                        Ganglia Collector.
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>ganglia-gmond 3.5.0-99, libganglia 3.5.0-99</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <div class="xyleme-table"><table border="1">
              
                
                
                <thead></thead>
                <tbody>
                  <tr>
                    <th rowspan="1">
                      <p>
                        <strong>Component - Description</strong>
                      </p>
                    </th>
                    <th rowspan="1">
                      <p>
                        <strong>Files and Versions</strong>
                      </p>
                    </th>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ambari Server Database</p>
                    </td>
                    <td rowspan="1">
                      <p><i></i>libpq5 postgresql postgresql-9.1 postgresql-client-9.1
                        postgresql-client-common postgresql-common ssl-cert
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ambari Agent - Installed on each host in your cluster. Communicates with the Ambari
                        Server to execute commands.
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>zlibc_0.9k-4.1_amd64</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Nagios Server - The host that runs the Nagios Server.</p>
                    </td>
                    <td rowspan="1">
                      <p>nagios3</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia Server - The host that runs the Ganglia Server.</p>
                    </td>
                    <td rowspan="1">
                      <p>gmetad ganglia-webfrontend ganglia-monitor-python rrdcached</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia Monitor - Installed on each host in the cluster. Sends metrics data to the
                        Ganglia Collector.
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>gmetad ganglia-webfrontend ganglia-monitor-python rrdcached</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <div class="xyleme-table"><table border="1">
              
                
                
                <thead></thead>
                <tbody>
                  <tr>
                    <th rowspan="1">
                      <p>
                        <strong>Component - Description</strong>
                      </p>
                    </th>
                    <th rowspan="1">
                      <p>
                        <strong>Files and Versions</strong>
                      </p>
                    </th>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ambari Server Database</p>
                    </td>
                    <td rowspan="1">
                      <p>libffi 3.0.5-1.el5, python26 2.6.8-2.el5, python26-libs 2.6.8-2.el5, postgresql
                        8.4.13-1.el6_3, postgresql-libs 8.4.13-1.el6_3, postgresql-server 8.4.13-1.el6_3
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ambari Agent - Installed on each host in your cluster. Communicates with the Ambari
                        Server to execute commands.
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>libffi 3.0.5-1.el5, python26 2.6.8-2.el5, python26-libs 2.6.8-2.el5</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Nagios Server - The host that runs the Nagios server.</p>
                    </td>
                    <td rowspan="1">
                      <p>nagios 3.5.0-99, nagios-devel 3.5.0-99, nagios-www 3.5.0-99, nagios-plugins 1.4.9-1
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia Server - The host that runs the Ganglia Server.</p>
                    </td>
                    <td rowspan="1">
                      <p>ganglia-gmetad 3.5.0-99, ganglia-devel 3.5.0-99, libganglia 3.5.0-99, ganglia-web
                        3.5.7-99, rrdtool 1.4.5-1.el5
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia Monitor - Installed on each host in the cluster. Sends metrics data to the
                        Ganglia Collector.
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>ganglia-gmond 3.5.0-99, libganglia 3.5.0-99</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            
          
        
        
          <h4 class="bold">Set Up Password-less SSH</h4>
          
            <p>To have Ambari Server automatically install Ambari Agents on all your cluster hosts, you must set
              up password-less SSH connections between the Ambari Server host and all other hosts in the cluster. The
              Ambari Server host uses SSH public key authentication to remotely access and install the Ambari Agent.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>You can choose to manually install the Agents on each cluster host. In this case, you do not
                  need to generate and distribute SSH keys.
                </p>
              </div>
            </aside>
            <ul class="number-list">
              
                <li>
                  <p>Generate public and private SSH keys on the Ambari Server host.</p>
                  <p>
                    <code>ssh-keygen</code>
                  </p>
                </li>
                <li>
                  <p>Copy the SSH Public Key (id_rsa.pub) to the root account on your target hosts.</p>
                  <p>
                    <code>.ssh/id_rsa
                      .ssh/id_rsa.pub
                    </code>
                  </p>
                </li>
                <li>
                  <p>Add the SSH Public Key to the authorized_keys file on your target hosts.</p>
                  <p>
                    <code>cat id_rsa.pub &gt;&gt; authorized_keys</code>
                  </p>
                </li>
                <li>
                  <p>Depending on your version of SSH, you may need to set permissions on the .ssh directory (to
                    700) and the authorized_keys file in that directory (to 600) on the target hosts.
                  </p>
                  <p>
                    <code>chmod 700 ~/.ssh
                      chmod 600 ~/.ssh/authorized_keys
                    </code>
                  </p>
                </li>
                <li>
                  <p>From the Ambari Server, make sure you can connect to each host in the cluster using SSH,
                    without having to enter a password.
                  </p>
                  <p>
                    <code>ssh root@</code>
                    &lt;remote.target.host&gt;
                    
                    where
                    &lt;remote.target.host&gt;
                    has the value of each host name in your cluster.
                  </p>
                </li>
                <li>
                  <p>If the following warning message displays during your first connection:
                    <code>Are you sure you want to continue connecting (yes/no)?
                    </code>
                    Enter<code>Yes</code>.
                  </p>
                </li>
                <li>
                  <p>Retain a copy of the SSH Private Key on the machine from which you will run the web-based
                    Ambari Install Wizard.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>It is possible to use a non-root SSH account, if that account can execute
                        <code>sudo</code>
                        without entering a password.
                      </p>
                    </div>
                  </aside>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Set up Service User Accounts</h4>
          
            <p>The Ambari install wizard creates one administrator-level user account for Ambari, admin. The
              credentials for the admin account are username/password = admin/admin. For more information about creating
              additional users and groups for your HDP cluster, see
              <a href="#ref-b61c95af-59c7-4714-8745-eabbbd3056c2">Users and Groups Overview</a>
              in<i>Managing Users and Groups</i>.

              Each HDP service requires a service user account. The Ambari Install wizard creates new and preserves any
              existing service user accounts, and uses these accounts when configuring Hadoop services. Service user
              account creation applies to service user accounts on the local operating system and to LDAP/AD accounts.
            </p>
            <p>For more information about customizing service user accounts for each HDP service, see one of the
              following topics:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>
                    <a href="#ref-eeda7cc9-867e-4485-90cd-9d9c35001c55">Customizing Services for HDP 2.x
                      Stack
                    </a>
                  </p>
                </li>
                <li>
                  <p>
                    <a href="#ref-6c6f06e3-5645-41fa-9d90-b081b0c7dd2f">Customizing Services for HDP 1.x
                      Stack
                    </a>
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Enable NTP on the Cluster and on the Browser Host</h4>
          
            <p>The clocks of all the nodes in your cluster and the machine that runs the browser through which
              you access the Ambari Web interface must be able to synchronize with each other.

              Install a network ttime protocol daem on each host:
              <code>yum install ntpd
              </code>
              To check that the NTP service is on, run the following command on each host:
              <code>chkconfig —list ntpd</code>
              To turn on the NTP service, run the following command on each host:
              <code>chkconfig ntpd</code>
            </p>
          
        
        
          <h4 class="bold">Check DNS</h4>
          
            <p>All hosts in your system must be configured for both forward and and reverse DNS.</p>
            <p>If you are unable to configure DNS in this way, you must edit the /etc/hosts file on every host in
              your cluster to contain the IP address and Fully Qualified Domain Name of each of your hosts. The
              following instructions cover a basic /etc/hosts setup for generic Linux hosts. Different versions and
              flavors of Linux might require slightly different commands. Please refer to the documentation for the
              operating system(s) deployed in your environment.
            </p>
          
          
            <h4 class="bold">Edit the Host File</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>Using a text editor, open the hosts file on every host in your cluster. For example:
                    </p>
                    <p>
                      <code>vi /etc/hosts</code>
                    </p>
                  </li>
                  <li>
                    <p>Add a line for each host in your cluster. The line should consist of the IP address and
                      the FQDN.
                      For example:
                    </p>
                    <p>
                      <code>1.2.3.4</code>
                      &lt;fully.qualified.domain.name&gt;
                    </p>
                    <aside class="custom-note">
                      <div class="icon"><img src="Icons/Important.png" width="50"></div>
                      <div class="simple-block">
                        <p>Do<strong>not</strong>remove the following two lines from your hosts file. Removing or
                          editing the following lines may cause various programs that require network functionality to
                          fail.
                        </p>
                        <p>
                          <code>127.0.0.1 localhost.localdomain localhost
                            ::1 localhost6.localdomain6 localhost6
                          </code>
                        </p>
                      </div>
                    </aside>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Set the Hostname</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>Use the "hostname" command to set the hostname on each host in your cluster.
                      For example:
                    </p>
                    <p>
                      <code>hostname</code>
                      &lt;fully.qualified.domain.name&gt;
                    </p>
                  </li>
                  <li>
                    <p>Confirm that the hostname is set by running the following command:</p>
                    <p>
                      <code>hostname -f</code>
                    </p>
                    <p>This should return the
                      &lt;fully.qualified.domain.name&gt;
                      you just set.
                    </p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Edit the Network Configuration File</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>Using a text editor, open the network configuration file on every host and set the desired
                      network configuration for each host. For example:
                    </p>
                    <p>
                      <code>vi /etc/sysconfig/network</code>
                    </p>
                  </li>
                  <li>
                    <p>Modify the HOSTNAME property to set the fully qualified domain name.</p>
                    <p>
                      <code>NETWORKING=yes
                        NETWORKING_IPV6=yes
                        HOSTNAME=
                      </code>
                      &lt;fully.qualified.domain.name&gt;
                    </p>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Configuring iptables</h4>
          
            <p>For Ambari to communicate during setup with the hosts it deploys to and manages, certain ports
              must be open and available. The easiest way to do this is to temporarily disable iptables, as follows:

              <code>chkconfig iptables off
                /etc/init.d/iptables stop
              </code>

              You can restart iptables after setup is complete. If the security protocols in your environment prevent
              disabling iptables, you can proceed with iptables enabled, if all required ports are open and available.
              For more information about required ports, see<a href="#ref-85947452-af53-46f1-96fa-133675313860">Configuring Network Port Numbers</a>.

              Ambari checks whether iptables is running during the Ambari Server setup process. If iptables is running,
              a warning displays, reminding you to check that required ports are open and available. The Host Confirm
              step in the Cluster Install Wizard also issues a warning for each host that has iptables running.
            </p>
          
        
        
          <h4 class="bold">Disable SELinux and PackageKit and check the umask Value</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>You must temporarily disable SELinux for the Ambari setup to function.
                    On each host in your cluster,
                  </p>
                  <p>
                    <code>setenforce 0</code>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>To permanently disable SELinux
                        set
                        <code>SELINUX=disabled</code>
                        in
                        <code>/etc/selinux/config</code>
                        This ensures that SELinux does not turn itself on after you reboot the machine .
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>On an installation host running RHEL/CentOS with PackageKit installed,
                    open
                    <code>/etc/yum/pluginconf.d/refresh-packagekit.conf</code>
                    using a text editor.
                    Make the following change:
                    <code></code>
                    <code>enabled=0</code>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>PackageKit is not enabled by default on SLES or Ubuntu systems. Unless you have
                        specifically enabled PackageKit, you may skip this step for a SLES or Ubuntu installation host.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>UMASK (User Mask or User file creation MASK) is the default permission or base permission
                    given when a new file or folder is created on a Linux machine. Most Linux distros set 022 as the
                    default umask. For a HDP cluster, make sure that umask is set to 022.
                    To set umask 022, run the following command as root on all hosts,
                    <code>vi /etc/profile
                    </code>then, append the following line:
                    <code>
                      umask 022
                    </code>
                  </p>
                </li>
              
            </ul>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-28d7e1f2-0adb-436a-a4b1-65b522fdcdf2">Using a Local Repository</h3>
        
          <p>If your cluster is behind a fire wall that prevents or limits Internet access, you can install
            Ambari and a Stack using local repositories. This section describes how to:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-71ea1556-a492-46b4-a6e5-029237e1dcd7">Obtain the repositories</a>
                </p>
              </li>
              <li>
                <p>Set up a local repository having:</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>
                        <a href="#ref-9cdb6241-6556-4788-ba58-df868d965d92">No Internet Access</a>
                      </p>
                    </li>
                    <li>
                      <p>
                        <a href="#ref-36521169-8297-4445-ae11-311be55e6492">Temporary Internet Access</a>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>
                  <a href="#ref-71cef54a-0d59-4593-b2f9-a049abda1436">Prepare the Ambari repository
                    configuration file
                  </a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Obtaining the Repositories</h4>
          
            <p>This section describes how to obtain:</p>
            <ul class="bullet-list">
              
                <li>
                  <p>
                    <a href="#ref-db19b022-0fb5-4c77-b8fb-bde987c5234d">Ambari Repositories</a>
                  </p>
                </li>
                <li>
                  <p>
                    <a href="#ref-3e43081a-a937-4d51-92cc-1fbf15645713">HDP Repositories</a>
                  </p>
                </li>
              
            </ul>
          
          
            <h4 class="bold">Ambari Repositories</h4>
            
              <p>If you do not have Internet access for setting up the Ambari repository, use the link
                appropriate for your OS family to download a tarball that contains the software.
              </p>
              <div class="tabs">
                Ambari 1.7.0 Tarball Links:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/centos6/ambari-1.7.0-centos6.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/suse11/ambari-1.7.0-suse11.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">UBUNTU 12</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/ubuntu12/ambari-1.7.0-ubuntu12.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/centos5/ambari-1.7.0-centos5.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/centos6/ambari-1.7.0-centos6.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/suse11/ambari-1.7.0-suse11.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>UBUNTU 12</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/ubuntu12/ambari-1.7.0-ubuntu12.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/centos5/ambari-1.7.0-centos5.tar.gz
                      </code>
                    </p>
                  </li>
                
                
              </ul>
              <p>If you have temporary Internet access for setting up the Ambari repository, use the link
                appropriate for your OS family to download a repository that contains the software.
              </p>
              <div class="tabs">
                Ambari 1.7.0 Repository File Links:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.7.0/ambari.repo -O
                        /etc/yum.repos.d/ambari.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/suse11/1.x/updates/1.7.0/ambari.repo -O
                        /etc/zypp/repos.d/ambari.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">UBUNTU 12</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/ubuntu12/1.x/updates/1.7.0/ambari.list -O
                        /etc/apt/sources.list/ambari.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/centos5/1.x/updates/1.7.0/ambari.repo -O
                        /etc/yum.repos.d/ambari.repo
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.7.0/ambari.repo -O
                        /etc/yum.repos.d/ambari.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/suse11/1.x/updates/1.7.0/ambari.repo -O
                        /etc/zypp/repos.d/ambari.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>UBUNTU 12</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/ubuntu12/1.x/updates/1.7.0/ambari.list -O
                        /etc/apt/sources.list/ambari.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/ambari/centos5/1.x/updates/1.7.0/ambari.repo -O
                        /etc/yum.repos.d/ambari.repo
                      </code>
                    </p>
                  </li>
                
                
              </ul>
            
          
          
            <h4 class="bold">HDP Stack Repositories</h4>
            
              <p>If you do not have Internet access to set up the Stack repositories, use the link appropriate
                for your OS family to download a tarball that contains the HDP Stack version you plan to install.
              </p>
              <div class="tabs">
                HDP 2.2 tarballs:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/HDP-2.2.0.0-centos6-rpm.tar.gz

                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.20/repos/centos6/HDP-UTILS-1.1.0.20-centos6.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11SP3</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11sp3/HDP-2.2.0.0-suse11sp3-rpm.tar.gz

                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.20/repos/suse11sp3/HDP-UTILS-1.1.0.20-suse11sp3.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">UBUNTU 12</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/ubuntu12/HDP-2.2.0.0-ubuntu12-deb.tar.gz

                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.20/repos/ubuntu12/HDP-UTILS-1.1.0.20-ubuntu12.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/HDP-2.2.0.0-centos5-rpm.tar.gz

                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.20/repos/centos5/HDP-UTILS-1.1.0.20-centos5.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/HDP-2.2.0.0-centos6-rpm.tar.gz

                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.20/repos/centos6/HDP-UTILS-1.1.0.20-centos6.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11SP3</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11sp3/HDP-2.2.0.0-suse11sp3-rpm.tar.gz

                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.20/repos/suse11sp3/HDP-UTILS-1.1.0.20-suse11sp3.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>UBUNTU 12</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/ubuntu12/HDP-2.2.0.0-ubuntu12-deb.tar.gz

                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.20/repos/ubuntu12/HDP-UTILS-1.1.0.20-ubuntu12.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/HDP-2.2.0.0-centos5-rpm.tar.gz

                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.20/repos/centos5/HDP-UTILS-1.1.0.20-centos5.tar.gz
                      </code>
                    </p>
                  </li>
                
                
              </ul>
              <div class="tabs">
                HDP 2.1 tarballs:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/HDP-2.1.5.0-centos6-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/centos6/HDP-UTILS-1.1.0.17-centos6.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/sles11sp1/HDP-2.1.5.0-sles11sp1-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/suse11/HDP-UTILS-1.1.0.17-suse11.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">UBUNTU 12</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/ubuntu12/HDP-2.1.5.0-ubuntu12-tars-tarball.tar.gz
                        wget -nv http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.18/repos/ubuntu12/
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/HDP-2.1.3.0-centos5-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/centos5/HDP-UTILS-1.1.0.17-centos5.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/HDP-2.1.5.0-centos6-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/centos6/HDP-UTILS-1.1.0.17-centos6.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/sles11sp1/HDP-2.1.5.0-sles11sp1-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/suse11/HDP-UTILS-1.1.0.17-suse11.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>UBUNTU 12</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/ubuntu12/HDP-2.1.5.0-ubuntu12-tars-tarball.tar.gz
                        wget -nv http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.18/repos/ubuntu12/hdp.list
                      </code>
                    </p>
                  </li>
                
                
              </ul>
              <div class="tabs">
                HDP 2.0 tarballs:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/HDP-2.0.12.0-centos6-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/centos6/HDP-UTILS-1.1.0.17-centos6.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11/HDP-2.0.12.0-suse11-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/suse11/HDP-UTILS-1.1.0.17-suse11.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/HDP-2.0.12.0-centos5-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/centos5/HDP-UTILS-1.1.0.17-centos5.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/HDP-2.0.12.0-centos6-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/centos6/HDP-UTILS-1.1.0.17-centos6.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11/HDP-2.0.12.0-suse11-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/suse11/HDP-UTILS-1.1.0.17-suse11.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/HDP-2.0.12.0-centos5-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/centos5/HDP-UTILS-1.1.0.17-centos5.tar.gz
                      </code>
                    </p>
                  </li>
                
                
              </ul>
              <div class="tabs">
                HDP 1.3 tarballs:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/HDP-1.3.9.0-centos6-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.16/repos/centos6/HDP-UTILS-1.1.0.16-centos6.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11/HDP-1.3.9.0-suse11-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.16/repos/suse11/HDP-UTILS-1.1.0.16-suse11.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/HDP-1.3.9.0-centos5-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.16/repos/centos5/HDP-UTILS-1.1.0.16-centos5.tar.gz
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/HDP-1.3.9.0-centos6-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.16/repos/centos6/HDP-UTILS-1.1.0.16-centos6.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11/HDP-1.3.9.0-suse11-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.16/repos/suse11/HDP-UTILS-1.1.0.16-suse11.tar.gz
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/HDP-1.3.9.0-centos5-rpm.tar.gz
                        wget -nv
                        http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.16/repos/centos5/HDP-UTILS-1.1.0.16-centos5.tar.gz
                      </code>
                    </p>
                  </li>
                
                
              </ul>
              <p>If you have temporary Internet access for setting up the Stack repositories, use the link
                appropriate for your OS family to download a repository that contains the HDP Stack version you plan to
                install.
              </p>
              <div class="tabs">
                HDP 2.2 repository file links:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv http://public-repo-1.hortonworks.com/HDP/centos6/2.x/GA/2.2.0.0/hdp.repo
                        -O /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11SP3</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11sp3/2.x/GA/2.2.0.0/hdp.repo -O
                        /etc/zypp/repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">UBUNTU 12</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv http://public-repo-1.hortonworks.com/HDP/ubuntu12/2.x/GA/2.2.0.0/hdp.list
                        -O /etc/apt/sources.list.d/HDP.list
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv http://public-repo-1.hortonworks.com/HDP/centos5/2.x/GA/2.2.0.0/hdp.repo
                        -O /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv http://public-repo-1.hortonworks.com/HDP/centos6/2.x/GA/2.2.0.0/hdp.repo
                        -O /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11SP3</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11sp3/2.x/GA/2.2.0.0/hdp.repo -O
                        /etc/zypp/repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>UBUNTU 12</p>
                    <p>
                      <code>wget -nv http://public-repo-1.hortonworks.com/HDP/ubuntu12/2.x/GA/2.2.0.0/hdp.list
                        -O /etc/apt/sources.list.d/HDP.list
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                    <p>
                      <code>wget -nv http://public-repo-1.hortonworks.com/HDP/centos5/2.x/GA/2.2.0.0/hdp.repo
                        -O /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                
                
              </ul>
              <div class="tabs">
                HDP 2.1 repository file links:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.1.5.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11SP3</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11sp3/2.x/updates/2.1.5.0/hdp.repo -O
                        /etc/zypp/repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">UBUNTU 12</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv http://public-repo-1.hortonworks.com/HDP/ubuntu12/2.1.5.0/hdp.list
                        /etc/apt/sources.list.d/HDP.list
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/2.x/updates/2.1.5.0/hdp.repo -O
                        /etc/yum.repos.d/hdp.repo
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.1.5.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11SP3</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11sp3/2.x/updates/2.1.5.0/hdp.repo -O
                        /etc/zypp/repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>UBUNTU 12</p>
                    <p>
                      <code>wget -nv http://public-repo-1.hortonworks.com/HDP/ubuntu12/2.1.5.0/hdp.list
                        /etc/apt/sources.list.d/HDP.list
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/2.x/updates/2.1.5.0/hdp.repo -O
                        /etc/yum.repos.d/hdp.repo
                      </code>
                    </p>
                  </li>
                
                
              </ul>
              <div class="tabs">
                HDP 2.0 repository file links:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.0.12.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11/2.x/updates/2.0.12.0/hdp.repo -O
                        /etc/zypp/repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/2.x/updates/2.0.12.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.0.12.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11/2.x/updates/2.0.12.0/hdp.repo -O
                        /etc/zypp/repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>RHEL/CentOS/ORACLE 5 (DEPRECATED)</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/2.x/updates/2.0.12.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                
                
              </ul>
              <div class="tabs">
                HDP 1.3 repository file links:
                
                <div class="tab">
                  <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/1.x/updates/1.3.7.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">SLES 11</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11/1.x/updates/1.3.7.0/hdp.repo -O
                        /etc/zypp/repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
                <div class="tab">
                  <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                  <div class="tab-content">
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/1.x/updates/1.3.7.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </div>
                </div>
              </div>
              <ul class="bullet-list">
                
                  <li>
                    <p>RHEL/CentOS/Oracle Linux 6</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos6/1.x/updates/1.3.7.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>SLES 11</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/suse11/1.x/updates/1.3.7.0/hdp.repo -O
                        /etc/zypp/repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
                    <p>
                      <code>wget -nv
                        http://public-repo-1.hortonworks.com/HDP/centos5/1.x/updates/1.3.7.0/hdp.repo -O
                        /etc/yum.repos.d/HDP.repo
                      </code>
                    </p>
                  </li>
                
                
              </ul>
            
          
        
        
          <h4 class="bold">Setting Up a Local Repository</h4>
          
            <p>Based on your Internet access, choose one of the following options:</p>
            <ul class="bullet-list">
              
                <li>
                  <p>No Internet Access</p>
                  <p>This option involves downloading the repository tarball, moving the tarball to the selected
                    mirror server in your cluster, and extracting to create the repository.
                  </p>
                </li>
                <li>
                  <p>Temporary Internet Access</p>
                  <p>This option involves using your temporary Internet access to sync (using reposync) the
                    software packages to your selected mirror server and creating the repository.
                  </p>
                  <p>Both options proceed in a similar, straightforward way. Setting up for each option presents
                    some key differences, as described in the following sections:
                  </p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>
                          <a href="#ref-cc2d0307-f181-498d-bd7e-515d7b8df5dd">Getting Started Setting Up a
                            Local Repository
                          </a>
                        </p>
                      </li>
                      <li>
                        <p>
                          <a href="#ref-9cdb6241-6556-4788-ba58-df868d965d92">Setting Up a Local Repository
                            with No Internet Access
                          </a>
                        </p>
                      </li>
                      <li>
                        <p>
                          <a href="#ref-36521169-8297-4445-ae11-311be55e6492">Setting Up a Local Repository
                            with Temporary Internet Access
                          </a>
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
          
            <h4 class="bold">Getting Started Setting Up a Local Repository</h4>
            
              <p>To get started setting up your local repository, complete the following prerequisites:
              </p>
              <ul class="bullet-list">
                
                  <li>
                    <p>Select an existing server in, or accessible to the cluster, that runs a supported
                      operating system
                    </p>
                  </li>
                  <li>
                    <p>Enable network access from all hosts in your cluster to the mirror server</p>
                  </li>
                  <li>
                    <p>Ensure the mirror server has a package manager installed such as yum (RHEL / CentOS /
                      Oracle Linux), zypper (SLES), or apt-get (Ubuntu)
                    </p>
                  </li>
                  <li>
                    <p>
                      <strong>Optional:</strong>
                      If your repository has temporary Internet access, and you are using RHEL/CentOS/Oracle Linux as
                      your OS, install yum utilities:
                    </p>
                    <p>
                      <code>yum install yum-utils createrepo</code>
                    </p>
                  </li>
                
              </ul>
              <ul class="number-list">
                
                  <li>
                    <p>Create an HTTP server.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>On the mirror server, install an HTTP server (such as Apache httpd) using the
                            instructions provided
                            <a href="http://httpd.apache.org/download.cgi">here</a>
                            .
                          </p>
                        </li>
                        <li>
                          <p>Activate this web server.</p>
                        </li>
                        <li>
                          <p>Ensure that any firewall settings allow inbound HTTP access from your cluster nodes
                            to your mirror server.
                          </p>
                          <aside class="custom-note">
                            <div class="icon"><img src="Icons/Note.png" width="50"></div>
                            <div class="simple-block">
                              <p>If you are using Amazon EC2, make sure that SELinux is disabled.</p>
                            </div>
                          </aside>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>On your mirror server, create a directory for your web server.</p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>For example, from a shell window, type:</p>
                          <ul class="Bullet">
                            
                              <li>
                                <p>
                                  <strong>For RHEL/CentOS/Oracle Linux:</strong>
                                   
                                </p>
                                <p>
                                  <code>mkdir -p /var/www/html/</code>
                                </p>
                              </li>
                              <li>
                                <p><strong>For SLES</strong>:
                                </p>
                                <p>
                                  <code>mkdir -p /srv/www/htdocs/rpms</code>
                                </p>
                              </li>
                              <li>
                                <p>
                                  <strong>For Ubuntu:</strong>
                                </p>
                                <p>
                                  <code>mkdir -p /var/www/html/</code>
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                        <li>
                          <p>If you are using a symlink, enable the
                            <code>followsymlinks</code>
                            on your web server.
                          </p>
                          <aside class="custom-note">
                            <div class="icon"><img src="Icons/Note.png" width="50"></div>
                            <div class="simple-block">
                              <p>After you have completed the steps in<a href="#ref-cc2d0307-f181-498d-bd7e-515d7b8df5dd">Getting Started Setting up
                                a Local Repository</a>, move on to specific setup for your repository internet access
                                type.
                              </p>
                            </div>
                          </aside>
                        </li>
                      
                    </ul>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Setting Up a Local Repository with No Internet Access</h4>
            
              <p>After completing the
                <a href="#ref-cc2d0307-f181-498d-bd7e-515d7b8df5dd">Getting Started Setting up a Local
                  Repository
                </a>
                procedure, finish setting up your repository by completing the following steps:
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>Obtain the tarball for the repository you would like to create. For options, see<a href="#ref-71ea1556-a492-46b4-a6e5-029237e1dcd7">Obtaining the Repositories</a>.
                    </p>
                  </li>
                  <li>
                    <p>Copy the repository tarballs to the web server directory and untar.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Browse to the web server directory you created.</p>
                          <ul class="Bullet">
                            
                              <li>
                                <p>
                                  <strong>For RHEL/CentOS/Oracle Linux:</strong>
                                   
                                </p>
                                <p>
                                  <code>cd /var/www/html/</code>
                                </p>
                              </li>
                              <li>
                                <p>
                                  <strong>For SLES:</strong>
                                </p>
                                <p>
                                  <code>cd /srv/www/htdocs/rpms</code>
                                </p>
                              </li>
                              <li>
                                <p>
                                  <strong>For Ubuntu:</strong>
                                </p>
                                <p>
                                  <code>cd /var/www/html/</code>
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                        <li>
                          <p>Untar the repository tarballs to the following locations:
                            where&lt;web.server&gt;,
                              &lt;web.server.directory&gt;,&lt;OS&gt;,&lt;version&gt;
                            , and
                            &lt;latest.version&gt;
                            represent the name, home directory, operating system type, version, and most recent release
                            version, respectively.
                          </p>
                          <div class="xyleme-table"><table border="1">
                            
                              
                              
                              <thead>
                                <tr>
                                  <th rowspan="1">
                                    <p>Repository Content</p>
                                  </th>
                                  <th rowspan="1">
                                    <p>Repository Location</p>
                                  </th>
                                </tr>
                              </thead>
                              <tbody>
                                <tr>
                                  <td rowspan="1">
                                    <p>Ambari Repository</p>
                                  </td>
                                  <td rowspan="1">
                                    <p>Untar under
                                      &lt;web.server.directory&gt;
                                    </p>
                                  </td>
                                </tr>
                                <tr>
                                  <td rowspan="1">
                                    <p>HDP Stack Repositories</p>
                                  </td>
                                  <td rowspan="1">
                                    <p>Create directory and untar under
                                      &lt;web.server.directory&gt;/hdp
                                    </p>
                                  </td>
                                </tr>
                              </tbody>
                              
                            
                            Untar Locations for a Local Repository - No Internet Access
                          </table></div>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Confirm you can browse to the newly created local repositories.</p>
                    <div class="xyleme-table"><table border="1">
                      
                        
                        
                        <thead>
                          <tr>
                            <th rowspan="1">
                              <p>Repository</p>
                            </th>
                            <th rowspan="1">
                              <p>URL</p>
                            </th>
                          </tr>
                        </thead>
                        <tbody>
                          <tr>
                            <td rowspan="1">
                              <p>Ambari Base URL</p>
                            </td>
                            <td rowspan="1">
                              <p>http://&lt;web.server&gt;/ambari/&lt;OS&gt;/2.x/updates/1.7.0</p>
                            </td>
                          </tr>
                          <tr>
                            <td rowspan="1">
                              <p>HDP Base URL</p>
                            </td>
                            <td rowspan="1">
                              <p>http://&lt;web.server&gt;/hdp/HDP/&lt;OS&gt;/2.x/updates/&lt;latest.version&gt;
                              </p>
                            </td>
                          </tr>
                          <tr>
                            <td rowspan="1">
                              <p>HDP-UTILS Base URL</p>
                            </td>
                            <td rowspan="1">
                              <p>
                                http://&lt;web-server&gt;/hdp/HDP-UTILS-&lt;version&gt;/repos/&lt;OS&gt;</p>
                            </td>
                          </tr>
                        </tbody>
                        
                      
                      URLs for a Local Repository - No Internet Access
                    </table></div>
                    <aside class="custom-note">
                      <div class="icon"><img src="Icons/Important.png" width="50"></div>
                      <div class="simple-block">
                        <p>Be sure to record these Base URLs. You will need them when installing Ambari and the
                          cluster.
                        </p>
                      </div>
                    </aside>
                  </li>
                  <li>
                    <p>Optional: If you have multiple repositories configured in your environment, deploy the
                      following plug-in on all the nodes in your cluster.
                    </p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Install the plug-in.</p>
                          <ul class="Bullet">
                            
                              <li>
                                <p>
                                  <strong>For RHEL and CentOS 6:</strong>
                                </p>
                                <p>
                                  <code>yum install yum-plugin-priorities</code>
                                </p>
                              </li>
                              <li>
                                <p>
                                  <strong>For RHEL and CentOS 5:</strong>
                                </p>
                                <p>
                                  <code>yum install yum-priorities</code>
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                        <li>
                          <p>Edit the
                            <code>/etc/yum/pluginconf.d/priorities.conf</code>
                            file to add the following:
                          </p>
                          <p>
                            <code>[main]
                              enabled=1
                              gpgcheck=0
                            </code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Setting up a Local Repository With Temporary Internet Access</h4>
            
              <p>After completing the
                <a href="#ref-9cdb6241-6556-4788-ba58-df868d965d92">Getting Started Setting up a Local
                  Repository
                </a>
                procedure, finish setting up your repository by completing the following steps:
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>Put the repository configuration files for Ambari and the Stack in place on the host. For
                      options, see<a href="#ref-71ea1556-a492-46b4-a6e5-029237e1dcd7">Obtaining the
                        Repositories</a>.
                    </p>
                  </li>
                  <li>
                    <p>Confirm availability of the repositories.</p>
                    <ul class="NoBullet">
                      
                        <li>
                          <p>
                            <strong>For RHEL/CentOS/Oracle Linux:</strong>
                          </p>
                          <p>
                            <code>yum repolist</code>
                          </p>
                        </li>
                        <li>
                          <p>
                            <strong>For SLES:</strong>
                          </p>
                          <p>
                            <code>zypper repos</code>
                          </p>
                        </li>
                        <li>
                          <p>
                            <strong>For Ubuntu:</strong>
                          </p>
                          <p>
                            <code>dpkg</code>
                            <code>-list</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Synchronize the repository contents to your mirror server.</p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>Browse to the web server directory:</p>
                          <ul class="NoBullet">
                            
                              <li>
                                <p>
                                  <strong>For RHEL/CentOS/Oracle Linux:</strong>
                                </p>
                                <p>
                                  <code>cd /var/www/html</code>
                                </p>
                              </li>
                              <li>
                                <p>
                                  <strong>For SLES:</strong>
                                </p>
                                <p>
                                  <code>cd /srv/www/htdocs/rpms</code>
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                        <li>
                          <p>For Ambari, create
                            <code>ambari</code>
                            directory and reposync.
                          </p>
                          <p>
                            <code>mkdir -p ambari/&lt;OS&gt;
                              cd ambari/&lt;OS&gt;
                              reposync -r Updates-ambari-1.7.0
                            </code>
                          </p>
                        </li>
                        <li>
                          <p>For HDP Stack Repositories, create
                            <code>hdp</code>
                            directory and reposync.
                          </p>
                          <p>
                            <code>mkdir -p hdp/&lt;OS&gt;
                              cd hdp/&lt;OS&gt;
                              reposync -r HDP-&lt;latest.version&gt;
                              reposync -r HDP-UTILS-&lt;version&gt;</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Generate the repository metadata.</p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>For Ambari:</p>
                          <p>
                            <code>createrepo &lt;web.server.directory&gt;/ambari/&lt;OS&gt;/Updates-ambari-1.7.0</code>
                          </p>
                        </li>
                        <li>
                          <p>For HDP Stack Repositories:</p>
                          <p>
                            <code>createrepo &lt;web.server.directory&gt;/hdp/&lt;OS&gt;/HDP-&lt;latest.version&gt;
                              createrepo
                              &lt;web.server.directory&gt;/hdp/&lt;OS&gt;/HDP-UTILS-&lt;version&gt;</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Confirm that you can browse to the newly created repository.</p>
                    <div class="xyleme-table"><table border="1">
                      
                        
                        
                        <thead>
                          <tr>
                            <th rowspan="1">
                              <p>Repository</p>
                            </th>
                            <th rowspan="1">
                              <p>URL</p>
                            </th>
                          </tr>
                        </thead>
                        <tbody>
                          <tr>
                            <td rowspan="1">
                              <p>Ambari Base URL</p>
                            </td>
                            <td rowspan="1">
                              <p>http://&lt;web.server&gt;/ambari/&lt;OS&gt;/Updates-ambari-1.7.0</p>
                            </td>
                          </tr>
                          <tr>
                            <td rowspan="1">
                              <p>HDP Base URL</p>
                            </td>
                            <td rowspan="1">
                              <p>http://&lt;web.server&gt;/hdp/&lt;OS&gt;/HDP-&lt;latest.version&gt;</p>
                            </td>
                          </tr>
                          <tr>
                            <td rowspan="1">
                              <p>HDP-UTILS Base URL</p>
                            </td>
                            <td rowspan="1">
                              <p>http://&lt;web.server&gt;/hdp/&lt;OS&gt;/HDP-UTILS-&lt;version&gt;</p>
                            </td>
                          </tr>
                        </tbody>
                        
                      
                      URLs for the New Repository
                    </table></div>
                    <aside class="custom-note">
                      <div class="icon"><img src="Icons/Important.png" width="50"></div>
                      <div class="simple-block">
                        <p>Be sure to record these Base URLs. You will need them when installing Ambari and the
                          Cluster.
                        </p>
                      </div>
                    </aside>
                  </li>
                  <li>
                    <p>Optional. If you have multiple repositories configured in your environment, deploy the
                      following plug-in on all the nodes in your cluster.
                    </p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Install the plug-in.</p>
                          <ul class="Bullet">
                            
                              <li>
                                <p>
                                  <strong>For RHEL and CentOS 6:</strong>
                                </p>
                                <p>
                                  <code>yum install yum-plugin-priorities</code>
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                        <li>
                          <p>Edit the
                            <code>/etc/yum/pluginconf.d/priorities.conf</code>
                            file to add the following:
                          </p>
                          <p>
                            <code>[main]
                              enabled=1
                              gpgcheck=0
                            </code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Preparing The Ambari Repository Configuration File</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>Download the
                      <code>ambari.repo</code>
                      file from the mirror server you created in the preceding sections or from the public repository.
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>From your mirror server:</p>
                          <p>
                            <code>http://</code>&lt;web_server&gt;<code>
                            /ambari/</code>&lt;OS&gt;
                            <code>/1.x/updates/1.7.0/ambari.repo</code>
                          </p>
                        </li>
                        <li>
                          <p>From the public repository:</p>
                          <p>
                            <code>http://public-repo-1.hortonworks.com/ambari/</code>&lt;OS&gt;
                            <code>/1.x/updates/1.7.0/ambari.repo</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Edit the ambari.repo file using the Ambari repository Base URL obtained when setting up
                      your local repository. Refer to step 3 in<a href="#ref-14d43287-b3d1-49a3-9712-a9d0efbe56fe">Setting Up a Local Repository with
                        No Internet Access</a>, or step 5 in<a href="#ref-36521169-8297-4445-ae11-311be55e6492">Setting Up a Local Repository with
                        Temporary Internet Access</a>, if necessary.
                    </p>
                    <div class="xyleme-table"><table border="1">
                      
                        
                        
                        <thead>
                          <tr>
                            <th rowspan="1">
                              <p>Repository</p>
                            </th>
                            <th rowspan="1">
                              <p>URL</p>
                            </th>
                          </tr>
                        </thead>
                        <tbody>
                          <tr>
                            <td rowspan="1">
                              <p>Ambari Base URL</p>
                            </td>
                            <td rowspan="1">
                              <p>http://&lt;web-server&gt;/ambari/&lt;OS&gt;/1.x/updates/1.7.0</p>
                            </td>
                          </tr>
                        </tbody>
                        
                      
                      Base URLs for a Local Repository
                    </table></div>
                  </li>
                  <li>
                    <p>If this an Ambari updates release, disable the GA repository definition.</p>
                    <p>
                      <strong>[ambari-1.x]</strong>
                      <code>name=Ambari 1.x
                        baseurl=http://public-repo-1.hortonworks.com/ambari/centos6/1.x/GA
                        gpgcheck=1
                        gpgkey=http://public-repo-1.hortonworks.com/ambari/centos6/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
                        enabled=0
                        priority=1
                      </code>
                      <strong>
                        [Updates-ambari-1.7.0]
                      </strong>
                      <code>name=ambari-1.7.0 - Updates
                        baseurl= &lt;this.is.the.AMBARI.base.url&gt;
                        gpgcheck=1
                        gpgkey=http://public-repo-1.hortonworks.com/ambari/centos6/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
                        enabled=1
                        priority=1
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>Place the ambari.repo file on the machine you plan to use for the Ambari Server.
                    </p>
                    <ul class="NoBullet">
                      
                        <li>
                          <p>
                            <strong>For RHEL/CentOS/Oracle Linux:</strong>
                          </p>
                          <p>
                            <code>/etc/yum.repos.d/ambari.repo</code>
                          </p>
                        </li>
                        <li>
                          <p>
                            <strong>For SLES:</strong>
                          </p>
                          <p>
                            <code>/etc/zypp/repos.d/ambari.repo</code>
                          </p>
                        </li>
                        <li>
                          <p>
                            <strong>For Ubuntu:</strong>
                          </p>
                          <p>
                            <code>/etc/apt-get install/list.d/ambari.list</code>
                          </p>
                        </li>
                        <li>
                          <p>Edit the
                            <code>/etc/yum/pluginconf.d/priorities.conf</code>
                            file to add the following:
                          </p>
                          <p>
                            <code>[main]
                              enabled=1
                              gpgcheck=0
                            </code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Proceed to
                      <a href="#ref-77031023-81db-4b1c-9434-2b68372a9920">Installing Ambari Server</a>
                      to install and setup Ambari Server.
                    </p>
                  </li>
                
              </ul>
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-ae4f3065-4bd1-4d55-a431-92a3d4b47690">
          Download the Ambari Repo
        </h3>
        
          <p>Select one of the following tabs that shows the OS family running on your installation host.
          </p>
          <div class="tabs">
            
            <div class="tab">
              <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
              <div class="tab-content">
                <p>
                  On a server host that has Internet access, use a command line editor to perform the following steps:
                </p>
                <ul class="number-list">
                  RHEL/CentOS/Oracle Linux 6
                  
                    <li>
                      <p>Log in to your host as<code>root</code>. You may
                        <code>sudo</code>
                        as
                        <code>su</code>
                        if your environment requires such access. For example, type:
                      </p>
                      <p>
                        &lt;username&gt;
                        <code>ssh</code>
                        &lt;hostname.FQDN&gt;
                        <code>sudo su -</code>
                        where
                        &lt;username&gt;
                        is your user name and
                        &lt;hostname.FQDN&gt;
                        is the fully qualified domain name of your server host.
                      </p>
                    </li>
                    <li>
                      <p>Download the Ambari repository file to a directory on your installation host.</p>
                      <p>
                        <code>wget -nv
                          http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.7.0/ambari.repo -O
                          /etc/yum.repos.d/ambari.repo
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Important.png" width="50"></div>
                        <div class="simple-block">
                          <p>Do not modify the
                            <code>ambari.repo</code>
                            file name. This file is expected to be available on the Ambari Server host during Agent
                            registration.
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>Confirm that the repository is configured by checking the repo list.</p>
                      <p>
                        <code>yum repolist</code>
                        You should see values similar to the following for Ambari repositories in the list.
                      </p>
                      <p>
                        Version values vary, depending on the installation.
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          
                          <thead></thead>
                          <tbody>
                            <tr>
                              <th rowspan="1">
                                <p>
                                  <strong>repo id</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>repo name</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>status</strong>
                                </p>
                              </th>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>AMBARI.1.7.0-1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Ambari 1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>5</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>base</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-6 - Base</p>
                              </td>
                              <td rowspan="1">
                                <p>6,518</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>extras</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-6 - Extras</p>
                              </td>
                              <td rowspan="1">
                                <p>15</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>updates</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-6 - Updates</p>
                              </td>
                              <td rowspan="1">
                                <p>209</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                    </li>
                    <li>
                      <p>Install the Ambari bits. This also installs the default PostgreSQL Ambari database.
                      </p>
                      <p>
                        <code>yum install ambari-server</code>
                      </p>
                    </li>
                    <li>
                      <p>Enter
                        <code>y</code>
                        when prompted to to confirm transaction and dependency checks.
                      </p>
                      <p>A successful installation displays output similar to the following:
                        <code>Installing : postgresql-libs-8.4.20-1.el6_5.x86_64 1/4
                          Installing : postgresql-8.4.20-1.el6_5.x86_64 2/4
                          Installing : postgresql-server-8.4.20-1.el6_5.x86_64 3/4
                          Installing : ambari-server-1.7.0-135.noarch 4/4
                          Verifying : postgresql-server-8.4.20-1.el6_5.x86_64 1/4
                          Verifying : postgresql-libs-8.4.20-1.el6_5.x86_64 2/4
                          Verifying : ambari-server-1.7.0-135.noarch 3/4
                          Verifying : postgresql-8.4.20-1.el6_5.x86_64 4/4

                          Installed:
                          ambari-server.noarch 0:1.7.0-135

                          Dependency Installed:
                          postgresql.x86_64 0:8.4.20-1.el6_5 postgresql-libs.x86_64 0:8.4.20-1.el6_5
                          postgresql-server.x86_64 0:8.4.20-1.el6_5

                          Complete!
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Note.png" width="50"></div>
                        <div class="simple-block">
                          <p>Accept the warning about trusting the Pivotal GPG Key. That key will be
                            automatically downloaded and used to validate packages from Pivotal. You will see the
                            following message:

                            <code>Importing GPG key 0x07513CAD:
                              Userid: "Jenkins (HDP Builds) &lt;jenkin@hortonworks.com&gt;"
                              From :
                              http://s3.amazonaws.com/dev.hortonworks.com/ambari/centos6/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
                            </code>
                          </p>
                        </div>
                      </aside>
                    </li>
                  
                </ul>
              </div>
            </div>
            <div class="tab">
              <p class="bold">SLES 11</p>
              <div class="tab-content">
                <p>On a server host that has Internet access, use a command line editor to perform the following
                  steps:
                </p>
                <ul class="number-list">
                  SLES 11
                  
                    <li>
                      <p>Log in to your host as<code>root</code>. You may
                        <code>sudo</code>
                        as
                        <code>su</code>
                        if your environment requires such access. For example, type:
                      </p>
                    </li>
                    <li>
                      <p>
                        &lt;username&gt;
                        <code>ssh</code>
                        &lt;hostname.FQDN&gt;
                        <code>sudo su -</code>
                        where
                        &lt;username&gt;
                        is your user name and
                        &lt;hostname.FQDN&gt;
                        is the fully qualified domain name of your server host.
                      </p>
                    </li>
                    <li>
                      <p>Download the Ambari repository file to a directory on your installation host.
                        <code>wget -nv
                          http://public-repo-1.hortonworks.com/ambari/suse11/1.x/updates/1.7.0/ambari.repo -O
                          /etc/zypp/repos.d/ambari.repo
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Important.png" width="50"></div>
                        <div class="simple-block">
                          <p>Do not modify the
                            <code>ambari.repo</code>
                            file name. This file is expected to be available on the Ambari Server host during Agent
                            registration.
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>Confirm the downloaded repository is configured by checking the repo list.</p>
                      <p>
                        <code>zypper repos</code>
                        You should see the Ambari repositories in the list.
                      </p>
                      <p>
                        Version values vary, depending on the installation.
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          
                          
                          <thead></thead>
                          <tbody>
                            <tr>
                              <th rowspan="1">
                                <p>
                                  <strong>Alias</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>Name</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>Enabled</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>Refresh</strong>
                                </p>
                              </th>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>AMBARI.1.7.0-1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Ambari 1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                              <td rowspan="1">
                                <p>No</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>http-demeter.uni-regensburg.de-c997c8f9</p>
                              </td>
                              <td rowspan="1">
                                <p>SUSE-Linux-Enterprise-Software-Development-Kit-11-SP1 11.1.1-1.57</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>opensuse</p>
                              </td>
                              <td rowspan="1">
                                <p>OpenSuse</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                    </li>
                    <li>
                      <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                      <p>
                        <code>zypper install ambari-server</code>
                      </p>
                    </li>
                    <li>
                      <p>Enter
                        <code>y</code>
                        when prompted to to confirm transaction and dependency checks.
                      </p>
                      <p>
                        <code>A successful installation displays output similar to the following:
                          Retrieving package postgresql-libs-8.3.5-1.12.x86_64 (1/4), 172.0 KiB (571.0 KiB unpacked)
                          Retrieving: postgresql-libs-8.3.5-1.12.x86_64.rpm [done (47.3 KiB/s)]
                          Installing: postgresql-libs-8.3.5-1.12 [done]
                          Retrieving package postgresql-8.3.5-1.12.x86_64 (2/4), 1.0 MiB (4.2 MiB unpacked)
                          Retrieving: postgresql-8.3.5-1.12.x86_64.rpm [done (148.8 KiB/s)]
                          Installing: postgresql-8.3.5-1.12 [done]
                          Retrieving package postgresql-server-8.3.5-1.12.x86_64 (3/4), 3.0 MiB (12.6 MiB unpacked)
                          Retrieving: postgresql-server-8.3.5-1.12.x86_64.rpm [done (452.5 KiB/s)]
                          Installing: postgresql-server-8.3.5-1.12 [done]
                          Updating etc/sysconfig/postgresql...
                          Retrieving package ambari-server-1.7.0-135.noarch (4/4), 99.0 MiB (126.3 MiB unpacked)
                          Retrieving: ambari-server-1.7.0-135.noarch.rpm [done (3.0 MiB/s)]
                          Installing: ambari-server-1.7.0-135 [done]
                          ambari-server 0:off 1:off 2:off 3:on 4:off 5:on 6:off
                        </code>
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
            <div class="tab">
              <p class="bold">UBUNTU 12</p>
              <div class="tab-content">
                <p>On a server host that has Internet access, use a command line editor to perform the following
                  steps:
                </p>
                <ul class="number-list">
                  UBUNTU 12
                  
                    <li>
                      <p>Log in to your host as<code>root</code>. You may
                        <code>sudo</code>
                        as
                        <code>su</code>
                        if your environment requires such access. For example, type:
                      </p>
                    </li>
                    <li>
                      <p>
                        &lt;username&gt;
                        <code>ssh</code>
                        &lt;hostname.FQDN&gt;
                        <code>sudo su -</code>
                        where
                        &lt;username&gt;
                        is your user name and
                        &lt;hostname.FQDN&gt;
                        is the fully qualified domain name of your server host.
                      </p>
                    </li>
                    <li>
                      <p>Download the Ambari repository file to a directory on your installation host.
                        <code>wget -nv
                          http://public-repo-1.hortonworks.com/ambari/ubuntu12/1.x/updates/1.7.0/ambari.list -O
                          /etc/apt/sources.list.d/ambari.list

                          apt-key adv --recv-keys --keyserver keyserver.ubuntu.com B9733A7A07513CAD

                          apt-get update
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Important.png" width="50"></div>
                        <div class="simple-block">
                          <p>Do not modify the
                            <code>ambari.list</code>
                            file name. This file is expected to be available on the Ambari Server host during Agent
                            registration.
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>Confirm that Ambari packages downloaded successfully by checking the package name
                        list.
                      </p>
                      <p>
                        <code>apt-cache pkgnames
                        </code>
                        You should see the Ambari packages in the list.
                      </p>
                      <p>
                        Version values vary, depending on the installation.
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          <thead></thead>
                          <tbody>
                            <tr>
                              <th rowspan="1">
                                <p>
                                  <strong>Alias</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>Name</strong>
                                </p>
                              </th>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>AMBARI-dev-2.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Ambari 2.x</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                    </li>
                    <li>
                      <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                      <p>
                        <code>apt-get install ambari-server</code>
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
            <div class="tab">
              <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
              <div class="tab-content">
                <p>
                  On a server host that has Internet access, use a command line editor to perform the following steps:
                </p>
                <ul class="number-list">
                  RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)
                  
                    <li>
                      <p>Log in to your host as<code>root</code>. You may
                        <code>sudo</code>
                        as
                        <code>su</code>
                        if your environment requires such access. For example, type:
                      </p>
                    </li>
                    <li>
                      <p>
                        &lt;username&gt;
                        <code>ssh</code>
                        &lt;hostname.FQDN&gt;
                        <code>sudo su -</code>
                        where
                        &lt;username&gt;
                        is your user name and
                        &lt;hostname.FQDN&gt;
                        is the fully qualified domain name of your server host.
                      </p>
                    </li>
                    <li>
                      <p>Download the Ambari repository file to a directory on your installation host.
                        <code>
                          wget -nv http://public-repo-1.hortonworks.com/ambari/centos5/1.x/updates/1.7.0/ambari.repo -O
                          /etc/yum.repos.d/ambari.repo
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Important.png" width="50"></div>
                        <div class="simple-block">
                          <p>Do not modify the
                            <code>ambari.repo</code>
                            file name. This file is expected to be available on the Ambari Server host during Agent
                            registration.
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>Confirm the repository is configured by checking the repo list.</p>
                      <p>
                        <code>yum repolist</code>
                        You should see the Ambari repositories in the list.
                      </p>
                      <p>
                        <code>AMBARI.1.7.0-1.x | 951 B 00:00
                          AMBARI.1.7.0-1.x/primary | 1.6 kB 00:00
                          AMBARI.1.7.0-1.x 5/5
                          epel | 3.7 kB 00:00
                          epel/primary_db | 3.9 MB 00:01
                        </code>
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          
                          <thead></thead>
                          <tbody>
                            <tr>
                              <th rowspan="1">
                                <p>
                                  <strong>repo Id</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>repo Name</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>status</strong>
                                </p>
                              </th>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>AMBARI.1.7.0-1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Ambari 1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>5</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>base</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-5 - Base</p>
                              </td>
                              <td rowspan="1">
                                <p>3,667</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>epel</p>
                              </td>
                              <td rowspan="1">
                                <p>Extra Packages for Enterprise Linux 5 - x86_64</p>
                              </td>
                              <td rowspan="1">
                                <p>7,614</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>puppet</p>
                              </td>
                              <td rowspan="1">
                                <p>Puppet</p>
                              </td>
                              <td rowspan="1">
                                <p>433</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>updates</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-5 - Updates</p>
                              </td>
                              <td rowspan="1">
                                <p>118</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                    </li>
                    <li>
                      <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                      <p>
                        <code>yum install ambari-server</code>
                        <code></code>
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
          </div>
        
        
          <p>
            Follow instructions in the section for the operating system that runs on your installation host.
            Use a command line editor to perform each instruction.
          </p>
          <ul class="number-list">
            RHEL/CentOS/Oracle Linux 6
            
              <li>
                <p>Log in to your host as<code>root</code>. You may
                  <code>sudo</code>
                  as
                  <code>su</code>
                  if your environment requires such access. For example, type:
                </p>
                <p>
                  &lt;username&gt;
                  <code>ssh</code>
                  &lt;hostname.FQDN&gt;
                  <code>sudo su -</code>
                  where
                  &lt;username&gt;
                  is your user name and
                  &lt;hostname.FQDN&gt;
                  is the fully qualified domain name of your server host.
                </p>
              </li>
              <li>
                <p>Download the Ambari repository file to a directory on your installation host.</p>
                <p>
                  <code>wget -nv
                    http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.7.0/ambari.repo -O
                    /etc/yum.repos.d/ambari.repo
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Do not modify the
                      <code>ambari.repo</code>
                      file name. This file is expected to be available on the Ambari Server host during Agent
                      registration.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Confirm that the repository is configured by checking the repo list.</p>
                <p>
                  <code>yum repolist</code>
                  You should see values similar to the following for Ambari repositories in the list.
                </p>
                <p>
                  Version values vary, depending on the installation.
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    
                    <thead></thead>
                    <tbody>
                      <tr>
                        <th rowspan="1">
                          <p>
                            <strong>repo id</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>repo name</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>status</strong>
                          </p>
                        </th>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>AMBARI.1.7.0-1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Ambari 1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>5</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>base</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-6 - Base</p>
                        </td>
                        <td rowspan="1">
                          <p>6,518</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>extras</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-6 - Extras</p>
                        </td>
                        <td rowspan="1">
                          <p>15</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>updates</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-6 - Updates</p>
                        </td>
                        <td rowspan="1">
                          <p>209</p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
              <li>
                <p>Install the Ambari bits. This also installs the default PostgreSQL Ambari database.</p>
                <p>
                  <code>yum install ambari-server</code>
                </p>
              </li>
              <li>
                <p>Enter
                  <code>y</code>
                  when prompted to to confirm transaction and dependency checks.
                </p>
                <p>A successful installation displays output similar to the following:
                  <code>Installing : postgresql-libs-8.4.20-1.el6_5.x86_64 1/4
                    Installing : postgresql-8.4.20-1.el6_5.x86_64 2/4
                    Installing : postgresql-server-8.4.20-1.el6_5.x86_64 3/4
                    Installing : ambari-server-1.7.0-135.noarch 4/4
                    Verifying : postgresql-server-8.4.20-1.el6_5.x86_64 1/4
                    Verifying : postgresql-libs-8.4.20-1.el6_5.x86_64 2/4
                    Verifying : ambari-server-1.7.0-135.noarch 3/4
                    Verifying : postgresql-8.4.20-1.el6_5.x86_64 4/4

                    Installed:
                    ambari-server.noarch 0:1.7.0-135

                    Dependency Installed:
                    postgresql.x86_64 0:8.4.20-1.el6_5 postgresql-libs.x86_64 0:8.4.20-1.el6_5
                    postgresql-server.x86_64 0:8.4.20-1.el6_5

                    Complete!
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>Accept the warning about trusting the Pivotal GPG Key. That key will be automatically
                      downloaded and used to validate packages from Pivotal. You will see the following message:

                      <code>Importing GPG key 0x07513CAD:
                        Userid: "Jenkins (HDP Builds) &lt;jenkin@hortonworks.com&gt;"
                        From :
                        http://s3.amazonaws.com/dev.hortonworks.com/ambari/centos6/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
                      </code>
                    </p>
                  </div>
                </aside>
              </li>
            
          </ul>
          <ul class="number-list">
            SLES 11
            
              <li>
                <p>Log in to your host as<code>root</code>. You may
                  <code>sudo</code>
                  as
                  <code>su</code>
                  if your environment requires such access. For example, type:
                </p>
              </li>
              <li>
                <p>
                  &lt;username&gt;
                  <code>ssh</code>
                  &lt;hostname.FQDN&gt;
                  <code>sudo su -</code>
                  where
                  &lt;username&gt;
                  is your user name and
                  &lt;hostname.FQDN&gt;
                  is the fully qualified domain name of your server host.
                </p>
              </li>
              <li>
                <p>Download the Ambari repository file to a directory on your installation host.
                  <code>wget -nv
                    http://public-repo-1.hortonworks.com/ambari/suse11/1.x/updates/1.7.0/ambari.repo -O
                    /etc/zypp/repos.d/ambari.repo
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Do not modify the
                      <code>ambari.repo</code>
                      file name. This file is expected to be available on the Ambari Server host during Agent
                      registration.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Confirm the downloaded repository is configured by checking the repo list.</p>
                <p>
                  <code>zypper repos</code>
                  You should see the Ambari repositories in the list.
                </p>
                <p>
                  Version values vary, depending on the installation.
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    
                    
                    <thead></thead>
                    <tbody>
                      <tr>
                        <th rowspan="1">
                          <p>
                            <strong>Alias</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>Name</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>Enabled</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>Refresh</strong>
                          </p>
                        </th>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>AMBARI.1.7.0-1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Ambari 1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>No</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>http-demeter.uni-regensburg.de-c997c8f9</p>
                        </td>
                        <td rowspan="1">
                          <p>SUSE-Linux-Enterprise-Software-Development-Kit-11-SP1 11.1.1-1.57</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>opensuse</p>
                        </td>
                        <td rowspan="1">
                          <p>OpenSuse</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
              <li>
                <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                <p>
                  <code>zypper install ambari-server</code>
                </p>
              </li>
              <li>
                <p>Enter
                  <code>y</code>
                  when prompted to to confirm transaction and dependency checks.
                </p>
                <p>
                  <code>A successful installation displays output similar to the following:
                    Retrieving package postgresql-libs-8.3.5-1.12.x86_64 (1/4), 172.0 KiB (571.0 KiB unpacked)
                    Retrieving: postgresql-libs-8.3.5-1.12.x86_64.rpm [done (47.3 KiB/s)]
                    Installing: postgresql-libs-8.3.5-1.12 [done]
                    Retrieving package postgresql-8.3.5-1.12.x86_64 (2/4), 1.0 MiB (4.2 MiB unpacked)
                    Retrieving: postgresql-8.3.5-1.12.x86_64.rpm [done (148.8 KiB/s)]
                    Installing: postgresql-8.3.5-1.12 [done]
                    Retrieving package postgresql-server-8.3.5-1.12.x86_64 (3/4), 3.0 MiB (12.6 MiB unpacked)
                    Retrieving: postgresql-server-8.3.5-1.12.x86_64.rpm [done (452.5 KiB/s)]
                    Installing: postgresql-server-8.3.5-1.12 [done]
                    Updating etc/sysconfig/postgresql...
                    Retrieving package ambari-server-1.7.0-135.noarch (4/4), 99.0 MiB (126.3 MiB unpacked)
                    Retrieving: ambari-server-1.7.0-135.noarch.rpm [done (3.0 MiB/s)]
                    Installing: ambari-server-1.7.0-135 [done]
                    ambari-server 0:off 1:off 2:off 3:on 4:off 5:on 6:off
                  </code>
                </p>
              </li>
            
          </ul>
          <ul class="number-list">
            UBUNTU 12
            
              <li>
                <p>Log in to your host as<code>root</code>. You may
                  <code>sudo</code>
                  as
                  <code>su</code>
                  if your environment requires such access. For example, type:
                </p>
              </li>
              <li>
                <p>
                  &lt;username&gt;
                  <code>ssh</code>
                  &lt;hostname.FQDN&gt;
                  <code>sudo su -</code>
                  where
                  &lt;username&gt;
                  is your user name and
                  &lt;hostname.FQDN&gt;
                  is the fully qualified domain name of your server host.
                </p>
              </li>
              <li>
                <p>Download the Ambari repository file to a directory on your installation host.
                  <code>wget -nv
                    http://public-repo-1.hortonworks.com/ambari/ubuntu12/1.x/updates/1.7.0/ambari.list -O
                    /etc/apt/sources.list.d/ambari.list

                    apt-key adv --recv-keys --keyserver keyserver.ubuntu.com B9733A7A07513CAD

                    apt-get update
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Do not modify the
                      <code>ambari.list</code>
                      file name. This file is expected to be available on the Ambari Server host during Agent
                      registration.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Confirm that Ambari packages downloaded successfully by checking the package name list.
                </p>
                <p>
                  <code>apt-cache pkgnames
                  </code>
                  You should see the Ambari packages in the list.
                </p>
                <p>
                  Version values vary, depending on the installation.
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    <thead></thead>
                    <tbody>
                      <tr>
                        <th rowspan="1">
                          <p>
                            <strong>Alias</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>Name</strong>
                          </p>
                        </th>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>AMBARI-dev-2.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Ambari 2.x</p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
              <li>
                <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                <p>
                  <code>apt-get install ambari-server</code>
                </p>
              </li>
            
          </ul>
          <ul class="number-list">
            RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)
            
              <li>
                <p>Log in to your host as<code>root</code>. You may
                  <code>sudo</code>
                  as
                  <code>su</code>
                  if your environment requires such access. For example, type:
                </p>
              </li>
              <li>
                <p>
                  &lt;username&gt;
                  <code>ssh</code>
                  &lt;hostname.FQDN&gt;
                  <code>sudo su -</code>
                  where
                  &lt;username&gt;
                  is your user name and
                  &lt;hostname.FQDN&gt;
                  is the fully qualified domain name of your server host.
                </p>
              </li>
              <li>
                <p>Download the Ambari repository file to a directory on your installation host.
                  <code>
                    wget -nv http://public-repo-1.hortonworks.com/ambari/centos5/1.x/updates/1.7.0/ambari.repo -O
                    /etc/yum.repos.d/ambari.repo
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Do not modify the
                      <code>ambari.repo</code>
                      file name. This file is expected to be available on the Ambari Server host during Agent
                      registration.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Confirm the repository is configured by checking the repo list.</p>
                <p>
                  <code>yum repolist</code>
                  You should see the Ambari repositories in the list.
                </p>
                <p>
                  <code>AMBARI.1.7.0-1.x | 951 B 00:00
                    AMBARI.1.7.0-1.x/primary | 1.6 kB 00:00
                    AMBARI.1.7.0-1.x 5/5
                    epel | 3.7 kB 00:00
                    epel/primary_db | 3.9 MB 00:01
                  </code>
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    
                    <thead></thead>
                    <tbody>
                      <tr>
                        <th rowspan="1">
                          <p>
                            <strong>repo Id</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>repo Name</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>status</strong>
                          </p>
                        </th>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>AMBARI.1.7.0-1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Ambari 1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>5</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>base</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-5 - Base</p>
                        </td>
                        <td rowspan="1">
                          <p>3,667</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>epel</p>
                        </td>
                        <td rowspan="1">
                          <p>Extra Packages for Enterprise Linux 5 - x86_64</p>
                        </td>
                        <td rowspan="1">
                          <p>7,614</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>puppet</p>
                        </td>
                        <td rowspan="1">
                          <p>Puppet</p>
                        </td>
                        <td rowspan="1">
                          <p>433</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>updates</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-5 - Updates</p>
                        </td>
                        <td rowspan="1">
                          <p>118</p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
              <li>
                <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                <p>
                  <code>yum install ambari-server</code>
                  <code></code>
                </p>
              </li>
            
          </ul>
          
        
        
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>When deploying HDP on a cluster having limited or no Internet access, you should provide access
                to the bits using an alternative method.
              </p>
              <ul class="bullet-list">
                
                  <li>
                    <p>For more information about setting up local repositories, see<a href="#ref-28d7e1f2-0adb-436a-a4b1-65b522fdcdf2">Optional: Configure Local
                      Repositories</a>.
                    </p>
                  </li>
                  <li>
                    <p>For more information about obtaining JCE policy archives for secure authentication, see
                      <a href="#ref-ec1f472e-3232-4a81-acc5-b3ef236f4737">Deploying JCE Policy Archives on the
                        Ambari Server</a>.
                    </p>
                  </li>
                
              </ul>
              <p>
                Ambari Server by default uses an embedded PostgreSQL database. When you install the Ambari Server, the
                PostgreSQL packages and dependencies must be available for install. These packages are typically
                available as part of your Operating System repositories. Please confirm you have the appropriate
                repositories available for the postgresql-server packages.
              </p>
            </div>
          </aside>
        
      
      
        <h3 class="horton-blue bold" id="ref-77031023-81db-4b1c-9434-2b68372a9920">Set Up the Ambari Server</h3>
        
          <p>The
            <code>ambari-server</code>
            command manages the setup process. Run the following command on the Ambari server host:
            You may append
            <a href="#ref-0edea938-0643-4e85-8906-3b02146100ba">Setup Options</a>
            to the command.

            <code>ambari-server setup</code>

            Respond to the following prompts:
          </p>
          <ul class="number-list">
            
              <li>
                <p>If you have
                  <i>not</i>
                  temporarily disabled SELinux, you may get a warning. Accept the default (<code>y</code>),
                  and continue.
                </p>
              </li>
              <li>
                <p>By default, Ambari Server runs under<code>root</code>. Accept the default (n) at
                  the
                  <code>Customize user account for ambari-server daemon</code>
                  prompt, to proceed as<code>root</code>.
                  If you want to create a different user to run the Ambari Server, or to assign a previously created
                  user, select
                  <code>y</code>
                  at the
                  <code>Customize user account for ambari-server daemon</code>
                  prompt, then provide a user name.
                </p>
              </li>
              <li>
                <p>If you have not temporarily disabled
                  <code>iptables</code>
                  you may get a warning. Enter
                  <code>y</code>
                  to continue.
                </p>
              </li>
              <li>
                <p>Select a JDK version to download. Enter 1 to download Oracle JDK 1.7.</p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>By default, Ambari Server setup downloads and installs Oracle JDK 1.7 and the accompanying
                      Java Cryptography Extension (JCE) Policy Files. If you plan to use a different version of the JDK,
                      see
                      <a href="#ref-0edea938-0643-4e85-8906-3b02146100ba">Setup Options</a>
                      for more information.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Accept the Oracle JDK license when prompted. You must accept this license to download the
                  necessary JDK from Oracle. The JDK is installed during the deploy phase.
                </p>
              </li>
              <li>
                <p>Select
                  <code>n</code>
                  at
                  <code>Enter advanced database configuration</code>
                  to use the default, embedded PostgreSQL database for Ambari. The default PostgreSQL database name is
                  <code>ambari</code>. The default user name and password are<code>
                    ambari/bigdata</code>.
                  Otherwise, to use an existing PostgreSQL, MySQL or Oracle database with Ambari, select<code>
                    y</code>.
                </p>
                <ul class="Bullet">
                  
                    <li>
                      <p>If you are using an existing PostgreSQL, MySQL, or Oracle database instance, use one of
                        the following prompts:
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Important.png" width="50"></div>
                        <div class="simple-block">
                          <p>You must prepare a non-default database instance, using the steps detailed in<a href="#ref-6db1b3ae-7e80-4a7c-a73d-20f11379078f">Using Non-Default
                            Databases-Ambari</a>, before running setup and entering advanced database configuration.
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>To use an existing Oracle 11g r2 instance, and select your own database name, user name,
                        and password for that database, enter<code>2</code>.
                      </p>
                      <p>Select the database you want to use and provide any information requested at the
                        prompts, including host name, port, Service Name or SID, user name, and password.
                      </p>
                    </li>
                    <li>
                      <p>To use an existing MySQL 5.x database, and select your own database name, user name, and
                        password for that database, enter<code>3</code>.
                      </p>
                      <p>Select the database you want to use and provide any information requested at the
                        prompts, including host name, port, database name, user name, and password.
                      </p>
                    </li>
                    <li>
                      <p>To use an existing PostgreSQL 9.x database, and select your own database name, user
                        name, and password for that database, enter<code>4</code>.
                      </p>
                      <p>Select the database you want to use and provide any information requested at the
                        prompts, including host name, port, database name, user name, and password.
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>At Proceed with configuring remote database connection properties [y/n] choose<code>
                  y</code>.
                </p>
              </li>
              <li>
                <p>Setup completes.</p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>If your host accesses the Internet through a proxy server, you must configure Ambari
                      Server to use this proxy server. See
                      <a href="#ref-0c356526-e74c-4420-a686-8b9bc17dd0c1">How to Set Up an Internet Proxy
                        Server for Ambari
                      </a>
                      for more information.
                    </p>
                  </div>
                </aside>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Setup Options</h4>
          
            <p>The following table describes options frequently used for Ambari Server setup.</p>
            <div class="xyleme-table"><table border="1">
              
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Option</p>
                    </th>
                    <th rowspan="1">
                      <p>Description</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>-j (or --java-home)</p>
                    </td>
                    <td rowspan="1">
                      <p>Specifies the JAVA_HOME path to use on the Ambari Server and all hosts in the cluster.
                        By default when you do not specify this option, Ambari Server setup downloads the Oracle JDK 1.7
                        binary and accompanying Java Cryptography Extension (JCE) Policy Files to
                        /var/lib/ambari-server/resources. Ambari Server then installs the JDK to /usr/jdk64.

                        Use this option when you plan to use a JDK other than the default Oracle JDK 1.7. See
                        <a href="#ref-c81d7e9a-dc5d-4ab4-a12c-34428c1f13dc">JDK Requirements</a>
                        for more information on the supported JDKs. If you are using an alternate JDK, you must manually
                        install the JDK on all hosts and specify the Java Home path during Ambari Server setup. If you
                        plan to use Kerberos, you must also install the JCE on all hosts.

                        This path must be valid on all hosts.
                        For example:
                        <code>ambari-server setup –j /usr/java/default</code>
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>--jdbc-driver</p>
                    </td>
                    <td rowspan="1">
                      <p>Should be the path to the JDBC driver JAR file. Use this option to specify the location
                        of the JDBC driver JAR and to make that JAR available to Ambari Server for distribution to
                        cluster hosts during configuration. Use this option with the --jdbc-db option to specify the
                        database type.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>--jdbc-db</p>
                    </td>
                    <td rowspan="1">
                      <p>Specifies the database type. Valid values are: [postgres | mysql | oracle] Use this
                        option with the --jdbc-driver option to specify the location of the JDBC driver JAR file.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>-s (or --silent)</p>
                    </td>
                    <td rowspan="1">
                      <p>Setup runs silently. Accepts all default prompt values.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>-v (or --verbose)</p>
                    </td>
                    <td rowspan="1">
                      <p>Prints verbose info and warning messages to the console during Setup.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>-g (or --debug)</p>
                    </td>
                    <td rowspan="1">
                      <p>Start Ambari Server in debug mode</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <p>
              <strong>Next Steps</strong>
            </p>
            <p>
              <a href="#ref-e59488d8-be73-492b-948d-5d8cc16429df">Start the Ambari Server</a>
            </p>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-e59488d8-be73-492b-948d-5d8cc16429df">Start the Ambari Server</h3>
        
          <ul class="bullet-list">
            
              <li>
                <p>Run the following command on the Ambari Server host:</p>
                <p>
                  <code>ambari-server start</code>
                </p>
              </li>
              <li>
                <p>To check the Ambari Server processes:</p>
                <p>
                  <code>ambari-server status</code>
                </p>
              </li>
              <li>
                <p>To stop the Ambari Server:</p>
                <p>
                  <code>ambari-server stop</code>
                </p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>If you plan to use an existing database instance for Hive/HCatalog or for Oozie, you must
                complete the preparations described in
                <a href="#ref-b9803b8c-5f91-40d5-bdc4-da481581efbf">Using Non-Default Databases-Oozie</a>
                <strong>before</strong>
                installing your Hadoop cluster.
              </p>
            </div>
          </aside>
          <p>
            <strong>Next Steps</strong>
          </p>
          <p>
            <a href="#ref-eb879df1-7042-4733-9221-4f2a7035d3e3">Install, configure and deploy an HDP cluster
            </a>
          </p>
        
      
    
    
      <h2 class="horton-green bold">Install, Configure and Deploy a HDP Cluster</h2>
      
        
          <p>This section describes how to use the Ambari install wizard running in your browser to install,
            configure, and deploy your cluster.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-13630fcb-440e-4e40-8392-ebcef86e9998">Log In to Apache Ambari</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-63454c1d-0873-4d81-b26e-b0901fe1b9ae">Name Your Cluster</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-955326d7-d6cf-4f0e-850b-4fb69b6bdc67">Select Stack</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-2db43b02-dfa3-41d2-8119-477b0f155ed6">Install Options</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-22984912-bf44-4b20-a804-8eed2033a8fb">Confirm Hosts</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-97d6e6ed-5f78-43ee-9b30-5a87e7bb37f4">Choose Services</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-a7effb31-eab4-4ed4-a0a9-00e24aa8fa42">Assign Masters</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-b4839e64-9f2f-4ee8-89c3-cc0d87322bb5">Assign Slaves and Clients</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-b3006969-a1ed-4a39-8fba-64a8295dbbd7">Customize Services</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-f69250a6-a5c4-41a9-a1ce-ef5aa2f91b3b">Review</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-ba4db19d-f9b4-4d40-99f0-dc01564f4b21">Install, Start and Test</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-3e303bad-752a-4f5d-9616-be9542881920">Complete</a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-13630fcb-440e-4e40-8392-ebcef86e9998">Log In to Apache Ambari</h3>
        
          <p>After starting the Ambari service, open Ambari Web using a web browser.</p>
          <ul class="number-list">
            
              <li>
                <p>Point your browser to
                  <code>http://</code>
                  &lt;your.ambari.server&gt;
                  <code>:8080</code>,<code></code>where
                  &lt;your.ambari.server&gt;
                  is the name of your ambari server host. For example, a default Ambari server host is located at
                  http://c6401.ambari.apache.org:8080.
                </p>
              </li>
              <li>
                <p>Log in to the Ambari Server using the default user name/password: admin/admin. You can change
                  these credentials later.
                </p>
                <p>For a new cluster, the Ambari install wizard displays a Welcome page from which you<a href="#ref-2f2795fb-36cd-45e0-8950-be9fac3a2a2f">launch the Ambari Install wizard</a>.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-2f2795fb-36cd-45e0-8950-be9fac3a2a2f">Launching the Ambari Install Wizard</h3>
        
          <p>From the Ambari Welcome page, choose Launch Install Wizard.</p>
          <div class="figure">
            
              
                
                <img src="System%20Admin%20Guides/Ambari/170Install/170AmbariWelcome.png" width="50">
              
            
          </div>
        
      
      
        <h3 class="horton-blue bold" id="ref-63454c1d-0873-4d81-b26e-b0901fe1b9ae">Name Your Cluster</h3>
        
          <ul class="number-list">
            
              <li>
                <p>In<code>Name your cluster</code>, type a name for the cluster you want to
                  create. Use no white spaces or special characters in the name.
                </p>
              </li>
              <li>
                <p>Choose<code>Next</code>.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-955326d7-d6cf-4f0e-850b-4fb69b6bdc67">Select Stack</h3>
        
          <p>The Service Stack (the Stack) is a coordinated and tested set of HDP components. Use a radio button
            to select the Stack version you want to install. To install an HDP 2x stack, select the HDP 2.2, HDP 2.1, or
            HDP 2.0 radio button.
          </p>
          <div class="figure">
            
              
                
                <img src="System%20Admin%20Guides/Ambari/170Install/Stack22_select.png" width="125">
              
            
          </div>
          <p>Expand Advanced Repository Options to select the Base URL of a repository from which Stack software
            packages download. Ambari sets the default Base URL for each repository, depending on the Internet
            connectivity available to the Ambari server host, as follows:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>For an Ambari Server host having Internet connectivity, Ambari sets the repository Base URL
                  for the latest patch release for the HDP Stack version. For an Ambari Server having NO Internet
                  connectivity, the repository Base URL defaults to the latest patch release version available at the
                  time of Ambari release.
                </p>
              </li>
              <li>
                <p>You can override the repository Base URL for the HDP Stack with an earlier patch release if
                  you want to install a specific patch release for a given HDP Stack version. For example, the HDP 2.1
                  Stack will default to the HDP 2.1 Stack patch release 7, or HDP-2.1.7. If you want to install HDP 2.1
                  Stack patch release 2, or HDP-2.1.2 instead, obtain the Base URL from the HDP Stack documentation,
                  then enter that location in Base URL.
                </p>
              </li>
              <li>
                <p>If you are using a local repository, see
                  <a href="#ref-28d7e1f2-0adb-436a-a4b1-65b522fdcdf2">Optional: Configure Ambari for Local
                    Repositories
                  </a>
                  for information about configuring a local repository location, then enter that location as the Base
                  URL instead of the default, public-hosted HDP Stack repositories.
                </p>
              </li>
            
          </ul>
          <div class="figure">
            
              
                <img src="System%20Admin%20Guides/Ambari/170Install/AdvRepo170.png" width="50">
              
            
          </div>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>The UI displays repository Base URLs based on Operating System Family (OS Family). Be sure to
                set the correct OS Family based on the Operating System you are running. The following table maps the OS
                Family to the Operating Systems.
              </p>
            </div>
          </aside>
          <div class="xyleme-table"><table border="1">
            <p class="italic bold">Operating Systems mapped to each OS Family</p>
            
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>
                      <strong>OS Family</strong>
                    </p>
                  </th>
                  <th rowspan="1">
                    <p>
                      <strong>Operating Systems</strong>
                    </p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>redhat6</p>
                  </td>
                  <td rowspan="1">
                    <p>Red Hat 6, CentOS 6, Oracle Linux 6</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>suse11</p>
                  </td>
                  <td rowspan="1">
                    <p>SUSE Linux Enterprise Server 11</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>ubuntu12</p>
                  </td>
                  <td rowspan="1">
                    <p>Ubuntu Precise 12.04</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>redhat5</p>
                  </td>
                  <td rowspan="1">
                    <p>Red Hat 5, CentOS 5, Oracle Linux 5</p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
        
      
      
        <h3 class="horton-blue bold" id="ref-2db43b02-dfa3-41d2-8119-477b0f155ed6">Install Options</h3>
        
          <p>In order to build up the cluster, the install wizard prompts you for general information about how
            you want to set it up. You need to supply the FQDN of each of your hosts. The wizard also needs to access
            the private key file you created in <a href="#ref-88addfc9-ec6c-4dcb-b2dd-75b4331d2809">Set Up
              Password-less SSH</a>. Using the host names and key file information, the wizard can locate, access,
            and interact securely with all hosts in the cluster.
          </p>
          <ul class="number-list">
            
              <li>
                <p>Use the
                  <code>Target Hosts</code>
                  text box to enter your list of host names, one per line. You can use ranges inside brackets to
                  indicate larger sets of hosts. For example, for host01.domain through host10.domain use
                  <code>host[01-10].domain</code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>If you are deploying on EC2, use the
                      <strong>internal Private DNS</strong>
                      host names.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>If you want to let Ambari automatically install the Ambari Agent on all your hosts using SSH,
                  select
                  <code>Provide your SSH Private Key</code>
                  and either use the
                  <code>Choose File</code>
                  button in the
                  <code>Host Registration Information</code>
                  section to find the private key file that matches the public key you installed earlier on all your
                  hosts or cut and paste the key into the text box manually.
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>If you are using IE 9, the
                      <strong>Choose File</strong>
                      button may not appear. Use the text box to cut and paste your private key manually.
                    </p>
                  </div>
                </aside>
                <p>Fill in the user name for the SSH key you have selected. If you do not want to use
                  <code>root</code>
                  , you must provide the user name for an account that can execute
                  <code>sudo</code>
                  without entering a password.
                </p>
              </li>
              <li>
                <p>If you do not want Ambari to automatically install the Ambari Agents, select<code>
                  Perform manual registration</code>. For further information, see<a href="#ref-ce168039-28fd-49cd-ba4b-455ce949b471">Installing Ambari Agents Manually</a>.
                </p>
              </li>
              <li>
                <p>Choose
                  <code>Register and Confirm</code>
                  to continue.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-22984912-bf44-4b20-a804-8eed2033a8fb">Confirm Hosts</h3>
        
          <p>
            <code>Confirm Hosts</code>
            prompts you to confirm that Ambari has located the correct hosts for your cluster and to check those hosts
            to make sure they have the correct directories, packages, and processes required to continue the install.
          </p>
          <p>If any hosts were selected in error, you can remove them by selecting the appropriate checkboxes and
            clicking the grey
            <code>Remove</code>
            <code>Selected</code>
            button. To remove a single host, click the small white
            <code>Remove</code>
            <strong></strong>
            button in the Action column.
          </p>
          <p>At the bottom of the screen, you may notice a yellow box that indicates some warnings were
            encountered during the check process. For example, your host may have already had a copy of
            <code>wget</code>
            or<code>curl</code>. Choose
            <code>Click here to see the warnings</code>
            <code></code>to see a list of what was checked and what caused the warning.
            The warnings page also provides access to a python script that can help you clear any issues you may
            encounter and let you run<code>Rerun Checks</code>.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>If you are deploying HDP using Ambari 1.4 or later on RHEL 6.5 you will likely see Ambari Agents
                fail to register with Ambari Server during the “Confirm Hosts” step in the Cluster Install wizard. Click
                the “Failed” link on the Wizard page to display the Agent logs. The following log entry indicates the
                SSL connection between the Agent and Server failed during registration:
                <code>INFO 2014-04-02 04:25:22,669 NetUtil.py:55
                  - Failed to connect to https://&lt;ambari-server&gt;:8440/cert/ca due to [Errno 1] _ssl.c:492:
                  error:100AE081:elliptic curve routines:EC_GROUP_new_by_curve_name:unknown group
                </code>
              </p>
              <p>
                For more information about this issue, see the<a href="#ref-51adbb3c-07ba-479f-82e9-7eb9f0e2fe02">Ambari Troubleshooting Guide</a>.
              </p>
            </div>
          </aside>
          <p>When you are satisfied with the list of hosts, choose<code>Next</code>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-97d6e6ed-5f78-43ee-9b30-5a87e7bb37f4">Choose Services</h3>
        
          <p>Based on the Stack chosen during Select Stack, you are presented with the choice of Services to
            install into the cluster. HDP Stack comprises many services. You may choose to install any other available
            services now, or to
            <a href="#ref-19a49eb0-7d00-4f33-bb7b-ed805a5cd656">add services</a>
            later. The install wizard selects all available services for installation by default.
          </p>
          <ul class="number-list">
            
              <li>
                <p>Choose
                  <code>none</code>
                  to clear all selections, or choose
                  <code>all</code>
                  to select all listed services.
                </p>
              </li>
              <li>
                <p>Choose or clear individual checkboxes to define a set of services to install now.</p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>To use Ambari for monitoring your cluster, you must select
                      <code>Nagios</code>
                      and
                      <code>Ganglia</code>
                      <strong>.</strong>
                      Not selecting these services generates a warning message when you complete this section. If you
                      monitor your cluster using other tools, ignore the warning.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>After selecting the services to install now, choose<code>Next</code>.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-a7effb31-eab4-4ed4-a0a9-00e24aa8fa42">Assign Masters</h3>
        
          <p>The Ambari install wizard assigns the master components for selected services to appropriate hosts
            in your cluster and displays the assignments in Assign Masters. The left column shows services and current
            hosts. The right column shows current master component assignments by host, indicating the number of CPU
            cores and amount of RAM installed on each host.
          </p>
          <ul class="number-list">
            
              <li>
                <p>To change the host assignment for a service, select a host name from the drop-down menu for
                  that service.
                </p>
              </li>
              <li>
                <p>To remove a ZooKeeper instance, click the green minus icon next to the host address you want
                  to remove.
                </p>
              </li>
              <li>
                <p>When you are satisfied with the assignments, choose<code>Next</code>.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-b4839e64-9f2f-4ee8-89c3-cc0d87322bb5">Assign Slaves and Clients</h3>
        
          <p>The Ambari installation wizard assigns the slave components (DataNodes, NodeManagers, and
            RegionServers) to appropriate hosts in your cluster. It also attempts to select hosts for installing the
            appropriate set of clients.
          </p>
          <ul class="number-list">
            
              <li>
                <p>Use
                  <strong>all</strong>
                  or
                  <strong>none</strong>
                  to select all of the hosts in the column or none of the hosts, respectively.
                </p>
                <p>If a host has a red asterisk next to it, that host is also running one or more master
                  components. Hover your mouse over the asterisk to see which master components are on that host.
                </p>
              </li>
              <li>
                <p>Fine-tune your selections by using the checkboxes next to specific hosts.</p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>As an option you can start the HBase REST server manually after the install process is
                      complete. It can be started on any host that has the HBase Master or the Region Server installed.
                      If you attempt to start it on the same host as the Ambari server, however, you need to start it
                      with the -p option, as its default port is 8080 and that conflicts with the Ambari Web default
                      port.
                      <code>/usr/lib/hbase/bin/hbase-daemon.sh start rest -p</code>
                      &lt;custom_port_number&gt;
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>When you are satisfied with your assignments, choose<code>Next</code>.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-b3006969-a1ed-4a39-8fba-64a8295dbbd7">Customize Services</h3>
        
          <p>
            <code>Customize Services</code>
            presents you with a set of tabs that let you manage configuration settings for HDP components. The wizard
            sets reasonable defaults for each of the options here, but you can use this set of tabs to tweak those
            settings. You are strongly encouraged to do so, as your requirements may be slightly different. Pay
            particular attention to the directories suggested by the installer.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Warning.png" width="50"></div>
            <div class="simple-block">
              <p>To prevent out-of-memory errors during the install, at the Customize Services step in the
                Cluster Install wizard browse to<code>Hive &gt; hive-site.xml</code>, then modify the
                following configuration settings:
              </p>
              <div class="xyleme-table"><table border="1">
                
                  
                  
                  
                  
                  <thead>
                    <tr>
                      <th rowspan="1">
                        <p>Property Name</p>
                      </th>
                      <th rowspan="1">
                        <p>Purpose</p>
                      </th>
                      <th rowspan="1">
                        <p>Default Value</p>
                      </th>
                      <th rowspan="1">
                        <p>Required Value</p>
                      </th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td rowspan="1">
                        <p>fs.hdfs.impl.disable.cache</p>
                      </td>
                      <td rowspan="1">
                        <p>Disable HDFS filesystem cache</p>
                      </td>
                      <td rowspan="1">
                        <p>false</p>
                      </td>
                      <td rowspan="1">
                        <p>true</p>
                      </td>
                    </tr>
                    <tr>
                      <td rowspan="1">
                        <p>fs.file.impl.disable.cache</p>
                      </td>
                      <td rowspan="1">
                        <p>Disable local filesystem cache</p>
                      </td>
                      <td rowspan="1">
                        <p>false</p>
                      </td>
                      <td rowspan="1">
                        <p>true</p>
                      </td>
                    </tr>
                  </tbody>
                  
                
              </table></div>
            </div>
          </aside>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>For the
                <code>HDFSServicesConfigsGeneral</code>
                configuration property, make sure to enter an integer value, in bytes, that sets the HDFS maximum edit
                log size for checkpointing. A typical value is 500000000.
              </p>
            </div>
          </aside>
          <p>Hover your cursor over each of the properties to see a brief description of what it does. The number
            of tabs you see is based on the type of installation you have decided to do. A typical installation has at
            least ten groups of configuration properties and other related options, such as database settings for
            Hive/HCat and Oozie, admin name/password, and alert email for Nagios.
          </p>
          <p>The install wizard sets reasonable defaults for all properties. You must provide database passwords
            for the Hive, Nagios, and Oozie services, the Master Secret for Knox, and a valid email address to which
            system alerts will be sent. Select each service that displays a number highlighted red. Then, fill in the
            required field on the Service Config tab. Repeat this until the red flags disappear.

            For example, Choose Hive. Expand the Hive Metastore section, if necessary. In Database Password, provide a
            password, then retype to confirm it, in the fields marked red and "This is required."
          </p>
          <p>For more information about customizing specific services for a particular HDP Stack, see<a href="http://docs.hortonworks.com/HDPDocuments/Ambari-1.7.0.0/Ambari_Reference_Guide_v170/index.html#Item2.1">
            Customizing HDP Services</a>.

            After you complete Customizing Services, choose<code>Next</code>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-f69250a6-a5c4-41a9-a1ce-ef5aa2f91b3b">Review</h3>
        
          <p>The assignments you have made are displayed. Check to make sure everything is correct. If you need
            to make changes, use the left navigation bar to return to the appropriate screen.
          </p>
          <p>To print your information for later reference, choose<code>Print</code>.
          </p>
          <p>When you are satisfied with your choices, choose<code>Deploy</code>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-ba4db19d-f9b4-4d40-99f0-dc01564f4b21">Install, Start and Test</h3>
        
          <p>The progress of the install displays on the screen. Ambari installs, starts, and runs a simple test
            on each component. Overall status of the process displays in progress bar at the top of the screen and
            host-by-host status displays in the main section. Do not refresh your browser during this process.
            Refreshing the browser may interrupt the progress indicators.
          </p>
          <p>To see specific information on what tasks have been completed per host, click the link in the
            <code>Message</code>
            column for the appropriate host. In the
            <code>Tasks</code>
            pop-up, click the individual task to see the related log files. You can select filter conditions by using
            the
            <code>Show</code>
            drop-down list. To see a larger version of the log contents, click the
            <code>Open</code>
            icon or to copy the contents to the clipboard, use the
            <code>Copy</code>
            icon.
          </p>
          <p>When
            <code>Successfully installed and started the services</code>
            appears, choose<code>Next</code>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-3e303bad-752a-4f5d-9616-be9542881920">Complete</h3>
        
          <p>The Summary page provides you a summary list of the accomplished tasks. Choose<code>
            Complete</code>. Ambari Web GUI displays.
          </p>
        
      
    
    
      <h2 class="horton-green bold">Upgrading Ambari</h2>
      
        
          <p>This section describes how to upgrade Ambari Server to 1.7.0, including how to upgrade the HDP stack
            to 2.2 and how to upgrade an older Ambari Server version to 1.2.5.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-57af99ac-4d29-4d2f-ab59-49bd0de14c97">Upgrading Ambari Server to 1.7.0</h3>
        
          <p>This procedure upgrades Ambari Server from version 1.2.5 and above to 1.7.0. If your current Ambari
            Server version is 1.2.4 or below, you must
            <a href="#ref-3a224c6c-b15e-4318-b71e-68db9103ec5d">upgrade the Ambari Server version to 1.2.5
            </a>
            before upgrading to version 1.7.0. Upgrading the Ambari Server version does not change the underlying Hadoop
            Stack.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Important.png" width="50"></div>
            <div class="simple-block">
              <p>Before Upgrading Ambari to 1.7.0, make sure that you perform the following actions:</p>
              <ul class="bullet-list">
                
                  <li>
                    <p>You
                      <strong>
                        <i>must</i>
                      </strong>
                      have root, administrative, or root-equivalent authorization on the Ambari server host and all
                      servers in the cluster.
                    </p>
                  </li>
                  <li>
                    <p>You
                      <strong>
                        <i>must</i>
                      </strong>
                      know the location of the Nagios server before you begin the upgrade process.
                      For example, to find the Nagios server using Ambari 1.6.0 or higher:
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>Browse
                            <code>Ambari Web</code>
                            &gt;
                            <code>Services</code>
                            &gt;
                            <code>Summary</code>
                          </p>
                        </li>
                        <li>
                          <p>Select the
                            <code>Nagios Server</code>
                            link
                          </p>
                        </li>
                        <li>
                          <p>Scroll down to view summary information about the Nagios server host</p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>If you are using Ambari with Oracle, you
                      <strong>
                        <i>must</i>
                      </strong>
                      create an Ambari user in the Oracle database and grant that user all required permissions.
                      Specifically, you must alter the Ambari database user and grant the SEQUENCE permission.
                      For more information about creating users and granting required user permissions, see<a href="#ref-e9b1e9fd-5904-46a7-a36c-3d3b96925f6a">Using Ambari with Oracle</a>.
                    </p>
                  </li>
                  <li>
                    <p>If you plan to upgrade your Stack, back up the configuration properties for your current
                      Hadoop services.
                      For more information about upgrading the Stack and locating the configuration files for your
                      current services, see one of the following topics:
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>
                            <a href="#ref-c30073a7-f386-4d8a-9619-8dde14e3e4d1">Upgrade from HDP 2.1 to HDP
                              2.2, Getting Ready to Upgrade
                            </a>
                          </p>
                        </li>
                        <li>
                          <p>
                            <a href="#ref-24d144de-9940-47d5-a9ea-e4480d3ddb02">Upgrade from HDP 2.0 to HDP
                              2.2, Getting Ready to Upgrade
                            </a>
                          </p>
                        </li>
                        <li>
                          <p>
                            <a href="#ref-2c87cbec-f2e9-4c82-96c6-de295bbd589f">Upgrade from HDP 1.3 to HDP
                              2.2, Getting Ready to Upgrade
                            </a>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                
              </ul>
            </div>
          </aside>
          <ul class="number-list">
            
              <li>
                <p>Stop the Nagios and Ganglia services.
                  In<code>Ambari Web</code>:
                </p>
                <ul class="Numeric">
                  
                    <li>
                      <p>Browse to
                        <code>Services</code>
                        and select the Nagios service.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>Service Actions</code>
                        to stop the Nagios service.
                      </p>
                    </li>
                    <li>
                      <p>Wait for the Nagios service to stop.</p>
                    </li>
                    <li>
                      <p>Browse to
                        <code>Services</code>
                        and select the Ganglia service.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>Service Actions</code>
                        to stop the Ganglia service.
                      </p>
                    </li>
                    <li>
                      <p>Wait for the Ganglia service to stop.</p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Stop the Ambari Server. On the Ambari Server host,</p>
                <p>
                  <code>ambari-server stop</code>
                </p>
              </li>
              <li>
                <p>Stop all Ambari Agents. On each Ambari Agent host,</p>
                <p>
                  <code>ambari-agent stop</code>
                </p>
              </li>
              <li>
                <p>Fetch the new Ambari repo using
                  <code>wget</code>
                  and replace the old repository file with the new repository file on all hosts in your cluster.
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Check your current directory before you download the new repository file to make sure that
                      there are no previous versions of the ambari.repo file. If you do not, and a previous version
                      exists, the new download will be saved with a numeric extension, such as ambari.repo.1. Make sure
                      that the version you copy is the new version.
                    </p>
                  </div>
                </aside>
                <p>
                  Select the repository appropriate for your environment from the following list:
                </p>
                <ul class="Bullet">
                  
                    <li>
                      <p>
                        <strong>For RHEL/CentOS 6/Oracle Linux 6:</strong>
                      </p>
                      <pre><code>wget -nv http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.7.0/ambari.repo
                        -O /etc/yum.repos.d/ambari.repo
                      </code></pre>
                    </li>
                    <li>
                      <p>
                        <strong>For SLES 11:</strong>
                      </p>
                      <pre><code>wget -nv http://public-repo-1.hortonworks.com/ambari/suse11/1.x/updates/1.7.0/ambari.repo -O
                        /etc/zypp/repos.d/ambari.repo
                      </code></pre>
                    </li>
                    <li>
                      <p>For Ubuntu 12:</p>
                      <pre><code>wget -nv http://public-repo-1.hortonworks.com/ambari/ubuntu12/1.x/updates/1.7.0/ambari.list
                        -O /etc/apt/sources/list.d/ambari.list
                      </code></pre>
                    </li>
                    <li>
                      <p>
                        <strong>For RHEL/CentOS 5/Oracle Linux 5:</strong>
                        (DEPRECATED)
                      </p>
                      <pre><code>wget -nv http://public-repo-1.hortonworks.com/ambari/centos5/1.x/updates/1.7.0/ambari.repo
                        -O /etc/yum.repos.d/ambari.repo
                      </code></pre>
                    </li>
                  
                </ul>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>If your cluster does not have access to the Internet, set up a local repository with this
                      data before you continue. See
                      <a href="#ref-28d7e1f2-0adb-436a-a4b1-65b522fdcdf2">Configure the Local Repositories
                      </a>
                      for more information.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Upgrade Ambari Server.</p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>Ambari Server does not automatically turn off<code>iptables</code>. Check that
                      your installation setup does not depend on
                      <code>iptables</code>
                      being disabled. After upgrading the server, you must either disable
                      <code>iptables</code>
                      manually or make sure that you have appropriate ports available on all cluster hosts. For more
                      information about ports, see<a href="#ref-85947452-af53-46f1-96fa-133675313860">
                        Configuring Network Port Numbers</a>.
                    </p>
                  </div>
                </aside>
                <p>At the Ambari Server host:</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>
                        <strong>For RHEL/CentOS/Oracle Linux:</strong>
                      </p>
                      <p>
                        <code>yum clean all
                          yum upgrade ambari-server ambari-log4j
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>
                        <strong>For SLES:</strong>
                      </p>
                      <p>
                        <code>zypper clean
                          zypper up ambari-server ambari-log4j
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>
                        <strong>For Ubuntu:</strong>
                      </p>
                      <p>
                        <code>apt-get clean all
                          apt-get install ambari-server ambari-log4j
                        </code>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Check for upgrade success by noting progress during the Ambari server installation process you
                  started in Step 5.
                </p>
                <ul class="Bullet">
                  
                    <li>
                      <p>As the process runs, the console displays output similar, although not identical, to the
                        following:
                      </p>
                      <pre><code>Setting up Upgrade Process
                        Resolving Dependencies
                        --&gt; Running transaction check
                        ---&gt; Package ambari-server.x86_64 0:1.2.2.3-1 will be updated
                        ---&gt; Package ambari-server.x86_64 0:1.2.2.4-1 will be updated ...
                        ---&gt; Package ambari-server.x86_64 0:1.2.2.5-1 will be an update ...
                      </code></pre>
                    </li>
                    <li>
                      <p>If the upgrade fails, the console displays output similar to the following:</p>
                      <pre><code>Setting up Upgrade Process
                        No Packages marked for Update
                      </code></pre>
                    </li>
                    <li>
                      <p>A successful upgrade displays the following output:</p>
                      <pre><code>Updated: ambari-log4j.noarch 0:1.7.0.111-1 ambari-server.noarch 0:1.7.0-111 Complete!</code></pre>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Upgrade the Ambari Server schema.</p>
                <p>On the Ambari Server host:
                  <code>
                    ambari-server upgrade
                  </code>
                </p>
              </li>
              <li>
                <p>Upgrade the Ambari Agent on all hosts.</p>
                <p>
                  At each Ambari Agent host:
                </p>
                <ul class="NoBullet">
                  
                    <li>
                      <p>
                        <strong>For RHEL/CentOS/Oracle Linux:</strong>
                      </p>
                      <p>
                        <code>yum upgrade ambari-agent ambari-log4j</code>
                      </p>
                    </li>
                    <li>
                      <p>
                        <strong>For SLES:</strong>
                      </p>
                      <p>
                        <code>zypper up ambari-agent ambari-log4j</code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Note.png" width="50"></div>
                        <div class="simple-block">
                          <p>Ignore the warning that begins with "There are some running programs that use files
                            deleted by recent upgrade".
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>
                        <strong>For Ubuntu:</strong>
                      </p>
                      <p>
                        <code>apt-get update
                          apt-get install ambari-agent ambari-log4j
                        </code>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>On each Agent host, check for a file named<code>/etc/ambari-agent/conf.save</code>
                  . If that folder exists, rename it back to
                  <code>/etc/ambari-agent</code>
                  <code>/conf</code>.
                </p>
                <p>
                  <code>mv /etc/ambari-agent/conf.save /etc/ambari-agent/conf</code>
                </p>
              </li>
              <li>
                <p>After the upgrade process completes, check each host to make sure the new 1.7.0 files have
                  been installed:
                </p>
                <p>
                  <code>rpm -qa | grep ambari</code>
                </p>
              </li>
              <li>
                <p>Start the Ambari Server. At the Ambari Server host,</p>
                <p>
                  <code>ambari-server start</code>
                </p>
              </li>
              <li>
                <p>Start the Ambari Agents on all hosts. At each Ambari Agent host,</p>
                <p>
                  <code>ambari-agent start</code>
                </p>
              </li>
              <li>
                <p>Open Ambari Web.
                </p>
                <p>Point your browser to http://&lt;your.ambari.server&gt;:8080

                  where &lt;your.ambari.server&gt; is the name of your ambari server host. For example,
                  c6401.ambari.apache.org.
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Refresh your browser so that it loads the new version of the Ambari Web code. If you have
                      problems, clear your browser cache manually, then restart Ambari Server.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Log in, using the Ambari administrator credentials that you have set up.</p>
                <p>
                  For example, the default name/password is<code>admin/admin</code>.
                </p>
              </li>
              <li>
                <p>Start the Nagios and Ganglia services.</p>
                <p>
                  In Ambari Web,
                </p>
                <ul class="Numeric">
                  
                    <li>
                      <p>Browse to
                        <code>Services</code>
                        and select each service.
                      </p>
                    </li>
                    <li>
                      <p>Use
                        <code>Service Actions</code>
                        to start the service.
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>If you have customized logging properties, you will see a Restart indicator next to each
                  service name after upgrading to Ambari 1.7.0.
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>Restarting a service pushes the configuration properties displayed in
                      <code>Custom log4j.properties</code>
                      to each host running components for that service.
                    </p>
                  </div>
                </aside>
                <p>
                  To preserve any custom logging properties after upgrading, for each service:
                </p>
                <ul class="Numeric">
                  
                    <li>
                      <p>Replace default logging properties with your custom logging properties, using
                        <code>Service Configs &gt; Custom
                          log4j.properties</code>.
                      </p>
                    </li>
                    <li>
                      <p>Restart all components in any services for which you have customized logging
                        properties.
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Review the HDP-UTILS repository Base URL setting.</p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>As of Ambari 1.7.0, the HDP-UTILS repository Base URL is no longer set in the ambari.repo
                      file. Browse to
                      <code>Ambari Web</code>
                      &gt;
                      <code>Admin</code>
                      &gt;<code>Repositories</code>, and confirm the value of the HDP-UTILS
                      repository Base URL is correct for your environment. If you are using a local repository for
                      HDP-UTILS, be sure to confirm the Base URL is correct for your locally hosted HDP-UTILS
                      repository.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Review your Ambari LDAP authentication settings.</p>
                <p>
                  If you have configured Ambari for LDAP authentication, you must re-run "ambari-server setup-ldap". For
                  further information, see<a href="#ref-b810db92-97de-4d4e-a905-239e2b8a2a04">Set Up LDAP or
                  Active Directory Authentication</a>.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-c30073a7-f386-4d8a-9619-8dde14e3e4d1">Upgrading the HDP Stack from 2.1 to 2.2</h3>
        
          <p>The HDP Stack is the coordinated set of Hadoop components that you have installed on hosts in your
            cluster. Your set of Hadoop components and hosts is unique to your cluster. Before upgrading the Stack on
            your cluster, review all Hadoop services and hosts in your cluster. For example, use the Hosts and Services
            views in Ambari Web, which summarize and list the components installed on each Ambari host, to determine the
            components installed on each host. For more information about using Ambari to view components in your
            cluster, see<a href="#ref-c4a195fa-6eec-41a3-a699-14e950d7893b">Working with Hosts</a>, and<a href="#ref-9cb21557-3948-4efa-b3cb-1c65f5b0ad31">Viewing Components on a Host</a>.

            Upgrading the HDP Stack is a three-step procedure:
          </p>
          <ul class="number-list">
            
              <li>
                <p>
                  <a href="#ref-322bc47c-0c63-4ec5-94a8-44cda871c440">Prepare the 2.1 Stack for Upgrade</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-5f38074c-4647-4ddf-9b62-9f77ff25e7db">Upgrade the 2.1 Stack to 2.2</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-dc97be02-1c3a-4a22-ac35-11113b3ec4a5">Complete the Upgrade of the 2.1 Stack to
                    2.2
                  </a>
                </p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>If you plan to<a href="#ref-938c5120-aa38-4cc6-afc7-b7c18ce1f239">upgrade your existing
                JDK</a>, do so after upgrading Ambari, before upgrading the Stack. The upgrade steps require that you
                remove HDP v2.1 components and install HDP v2.2 components.

                As noted in that section, you should remove and install on each host, only the components on each host
                that you want to run on the HDP 2.2 stack. For example, if you want to run Storm or Falcon components on
                the HDP 2.2 stack, you will install those components and then configure their properties during the
                upgrade procedure.
              </p>
            </div>
          </aside>
        
        
          <p>In preparation for future HDP 2.2 releases to support rolling upgrades, the HDP RPM package version
            naming convention has changed to include the HDP 2.2 product version in file and directory names. HDP 2.2
            marks the first release where HDP rpms, debs, and directories contain versions in the names to permit
            side-by-side installations of later HDP releases. To transition between previous releases and HDP 2.2,
            Pivotal provides hdp-select, a script that symlinks your directories to
            <code>hdp/current</code>
            and lets you maintain using the same binary and configuration paths that you were using before.

            The following instructions have you remove your older version HDP components, install hdp-select, and
            install HDP 2.2 components to prepare for rolling upgrade.
          </p>
        
        
          <h4 class="bold">Prepare the 2.1 Stack for Upgrade</h4>
          
            <p>To prepare for upgrading the HDP Stack, perform the following tasks:</p>
            <ul class="bullet-list">
              
                <li>
                  <p>Disable Security.</p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>If your Stack has Kerberos Security turned on, turn it off before performing the
                        upgrade. On<code>Ambari Web UI</code>&gt;
                        <code>Admin</code>
                        &gt;<code>Security</code>,<code></code>click
                        <code>Disable Security</code>. You can turn Kerberos Security on again after
                        performing the upgrade.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Checkpoint user metadata and capture the HDFS operational state.</p>
                  <p>

                    This step supports rollback and restore of the original state of HDFS data, if necessary.
                  </p>
                </li>
                <li>
                  <p>Backup Hive and Oozie metastore databases.
                  </p>
                  <p>
                    This step supports rollback and restore of the original state of Hive and Oozie data, if necessary.
                  </p>
                </li>
                <li>
                  <p>Stop all HDP and Ambari services.</p>
                </li>
                <li>
                  <p>Make sure to finish all current jobs running on the system before upgrading the stack.
                  </p>
                </li>
              
            </ul>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>Libraries will change during the upgrade. Any jobs remaining active that use the older version
                  libraries will probably fail during the upgrade.
                </p>
              </div>
            </aside>
          
          
            <ul class="number-list">
              
                <li>
                  <p>Use
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    <code>Service Actions</code>
                    <code></code>to stop all services except HDFS and ZooKeeper.
                  </p>
                </li>
                <li>
                  <p>Stop any client programs that access HDFS.</p>
                  <p>
                    Perform steps 3 through 8 on the NameNode host. In a highly-available NameNode configuration,
                    execute the following procedure on the primary NameNode.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>To locate the primary NameNode in an Ambari-managed HDP cluster, browse
                        <code>Ambari Web</code>
                        &gt;
                        <code>Services</code>
                        &gt;<code>HDFS</code>. In Summary, click<code>
                          NameNode</code>.
                        <code>Hosts</code>
                        &gt;
                        <code>Summary</code>
                        displays the host name FQDN.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>If HDFS is in a non-finalized state from a prior upgrade operation, you must finalize HDFS
                    before upgrading further. Finalizing HDFS will remove all links to the metadata of the prior HDFS
                    version. Do this only if you do not want to rollback to that prior HDFS version.
                  </p>
                  <p>
                    On the NameNode host, as the HDFS user,

                    <code>su -l</code>
                    &lt;HDFS_USER&gt;
                    <code>
                      hdfs dfsadmin -finalizeUpgrade
                    </code>
                    where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.
                  </p>
                </li>
                <li>
                  <p>Check the NameNode directory to ensure that there is no snapshot of any prior HDFS
                    upgrade.
                  </p>
                  <p>
                    Specifically, using<code>Ambari Web &gt; HDFS &gt; Configs &gt; NameNode</code>,
                    examine the
                    <code>&lt;dfs.namenode.name.dir&gt;</code>
                    or the
                    <code>&lt;dfs.name.dir&gt;</code>
                    directory in the NameNode Directories property. Make sure that only a "\current" directory and no
                    "\previous" directory exists on the NameNode host.
                  </p>
                </li>
                <li>
                  <p>Create the following logs and other files.</p>
                  <p>
                    Creating these logs allows you to check the integrity of the file system, post-upgrade.

                    As the HDFS user,
                    <code>
                      su -l
                    </code>
                    &lt;HDFS_USER&gt;
                    
                    where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Run
                          <code>fsck</code>
                          with the following flags and send the results to a log.
                        </p>
                        <p>
                          The resulting file contains a complete block map of the file system. You use this log later to
                          confirm the upgrade.
                        </p>
                        <p>
                          <code>hdfs fsck / -files -blocks -locations &gt; dfs-old-fsck-1.log</code>
                          <code></code>
                        </p>
                      </li>
                      <li>
                        <p>Optional: Capture the complete namespace of the file system.</p>
                        <p>
                          The following command does a recursive listing of the root file system:
                        </p>
                        <p>
                          <code>hadoop dfs -ls -R / &gt; dfs-old-lsr-1.log</code>
                        </p>
                      </li>
                      <li>
                        <p>Create a list of all the DataNodes in the cluster.</p>
                        <p>
                          <code>
                            hdfs dfsadmin -report &gt; dfs-old-report-1.log
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Optional: Copy all unrecoverable data stored in HDFS to a local file system or to a
                          backup instance of HDFS.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p><strong>Save the namespace</strong>.
                  </p>
                  <p>
                    You must be the HDFS service user to do this and you must put the cluster in Safe Mode.
                  </p>
                  <p>
                    <code>hdfs dfsadmin -safemode enter
                      hdfs dfsadmin -saveNamespace
                    </code>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>In a highly-available NameNode configuration, the command
                        <code>hdfs dfsadmin -saveNamespace</code>
                        sets a checkpoint in the first NameNode specified in the configuration, in<code>
                          dfs.ha.namenodes.[nameservice ID]</code>. You can also use the dfsadmin
                        <code>-fs</code>
                        option to specify which NameNode to connect.

                        For example, to force a checkpoint in namenode 2:
                        <code>
                          hdfs dfsadmin -fs hdfs://namenode2-hostname:namenode2-port -saveNamespace
                        </code>
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Copy the checkpoint files located in
                    &lt;dfs.name.dir/current&gt;
                    into a backup directory.
                  </p>
                  <p>
                    Find the directory, using Ambari Web &gt; HDFS &gt; Configs &gt; NameNode &gt; NameNode Directories
                    on your primary NameNode host.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>In a highly-available NameNode configuration, the location of the checkpoint depends on
                        where the saveNamespace command is sent, as defined in the preceding step.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Store the layoutVersion for the NameNode.</p>
                  <p>
                    Make a copy of the file at
                    &lt;dfs.name.dir&gt;
                    <code>/current/VERSION</code>, where&lt;dfs.name.dir&gt; is the
                    value of the config parameter NameNode directories. This file will be used later to verify that the
                    layout version is upgraded.
                  </p>
                </li>
                <li>
                  <p>Stop HDFS.</p>
                </li>
                <li>
                  <p>Stop ZooKeeper.</p>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    &lt;service.name&gt;
                    &gt;<code>Summary</code>, review each service and make sure that all services in
                    the cluster are completely stopped.
                  </p>
                </li>
                <li>
                  <p>At the Hive Metastore database host, stop the Hive metastore
                    <strong>
                      <i>service</i>
                    </strong>
                    , if you have not done so already.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>Make sure that the Hive metastore
                        <strong>
                          <i>database</i>
                        </strong>
                        is running. For more information about Administering the Hive metastore database, see the<a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin">
                          Hive Metastore Administrator documentation</a>.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>If you are upgrading Hive and Oozie, back up the Hive and Oozie metastore databases on the
                    Hive and Oozie database host machines, respectively.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>Make sure that your Hive database is updated to the minimum recommended version.

                        <strong>If you are using Hive with MySQL, we recommend upgrading your MySQL database to version
                          5.6.21 before upgrading the HDP Stack to v2.2.
                        </strong>
                        For specific information, see<a href="#ref-f35b0203-6267-4533-9e88-652452ece5f5">
                          Database Requirements</a>.
                      </p>
                    </div>
                  </aside>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Optional - Back up the Hive Metastore database.</p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Note.png" width="50"></div>
                          <div class="simple-block">
                            <p>These instructions are provided for your convenience. Please check your database
                              documentation for the latest back up instructions.
                            </p>
                          </div>
                        </aside>
                        <div class="xyleme-table"><table border="1">
                          <p class="italic bold">Hive Metastore Database Backup and Restore</p>
                          
                            
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Database Type</p>
                                </th>
                                <th rowspan="1">
                                  <p>Backup</p>
                                </th>
                                <th rowspan="1">
                                  <p>Restore</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>MySQL</p>
                                </td>
                                <td rowspan="1">
                                  <p>mysqldump
                                    &lt;dbname&gt;
                                    &gt;
                                    &lt;outputfilename.sql&gt;
                                    For example: mysqldump hive &gt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>mysql
                                    &lt;dbname&gt;
                                    &lt;
                                    &lt;inputfilename.sql&gt;
                                    For example: mysql hive &lt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>Postgres</p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u
                                    &lt;username&gt;
                                    pg_dump
                                    &lt;databasename&gt;
                                    &gt;
                                    &lt;outputfilename.sql&gt;
                                    For example: sudo -u postgres pg_dump hive &gt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u
                                    &lt;username&gt;
                                    psql
                                    &lt;databasename&gt;
                                    &lt;
                                    &lt;inputfilename.sql&gt;
                                    For example: sudo -u postgres psql hive &lt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>Oracle</p>
                                </td>
                                <td rowspan="1">
                                  <p>Connect to the Oracle database using sqlplus
                                    export the database: exp username/password@database full=yes file=output_file.dmp
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>Import the database: imp username/password@database ile=input_file.dmp
                                  </p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Optional - Back up the Oozie Metastore database.</p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Note.png" width="50"></div>
                          <div class="simple-block">
                            <p>These instructions are provided for your convenience. Please check your database
                              documentation for the latest back up instructions.
                            </p>
                          </div>
                        </aside>
                        <div class="xyleme-table"><table border="1">
                          <p class="italic bold">Oozie Metastore Database Backup and Restore</p>
                          
                            
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Database Type</p>
                                </th>
                                <th rowspan="1">
                                  <p>Backup</p>
                                </th>
                                <th rowspan="1">
                                  <p>Restore</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>MySQL</p>
                                </td>
                                <td rowspan="1">
                                  <p>mysqldump
                                    &lt;dbname&gt;
                                    &gt;
                                    &lt;outputfilename.sql&gt;
                                    For example: mysqldump oozie &gt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>mysql
                                    &lt;dbname&gt;
                                    &lt;
                                    &lt;inputfilename.sql&gt;
                                    For example: mysql oozie &lt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>Postgres</p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u
                                    &lt;username&gt;
                                    pg_dump
                                    &lt;databasename&gt;
                                    &gt;
                                    &lt;outputfilename.sql&gt;
                                    For example: sudo -u postgres pg_dump oozie &gt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u
                                    &lt;username&gt;
                                    psql
                                    &lt;databasename&gt;
                                    &lt;
                                    &lt;inputfilename.sql&gt;
                                    For example: sudo -u postgres psql oozie &lt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Backup Hue.
                    If you are using the embedded SQLite database, you must perform a backup of the database before you
                    upgrade Hue to prevent data loss. To make a backup copy of the database, stop Hue, then "dump" the
                    database content to a file, as follows:
                  </p>
                  <p>
                    <code>./etc/init.d/hue stop

                      su $HUE_USER
                      mkdir ~/hue_backup
                      cd /var/lib/hue
                      sqlite3 desktop.db .dump &gt; ~/hue_backup/desktop.bak

                    </code>For other databases, follow your vendor-specific instructions to create a backup.
                    <code></code>
                  </p>
                </li>
                <li>
                  <p>On the Ambari Server host, stop Ambari Server and confirm that it is stopped.</p>
                  <p>
                    <code>ambari-server stop</code>
                    <code>ambari-server status</code>
                  </p>
                </li>
                <li>
                  <p>Stop all Ambari Agents.
                    On every host in your cluster known to Ambari,
                  </p>
                  <p>
                    <code>ambari-agent stop</code>
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Upgrade the 2.1 Stack to 2.2</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>Upgrade the HDP repository on all hosts and replace the old repository file with the new
                    file:
                  </p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>
                          <strong>For RHEL/CentOS/Oracle Linux 6:</strong>
                        </p>
                        <pre><code>wget -nv http://public-repo-1.hortonworks.com/HDP/centos6/2.x/GA/2.2.0.0/hdp.repo -O
                          /etc/yum.repos.d/HDP.repo
                        </code></pre>
                      </li>
                      <li>
                        <p>
                          <strong>For SLES 11 SP3:</strong>
                        </p>
                        <pre><code>wget -nv http://public-repo-1.hortonworks.com/HDP/suse11sp3/2.x/GA/2.2.0.0/hdp.repo -O
                          /etc/zypp/repos.d/HDP.repo
                        </code></pre>
                      </li>
                      <li>
                        <p>
                          <strong>For SLES 11 SP1:</strong>
                        </p>
                        <pre><code>wget -nv http://public-repo-1.hortonworks.com/HDP/sles11sp1/2.x/GA/2.2.0.0/hdp.repo -O
                          /etc/zypp/repos.d/HDP.repo
                        </code></pre>
                      </li>
                      <li>
                        <p>
                          <strong>For UBUNTU12:</strong>
                        </p>
                        <pre><code>wget -nv http://public-repo-1.hortonworks.com/HDP/ubuntu1/2.x/GA/2.2.0.0/hdp.list -O
                          /etc/apt/sourceslist.d/HDP.list
                        </code></pre>
                      </li>
                      <li>
                        <p>
                          <strong>For RHEL/CentOS/Oracle Linux 5:</strong>
                          (DEPRECATED)
                        </p>
                        <pre><code>wget -nv http://public-repo-1.hortonworks.com/HDP/centos5/2.x/GA/2.2.0.0/hdp.repo -O
                          /etc/yum.repos.d/HDP.repo
                        </code></pre>
                      </li>
                    
                  </ul>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>Make sure to download the HDP.repo file under
                        <code>/etc/yum.repos.d</code>
                        on ALL hosts.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Update the Stack version in the Ambari Server database.</p>
                  <p>
                    On the Ambari Server host, use the following command to update the Stack version to HDP-2.2:
                  </p>
                  <p>
                    <code>ambari-server upgradestack HDP-2.2</code>
                  </p>
                </li>
                <li>
                  <p>Back up the files in following directories on the Oozie server host and make sure that all
                    files, including *site.xml files are copied.
                  </p>
                  <p>
                    <code>mkdir oozie-conf-bak
                      cp -R /etc/oozie/conf/* oozie-conf-bak
                    </code>
                  </p>
                </li>
                <li>
                  <p>Remove the old oozie directories on all Oozie server and client hosts</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>
                          <code>rm -rf /etc/oozie/conf</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>rm -rf /usr/lib/oozie/</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>rm -rf /var/lib/oozie/</code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Upgrade the Stack on all Ambari Agent hosts.</p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>For each host, identify the HDP components installed on that host. Use Ambari Web, as
                        described<a href="#ref-9cb21557-3948-4efa-b3cb-1c65f5b0ad31">here</a>, to view
                        components on each host in your cluster. Based on the HDP components installed, edit the
                        following upgrade commands for each host to upgrade only those components residing on that host.

                        For example, if you know that a host has
                        <strong>
                          <i>no</i>
                        </strong>
                        HBase service or client packages installed, then you can edit the command to
                        <strong>
                          <i>not</i>
                        </strong>
                        include HBase, as follows:

                        <code>yum install "collectd*" "gccxml*" "pig*" "hdfs*" "sqoop*" "zookeeper*" "hive*"
                        </code>
                      </p>
                    </div>
                  </aside>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>If you are writing to multiple systems using a script, do not use " " with the run
                        command. You can use " " with pdsh -y.
                      </p>
                    </div>
                  </aside>
                  <ul class="Bullet">
                    
                      <li>
                        <p>For RHEL/CentOS/Oracle Linux:</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>On all hosts, clean the yum repository.</p>
                              <p>
                                <code>yum clean all</code>
                              </p>
                            </li>
                            <li>
                              <p>Remove all HDP 2.1 components that you want to upgrade.</p>
                              <p>
                                This command un-installs the HDP 2.1 component bits. It leaves the user data and
                                metadata, but removes your configurations.
                              </p>
                              <pre><code>yum erase "hadoop*" "webhcat*" "hcatalog*" "oozie*" "pig*" "hdfs*" "sqoop*"
                                "zookeeper*" "hbase*" "hive*" "tez*" "storm*" "falcon*" "flume*" "phoenix*" "accumulo*"
                                "mahout*" "hue*" "hdp_mon_nagios_addons"
                              </code></pre>
                            </li>
                            <li>
                              <p>Remove your old hdp.repo and hdp-utils repo files.</p>
                              <p>
                                <code>rm etc/yum/repos.d/hdp.repo hdp-utils.repo</code>
                              </p>
                            </li>
                            <li>
                              <p>Install all HDP 2.2 components that you want to upgrade.</p>
                              <pre><code>yum install "hadoop_2_2_0_0_*" "oozie_2_2_0_0_*" "pig_2_2_0_0_*" "sqoop_2_2_0_0_*"
                                "zookeeper_2_2_0_0_*" "hbase_2_2_0_0_*" "hive_2_2_0_0_*" "tez_2_2_0_0_*"
                                "storm_2_2_0_0_*" "falcon_2_2_0_0_*" "flume_2_2_0_0_*" "phoenix_2_2_0_0_*"
                                "accumulo_2_2_0_0_*" "mahout_2_2_0_0_*"
                                rpm -e --nodeps hue-shell
                                yum install hue hue-common hue-beeswax hue-hcatalog hue-pig hue-oozie
                              </code></pre>
                            </li>
                            <li>
                              <p>Verify that the components were upgraded.</p>
                              <p>
                                <code>yum list installed | grep HDP-</code>
                                &lt;old.stack.version.number&gt;
                              </p>
                              <p>
                                No component file names should appear in the returned list.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>For SLES:</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>On all hosts, clean the zypper repository.</p>
                              <p>
                                <code>zypper clean --all</code>
                              </p>
                            </li>
                            <li>
                              <p>Remove all HDP 2.1 components that you want to upgrade.</p>
                              <p>
                                This command un-installs the HDP 2.1 component bits. It leaves the user data and
                                metadata, but removes your configurations.
                              </p>
                              <pre><code>zypper remove "hadoop*" "webhcat*" "hcatalog*" "oozie*" "pig*" "hdfs*" "sqoop*"
                                "zookeeper*" "hbase*" "hive*" "tez*" "storm*" "falcon*" "flume*" "phoenix*" "accumulo*"
                                "mahout*" "hue*" "hdp_mon_nagios_addons"
                              </code></pre>
                            </li>
                            <li>
                              <p>Remove your old hdp.repo and hdp-utils repo files.</p>
                              <p>
                                <code>rm etc/zypp/repos.d/hdp.repo hdp-utils.repo</code>
                              </p>
                            </li>
                            <li>
                              <p>Install all HDP 2.2 components that you want to upgrade.</p>
                              <p>
                                <code>
                                </code>
                              </p>
                              <pre><code>zypper install "hadoop\_2_2_0_0_*" "oozie\_2_2_0_0_*" "pig\_2_2_0_0_*"
                                "sqoop\_2_2_0_0_*" "zookeeper\_2_2_0_0_*" "hbase\_2_2_0_0_*" "hive\_2_2_0_0_*"
                                "tez\_2_2_0_0_*" "storm\_2_2_0_0_*" "falcon\_2_2_0_0_*" "flume\_2_2_0_0_*"
                                "phoenix\_2_2_0_0_*" "accumulo\_2_2_0_0_*" "mahout\_2_2_0_0_*"
                                rpm -e --nodeps hue-shell
                                zypper install hue hue-common hue-beeswax hue-hcatalog hue-pig hue-oozie
                              </code></pre>
                            </li>
                            <li>
                              <p>Verify that the components were upgraded.</p>
                              <p>
                                <code>rpm -qa | grep hdfs, &amp;&amp; rpm -qa | grep hive &amp;&amp; rpm -qa |
                                  grep hcatalog
                                </code>
                              </p>
                              <p>
                                No component files names should appear in the returned list.
                              </p>
                            </li>
                            <li>
                              <p>If any components were not upgraded, upgrade them as follows:</p>
                              <p>
                                <code>yast --update hdfs hcatalog hive</code>
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Symlink directories, using<code>hdp-select</code>.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Warning.png" width="50"></div>
                    <div class="simple-block">
                      <p>To prevent version-specific directory issues for your scripts and updates, Pivotal
                        provides<code>hdp-select</code>, a script that symlinks directories to hdp-current
                        and modifies paths for configuration directories.
                      </p>
                    </div>
                  </aside>
                  <p>
                    Check that the
                    <code>hdp-select</code>
                    package installed:
                    <code>
                      rpm -qa | grep hdp-select
                    </code>

                    You should see:
                    <code>hdp-select-2.2.0.0-2041.el6.noarch for the HDP 2.2 release.
                    </code>

                    If not, then run:
                    <code>
                      yum install hdp-select
                    </code>

                    Run
                    <code>hdp-select</code>
                    as root, on every node.
                    <code>
                      hdp-select set all 2.2.0.0-&lt;</code>
                    $version
                    <code>&gt;
                    </code>
                    where
                    $version
                    is the build number. For the HDP 2.2 release &lt;$version&gt; = 2041.
                    <code></code>
                  </p>
                </li>
                <li>
                  <p>On the Hive Metastore database host, stop the Hive Metastore
                    <i>
                      <strong>service</strong>
                    </i>
                    , if you have not done so already. Make sure that the Hive Metastore
                    <i>
                      <strong>database</strong>
                    </i>
                    is running.
                  </p>
                </li>
                <li>
                  <p>Upgrade the Hive metastore database schema from v13 to v14, using the following
                    instructions:
                  </p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Set java home:</p>
                        <p>
                          <code>export JAVA_HOME=/path/to/java</code>
                        </p>
                      </li>
                      <li>
                        <p>Copy (rewrite) old Hive configurations to new conf dir:</p>
                        <p>
                          <code>cp -R /etc/hive/conf.server/* /etc/hive/conf/</code>
                        </p>
                      </li>
                      <li>
                        <p>Copy jdbc connector to
                          <code>/usr/hdp/</code>
                          &lt;$version&gt;
                          <code>/hive/lib</code>, if it is not already in that location.
                        </p>
                      </li>
                      <li>
                        <p>
                          &lt;HIVE_HOME&gt;
                          <code>/bin/schematool -upgradeSchema -dbType</code>
                          &lt;databaseType&gt;

                          where
                          &lt;HIVE_HOME&gt;
                          is the Hive installation directory.
                        </p>
                        <p>
                          For example, on the Hive Metastore host:

                          /usr/hdp/2.2.0.0-&lt;$version&gt;/hive/bin/schematool -upgradeSchema
                          -dbType
                          &lt;databaseType&gt;

                          where
                          &lt;$version&gt;
                          is the 2.2.0 build number and
                          &lt;databaseType&gt;
                          is derby, mysql, oracle, or postgres.
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Complete the Upgrade of the 2.1 Stack to 2.2</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>Start Ambari Server.</p>
                  <p>On the Ambari Server host,
                    <code>
                      ambari-server start
                    </code>
                  </p>
                </li>
                <li>
                  <p>Start all Ambari Agents.</p>
                  <p>
                    At each Ambari Agent host,
                    <code>
                      ambari-agent start
                    </code>
                  </p>
                </li>
                <li>
                  <p>Update the repository Base URLs in Ambari Server for the HDP-2.2 stack.</p>
                  <p>
                    Browse to
                    <code>Ambari Web &gt; Admin &gt; Repositories,</code>
                    then set the values for the HDP and HDP-UTILS repository Base URLs. For more information about
                    viewing and editing repository Base URLs, see<a href="#ref-0cf8106e-364a-46d5-85aa-38dd0476a7e2">Viewing Cluster Stack Version and
                    Repository URLs</a>.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>For a remote, accessible, public repository, the HDP and HDP-UTILS Base URLs are the
                        same as the baseurl=values in the HDP.repo file downloaded in<a href="#ref-c30073a7-f386-4d8a-9619-8dde14e3e4d1">Upgrade the Stack</a>: Step 1.
                        For a local repository, use the local repository Base URL that you configured for the HDP Stack.
                        For links to download the HDP repository files for your version of the Stack, see<a href="#ref-3e43081a-a937-4d51-92cc-1fbf15645713">HDP Stack Repositories</a>.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Using the Ambari Web UI, add the Tez service if if it has not been installed already. For
                    more information about adding a service, see<a href="#ref-19a49eb0-7d00-4f33-bb7b-ed805a5cd656">Adding a Service</a>.
                  </p>
                </li>
                <li>
                  <p>Using the Ambari Web UI, add any new services that you want to run on the HDP 2.2 stack. You
                    must add a Service before editing configuration properties necessary to complete the upgrade.
                  </p>
                </li>
                <li>
                  <p>Using the
                    <code>Ambari Web UI</code>
                    &gt;<code>Services</code>, start the ZooKeeper service.
                  </p>
                </li>
                <li>
                  <p>Copy (rewrite) old hdfs configurations to new conf directory, on all Datanode and Namenode
                    hosts,
                  </p>
                  <p>
                    <code>cp /etc/hadoop/conf.empty/hdfs-site.xml.rpmsave /etc/hadoop/conf/hdfs-site.xml;
                      cp /etc/hadoop/conf.empty/hadoop-env.sh.rpmsave /etc/hadoop/conf/hadoop-env.sh.xml;
                      cp /etc/hadoop/conf.empty/log4j.properties.rpmsave /etc/hadoop/conf/log4j.properties;
                      cp /etc/hadoop/conf.empty/core-site.xml.rpmsave /etc/hadoop/conf/core-site.xml
                    </code>
                  </p>
                </li>
                <li>
                  <p>If you are upgrading from an HA NameNode configuration, start all JournalNodes.</p>
                  <p>
                    At each JournalNode host, run the following command:

                    <code>su -l</code>
                    &lt;HDFS_USER&gt;
                    <code>-c "/usr/hdp/2.2.0.0-</code>
                    &lt;$version&gt;
                    <code>/hadoop/sbin/hadoop-daemon.sh start journalnode"

                    </code>where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>All JournalNodes must be running when performing the upgrade, rollback, or finalization
                        operations. If any JournalNodes are down when running any such operation, the operation will
                        fail.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Because the file system version has now changed, you must start the NameNode manually.
                    On the active NameNode host, as the HDFS user,
                  </p>
                  <p>
                    <code>su -l</code>
                    &lt;HDFS_USER&gt;
                    <code>-c "export HADOOP_LIBEXEC_DIR=/usr/hdp/2.2.0.0-</code>
                    &lt;$version&gt;
                    <code>/hadoop/libexec &amp;&amp; /usr/hdp/2.2.0.0-</code>
                    &lt;$version&gt;
                    <code>/hadoop/sbin/hadoop-daemon.sh start namenode -upgrade"

                    </code>where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.
                  </p>
                  <p>
                    To check if the Upgrade is progressing, check that the "
                    <code>\previous</code>
                    " directory has been created in
                    <code>\NameNode</code>
                    and
                    <code>\JournalNode</code>
                    directories. The "<code>\previous</code>" directory contains a snapshot of the data
                    before upgrade.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>In a NameNode HA configuration, this NameNode does not enter the standby state as usual.
                        Rather, this NameNode immediately enters the active state, upgrades its local storage
                        directories, and upgrades the shared edit log. At this point, the standby NameNode in the HA
                        pair is
                        still down, and not synchronized
                        with the upgraded, active NameNode.
                      </p>
                      <p>To re-establish HA, you must synchronize the active and standby NameNodes. To do so,
                        bootstrap the standby NameNode by running the NameNode with the '-bootstrapStandby' flag. Do NOT
                        start the standby NameNode with the '-upgrade' flag.

                        At the Standby NameNode,
                      </p>
                      <p>
                        <code>su -l</code>
                        &lt;HDFS_USER&gt;
                        <code>-c "hdfs namenode -bootstrapStandby -force"

                        </code>where
                        &lt;HDFS_USER&gt;
                        is the HDFS Service user. For example, hdfs.
                      </p>
                      <p>
                        The bootstrapStandby command downloads the most recent fsimage from the active NameNode into the
                        &lt;dfs.name.dir&gt;
                        directory on the standby NameNode. Optionally, you can access that directory to make sure the
                        fsimage has been successfully downloaded. After verifying, start the ZKFailoverController, then
                        start the standby NameNode using<code>Ambari Web &gt; Hosts &gt;
                        Components</code>.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Start all DataNodes.</p>
                  <p>
                    At each DataNode, as the HDFS user,
                  </p>
                  <pre><code>su -l &lt;HDFS_USER&gt; -c "/usr/hdp/2.2.0.0-&lt;$version&gt;/hadoop/sbin/hadoop-daemon.sh
                    --config /etc/hadoop/conf start datanode"
                  </code></pre>
                  <p>
                    where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.
                    <code>
                    </code>
                    The NameNode sends an upgrade command to DataNodes after receiving block reports.
                  </p>
                </li>
                <li>
                  <p>Update HDFS Configuration Properties for HDP 2.2</p>
                  <p>
                    Using<code>Ambari Web UI &gt; Services &gt; HDFS &gt; Configs &gt;
                    core-site.xml</code>:
                  </p>
                  <ul class="Arrow">
                    
                      <li>
                        <p>Add</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>hadoop.http.authentication.simple.anonymous.allowed</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                  <p><code>Using Ambari Web UI &gt; Services &gt; HDFS &gt; Configs &gt;
                    hdfs-site.xml</code>:
                  </p>
                  <ul class="Arrow">
                    
                      <li>
                        <p>Add</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>dfs.namenode.startup.delay.block.deletion.sec</p>
                                </td>
                                <td rowspan="1">
                                  <p>3600</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Modify</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>dfs.datanode.max.transfer.threads</p>
                                </td>
                                <td rowspan="1">
                                  <p>4096</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Restart HDFS.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Open the Ambari Web GUI. If the browser in which Ambari is running has been open
                          throughout the process, clear the browser cache, then refresh the browser.
                        </p>
                      </li>
                      <li>
                        <p>Choose<code>Ambari Web &gt; Services &gt; HDFS &gt; Service Actions
                          &gt; Restart All</code>.
                        </p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Important.png" width="50"></div>
                          <div class="simple-block">
                            <ul class="number-list">
                              In a cluster configured for NameNode High Availability, use the following
                                procedure to restart NameNodes. Using the following procedure preserves HA when
                                upgrading the cluster.
                              
                              
                                <li>
                                  <p>Using Ambari Web &gt; Services &gt; HDFS, choose Active NameNode.</p>
                                  <p>This shows the host name of the current, active NameNode.</p>
                                </li>
                                <li>
                                  <p>Write down (or copy, or remember) the host name of the active NameNode.
                                  </p>
                                  <p>You need this host name for step 4.</p>
                                </li>
                                <li>
                                  <p>Using Ambari Web &gt; Services &gt; HDFS &gt; Service Actions &gt; choose
                                    Stop.
                                  </p>
                                  <p>This stops all of the HDFS Components, including both NameNodes.</p>
                                </li>
                                <li>
                                  <p>Using Ambari Web &gt; Hosts &gt; choose the host name you noted in Step 2,
                                    then start that NameNode component, using Host Actions &gt; Start.
                                  </p>
                                  <p>This causes the original, active NameNode to re-assume its role as the
                                    active NameNode.
                                  </p>
                                </li>
                                <li>
                                  <p>Using Ambari Web &gt; Services &gt; HDFS &gt; Service Actions, choose
                                    Re-Start All.
                                  </p>
                                </li>
                              
                            </ul>
                          </div>
                        </aside>
                      </li>
                      <li>
                        <p>Choose<code>Service Actions &gt; Run Service
                          Check</code>. Makes sure the service check passes.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>After the DataNodes are started, HDFS exits SafeMode. To monitor the status, run the
                    following command, on each DataNode:
                  </p>
                  <p>
                    <code>sudo su -l</code>
                    &lt;HDFS_USER&gt;
                    <code>-c "hdfs dfsadmin -safemode get"</code>

                    where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.

                    When HDFS exits SafeMode, the following message displays:
                  </p>
                  <pre><code>Safe mode is OFF</code></pre>
                </li>
                <li>
                  <p>Make sure that the HDFS upgrade was successful.
                    Optionally, repeat step 5 in
                    <a href="#ref-322bc47c-0c63-4ec5-94a8-44cda871c440">Prepare the 2.1 Stack for Upgrade
                    </a>
                    to create new versions of the logs and reports, substituting "-
                    <code>new</code>
                    " for "-
                    <code>old</code>
                    " in the file names as necessary.
                  </p>
                  <p></p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Compare the old and new versions of the following log files:</p>
                        <ul class="Bullet">
                          
                            <li>
                              <p>
                                <code>dfs-old-fsck-1.log</code>
                                versus<code>dfs-new-fsck-1.log</code>.
                              </p>
                              <p>
                                The files should be identical unless the hadoop fsck reporting format has changed in the
                                new version.
                              </p>
                            </li>
                            <li>
                              <p>
                                <code>dfs-old-lsr-1.log</code>
                                versus<code>dfs-new-lsr-1.log</code>.
                              </p>
                              <p>
                                The files should be identical unless the format of hadoop fs -lsr reporting or the data
                                structures have changed in the new version.
                              </p>
                            </li>
                            <li>
                              <p>
                                <code>dfs-old-report-1.log</code>
                                versus
                                <code>fs-new-report-1.log</code>
                              </p>
                              <p>
                                Make sure that all DataNodes in the cluster before upgrading are up and running.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Upgrade Application Timeline Server (ATS) components for YARN.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>If upgrading your HDP Stack version from 2.1.1 or 2.1.2, you must modify the following
                          YARN configuration property:
                        </p>
                        <p>
                          Browse to<code>Ambari Web &gt; Services &gt; YARN Configs &gt; Application
                          Timeline Server</code>, and set
                          yarn.timeline-service.store-class=org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
                        </p>
                      </li>
                      <li>
                        <p>If YARN is installed in your HDP 2.1 stack, and the ATS components are NOT, then you
                          must create and install ATS service and host components using the API.

                          Run the following commands on the server that will host the YARN ATS in your cluster. Be sure
                          to replace &lt;your_ATS_component_hostname&gt; with a host name appropriate for your
                          environment.
                        </p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Create the ATS Service Component.</p>
                              <pre><code>curl --user admin:admin -H "X-Requested-By: ambari" -i -X POST
                                http://localhost:8080/api/v1/clusters/&lt;your_cluster_name&gt;/services/YARN/components/APP_TIMELINE_SERVER
                              </code></pre>
                            </li>
                            <li>
                              <p>Create the ATS Host Component.</p>
                              <pre><code>curl --user admin:admin -H "X-Requested-By: ambari" -i -X POST
                                http://localhost:8080/api/v1/clusters/&lt;your_cluster_name&gt;/hosts/&lt;your_ATS_component_hostname&gt;/host_components/APP_TIMELINE_SERVER
                              </code></pre>
                            </li>
                            <li>
                              <p>Install the ATS Host Component.</p>
                              <pre><code>curl --user admin:admin -H "X-Requested-By: ambari" -i -X PUT -d '{"HostRoles": {
                                "state": "INSTALLED"}}' http://localhost:8080/api/v1/clusters/&lt;your_cluster_name&gt;/hosts/&lt;your_ATS_component_hostname&gt;/host_components/APP_TIMELINE_SERVER
                              </code></pre>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                  <p>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>curl commands use the default username/password = admin/admin. To run the curl commands
                        using non-default credentials, modify the --user option to use your Ambari administrator
                        credentials.

                        For example: -
                        <code>-user</code>
                        &lt;ambari_admin_username&gt;:
                          &lt;ambari_admin_password&gt;.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Prepare MR2 and Yarn for work. Execute HDFS commands on any host.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Create mapreduce dir in hdfs.</p>
                        <p>
                          <code>su -l</code>
                          &lt;HDFS_USER&gt;
                          <code>-c "hdfs dfs -mkdir -p /hdp/apps/2.2.0.0-&lt;$version&gt;/mapreduce/"
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Copy new mapreduce.tar.gz to HDFS mapreduce dir.</p>
                        <p>
                          <code>su -l</code>
                          &lt;HDFS_USER&gt;
                          <code>-c "hdfs dfs -copyFromLocal /usr/hdp/2.2.0.0-&lt;$version&gt;/hadoop/mapreduce.tar.gz
                            /hdp/apps/2.2.0.0-&lt;$version&gt;/mapreduce/."
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Grant permissions for created mapreduce dir in hdfs.</p>
                        <pre><code>su -l &lt;HDFS_USER&gt; -c "hdfs dfs -chown -R &lt;HDFS_USER&gt;:&lt;HADOOP_GROUP&gt;
                          /hdp";
                          su -l &lt;HDFS_USER&gt; -c "hdfs dfs -chmod -R 555 /hdp/apps/2.2.0.0-&lt;$version&gt;/mapreduce";
                          su -l &lt;HDFS_USER&gt; -c "hdfs dfs -chmod -R 444 /hdp/apps/2.2.0.0-&lt;$version&gt;/mapreduce/mapreduce.tar.gz"
                        </code></pre>
                      </li>
                      <li>
                        <p>Update YARN Configuration Properties for HDP 2.2</p>
                        <p>
                          On ambari-server host,
                          <code>cd /var/lib/ambari-server/resources/scripts</code>
                        </p>
                        <ul class="Arrow">
                          
                            <li>
                              <p>then run the following scripts:</p>
                              <p>
                                <code>./configs.sh set localhost</code>
                                &lt;your.cluster.name&gt;
                                <code>capacity-scheduler "yarn.scheduler.capacity.resource-calculator"
                                  "org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator";
                                  ./configs.sh set localhost
                                </code>
                                &lt;your.cluster.name&gt;
                                <code>capacity-scheduler "yarn.scheduler.capacity.root.accessible-node-labels"
                                  "*";
                                  ./configs.sh set localhost
                                </code>
                                &lt;your.cluster.name&gt;
                                <code>capacity-scheduler
                                  "yarn.scheduler.capacity.root.accessible-node-labels.default.capacity" "-1";
                                  ./configs.sh set localhost
                                </code>
                                &lt;your.cluster.name&gt;
                                <code>capacity-scheduler
                                  "yarn.scheduler.capacity.root.accessible-node-labels.default.maximum-capacity" "-1";
                                  ./configs.sh set localhost
                                </code>
                                &lt;your.cluster.name&gt;
                                <code>capacity-scheduler
                                  "yarn.scheduler.capacity.root.default-node-label-expression" ""
                                </code>
                              </p>
                            </li>
                          
                        </ul>
                        <p>
                          Using
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Service</code>
                          &gt;
                          <code>Yarn</code>
                          &gt;
                          <code>Configs</code>
                          &gt;
                          <code>Advanced</code>
                          &gt;<code>yarn-site</code>:
                        </p>
                        <ul class="Arrow">
                          
                            <li>
                              <p>Add</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.application.classpath</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>$HADOOP_CONF_DIR,/usr/hdp/current/hadoop-client/*,
                                          /usr/hdp/current/hadoop-client/lib/*,
                                          /usr/hdp/current/hadoop-hdfs-client/*,
                                          /usr/hdp/current/hadoop-hdfs-client/lib/*,
                                          /usr/hdp/current/hadoop-yarn-client/*
                                          ,/usr/hdp/current/hadoop-yarn-client/lib/*
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hadoop.registry.zk.quorum</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>&lt;!--List of hostname:port pairs defining the zookeeper quorum
                                          binding for the registry--&gt;</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hadoop.registry.rm.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.client.nodemanager-connect.max-wait-ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>900000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.client.nodemanager-connect.retry-interval-ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.node-labels.fs-store.retry-policy-spec</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>2000, 500</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.node-labels.fs-store.root-dir</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/system/yarn/node-labels</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.node-labels.manager-class</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          org.apache.hadoop.yarn.server.resourcemanager.nodelabels.MemoryRMNodeLabelsManager
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.bind-host</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.0.0.0</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>
                                          yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>90</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>hadoop-yarn</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.linux-container-executor.cgroups.mount</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>
                                          yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.linux-container-executor.resources-handler.class
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.log-aggregation.debug-enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.log-aggregation.num-log-files-per-app</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>30</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-1</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.recovery.dir</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/var/log/hadoop-yarn/nodemanager/recovery-state</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.recovery.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.resource.cpu-vcores</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.nodemanager.resource.percentage-physical-cpu-limit</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>100</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.bind-host</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.0.0.0</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.connect.max-wait.ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>900000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.connect.retry-interval.ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>30000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.fs.state-store.retry-policy-spec</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>2000, 500</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.fs.state-store.uri</p>
                                      </td>
                                      <td rowspan="1">
                                        <p> &lt;enter a "space" as the property value&gt;</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.ha.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.recovery.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.state-store.max-completed-applications</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>${yarn.resourcemanager.max-completed-applications}</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.store.class</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.system-metrics-publisher.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.work-preserving-recovery.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.zk-acl</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>world:anyone:rwcda</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.zk-address</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>localhost:2181</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.zk-num-retries</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.zk-retry-interval-ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.zk-state-store.parent-path</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/rmstore</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.resourcemanager.zk-timeout-ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.timeline-service.bind-host</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.0.0.0</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.timeline-service.client.max-retries</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>30</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.timeline-service.client.retry-interval-ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.timeline-service.http-authentication.simple.anonymous.allowed
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.timeline-service.http-authentication.type</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>simple</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.timeline-service.leveldb-timeline-store.read-cache-size
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>104857600</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>
                                          yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>
                                          yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
                                        </p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10000</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                            <li>
                              <p>Modify</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.timeline-service.webapp.address</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>&lt;PUT_THE_FQDN_OF_ATS_HOST_NAME_HERE&gt;:8188
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.timeline-service.webapp.https.address</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>&lt;PUT_THE_FQDN_OF_ATS_HOST_NAME_HERE&gt;:8190
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.timeline-service.address</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>&lt;PUT_THE_FQDN_OF_ATS_HOST_NAME_HERE&gt;
                                          :10200
                                        </p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Update MapReduce2 Configuration Properties for HDP 2.2</p>
                        <p>
                          Using
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Services &gt; MapReduce2</code>
                          &gt;
                          <code>Configs</code>
                          &gt;<code>mapred-site.xml</code>:
                        </p>
                        <ul class="Arrow">
                          
                            <li>
                              <p>Add</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.job.emit-timeline-data</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.jobhistory.bind-host</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.0.0.0</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.reduce.shuffle.fetch.retry.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.reduce.shuffle.fetch.retry.interval-ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.reduce.shuffle.fetch.retry.timeout-ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>30000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.application.framework.path</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework
                                        </p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                            <li>
                              <p>Modify</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.admin.map.child.java.opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true
                                          -Dhdp.version=${hdp.version}
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.admin.reduce.child.java.opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true
                                          -Dhdp.version=${hdp.version}
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.app.mapreduce.am.admin-command-opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-Dhdp.version=${hdp.version}</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.app.mapreduce.am.command-opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-Xmx546m -Dhdp.version=${hdp.version}</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.application.classpath</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:
                                          $PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:
                                          $PWD/mr-framework/hadoop/share/hadoop/common/*:
                                          $PWD/mr-framework/hadoop/share/hadoop/common/lib/*:
                                          $PWD/mr-framework/hadoop/share/hadoop/yarn/*:
                                          $PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:
                                          $PWD/mr-framework/hadoop/share/hadoop/hdfs/*:
                                          $PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:
                                          /usr/hdp/${hdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${hdp.version}.jar:/etc/hadoop/conf/secure$
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.admin.user.env</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-amd64-64
                                        </p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Update HBase Configuration Properties for HDP 2.2</p>
                        <p>
                          Using
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Services</code>
                          &gt;
                          <code>HBase</code>
                          &gt;
                          <code>Configs</code>
                          &gt;<code>hbase-site.xml</code>:
                        </p>
                        <ul class="Arrow">
                          
                            <li>
                              <p>Add</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hbase.hregion.majorcompaction.jitter</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.50</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                            <li>
                              <p>Modify</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hbase.hregion.majorcompaction</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>604800000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hbase.hregion.memstore.block.multiplier</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>4</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                            <li>
                              <p>Remove</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hbase.hstore.flush.retries.number</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>120</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Update Hive Configuration Properties for HDP 2.2</p>
                        <p>
                          Using
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Services</code>
                          &gt;
                          <code>Hive</code>
                          &gt;
                          <code>Configs</code>
                          &gt;<code>hive-site.xml</code>:
                        </p>
                        <ul class="Arrow">
                          
                            <li>
                              <p>Add</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.cluster.delegation.token.store.zookeeper.connectString</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>&lt;!-- The ZooKeeper token store connect string. --&gt;</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.auto.convert.sortmerge.join.to.mapjoin</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.cbo.enable</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.cli.print.header</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.cluster.delegation.token.store.class</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.cluster.delegation.token.store.zookeeper.znode</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/hive/cluster/delegation</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.conf.restricted.list</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          hive.security.authenticator.manager,hive.security.authorization.manager,hive.users.in.admin.role
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.convert.join.bucket.mapjoin.tez</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.compress.intermediate</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.compress.output</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.dynamic.partition</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.dynamic.partition.mode</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>nonstrict</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.max.created.files</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>100000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.max.dynamic.partitions</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>5000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.max.dynamic.partitions.pernode</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>2000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.orc.compression.strategy</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>SPEED</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.orc.default.compress</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>ZLIB</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.orc.default.stripe.size</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>67108864</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.parallel</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.parallel.thread.number</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>8</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.reducers.bytes.per.reducer</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>67108864</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.reducers.max</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1009</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.scratchdir</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/tmp/hive</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.submit.local.task.via.child</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.exec.submitviachild</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.fetch.task.aggr</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.fetch.task.conversion</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>more</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.fetch.task.conversion.threshold</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1073741824</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.map.aggr.hash.force.flush.memory.threshold</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.9</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.map.aggr.hash.min.reduction</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.5</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.map.aggr.hash.percentmemory</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.5</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.mapjoin.optimized.hashtable</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.merge.mapfiles</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.merge.mapredfiles</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.merge.orcfile.stripe.level</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.merge.rcfile.block.level</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.merge.size.per.task</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>256000000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.merge.smallfiles.avgsize</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>16000000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.merge.tezfiles</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.metastore.authorization.storage.checks</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.metastore.client.connect.retry.delay</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>5s</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.metastore.connect.retries</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>24</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.metastore.failure.retries</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>24</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.metastore.server.max.threads</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>100000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.optimize.constant.propagation</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.optimize.metadataonly</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.optimize.null.scan</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.optimize.sort.dynamic.partition</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.orc.compute.splits.num.threads</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.prewarm.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.prewarm.numcontainers</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.security.metastore.authenticator.manager</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.security.metastore.authorization.auth.reads</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.allow.user.substitution</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.logging.operation.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.logging.operation.log.location</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>${system:java.io.tmpdir}/${system:user.name}/operation_logs</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.table.type.mapping</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>CLASSIC</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.thrift.http.path</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>cliservice</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.thrift.http.port</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10001</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.thrift.max.worker.threads</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>500</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.thrift.sasl.qop</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>auth</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.transport.mode</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>binary</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.use.SSL</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.smbjoin.cache.rows</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.stats.dbclass</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>fs</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.stats.fetch.column.stats</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.stats.fetch.partition.stats</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.support.concurrency</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.tez.auto.reducer.parallelism</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.tez.cpu.vcores</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-1</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.tez.dynamic.partition.pruning</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.tez.dynamic.partition.pruning.max.data.size</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>104857600</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.tez.dynamic.partition.pruning.max.event.size</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1048576</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.tez.log.level</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>INFO</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.tez.max.partition.factor</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>2.0</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.tez.min.partition.factor</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.25</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.tez.smb.number.waves</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.5</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.user.install.directory</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/user/</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.vectorized.execution.reduce.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.zookeeper.client.port</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>2181</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.zookeeper.namespace</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>hive_zookeeper_namespace</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.zookeeper.quorum</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>&lt;!-- List of zookeeper server to talk to --&gt;</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                            <li>
                              <p>Modify</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.metastore.client.socket.timeout</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1800s</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.optimize.reducededuplication.min.reducer</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>4</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.security.authorization.manager</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.security.metastore.authorization.manager</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider,
                                          org.apache.hadoop.hive.ql.security.authorization.MetaStoreAuthzAPIAuthorizerEmbedOnly
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.server2.support.dynamic.service.discovery</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>hive.vectorized.groupby.checkinterval</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>4096</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>fs.file.impl.disable.cache</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>fs.hdfs.impl.disable.cache</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;<code>Service Actions</code>, start YARN.
                  </p>
                </li>
                <li>
                  <p>Using
                    <code></code>
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;<code>Service Actions</code>, start MapReduce2.
                  </p>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;<code>Service Actions</code>, start HBase and ensure the service check
                    passes.
                  </p>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    <code>Service Actions</code>
                    <code>,</code>start the Hive service.
                  </p>
                </li>
                <li>
                  <p>Upgrade Oozie.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Perform the following preparation steps on each Oozie server host:</p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Note.png" width="50"></div>
                          <div class="simple-block">
                            <p>You must replace your Oozie configuration after upgrading.</p>
                          </div>
                        </aside>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Copy configurations from
                                <code>oozie-conf-bak</code>
                                to the
                                <code>/etc/oozie/conf</code>
                                directory on each Oozie server and client.
                              </p>
                            </li>
                            <li>
                              <p>Create
                                <code>/usr/hdp/2.2.0.0-</code>
                                &lt;$version&gt;
                                <code>/oozie/libext-upgrade22</code>
                                directory.
                              </p>
                              <p>
                                <code>mkdir /usr/hdp/2.2.0.0-</code>
                                &lt;$version&gt;
                                <code>/oozie/libext-upgrade22</code>
                              </p>
                            </li>
                            <li>
                              <p>Copy the JDBC jar of your Oozie database to both
                                <code>/usr/hdp/2.2.0.0-</code>
                                &lt;$version&gt;
                                <code>/oozie/libext-upgrade22</code>
                                and
                                <code>/usr/hdp/2.2.0.0-</code>
                                &lt;$version&gt;
                                <code>/oozie/libtools</code>.

                                For example, if you are using MySQL, copy your<code>
                                  mysql-connector-java.jar</code>.
                                <code>
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Copy these files to
                                <code>/usr/hdp/2.2.0.0-</code>
                                &lt;$version&gt;
                                <code>/oozie/libext-upgrade22</code>
                                directory
                              </p>
                              <p>
                                <code>cp /usr/lib/hadoop/lib/hadoop-lzo*.jar /usr/hdp/2.2.0.0-
                                </code>
                                &lt;$version&gt;
                                <code>/oozie/libext-upgrade22;
                                  cp /usr/share/HDP-oozie/ext-2.2.zip /usr/hdp/2.2.0.0-
                                </code>
                                &lt;$version&gt;
                                <code>/oozie/libext-upgrade22;
                                  cp /usr/share/HDP-oozie/ext-2.2.zip /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Grant read/write access to the Oozie user.</p>
                              <p>
                                <code>chmod -R 777 /usr/hdp/2.2.0.0-</code>
                                &lt;$version&gt;
                                <code>/oozie/libext-upgrade22</code>
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Upgrade steps:</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>On the Services view, make sure that YARN and MapReduce2 services are running.
                              </p>
                            </li>
                            <li>
                              <p>Make sure that the Oozie service is stopped.</p>
                            </li>
                            <li>
                              <p>In<code>/etc/oozie/conf/oozie-env.sh</code>, comment out
                                <code>CATALINA_BASE</code>
                                property, also do the same using Ambari Web UI in
                                <code>Services</code>
                                &gt;
                                <code>Oozie</code>
                                &gt;
                                <code>Configs</code>
                                &gt;<code>Advanced oozie-env</code>.
                              </p>
                            </li>
                            <li>
                              <p>Upgrade Oozie.

                                At the Oozie database host, as the Oozie service user:
                              </p>
                              <p>
                                <code>sudo su -l</code>
                                &lt;OOZIE_USER&gt;
                                <code>-c"/usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/bin/ooziedb.sh upgrade -run"

                                </code>where
                                &lt;OOZIE_USER&gt;
                                is the Oozie service user. For example, oozie.
                              </p>
                              <p>Make sure that the output contains the string "Oozie DB has been upgraded to
                                Oozie version&lt;OOZIE_Build_Version&gt;.
                              </p>
                            </li>
                            <li>
                              <p>Prepare the Oozie WAR file.</p>
                              <aside class="custom-note">
                                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                                <div class="simple-block">
                                  <p>The Oozie server must be
                                    <strong>not</strong>
                                    running for this step. If you get the message "ERROR: Stop Oozie first", it means
                                    the script still thinks it's running. Check, and if needed, remove the process id
                                    (pid) file indicated in the output. You may see additional "File Not Found" error
                                    messages during a successful upgrade of Oozie.
                                  </p>
                                </div>
                              </aside>
                              <p>On the Oozie server, as the Oozie user
                                <code>
                                  sudo su -l
                                </code>
                                &lt;OOZIE_USER&gt;
                                <code>-c "/usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/bin/oozie-setup.sh
                                  prepare-war -d /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext-upgrade22"

                                </code>where
                                &lt;OOZIE_USER&gt;
                                is the Oozie service user. For example, oozie.
                              </p>
                              <p>Make sure that the output contains the string "New Oozie WAR file added".
                              </p>
                            </li>
                            <li>
                              <p>Using<code>Ambari Web</code>, choose
                                <code>Services</code>
                                &gt;
                                <code>Oozie</code>
                                &gt;<code>Configs</code>, expand<code>oozie-log4j</code>
                                , then add the following property:
                              </p>
                              <p>
                                <code>log4j.appender.oozie.layout.ConversionPattern=%d{ISO8601} %5p %c{1}:%L -
                                  SERVER[
                                </code>
                                ${oozie.instance.id}
                                <code>] %m%n</code>

                                where
                                ${oozie.instance.id}
                                is determined by Oozie, automatically.
                              </p>
                            </li>
                            <li>
                              <p>Using
                                <code>Ambari Web</code>
                                &gt;
                                <code>Services</code>
                                &gt;
                                <code>Oozie</code>
                                &gt;
                                <code>Configs</code>
                                <code>,</code>expand<code>Advanced
                                  oozie-site</code>, then edit the following properties:
                              </p>
                              <ul class="UppercaseAlpha">
                                
                                  <li>
                                    <p>In<code>oozie.service.coord.push.check.requeue.interval</code>
                                      ,
                                      <strong>
                                        <i>replace</i>
                                      </strong>
                                      the existing property value with the following one:
                                    </p>
                                    <p>
                                      <code>30000</code>
                                    </p>
                                  </li>
                                  <li>
                                    <p>In<code>oozie.service.URIHandlerService.uri.handlers</code>,
                                      <strong>
                                        <i>append</i>
                                      </strong>
                                      to the existing property value the following string, if is it is not already
                                      present:
                                    </p>
                                    <p>
                                      <code>
                                        org.apache.oozie.dependency.FSURIHandler,org.apache.oozie.dependency.HCatURIHandler
                                      </code>
                                    </p>
                                  </li>
                                  <li>
                                    <p>In<code>oozie.services</code>, make sure all the following
                                      properties are present:
                                    </p>
                                    <pre><code>org.apache.oozie.service.SchedulerService,
                                      org.apache.oozie.service.InstrumentationService,
                                      org.apache.oozie.service.MemoryLocksService,
                                      org.apache.oozie.service.UUIDService,
                                      org.apache.oozie.service.ELService,
                                      org.apache.oozie.service.AuthorizationService,
                                      org.apache.oozie.service.UserGroupInformationService,
                                      org.apache.oozie.service.HadoopAccessorService,
                                      org.apache.oozie.service.JobsConcurrencyService,
                                      org.apache.oozie.service.URIHandlerService,
                                      org.apache.oozie.service.DagXLogInfoService,
                                      org.apache.oozie.service.SchemaService,
                                      org.apache.oozie.service.LiteWorkflowAppService,
                                      org.apache.oozie.service.JPAService,
                                      org.apache.oozie.service.StoreService,
                                      org.apache.oozie.service.CoordinatorStoreService,
                                      org.apache.oozie.service.SLAStoreService,
                                      org.apache.oozie.service.DBLiteWorkflowStoreService,
                                      org.apache.oozie.service.CallbackService,
                                      org.apache.oozie.service.ActionService,
                                      org.apache.oozie.service.ShareLibService,
                                      org.apache.oozie.service.CallableQueueService,
                                      org.apache.oozie.service.ActionCheckerService,
                                      org.apache.oozie.service.RecoveryService,
                                      org.apache.oozie.service.PurgeService,
                                      org.apache.oozie.service.CoordinatorEngineService,
                                      org.apache.oozie.service.BundleEngineService,
                                      org.apache.oozie.service.DagEngineService,
                                      org.apache.oozie.service.CoordMaterializeTriggerService,
                                      org.apache.oozie.service.StatusTransitService,
                                      org.apache.oozie.service.PauseTransitService,
                                      org.apache.oozie.service.GroupsService,
                                      org.apache.oozie.service.ProxyUserService,
                                      org.apache.oozie.service.XLogStreamingService,
                                      org.apache.oozie.service.JvmPauseMonitorService
                                    </code></pre>
                                  </li>
                                  <li>
                                    <p>Add the
                                      <code>oozie.service.AuthorizationService.security.enabled
                                      </code>
                                      <code></code>property with the following property value:
                                      <code>false</code>
                                    </p>
                                    <p>
                                      Specifies whether security (user name/admin role) is enabled or not. If disabled
                                      any user can manage Oozie system and manage any job.
                                    </p>
                                  </li>
                                  <li>
                                    <p>Add the
                                      <code>oozie.service.HadoopAccessorService.kerberos.enabled
                                      </code>
                                      <code></code>property with the following property value:
                                      <code>false</code>
                                    </p>
                                    <p>
                                      Indicates if Oozie is configured to use Kerberos.
                                    </p>
                                  </li>
                                  <li>
                                    <p>In<code>oozie.services.ext</code>,
                                      <strong>
                                        <i>append</i>
                                      </strong>
                                      to the existing property value the following string, if is it is not already
                                      present:
                                    </p>
                                    <pre><code>
                                      org.apache.oozie.service.PartitionDependencyManagerService,org.apache.oozie.service.HCatAccessorService
                                    </code></pre>
                                  </li>
                                  <li>
                                    <p>After modifying all properties on the Oozie Configs page, choose
                                      <code>Save</code>
                                      to update<code>oozie.site.xml</code>, using the modified
                                      configurations.
                                    </p>
                                  </li>
                                
                              </ul>
                            </li>
                            <li>
                              <p>Replace the content of
                                <code>/usr/oozie/share</code>
                                in HDFS.
                              </p>
                              <p>
                                On the Oozie server host:
                              </p>
                              <ul class="Numeric">
                                
                                  <li>
                                    <p>Extract the Oozie sharelib into a
                                      <code>tmp</code>
                                      folder.
                                    </p>
                                    <p>
                                      <code>mkdir -p /tmp/oozie_tmp;
                                        cp /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/oozie-sharelib.tar.gz /tmp/oozie_tmp;
                                        cd /tmp/oozie_tmp;
                                        tar xzvf oozie-sharelib.tar.gz;
                                      </code>
                                    </p>
                                  </li>
                                  <li>
                                    <p>Back up the
                                      <code>/user/oozie/share</code>
                                      folder in HDFS and then delete it.
                                    </p>
                                    <p>
                                      If you have any custom files in this folder, back them up separately and then add
                                      them to the /share folder after updating it.
                                    </p>
                                    <p>
                                      <code>mkdir /tmp/oozie_tmp/oozie_share_backup;
                                        chmod 777 /tmp/oozie_tmp/oozie_share_backup;
                                      </code>
                                    </p>
                                    <p>
                                      <code>su -l</code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -copyToLocal /user/oozie/share
                                        /tmp/oozie_tmp/oozie_share_backup";
                                        su -l
                                      </code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -rm -r /user/oozie/share";
                                      </code>
                                      where
                                      &lt;HDFS_USER&gt;
                                      is the HDFS service user. For example, hdfs.
                                    </p>
                                  </li>
                                  <li>
                                    <p>Add the latest share libs that you extracted in step 1. After you have
                                      added the files, modify ownership and acl.
                                    </p>
                                    <p>
                                      <code>su -l</code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -copyFromLocal /tmp/oozie_tmp/share /user/oozie/.";
                                        su -l
                                      </code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -chown -R &lt;OOZIE_USER&gt;:&lt;HADOOP_GROUP&gt;
                                        /user/oozie";
                                        su -l
                                      </code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -chmod -R 755 /user/oozie";
                                      </code>
                                      where
                                      &lt;HDFS_USER&gt;
                                      is the HDFS service user. For example, hdfs.
                                    </p>
                                  </li>
                                
                              </ul>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Update Oozie Configuration Properties for HDP 2.2</p>
                        <p>
                          Using<code>Ambari Web UI &gt; Services &gt; Oozie &gt; Configs &gt;
                          oozie-site.xml</code>:
                        </p>
                        <ul class="Arrow">
                          
                            <li>
                              <p>Add</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>oozie.authentication.simple.anonymous.allowed</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>oozie.service.coord.check.maximum.frequency</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>oozie.service.HadoopAccessorService.kerberos.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                            <li>
                              <p>Modify</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>oozie.service.SchemaService.wf.ext.schemas</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          shell-action-0.1.xsd,shell-action-0.2.xsd,shell-action-0.3.xsd,email-action-0.1.xsd,email-action-0.2.xsd,
                                          hive-action-0.2.xsd,hive-action-0.3.xsd,hive-action-0.4.xsd,hive-action-0.5.xsd,sqoop-action-0.2.xsd,
                                          sqoop-action-0.3.xsd,sqoop-action-0.4.xsd,ssh-action-0.1.xsd,ssh-action-0.2.xsd,distcp-action-0.1.xsd,
                                          distcp-action-0.2.xsd,oozie-sla-0.1.xsd,oozie-sla-0.2.xsd
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>oozie.services.ext</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          org.apache.oozie.service.JMSAccessorService,org.apache.oozie.service.PartitionDependencyManagerService,
                                          org.apache.oozie.service.HCatAccessorService
                                        </p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Use the
                    <code>Ambari Web UI</code>
                    &gt;
                    <code>Services</code>
                    view to start the Oozie service.
                  </p>
                  <p>
                    Make sure that ServiceCheck passes for Oozie.
                  </p>
                </li>
                <li>
                  <p>Update WebHCat.</p>
                  <ul class="UppercaseAlpha">
                    
                      <li>
                        <p>Modify the
                          <code>webhcat-site</code>
                          config type.
                        </p>
                        <p>Using
                          <code>Ambari Web</code>
                          &gt;
                          <code>Services</code>
                          &gt;<code>WebHCat</code>, modify the following configuration:
                        </p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Action</p>
                                </th>
                                <th rowspan="1">
                                  <p>Property Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Property Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>Modify</p>
                                </td>
                                <td rowspan="1">
                                  <p>templeton.storage.class</p>
                                </td>
                                <td rowspan="1">
                                  <p>org.apache.hive.hcatalog.templeton.tool.ZooKeeperStorage</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Expand
                          <code>Advanced</code>
                          &gt;<code>webhcat-site.xml</code>.
                        </p>
                        <p>
                          Check if property
                          <code>templeton.port</code>
                          exists. If not, then add it using the Custom webhcat-site panel. The default value for
                          templeton.port = 50111.
                        </p>
                      </li>
                      <li>
                        <p>On each WebHCat host, update the Pig and Hive tar bundles, by updating the following
                          files:
                        </p>
                        <ul class="Bullet">
                          
                            <li>
                              <p>
                                <code>/apps/webhcat/pig.tar.gz</code>
                              </p>
                            </li>
                            <li>
                              <p>
                                <code>/apps/webhcat/hive.tar.gz</code>
                              </p>
                              <aside class="custom-note">
                                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                                <div class="simple-block">
                                  <p>Find these files only on a host where WebHCat is installed.</p>
                                </div>
                              </aside>
                            </li>
                          
                        </ul>
                        <ul class="Numeric">
                          For example, to update a *.tar.gz file:
                          
                            <li>
                              <p>Move the file to a local directory.</p>
                              <p>
                                <code>su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hadoop --config /etc/hadoop/conf fs -copyToLocal
                                  /apps/webhcat/*.tar.gz
                                </code>
                                &lt;local_backup_dir&gt;
                                <code>"</code>
                              </p>
                            </li>
                            <li>
                              <p>Remove the old file.</p>
                              <p>
                                <code>su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hadoop --config /etc/hadoop/conf fs -rm /apps/webhcat/*.tar.gz"
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Copy the new file.</p>
                              <pre><code>su -l &lt;HCAT_USER&gt; -c "hdfs --config /etc/hadoop/conf dfs -copyFromLocal
                                /usr/hdp/2.2.0.0-&lt;$version&gt;/hive/hive.tar.gz /apps/webhcat/"; su -l &lt;HCAT_USER&gt;
                                -c "hdfs --config /etc/hadoop/conf dfs -copyFromLocal /usr/hdp/2.2.0.0-&lt;$version&gt;/pig/pig.tar.gz
                                /apps/webhcat/";
                              </code></pre>
                              <p>
                                where
                                &lt;HCAT_USER&gt;
                                is the HCatalog service user. For example, hcat.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>On each WebHCat host, update
                          <code>/app/webhcat/hadoop-streaming.jar</code>
                          file.
                        </p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Move the file to a local directory.</p>
                              <p>
                                <code>su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hadoop --config /etc/hadoop/conf fs -copyToLocal
                                  /apps/webhcat/hadoop-streaming*.jar &lt;local_backup_dir&gt;"
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Remove the old file.</p>
                              <pre><code>su -l &lt;HCAT_USER&gt; -c "hadoop --config /etc/hadoop/conf fs -rm
                                /apps/webhcat/hadoop-streaming*.jar"
                              </code></pre>
                            </li>
                            <li>
                              <p>Copy the new hadoop-streaming.jar file.</p>
                              <pre><code>su -l &lt;HCAT_USER&gt; -c "hdfs --config /etc/hadoop/conf dfs -copyFromLocal
                                /usr/hdp/2.2.0.0-&lt;$version&gt;/hadoop-mapreduce/hadoop-streaming*.jar /apps/webhcat"
                              </code></pre>
                              <p>
                                where
                                &lt;HCAT_USER&gt;
                                is the HCatalog service user. For example, hcat.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>If Tez was not installed during the upgrade, you must prepare Tez for work, using the
                    following steps:
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>The Tez client should be available on the same host with Pig.</p>
                    </div>
                  </aside>
                  <p>
                    If you use Tez as the Hive execution engine, and if the variable hive.server2.enabled.doAs is set to
                    true, you must create a scratch directory on the NameNode host for the username that will run the
                    HiveServer2 service. If you installed Tez before upgrading the Stack, use the following commands:

                    <code>sudo su -c "hdfs -makedir /tmp/hive-</code>
                    &lt;username&gt;
                    <code>"
                      sudo su -c "hdfs -chmod 777 /tmp/hive-
                    </code>
                    &lt;username&gt;
                    <code>"
                    </code>where&lt;username&gt; is the name of the user that runs the
                    HiveServer2 service.
                  </p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Update Tez Configuration Properties for HDP 2.2</p>
                        <p>
                          Using
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Services</code>
                          &gt;
                          <code>Tez</code>
                          &gt;
                          <code>Configs</code>
                          &gt;<code>tez-site.xml</code>:
                        </p>
                        <ul class="Arrow">
                          
                            <li>
                              <p>Add</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.container.idle.release-timeout-max.millis</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>20000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.container.idle.release-timeout-min.millis</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.launch.cluster-default.cmd-opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-server -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.launch.cmd-opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA
                                          -XX:+UseParallelGC
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.launch.env</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib
                                          /native/Linux-amd64-64
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.max.app.attempts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>2</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.maxtaskfailures.per.node</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.cluster.additional.classpath.prefix</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          /usr/hdp/${hdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${hdp.version}.jar:/etc/hadoop/conf/secure
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.counters.max</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>2000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.counters.max.groups</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.generate.debug.artifacts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.grouping.max-size</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1073741824</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.grouping.min-size</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>16777216</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.grouping.split-waves</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1.7</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.history.logging.service.class</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.tez.dag.history.logging.ats.ATSHistoryLoggingService
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.runtime.compress</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.runtime.compress.codec</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.hadoop.io.compress.SnappyCodec</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.runtime.io.sort.mb</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>272</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.runtime.unordered.output.buffer.size-mb</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>51</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.shuffle-vertex-manager.max-src-fraction</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.4</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.shuffle-vertex-manager.min-src-fraction</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.2</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.task.am.heartbeat.counter.interval-ms.max</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>4000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.task.launch.cluster-default.cmd-opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-server -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.task.launch.cmd-opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA
                                          -XX:+UseParallelGC
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.task.launch.env</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib
                                          /native/Linux-amd64-64
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.task.max-events-per-heartbeat</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>500</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.task.resource.memory.mb</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>682</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                            <li>
                              <p>Modify</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.container.reuse.non-local-fallback.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.resource.memory.mb</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1364</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.lib.uris</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/hdp/apps/${hdp.version}/tez/tez.tar.gz</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.session.client.timeout.secs</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-1</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                            <li>
                              <p>Remove</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.container.session.delay-allocation-millis</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>10000</p>
                                        <p> </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.env</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          LD_LIBRARY_PATH=/usr/hdp/2.2.0.0-1947/hadoop/lib/native:/usr/hdp/2.2.0.0-1947/hadoop/lib/native/Linux-amd64-64
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.grouping.max-size</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1073741824</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.grouping.min-size</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>16777216</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.grouping.split-waves</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1.4</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.java.opt</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-server -Xmx546m -Djava.net.preferIPv4Stack=true -XX:+UseNUMA
                                          -XX:+UseParallelGC
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.shuffle-vertex-manager.max-src-fraction</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.4</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.am.shuffle-vertex-manager.min-src-fraction</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.2</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.runtime.intermediate-input.compress.codec</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.hadoop.io.compress.SnappyCodec</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.runtime.intermediate-input.is-compressed</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.runtime.intermediate-output.compress.codec</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.hadoop.io.compress.SnappyCodec</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.runtime.intermediate-output.should-compress</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>tez.yarn.ats.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>true</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Put Tez libraries in hdfs. Execute at any host:</p>
                        <pre><code>su -l hdfs -c "hdfs dfs -mkdir -p /hdp/apps/2.2.0.0-&lt;$version&gt;/tez/"
                          su -l hdfs -c "hdfs dfs -copyFromLocal /usr/hdp/2.2.0.0-&lt;$version&gt;/tez/lib/tez.tar.gz
                          /hdp/apps/2.2.0.0-&lt;$version&gt;/tez/."
                          su -l hdfs -c "hdfs dfs -chown -R &lt;HDFS_USER&gt;:&lt;HADOOP_GROUP&gt; /hdp" su -l hdfs -c
                          "hdfs dfs -chmod -R 555 /hdp/apps/2.2.0.0-1899/tez" su -l hdfs -c "hdfs dfs -chmod -R 444
                          /hdp/apps/2.2.0.0-1899/tez/tez.tar.gz"
                        </code></pre>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Prepare the Storm service properties.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Edit nimbus.childopts.</p>
                        <p>
                          Using Ambari Web UI &gt; Services &gt; Storm &gt; Configs &gt; Nimbus &gt; find
                          nimbus.childopts. Update the path for the jmxetric-1.0.4.jar to:
                          /usr/hdp/current/storm-nimbus/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar.
                          If nimbus.childopts property value contains
                          "-Djava.security.auth.login.config=/path/to/storm_jaas.conf", remove this text.
                        </p>
                      </li>
                      <li>
                        <p>Edit supervisor.childopts.</p>
                        <p>
                          Using Ambari Web UI &gt; Services &gt; Storm &gt; Configs &gt; Supervisor &gt; find
                          supervisor.childopts. Update the path for the jmxetric-1.0.4.jar to:
                          /usr/hdp/current/storm-nimbus/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar.
                          If supervisor.childopts property value contains
                          "-Djava.security.auth.login.config=/etc/storm/conf/storm_jaas.conf", remove this text.
                        </p>
                      </li>
                      <li>
                        <p>Edit worker.childopts.</p>
                        <p>
                          Using Ambari Web UI &gt; Services &gt; Storm &gt; Configs &gt; Advanced &gt; storm-site find
                          worker.childopts. Update the path for the jmxetric-1.0.4.jar to:
                          /usr/hdp/current/storm-nimbus/contrib/storm-jmxetric/lib/jmxetric-1.0.4.jar.

                          Check if the _storm.thrift.nonsecure.transport property exists. If not, add it,
                          _storm.thrift.nonsecure.transport = backtype.storm.security.auth.SimpleTransportPlugin, using
                          the Custom storm-site panel.
                        </p>
                      </li>
                      <li>
                        <p>Remove the
                          <code>storm.local.dir</code>
                          from every host where the Storm component is installed.
                        </p>
                        <p>
                          You can find this property in the Storm &gt; Configs &gt; General tab.
                        </p>
                        <p>
                          <code>rm -rf</code>
                          &lt;storm.local.dir&gt;
                        </p>
                      </li>
                      <li>
                        <p>If you are planning to enable secure mode, navigate to
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Services</code>
                          &gt;
                          <code>Storm</code>
                          &gt;<code>Configs</code>&gt;
                          <code>Advanced storm-site</code>
                          and add the following property:
                        </p>
                        <pre><code>
                          _storm.thrift.secure.transport=backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin
                        </code></pre>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Upgrade Pig.</p>
                  <p>
                    Copy the the Pig configuration files to /etc/pig/conf.
                  </p>
                  <p>
                    <code>cp /etc/pig/conf.dist/pig.properties.rpmsave /etc/pig/conf/pig.properties;
                      cp /etc/pig/conf.dist/pig-env.sh /etc/pig/conf/;
                      cp /etc/pig/conf.dist/log4j.properties.rpmsave /etc/pig/conf/log4j.properties
                    </code>
                  </p>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web UI</code>
                    &gt;
                    <code>Services</code>
                    &gt;<code>Storm</code>, start the Storm service.
                  </p>
                </li>
                <li>
                  <p>Prepare the Falcon service properties:</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Update Falcon Configuration Properties for HDP 2.2</p>
                        <p>
                          Using
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Services</code>
                          &gt;
                          <code>Falcon</code>
                          &gt;
                          <code>Configs</code>
                          &gt;<code>falcon startup properties</code>:
                        </p>
                        <ul class="Arrow">
                          
                            <li>
                              <p>Add</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.application.services</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.falcon.security.AuthenticationInitializationService,\
                                          org.apache.falcon.workflow.WorkflowJobEndNotificationService,\
                                          org.apache.falcon.service.ProcessSubscriberService,\
                                          org.apache.falcon.entity.store.ConfigurationStore,\
                                          org.apache.falcon.rerun.service.RetryService,\
                                          org.apache.falcon.rerun.service.LateRunService,\
                                          org.apache.falcon.service.LogCleanupService
                                        </p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                          
                        </ul>
                        <p>
                          Using
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Services</code>
                          &gt;
                          <code>Falcon</code>
                          &gt;
                          <code>Configs</code>
                          &gt;<code>advanced falcon-startup</code>:
                        </p>
                        <ul class="Arrow">
                          
                            <li>
                              <p>Add</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.dfs.namenode.kerberos.principal</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>nn/_HOST@EXAMPLE.COM</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.enableTLS</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.http.authentication.cookie.domain</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>EXAMPLE.COM</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.http.authentication.kerberos.keytab</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/etc/security/keytabs/spnego.service.keytab</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.http.authentication.kerberos.principal</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>HTTP/_HOST@EXAMPLE.COM</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.security.authorization.admin.groups</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>falcon</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.security.authorization.admin.users</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>falcon,ambari-qa</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.security.authorization.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.security.authorization.provider</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.falcon.security.DefaultAuthorizationProvider</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.security.authorization.superusergroup</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>falcon</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.service.authentication.kerberos.keytab</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/etc/security/keytabs/falcon.service.keytab</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.falcon.service.authentication.kerberos.principal</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>falcon/_HOST@EXAMPLE.COM</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>*.journal.impl</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.falcon.transaction.SharedFileSystemJournal</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>prism.application.services</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.falcon.entity.store.ConfigurationStore</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>prism.configstore.listeners</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>org.apache.falcon.entity.v0.EntityGraph,\
                                          org.apache.falcon.entity.ColoClusterRelation,\
                                          org.apache.falcon.group.FeedGroupMap
                                        </p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;<code>Service Actions</code>, re-start all stopped services.
                  </p>
                </li>
                <li>
                  <p>The upgrade is now fully functional but not yet finalized. Using the
                    <code>finalize</code>
                    command removes the previous version of the NameNode and DataNode storage directories.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>After the upgrade is finalized, the system cannot be rolled back. Usually this step is
                        not taken until a thorough testing of the upgrade has been performed.
                      </p>
                    </div>
                  </aside>
                  <p>
                    The upgrade must be finalized before another upgrade can be performed.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>Directories used by Hadoop 1 services set in
                        <code>/etc/hadoop/conf/taskcontroller.cfg</code>
                        are not automatically deleted after upgrade. Administrators can choose to delete these
                        directories after the upgrade.
                      </p>
                    </div>
                  </aside>
                  <p>
                    To finalize the upgrade, execute the following command once, on the primary NameNode host in your
                    HDP cluster,
                    <code>
                      sudo su -l
                    </code>
                    &lt;HDFS_USER&gt;
                    <code>-c "hdfs dfsadmin -finalizeUpgrade"

                    </code>where
                    &lt;HDFS_USER&gt;
                    is the HDFS service user. For example, hdfs.
                  </p>
                </li>
              
            </ul>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-24d144de-9940-47d5-a9ea-e4480d3ddb02">Upgrading the HDP Stack from 2.0 to 2.2</h3>
        
          <p>The HDP Stack is the coordinated set of Hadoop components that you have installed on hosts in your
            cluster. Your set of Hadoop components and hosts is unique to your cluster. Before upgrading the Stack on
            your cluster, review all Hadoop services and hosts in your cluster to confirm the location of Hadoop
            components. For example, use the<code>Hosts</code>and
            <code>Services</code>
            views in Ambari Web, which summarize and list the components installed on each Ambari host, to determine the
            components installed on each host. For more information about using Ambari to view components in your
            cluster, see<a href="#ref-c4a195fa-6eec-41a3-a699-14e950d7893b">Working with Hosts</a>, and<a href="#ref-9cb21557-3948-4efa-b3cb-1c65f5b0ad31">Viewing Components on a Host</a>.
          </p>
          <p>
            Complete the following procedures to upgrade the Stack from version 2.0 to version 2.2 on your current,
            Ambari-installed-and-managed cluster.
          </p>
          <ul class="number-list">
            
              <li>
                <p>
                  <a href="#ref-e17b9cf0-81d0-4b3c-b85d-457f7a2e53e3">Prepare the 2.0 Stack for Upgrade</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-41831906-2d58-4560-8544-0984950cd0c8">Upgrade the 2.0 Stack</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-1512192f-112b-4852-b7e8-81e2727e7fff">Complete the Upgrade of the 2.0 Stack to
                    2.2
                  </a>
                </p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>If you plan to upgrade your existing JDK, do so after upgrading Ambari, before upgrading the
                Stack. The upgrade steps require that you remove HDP v2.0 components and install HDP v2.2 components. As
                noted in that section, you should remove and install on each host, only the components on each host that
                you want to run on the HDP 2.2 stack.

                For example, if you want to run Storm or Falcon components on the HDP 2.2 stack, you will install those
                components and then configure their properties during the upgrade procedure.
              </p>
            </div>
          </aside>
        
        
          <p>In preparation for future HDP 2.2 releases to support rolling upgrades, the HDP RPM package version
            naming convention has changed to include the HDP 2.2 product version in file and directory names. HDP 2.2
            marks the first release where HDP rpms, debs, and directories contain versions in the names to permit
            side-by-side installations of later HDP releases. To transition between previous releases and HDP 2.2,
            Pivotal provides hdp-select, a script that symlinks your directories to
            <code>hdp/current</code>
            and lets you maintain using the same binary and configuration paths that you were using before.

            The following instructions have you remove your old versions of HDP, install hdp-select, and install HDP 2.2
            to prepare for rolling upgrade.
          </p>
        
        
          <h4 class="bold">Prepare the 2.0 Stack for Upgrade</h4>
          
            <p>To prepare for upgrading the HDP Stack, this section describes how to perform the following
              tasks:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>Disable Security.</p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>If your Stack has Kerberos Security turned on, turn it off before performing the
                        upgrade. On<code>Ambari Web UI</code>&gt;
                        <code>Admin</code>
                        &gt;<code>Security</code>click<code>Disable
                          Security</code>. You can re-enable Security after performing the upgrade.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Checkpoint user metadata and capture the HDFS operational state.
                    This step supports rollback and restore of the original state of HDFS data, if necessary.
                  </p>
                </li>
                <li>
                  <p>Backup Hive and Oozie metastore databases.
                    This step supports rollback and restore of the original state of Hive and Oozie data, if necessary.
                  </p>
                </li>
                <li>
                  <p>Stop all HDP and Ambari services.</p>
                </li>
                <li>
                  <p>Make sure to finish all current jobs running on the system before upgrading the stack.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>Libraries will change during the upgrade. Any jobs remaining active that use the older
                        version libraries will probably fail during the upgrade.
                      </p>
                    </div>
                  </aside>
                </li>
              
            </ul>
          
          
            <ul class="number-list">
              
                <li>
                  <p>Use
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    <code>Service Actions</code>
                    <code></code>to stop all services except HDFS and ZooKeeper.
                  </p>
                </li>
                <li>
                  <p>Stop any client programs that access HDFS.</p>
                  <p>Perform steps 3 through 8 on the NameNode host. In a highly-available NameNode
                    configuration, execute the following procedure on the primary NameNode.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>To locate the primary NameNode in an Ambari-managed HDP cluster, browse
                        <code>Ambari Web</code>
                        &gt;
                        <code>Services</code>
                        &gt;<code>HDFS</code>. In Summary, click NameNode.
                        <code>Hosts</code>
                        &gt;<code>Summary</code>displays the host name FQDN.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>If HDFS is in a non-finalized state from a prior upgrade operation, you must finalize HDFS
                    before upgrading further. Finalizing HDFS will remove all links to the metadata of the prior HDFS
                    version - do this only if you do not want to rollback to that prior HDFS version.
                  </p>
                  <p>On the NameNode host, as the HDFS user,
                    <code>
                      su -l
                    </code>
                    &lt;HDFS_USER&gt;
                    <code>
                      hdfs dfsadmin -finalizeUpgrade
                    </code>
                    where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.
                  </p>
                </li>
                <li>
                  <p>Check the NameNode directory to ensure that there is no snapshot of any prior HDFS upgrade.

                    Specifically, using<code>Ambari Web &gt; HDFS &gt; Configs &gt;
                      NameNode</code>, examine the
                    &lt;$dfs.namenode.name.dir&gt;
                    or the
                    &lt;$dfs.name.dir&gt;
                    directory in the NameNode Directories property. Make sure that only a "\current" directory and no
                    "\previous" directory exists on the NameNode host.
                  </p>
                </li>
                <li>
                  <p>Create the following logs and other files.</p>
                  <p>
                    Creating these logs allows you to check the integrity of the file system, post-upgrade.

                    As the HDFS user,
                    <code>
                      su -l
                    </code>
                    &lt;HDFS_USER&gt;

                    where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Run
                          <code>fsck</code>
                          with the following flags and send the results to a log. The resulting file contains a complete
                          block map of the file system. You use this log later to confirm the upgrade.
                        </p>
                        <p>
                          <code>hdfs fsck / -files -blocks -locations &gt; dfs-old-fsck-1.log</code>
                          <code></code>
                        </p>
                      </li>
                      <li>
                        <p>Optional: Capture the complete namespace of the filesystem.

                          The following command does a recursive listing of the root file system:
                          <code>
                            hadoop dfs -ls -R / &gt; dfs-old-lsr-1.log
                          </code>
                          <code></code>
                        </p>
                      </li>
                      <li>
                        <p>Create a list of all the DataNodes in the cluster.</p>
                        <p>
                          <code>hdfs dfsadmin -report &gt; dfs-old-report-1.log</code>
                        </p>
                      </li>
                      <li>
                        <p>Optional: Copy all unrecoverable data stored in HDFS to a local file system or to a
                          backup instance of HDFS.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p><strong>Save the namespace</strong>.
                  </p>
                  <p>
                    You must be the HDFS service user to do this and you must put the cluster in Safe Mode.
                  </p>
                  <p>
                    <code>hdfs dfsadmin -safemode enter</code>
                    
                    <code>
                      hdfs dfsadmin -saveNamespace
                    </code>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>In a highly-available NameNode configuration, the command
                        <code>hdfs dfsadmin -saveNamespace</code>
                        sets a checkpoint in the first NameNode specified in the configuration, in<code>
                          dfs.ha.namenodes.[nameservice ID]</code>. You can also use the dfsadmin
                        <code>-fs</code>
                        option to specify which NameNode to connect.

                        For example, to force a checkpoint in namenode 2:

                        <code>hdfs dfsadmin -fs hdfs://namenode2-hostname:namenode2-port -saveNamespace
                        </code>
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Copy the checkpoint files located in
                    &lt;$dfs.name.dir/current&gt;
                    into a backup directory.
                  </p>
                  <p>

                    Find the directory, using Ambari Web &gt; HDFS &gt; Configs &gt; NameNode &gt; NameNode Directories
                    on your primary NameNode host.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>In a highly-available NameNode configuration, the location of the checkpoint depends on
                        where the saveNamespace command is sent, as defined in the preceding step.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Store the layoutVersion for the NameNode.

                    Make a copy of the file at
                    &lt;dfs.name.dir&gt;
                    <code>/current/VERSION</code>
                    where
                    &lt;dfs.name.dir&gt;
                    is the value of the config parameter<code>NameNode directories</code>. This file will be
                    used later to verify that the layout version is upgraded.
                  </p>
                </li>
                <li>
                  <p>Stop HDFS.</p>
                </li>
                <li>
                  <p>Stop ZooKeeper.</p>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    &lt;service.name&gt;
                    &gt;<code>Summary</code>, review each service and make sure that all services in
                    the cluster are completely stopped.
                  </p>
                </li>
                <li>
                  <p>On the Hive Metastore database host, stop the Hive metastore
                    <i>
                      <strong>service</strong>
                    </i>
                    , if you have not done so already.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>Make sure that the Hive metastore
                        <strong>
                          <i>database</i>
                        </strong>
                        is running. For more information about Administering the Hive metastore database, see the<a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin">
                          Hive Metastore Administrator documentation</a>.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>If you are upgrading Hive and Oozie, back up the Hive and Oozie metastore databases on the
                    Hive and Oozie database host machines, respectively.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>Make sure that your Hive database is updated to the minimum recommended version.
                        <strong>If you are using Hive with MySQL, we recommend upgrading your MySQL database version to
                          5.6.21 before upgrading the HDP Stack to v2.2.
                        </strong>
                        For specific information, see<a href="#ref-f35b0203-6267-4533-9e88-652452ece5f5">
                          Database Requirements</a>.
                      </p>
                    </div>
                  </aside>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Optional - Back up the Hive Metastore database.</p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Note.png" width="50"></div>
                          <div class="simple-block">
                            <p>These instructions are provided for your convenience. Please check your database
                              documentation for the latest back up instructions.
                            </p>
                          </div>
                        </aside>
                        <div class="xyleme-table"><table border="1">
                          <p class="italic bold">Hive Metastore Database Backup and Restore</p>
                          
                            
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Database Type</p>
                                </th>
                                <th rowspan="1">
                                  <p>Backup</p>
                                </th>
                                <th rowspan="1">
                                  <p>Restore</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>MySQL</p>
                                </td>
                                <td rowspan="1">
                                  <p>mysqldump
                                    &lt;dbname&gt;
                                    &gt;
                                    &lt;outputfilename.sql&gt;
                                    For example: mysqldump hive &gt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>mysql
                                    &lt;dbname&gt;
                                    &lt;
                                    &lt;inputfilename.sql&gt;
                                    For example: mysql hive &lt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>Postgres</p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u
                                    &lt;username&gt;
                                    pg_dump
                                    &lt;databasename&gt;
                                    &gt;
                                    &lt;outputfilename.sql&gt;
                                    For example: sudo -u postgres pg_dump hive &gt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u
                                    &lt;username&gt;
                                    psql
                                    &lt;databasename&gt;
                                    &lt;
                                    &lt;inputfilename.sql&gt;
                                    For example: sudo -u postgres psql hive &lt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>Oracle</p>
                                </td>
                                <td rowspan="1">
                                  <p>Connect to the Oracle database using sqlplus
                                    export the database: exp username/password@database full=yes file=output_file.dmp
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>Import the database: imp username/password@database ile=input_file.dmp
                                  </p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Optional - Back up the Oozie Metastore database.</p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Note.png" width="50"></div>
                          <div class="simple-block">
                            <p>These instructions are provided for your convenience. Please check your database
                              documentation for the latest back up instructions.
                            </p>
                          </div>
                        </aside>
                        <div class="xyleme-table"><table border="1">
                          <p class="italic bold">Oozie Metastore Database Backup and Restore</p>
                          
                            
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Database Type</p>
                                </th>
                                <th rowspan="1">
                                  <p>Backup</p>
                                </th>
                                <th rowspan="1">
                                  <p>Restore</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>MySQL</p>
                                </td>
                                <td rowspan="1">
                                  <p>mysqldump
                                    &lt;dbname&gt;
                                    &gt;
                                    &lt;outputfilename.sql&gt;
                                    For example: mysqldump oozie &gt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>mysql
                                    &lt;dbname&gt;
                                    &lt;
                                    &lt;inputfilename.sql&gt;
                                    For example: mysql oozie &lt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>Postgres</p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u
                                    &lt;username&gt;
                                    pg_dump
                                    &lt;databasename&gt;
                                    &gt;
                                    &lt;outputfilename.sql&gt;
                                    For example: sudo -u postgres pg_dump oozie &gt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u
                                    &lt;username&gt;
                                    psql
                                    &lt;databasename&gt;
                                    &lt;
                                    &lt;inputfilename.sql&gt;
                                    For example: sudo -u postgres psql oozie &lt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>On the Ambari Server host, stop Ambari Server and confirm that it is stopped.</p>
                  <p>
                    <code>ambari-server stop</code>
                    <code>ambari-server status</code>
                  </p>
                </li>
                <li>
                  <p>Stop all Ambari Agents.</p>
                  <p>
                    At every host in your cluster known to Ambari,
                  </p>
                  <p>
                    <code>ambari-agent stop</code>
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Upgrade the 2.0 Stack to 2.2</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>Upgrade the HDP repository on all hosts and replace the old repository file with the new
                    file:
                  </p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>
                          <strong>For RHEL/CentOS/Oracle Linux 6:</strong>
                        </p>
                        <pre><code>wget -nv http://public-repo-1.hortonworks.com/HDP/centos6/2.x/GA/2.2.0.0/hdp.repo -O
                          /etc/yum.repos.d/HDP.repo
                        </code></pre>
                      </li>
                      <li>
                        <p>
                          <strong>For SLES 11 SP3:</strong>
                        </p>
                        <pre><code>wget -nv http://public-repo-1.hortonworks.com/HDP/suse11sp3/2.x/GA/2.2.0.0/hdp.repo -O
                          /etc/zypp/repos.d/HDP.repo
                        </code></pre>
                      </li>
                      <li>
                        <p>
                          <strong>For SLES 11 SP1:</strong>
                        </p>
                        <pre><code>wget -nv http://public-repo-1.hortonworks.com/HDP/sles11sp1/2.x/GA/2.2.0.0/hdp.repo -O
                          /etc/zypp/repos.d/HDP.repo
                        </code></pre>
                      </li>
                      <li>
                        <p>
                          <strong>For UBUNTU:</strong>
                        </p>
                        <pre><code>
                          wget -nv http://public-repo-1.hortonworks.com/HDP/ubuntu1/2.x/GA/2.2.0.0/hdp.list -O
                          /etc/apt/sourceslist.d/HDP.list
                        </code></pre>
                      </li>
                      <li>
                        <p>
                          <strong>For RHEL/CentOS/Oracle Linux 5:</strong>
                        </p>
                        <pre><code>wget -nv http://public-repo-1.hortonworks.com/HDP/centos5/2.x/GA/2.2.0.0/hdp.repo -O
                          /etc/yum.repos.d/HDP.repo
                        </code></pre>
                      </li>
                    
                  </ul>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>Make sure to download the HDP.repo file under /etc/yum.repos on ALL hosts.</p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Update the Stack version in the Ambari Server database.
                    On the Ambari Server host, use the following command to update the Stack version to HDP-2.2:
                    <code></code>
                  </p>
                  <p>
                    <code>
                      ambari-server upgradestack HDP-2.2
                    </code>
                  </p>
                </li>
                <li>
                  <p>Back up the files in following directories on the Oozie server host and make sure that all
                    files, including *site.xml files are copied.
                  </p>
                  <p>
                    <code>mkdir oozie-conf-bak
                      cp -R /etc/oozie/conf/* oozie-conf-bak
                    </code>
                  </p>
                </li>
                <li>
                  <p>Remove the old oozie directories on all Oozie server and client hosts.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>
                          <code>rm -rf /etc/oozie/conf</code>
                        </p>
                      </li>
                      <li>
                        <p>r
                          <code>m -rf /usr/lib/oozie/</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>rm -rf /var/lib/oozie/</code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Upgrade the Stack on all Ambari Agent hosts.</p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>For each host, identify the HDP components installed on each host. Use Ambari Web, as
                        described<a href="#ref-9cb21557-3948-4efa-b3cb-1c65f5b0ad31">here</a>, to view
                        components on each host in your cluster.

                        Based on the HDP components installed, tailor the following upgrade commands for each host to
                        upgrade only components residing on that host. For example, if you know that a host has
                        <strong>
                          <i>no</i>
                        </strong>
                        HBase service or client packages installed, then you can adapt the command to
                        <strong>
                          <i>not</i>
                        </strong>
                        include HBase, as follows:

                        <code>yum install "collectd*" "gccxml*" "pig*" "hadoop*" "sqoop*" "zookeeper*" "hive*"
                        </code>
                      </p>
                    </div>
                  </aside>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>If you are writing to multiple systems using a script, do not use " " with the run
                        command. You can use " " with pdsh -y.
                      </p>
                    </div>
                  </aside>
                  <ul class="Bullet">
                    
                      <li>
                        <p>For RHEL/CentOS/Oracle Linux:</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>On all hosts, clean the yum repository.</p>
                              <p>
                                <code>yum clean all</code>
                              </p>
                            </li>
                            <li>
                              <p>Remove all components that you want to upgrade. At least, WebHCat, HCatlaog, and
                                Oozie components.
                                This command un-installs the HDP 2.0 component bits. It leaves the user data and
                                metadata, but removes your configurations.
                              </p>
                              <pre><code>yum erase "hadoop*" "webhcat*" "hcatalog*" "oozie*" "pig*" "hdfs*" "sqoop*"
                                "zookeeper*" "hbase*" "hive*" "phoenix*" "accumulo*" "mahout*" "hue*" "flume*"
                                "hdp_mon_nagios_addons"
                              </code></pre>
                            </li>
                            <li>
                              <p>Remove your old hdp.repo and hdp-utils repo files.</p>
                              <p>
                                <code>rm etc/yum/repos.d/hdp.repo hdp-utils.repo</code>
                              </p>
                            </li>
                            <li>
                              <p>Install the following components:</p>
                              <pre><code>yum install "hadoop_2_2_0_0_*" "zookeeper_2_2_0_0_*" "hive_2_2_0_0_*"
                                "flume_2_2_0_0_*" "phoenix_2_2_0_0_*" "accumulo_2_2_0_0_*" "mahout_2_2_0_0_*"
                                rpm -e --nodeps hue-shell
                                yum install hue hue-common hue-beeswax hue-hcatalog hue-pig hue-oozie
                              </code></pre>
                            </li>
                            <li>
                              <p>Verify that the components were upgraded.</p>
                              <p>
                                <code>yum list installed | grep HDP-</code>
                                &lt;old-stack-version-number&gt;
                              </p>
                              <p>
                                Nothing should appear in the returned list.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>For SLES:</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>On all hosts, clean the zypper repository.</p>
                              <p>
                                <code>zypper clean --all</code>
                              </p>
                            </li>
                            <li>
                              <p>Remove WebHCat, HCatalog, and Oozie components.
                                This command uninstalls the HDP 2.0 component bits. It leaves the user data and
                                metadata, but removes your configurations.
                              </p>
                              <pre><code>zypper remove "hadoop*" "webhcat*" "hcatalog*" "oozie*" "pig*" "hdfs*" "sqoop*"
                                "zookeeper*" "hbase*" "hive*" "phoenix*" "accumulo*" "mahout*" "hue*" "flume*"
                                "hdp_mon_nagios_addons"
                              </code></pre>
                            </li>
                            <li>
                              <p>Remove your old hdp.repo and hdp-utils repo files.</p>
                              <p>
                                <code>rm etc/zypp/repos.d/hdp.repo hdp-utils.repo</code>
                              </p>
                            </li>
                            <li>
                              <p>Install the following components:</p>
                              <pre><code>zypper install "hadoop\_2_2_0_0_*" "oozie\_2_2_0_0_*" "pig\_2_2_0_0_*"
                                "sqoop\_2_2_0_0_*" "zookeeper\_2_2_0_0_*" "hbase\_2_2_0_0_*" "hive\_2_2_0_0_*"
                                "flume\_2_2_0_0_*" "phoenix\_2_2_0_0_*" "accumulo\_2_2_0_0_*" "mahout\_2_2_0_0_*"
                                rpm -e --nodeps hue-shell
                                zypper install hue hue-common hue-beeswax hue-hcatalog hue-pig hue-oozie
                              </code></pre>
                            </li>
                            <li>
                              <p>Verify that the components were upgraded.</p>
                              <p>
                                <code>rpm -qa | grep hadoop, &amp;&amp; rpm -qa | grep hive &amp;&amp; rpm -qa
                                  | grep hcatalog
                                </code>
                              </p>
                              <p>
                                No 2.0 components should appear in the returned list.
                              </p>
                            </li>
                            <li>
                              <p>If components were not upgraded, upgrade them as follows:</p>
                              <p>
                                <code>yast --update hadoop hcatalog hive</code>
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Symlink directories, using<code>hdp-select</code>.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Warning.png" width="50"></div>
                    <div class="simple-block">
                      <p>To prevent version-specific directory issues for your scripts and updates, Pivotal
                        provides<code>hdp-select</code>, a script that symlinks directories to hdp-current
                        and modifies paths for configuration directories.
                      </p>
                      <p>Check that the
                        <code>hdp-select</code>
                        package installed:

                        <code>rpm -qa | grep hdp-select</code>

                        You should see:
                        <code>hdp-select-2.2.0.0-2041.el6.noarch</code>

                        If not, then run:

                        <code>yum install hdp-select</code>

                        Run
                        <code>hdp-select</code>
                        as root, on every node. In<code>/usr/bin</code>:
                        <code>
                          hdp-select set all 2.2.0.0-
                        </code>
                        &lt;$version&gt;
                        
                        <code>
                        </code>where
                        &lt;$version&gt;
                        is the build number. For the HDP 2.2 release &lt;$version&gt; = 2041.
                        <code>
                        </code>
                      </p>
                    </div>
                  </aside>
                  <p>Check that the
                    <code>hdp-select</code>
                    package installed:

                    <code>rpm -qa | grep hdp-select</code>

                    You should see:
                    <code>hdp-select-2.2.0.0-2041.el6.noarch</code>

                    If not, then run:

                    <code>yum install hdp-select</code>

                    Run
                    <code>hdp-select</code>
                    as root, on every node. In<code>/usr/bin</code>:
                    <code>
                      hdp-select set all 2.2.0.0-
                    </code>
                    &lt;$version&gt;
                    
                    <code>
                    </code>where
                    &lt;$version&gt;
                    is the build number. For the HDP 2.2 release &lt;$version&gt; = 2041.
                    <code>
                    </code>
                  </p>
                </li>
                <li>
                  <p>On the Hive Metastore database host, stop the Hive Metastore
                    <i>
                      <strong>service</strong>
                    </i>
                    , if you have not done so already. Make sure that the Hive Metastore
                    <i>
                      <strong>database</strong>
                    </i>
                    is running.
                  </p>
                </li>
                <li>
                  <p>Upgrade the Hive metastore database schema from v12 to v14, using the following
                    instructions:
                  </p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Set java home:</p>
                        <p>
                          <code>export JAVA_HOME=/path/to/java</code>
                        </p>
                      </li>
                      <li>
                        <p>Copy (rewrite) old Hive configurations to new conf dir:</p>
                        <p>
                          <code>cp -R /etc/hive/conf.server/* /etc/hive/conf/</code>
                        </p>
                      </li>
                      <li>
                        <p>Copy the jdbc connector to
                          <code>/usr/hdp/</code>
                          &lt;$version&gt;
                          <code>/hive/lib</code>, if it not there, yet.
                        </p>
                      </li>
                      <li>
                        <p>
                          &lt;HIVE_HOME&gt;
                          <code>/bin/schematool -upgradeSchema -dbType</code>
                          &lt;databaseType&gt;
                        </p>
                        <p>where &lt;HIVE_HOME&gt; is the Hive installation directory.</p>
                        <p>
                          For example, on the Hive Metastore host:

                          /usr/hdp/2.2.0.0-&lt;$version&gt;/hive/bin/schematool -upgradeSchema
                          -dbType
                          &lt;databaseType&gt;
                          
                          where &lt;$version&gt; is the 2.2.0 build number and
                          &lt;databaseType&gt;
                          is derby, mysql, oracle, or postgres.
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Complete the Upgrade of the 2.0 Stack to 2.2</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>Start Ambari Server.</p>
                  <p>On the Server host,
                    <code>
                      amber-server start
                    </code>
                  </p>
                </li>
                <li>
                  <p>Start all Ambari Agents.</p>
                  <p>On each Ambari Agent host,
                    <code>
                      ambari-agent start
                    </code>
                  </p>
                </li>
                <li>
                  <p>Update the repository Base URLs in the Ambari Server for the HDP 2.2 stack.</p>
                  <p>
                    Browse to
                    <code>Ambari Web</code>
                    &gt;
                    <code>Admin</code>
                    &gt;<code>Repositories</code>, then set the value of the HDP and HDP-UTILS
                    repository Base URLs. For more information about viewing and editing repository Base URLs, see<a href="#ref-0cf8106e-364a-46d5-85aa-38dd0476a7e2">Viewing Cluster Stack Version and
                    Repository URLs</a>.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>
                        For a remote, accessible, public repository, the HDP and HDP-UTILS Base URLs are the same as the
                        baseurl=values in the HDP.repo file downloaded in Upgrade the Stack: Step 1. For a local
                        repository, use the local repository Base URL that you configured for the HDP Stack. For links
                        to download the HDP repository files for your version of the Stack, see<a href="#ref-3e43081a-a937-4d51-92cc-1fbf15645713">HDP Repositories</a>.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Using the<code>Ambari Web UI &gt; Services</code>, start the
                    ZooKeeper service.
                  </p>
                </li>
                <li>
                  <p>At all Datanode and Namenode hosts, copy (rewrite) old hdfs configurations to new conf
                    directory:
                  </p>
                  <p>
                    <code>cp /etc/hadoop/conf.empty/hdfs-site.xml.rpmsave /etc/hadoop/conf/hdfs-site.xml;
                    </code>
                    
                    <code>
                      cp /etc/hadoop/conf.empty/hadoop-env.sh.rpmsave /etc/hadoop/conf/hadoop-env.sh;
                    </code>
                    
                    <code>
                      cp /etc/hadoop/conf.empty/log4j.properties.rpmsave /etc/hadoop/conf/log4j.properties;
                    </code>
                    
                    <code>
                      cp /etc/hadoop/conf.empty/core-site.xml.rpmsave /etc/hadoop/conf/core-site.xml
                    </code>
                  </p>
                </li>
                <li>
                  <p>If you are upgrading from an HA NameNode configuration, start all JournalNodes.</p>
                  <p>
                    On each JournalNode host, run the following command:

                    <code>su -l</code>
                    &lt;HDFS_USER&gt;
                    <code>-c "/usr/hdp/2.2.0.0-</code>
                    &lt;$version&gt;
                    <code>/hadoop/sbin/hadoop-daemon.sh start journalnode"

                    </code>where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>All JournalNodes must be running when performing the upgrade, rollback, or finalization
                        operations. If any JournalNodes are down when running any such operation, the operation will
                        fail.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Because the file system version has now changed, you must start the NameNode manually.
                  </p>
                  <p>
                    On the active NameNode host, as the HDFS user:
                  </p>
                  <pre><code>su -l &lt;HDFS_USER&gt; -c "export HADOOP_LIBEXEC_DIR=/usr/hdp/2.2.0.0-&lt;$version&gt;/hadoop/libexec
                    &amp;&amp; /usr/hdp/2.2.0.0-&lt;$version&gt;/hadoop/sbin/hadoop-daemon.sh start namenode -upgrade"
                  </code></pre>
                  <p>
                    To check if the Upgrade is in progress, check that the "
                    <code>\previous</code>
                    " directory has been created in \NameNode and \JournalNode directories. The "
                    <code>\previous</code>
                    " directory contains a snapshot of the data before upgrade.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>In a NameNode HA configuration, this NameNode will not enter the standby state as usual.
                        Rather, this NameNode will immediately enter the active state, perform an upgrade of its local
                        storage directories, and also perform an upgrade of the shared edit log. At this point, the
                        standby NameNode in the HA pair is still down. It will be out of sync with the upgraded active
                        NameNode.

                        To synchronize the active and standby NameNode, re-establishing HA, re-bootstrap the standby
                        NameNode by running the NameNode with the '-bootstrapStandby' flag. Do NOT start this standby
                        NameNode with the '-upgrade' flag.
                      </p>
                      <p>As the HDFS user:
                      </p>
                      <p>
                        <code>su -l</code>
                        &lt;HDFS_USER&gt;
                        <code>-c "hdfs namenode -bootstrapStandby -force"w
                        </code>
                      </p>
                      <p>The bootstrapStandby command will download the most recent fsimage from the active
                        NameNode into the &lt;dfs.name.dir&gt; directory of the standby NameNode. You can enter that
                        directory to make sure the fsimage has been successfully downloaded. After verifying, start the
                        ZKFailoverController via Ambari, then start the standby NameNode via Ambari. You can check the
                        status of both NameNodes using the Web UI.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Start all DataNodes.</p>
                  <p>
                    On each DataNode, as the HDFS user,
                  </p>
                  <pre><code>su -l &lt;HDFS_USER&gt; -c "/usr/hdp/2.2.0.0-&lt;$version&gt;/hadoop/sbin/hadoop-daemon.sh
                    --config /etc/hadoop/conf start datanode"
                  </code></pre>
                  <p>
                    where
                    &lt;HDFS_USER&gt;
                    is the HDFS Service user. For example, hdfs.
                    <code>
                    </code>The NameNode sends an upgrade command to DataNodes after receiving block reports.
                  </p>
                </li>
                <li>
                  <p>Update HDFS Configuration Properties for HDP 2.2</p>
                  <p>
                    Using
                    <code>Ambari Web UI</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    <code>HDFS</code>
                    &gt;
                    <code>Configs</code>
                    &gt;<code>core-site.xml</code>:
                  </p>
                  <ul class="Arrow">
                    
                      <li>
                        <p>Add</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>hadoop.proxyuser.falcon.groups</p>
                                </td>
                                <td rowspan="1">
                                  <p>users</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hadoop.proxyuser.falcon.hosts</p>
                                </td>
                                <td rowspan="1">
                                  <p>*</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                  <p>
                    <code>Using Ambari Web UI</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    <code>HDFS</code>
                    &gt;
                    <code>Configs</code>
                    &gt;<code>hdfs-site.xml</code>:
                  </p>
                  <ul class="Arrow">
                    
                      <li>
                        <p>Add</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>dfs.namenode.startup.delay.block.deletion.sec</p>
                                </td>
                                <td rowspan="1">
                                  <p>3600</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Modify</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>dfs.datanode.max.transfer.threads</p>
                                </td>
                                <td rowspan="1">
                                  <p>4096</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Restart HDFS.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Open the Ambari Web GUI. If the browser in which Ambari is running has been open
                          throughout the process, clear the browser cache, then refresh the browser.
                        </p>
                      </li>
                      <li>
                        <p>Choose
                          <code>Ambari Web</code>
                          &gt;
                          <code>Services</code>
                          &gt;
                          <code>HDFS</code>
                          &gt;
                          <code>Service Actions</code>
                          &gt;
                          <code>Restart All.</code>
                        </p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Important.png" width="50"></div>
                          <div class="simple-block">
                            <ul class="number-list">
                              In a cluster configured for NameNode High Availability, use the following
                                procedure to restart NameNodes. Using the following procedure preserves HA when
                                upgrading the cluster.
                              
                              
                                <li>
                                  <p>Using Ambari Web &gt; Services &gt; HDFS, choose Active NameNode.</p>
                                  <p>This shows the host name of the current, active NameNode.</p>
                                </li>
                                <li>
                                  <p>Write down (or copy, or remember) the host name of the active NameNode.
                                  </p>
                                  <p>You need this host name for step 4.</p>
                                </li>
                                <li>
                                  <p>Using Ambari Web &gt; Services &gt; HDFS &gt; Service Actions &gt; choose
                                    Stop.
                                  </p>
                                  <p>This stops all of the HDFS Components, including both NameNodes.</p>
                                </li>
                                <li>
                                  <p>Using Ambari Web &gt; Hosts &gt; choose the host name you noted in Step 2,
                                    then start that NameNode component, using Host Actions &gt; Start.
                                  </p>
                                  <p>This causes the original, active NameNode to re-assume its role as the
                                    active NameNode.
                                  </p>
                                </li>
                                <li>
                                  <p>Using Ambari Web &gt; Services &gt; HDFS &gt; Service Actions, choose
                                    Re-Start All.
                                  </p>
                                </li>
                              
                            </ul>
                          </div>
                        </aside>
                      </li>
                      <li>
                        <p>Choose
                          <code>Service Actions</code>
                          &gt;<code>Run Service Check</code>. Makes sure the service checks pass.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>After the DataNodes are started, HDFS exits safe mode. Monitor the status, by running the
                    following command, as the HDFS user:
                  </p>
                  <p>
                    <code>sudo su -l</code>
                    &lt;HDFS_USER&gt;
                    <code>-c "hdfs dfsadmin -safemode get"</code>
                  </p>
                  <p>
                    When HDFS exits safe mode, the following message displays:
                  </p>
                  <p>
                    <code>Safe mode is OFF</code>
                  </p>
                </li>
                <li>
                  <p>Make sure that the HDFS upgrade was successful.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Compare the old and new versions of the following log files:</p>
                        <ul class="Bullet">
                          
                            <li>
                              <p>
                                <code>dfs-old-fsck-1.log</code>
                                versus<code>dfs-new-fsck-1.log</code>.
                              </p>
                              <p>
                                The files should be identical unless the hadoop fsck reporting format has changed in the
                                new version.
                              </p>
                            </li>
                            <li>
                              <p>
                                <code>dfs-old-lsr-1.log</code>
                                versus<code>dfs-new-lsr-1.log</code>.
                              </p>
                              <p>
                                The files should be identical unless the format of hadoop fs -lsr reporting or the data
                                structures have changed in the new version.
                              </p>
                            </li>
                            <li>
                              <p>
                                <code>dfs-old-report-1.log</code>
                                versus
                                <code>fs-new-report-1.log.</code>
                              </p>
                              <p>
                                Make sure that all DataNodes in the cluster before upgrading are up and running.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Update HBase Configuration Properties for HDP 2.2</p>
                  <p>
                    Using
                    <code>Ambari Web UI</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    <code>HBase</code>
                    &gt;
                    <code>Configs</code>
                    &gt;<code>hbase-site.xml</code>:
                  </p>
                  <ul class="Arrow">
                    
                      <li>
                        <p>Add</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>hbase.hregion.majorcompaction.jitter</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.50</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Modify</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>hbase.hregion.majorcompaction</p>
                                </td>
                                <td rowspan="1">
                                  <p>604800000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hbase.hregion.memstore.block.multiplier</p>
                                </td>
                                <td rowspan="1">
                                  <p>4</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Remove</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>hbase.hstore.flush.retries.number</p>
                                </td>
                                <td rowspan="1">
                                  <p>120</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Using Ambari Web, navigate to
                    <code>Services</code>
                    &gt;
                    <code>Hive</code>
                    &gt;
                    <code>Configs</code>
                    &gt;
                    <code>Advanced</code>
                    <code></code>and verify that the following properties are set to their
                    default values:
                  </p>
                  <pre><code>Hive (Advanced)
                    hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
                    hive.security.metastore.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
                    hive.security.authenticator.manager=org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator
                  </code></pre>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>The Security Wizard enables Hive authorization. The default values for these properties
                        changed in Hive-0.12. If you are upgrading Hive from 0.12 to 0.13 in a secure cluster, you
                        should not need to change the values. If upgrading from Hive-older than version 0.12 to
                        Hive-0.12 or greater in a secure cluster, you will need to correct the values.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Update Hive Configuration Properties for HDP 2.2</p>
                  <p>
                    Using
                    <code>Ambari Web UI</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    <code>Hive</code>
                    &gt;
                    <code>Configs</code>
                    &gt;<code>hive-site.xml</code>:
                  </p>
                  <ul class="Arrow">
                    
                      <li>
                        <p>Add</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.cluster.delegation.token.store.zookeeper.connectString</p>
                                </td>
                                <td rowspan="1">
                                  <p>&lt;!-- The ZooKeeper token store connect string. --&gt;</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>datanucleus.cache.level2.type</p>
                                </td>
                                <td rowspan="1">
                                  <p>none</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.auto.convert.sortmerge.join.to.mapjoin</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.cbo.enable</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.cli.print.header</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.cluster.delegation.token.store.class</p>
                                </td>
                                <td rowspan="1">
                                  <p>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.cluster.delegation.token.store.zookeeper.znode</p>
                                </td>
                                <td rowspan="1">
                                  <p>/hive/cluster/delegation</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.compactor.abortedtxn.threshold</p>
                                </td>
                                <td rowspan="1">
                                  <p>1000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.compactor.check.interval</p>
                                </td>
                                <td rowspan="1">
                                  <p>300L</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.compactor.delta.num.threshold</p>
                                </td>
                                <td rowspan="1">
                                  <p>10</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.compactor.delta.pct.threshold</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.1f</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.compactor.initiator.on</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.compactor.worker.threads</p>
                                </td>
                                <td rowspan="1">
                                  <p>0</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.compactor.worker.timeout</p>
                                </td>
                                <td rowspan="1">
                                  <p>86400L</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.compute.query.using.stats</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.conf.restricted.list</p>
                                </td>
                                <td rowspan="1">
                                  <p>
                                    hive.security.authenticator.manager,hive.security.authorization.manager,hive.users.in.admin.role
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.convert.join.bucket.mapjoin.tez</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.enforce.sortmergebucketmapjoin</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.compress.intermediate</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.compress.output</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.dynamic.partition</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.dynamic.partition.mode</p>
                                </td>
                                <td rowspan="1">
                                  <p>nonstrict</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.max.created.files</p>
                                </td>
                                <td rowspan="1">
                                  <p>100000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.max.dynamic.partitions</p>
                                </td>
                                <td rowspan="1">
                                  <p>5000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.max.dynamic.partitions.pernode</p>
                                </td>
                                <td rowspan="1">
                                  <p>2000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.orc.compression.strategy</p>
                                </td>
                                <td rowspan="1">
                                  <p>SPEED</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.orc.default.compress</p>
                                </td>
                                <td rowspan="1">
                                  <p>ZLIB</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.orc.default.stripe.size</p>
                                </td>
                                <td rowspan="1">
                                  <p>67108864</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.parallel</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.parallel.thread.number</p>
                                </td>
                                <td rowspan="1">
                                  <p>8</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.reducers.bytes.per.reducer</p>
                                </td>
                                <td rowspan="1">
                                  <p>67108864</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.reducers.max</p>
                                </td>
                                <td rowspan="1">
                                  <p>1009</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.scratchdir</p>
                                </td>
                                <td rowspan="1">
                                  <p>/tmp/hive</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.submit.local.task.via.child</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.exec.submitviachild</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.fetch.task.aggr</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.fetch.task.conversion</p>
                                </td>
                                <td rowspan="1">
                                  <p>more</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.fetch.task.conversion.threshold</p>
                                </td>
                                <td rowspan="1">
                                  <p>1073741824</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.limit.optimize.enable</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.limit.pushdown.memory.usage</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.04</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.map.aggr.hash.force.flush.memory.threshold</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.9</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.map.aggr.hash.min.reduction</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.5</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.map.aggr.hash.percentmemory</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.5</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.mapjoin.optimized.hashtable</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.merge.mapfiles</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.merge.mapredfiles</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.merge.orcfile.stripe.level</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.merge.rcfile.block.level</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.merge.size.per.task</p>
                                </td>
                                <td rowspan="1">
                                  <p>256000000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.merge.smallfiles.avgsize</p>
                                </td>
                                <td rowspan="1">
                                  <p>16000000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.merge.tezfiles</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.metastore.authorization.storage.checks</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.metastore.client.connect.retry.delay</p>
                                </td>
                                <td rowspan="1">
                                  <p>5s</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.metastore.connect.retries</p>
                                </td>
                                <td rowspan="1">
                                  <p>24</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.metastore.failure.retries</p>
                                </td>
                                <td rowspan="1">
                                  <p>24</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.metastore.kerberos.keytab.file</p>
                                </td>
                                <td rowspan="1">
                                  <p>/etc/security/keytabs/hive.service.keytab</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.metastore.kerberos.principal</p>
                                </td>
                                <td rowspan="1">
                                  <p>hive/_HOST@EXAMPLE.COM</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.metastore.server.max.threads</p>
                                </td>
                                <td rowspan="1">
                                  <p>100000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.optimize.constant.propagation</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.optimize.metadataonly</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.optimize.null.scan</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.optimize.sort.dynamic.partition</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.orc.compute.splits.num.threads</p>
                                </td>
                                <td rowspan="1">
                                  <p>10</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.orc.splits.include.file.footer</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.prewarm.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.prewarm.numcontainers</p>
                                </td>
                                <td rowspan="1">
                                  <p>10</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.security.metastore.authenticator.manager</p>
                                </td>
                                <td rowspan="1">
                                  <p>org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.security.metastore.authorization.auth.reads</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.allow.user.substitution</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.authentication.spnego.keytab</p>
                                </td>
                                <td rowspan="1">
                                  <p>HTTP/_HOST@EXAMPLE.COM</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.authentication.spnego.principal</p>
                                </td>
                                <td rowspan="1">
                                  <p>/etc/security/keytabs/spnego.service.keytab</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.logging.operation.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.logging.operation.log.location</p>
                                </td>
                                <td rowspan="1">
                                  <p>${system:java.io.tmpdir}/${system:user.name}/operation_logs</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.table.type.mapping</p>
                                </td>
                                <td rowspan="1">
                                  <p>CLASSIC</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.tez.default.queues</p>
                                </td>
                                <td rowspan="1">
                                  <p>default</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.tez.sessions.per.default.queue</p>
                                </td>
                                <td rowspan="1">
                                  <p>1</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.thrift.http.path</p>
                                </td>
                                <td rowspan="1">
                                  <p>cliservice</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.thrift.http.port</p>
                                </td>
                                <td rowspan="1">
                                  <p>10001</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.thrift.max.worker.threads</p>
                                </td>
                                <td rowspan="1">
                                  <p>500</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.thrift.sasl.qop</p>
                                </td>
                                <td rowspan="1">
                                  <p>auth</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.transport.mode</p>
                                </td>
                                <td rowspan="1">
                                  <p>binary</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.use.SSL</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.smbjoin.cache.rows</p>
                                </td>
                                <td rowspan="1">
                                  <p>10000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.stats.autogather</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.stats.dbclass</p>
                                </td>
                                <td rowspan="1">
                                  <p>fs</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.stats.fetch.column.stats</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.stats.fetch.partition.stats</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.support.concurrency</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.auto.reducer.parallelism</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.cpu.vcores</p>
                                </td>
                                <td rowspan="1">
                                  <p>-1</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.dynamic.partition.pruning</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.dynamic.partition.pruning.max.data.size</p>
                                </td>
                                <td rowspan="1">
                                  <p>104857600</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.dynamic.partition.pruning.max.event.size</p>
                                </td>
                                <td rowspan="1">
                                  <p>1048576</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.input.format</p>
                                </td>
                                <td rowspan="1">
                                  <p>org.apache.hadoop.hive.ql.io.HiveInputFormat</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.log.level</p>
                                </td>
                                <td rowspan="1">
                                  <p>INFO</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.max.partition.factor</p>
                                </td>
                                <td rowspan="1">
                                  <p>2.0</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.min.partition.factor</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.25</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.smb.number.waves</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.5</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.txn.manager</p>
                                </td>
                                <td rowspan="1">
                                  <p>org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.txn.max.open.batch</p>
                                </td>
                                <td rowspan="1">
                                  <p>1000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.txn.timeout</p>
                                </td>
                                <td rowspan="1">
                                  <p>300</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.user.install.directory</p>
                                </td>
                                <td rowspan="1">
                                  <p>/user/</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.vectorized.execution.reduce.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.vectorized.groupby.checkinterval</p>
                                </td>
                                <td rowspan="1">
                                  <p>4096</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.vectorized.groupby.flush.percent</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.1</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.vectorized.groupby.maxentries</p>
                                </td>
                                <td rowspan="1">
                                  <p>100000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.zookeeper.client.port</p>
                                </td>
                                <td rowspan="1">
                                  <p>2181</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.zookeeper.namespace</p>
                                </td>
                                <td rowspan="1">
                                  <p>hive_zookeeper_namespace</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.zookeeper.quorum</p>
                                </td>
                                <td rowspan="1">
                                  <p>&lt;!-- List of zookeeper server to talk to --&gt;</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Modify</p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.auto.convert.join.noconditionaltask.size</p>
                                </td>
                                <td rowspan="1">
                                  <p>238026752</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.metastore.client.socket.timeout</p>
                                </td>
                                <td rowspan="1">
                                  <p>1800s</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.optimize.reducededuplication.min.reducer</p>
                                </td>
                                <td rowspan="1">
                                  <p>4</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.security.authorization.manager</p>
                                </td>
                                <td rowspan="1">
                                  <p>
                                    org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.security.metastore.authorization.manager</p>
                                </td>
                                <td rowspan="1">
                                  <p>
                                    org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider,org.apache.hadoop.hive.ql.security.authorization.MetaStoreAuthzAPIAuthorizerEmbedOnly
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.server2.support.dynamic.service.discovery</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.container.size</p>
                                </td>
                                <td rowspan="1">
                                  <p>682</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hive.tez.java.opts</p>
                                </td>
                                <td rowspan="1">
                                  <p>-server -Xmx546m -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA
                                    -XX:+UseParallelGC -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>fs.file.impl.disable.cache</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>fs.hdfs.impl.disable.cache</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>If YARN is installed in your HDP 2.0 stack, and the Application Timeline Server (ATS)
                    components are<strong>NOT</strong>, then you must create and install ATS service and host components via
                    API by running the following commands on the server that will host the YARN application timeline
                    server in your cluster. Be sure to replace
                    &lt;your_ATS_component_hostname&gt;
                    with a host name appropriate for your envrionment.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>Ambari does not currently support ATS in a kerberized cluster. If you are upgrading YARN
                        in a kerberized cluster, skip this step.
                      </p>
                    </div>
                  </aside>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Create the ATS Service Component.</p>
                        <pre><code>curl --user admin:admin -H "X-Requested-By: ambari" -i -X POST
                          http://localhost:8080/api/v1/clusters/&lt;your_cluster_name&gt;/services/YARN/components/APP_TIMELINE_SERVER
                        </code></pre>
                      </li>
                      <li>
                        <p>Create the ATS Host Component.</p>
                        <pre><code>
                          curl --user admin:admin -H "X-Requested-By: ambari" -i -X POST
                          http://localhost:8080/api/v1/clusters/&lt;your_cluster_name&gt;/hosts/&lt;your_ATS_component_hostname&gt;/host_components/APP_TIMELINE_SERVER
                        </code></pre>
                      </li>
                      <li>
                        <p>Install the ATS Host Component.</p>
                        <pre><code>curl --user admin:admin -H "X-Requested-By: ambari" -i -X PUT -d '{ "HostRoles": {
                          "state": "INSTALLED"}}' http://localhost:8080/api/v1/clusters/&lt;your_cluster_name&gt;/hosts/&lt;your_ATS_component_hostname&gt;/host_components/APP_TIMELINE_SERVER
                        </code></pre>
                      </li>
                    
                  </ul>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>curl commands use the default<code>username/password = admin/admin</code>.
                        To run the curl commands using non-default credentials, modify the --user option to use your
                        Ambari administrator credentials. For example: --user
                          &lt;ambari_admin_username&gt;:&lt;ambari_admin_password&gt;
                        .
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Make the following config changes required for Application Timeline Server. Use the Ambari
                    web UI to navigate to the service dashboard and add/modify the following configurations:
                  </p>
                  <pre><code>YARN (Custom yarn-site.xml)
                    yarn.timeline-service.leveldb-timeline-store.path=/var/log/hadoop-yarn/timeline
                    yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms=300000
                    yarn.timeline-service.store-class=org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
                    yarn.timeline-service.ttl-enable=true
                    yarn.timeline-service.ttl-ms=2678400000
                    yarn.timeline-service.generic-application-history.store-class=org.apache.hadoop.yarn.server.applicationhistoryservice.NullApplicationHistoryStore
                    yarn.timeline-service.webapp.address=&lt;PUT_THE_FQDN_OF_ATS_HOST_NAME_HERE&gt;:8188
                    yarn.timeline-service.webapp.https.address=&lt;PUT_THE_FQDN_OF_ATS_HOST_NAME_HERE&gt;:8190
                    yarn.timeline-service.address=&lt;PUT_THE_FQDN_OF_ATS_HOST_NAME_HERE&gt;:10200
                  </code></pre>
                  <pre><code>
                    HIVE (hive-site.xml)
                    hive.execution.engine=mr
                    hive.exec.failure.hooks=org.apache.hadoop.hive.ql.hooks.ATSHook
                    hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.ATSHook
                    hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.ATSHook
                    hive.tez.container.size=&lt;map-container-size&gt;</code></pre>
                  <p>
                    <code>*If mapreduce.map.memory.mb &gt; 2GB then set it equal to
                      mapreduce.map.memory. Otherwise, set it equal to
                    </code>
                  </p>
                  <pre><code>mapreduce.reduce.memory.mb*
                    hive.tez.java.opts="-server -Xmx" + Math.round(0.8 * map-container-size) + "m
                    -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseParallelGC"
                  </code></pre>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>Use configuration values appropriate for your environment. For example, the value "800"
                        in the preceding example is shown only for illustration purposes.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Prepare MR2 and Yarn for work. Execute hdfs commands on any host.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Create mapreduce dir in hdfs.</p>
                        <p>
                          <code>su -l</code>
                          &lt;HDFS_USER&gt;
                          <code>-c "hdfs dfs -mkdir -p /hdp/apps/2.2.0.0-&lt;$version&gt;/mapreduce/"
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Copy new mapreduce.tar.gz to hdfs mapreduce dir.</p>
                        <pre><code>su -l &lt;HDFS_USER&gt; -c "hdfs dfs -copyFromLocal /usr/hdp/2.2.0.0-&lt;$version&gt;/hadoop/mapreduce.tar.gz
                          /hdp/apps/2.2.0.0-&lt;$version&gt;/mapreduce/."
                        </code></pre>
                      </li>
                      <li>
                        <p>Grant permissions for created mapreduce dir in hdfs.</p>
                        <pre><code>su -l &lt;HDFS_USER&gt; -c "hdfs dfs -chown -R &lt;HDFS_USER&gt;:&lt;HADOOP_GROUP&gt;
                          /hdp";
                          su -l &lt;HDFS_USER&gt; -c "hdfs dfs -chmod -R 555 /hdp/apps/2.2.0.0-&lt;$version&gt;/mapreduce";
                          su -l &lt;HDFS_USER&gt; -c "hdfs dfs -chmod -R 444 /hdp/apps/2.2.0.0-&lt;$version&gt;/mapreduce/mapreduce.tar.gz"
                        </code></pre>
                      </li>
                      <li>
                        <p>Using
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Service</code>
                          &gt;
                          <code>Mapreduce2</code>
                          &gt;
                          <code>Configs</code>
                          &gt;
                          <code>Advanced</code>
                          &gt;<code>mapred-site</code>:
                        </p>
                        <ul class="Bullet">
                          
                            <li>
                              <p>Add</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.job.emit-timeline-data</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>false</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.jobhistory.bind-host</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>0.0.0.0</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.reduce.shuffle.fetch.retry.enabled</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.reduce.shuffle.fetch.retry.interval-ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>1000</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.reduce.shuffle.fetch.retry.timeout-ms</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>30000</p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                            <li>
                              <p>Modify</p>
                              <div class="xyleme-table"><table border="1">
                                
                                  
                                  
                                  <thead>
                                    <tr>
                                      <th rowspan="1">
                                        <p>Name</p>
                                      </th>
                                      <th rowspan="1">
                                        <p>Value</p>
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.admin.map.child.java.opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true
                                          -Dhdp.version=${hdp.version}
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.admin.reduce.child.java.opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true
                                          -Dhdp.version=${hdp.version}
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.map.java.opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-Xmx546m</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.map.memory.mb</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>682</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.reduce.java.opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-Xmx546m</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.task.io.sort.mb</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>273</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.app.mapreduce.am.admin-command-opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-Dhdp.version=${hdp.version}</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.app.mapreduce.am.command-opts</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>-Xmx546m -Dhdp.version=${hdp.version}</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>yarn.app.mapreduce.am.resource.mb</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>682</p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.application.framework.path</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.application.classpath</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          $PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:/usr/hdp/${hdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${hdp.version}.jar:/etc/hadoop/conf/secure
                                        </p>
                                      </td>
                                    </tr>
                                    <tr>
                                      <td rowspan="1">
                                        <p>mapreduce.admin.user.env</p>
                                      </td>
                                      <td rowspan="1">
                                        <p>
                                          LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-amd64-64
                                        </p>
                                      </td>
                                    </tr>
                                  </tbody>
                                  
                                
                              </table></div>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Using
                          <code>Ambari Web UI</code>
                          &gt;
                          <code>Service</code>
                          &gt;
                          <code>Yarn</code>
                          &gt;
                          <code>Configs</code>
                          &gt;
                          <code>Advanced</code>
                          &gt;<code>yarn-site</code>. Add/modify the following property:
                        </p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>hadoop.registry.zk.quorum</p>
                                </td>
                                <td rowspan="1">
                                  <p>&lt;!--List of hostname:port pairs defining the zookeeper quorum binding for
                                    the registry--&gt;</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>hadoop.registry.rm.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.client.nodemanager-connect.max-wait-ms</p>
                                </td>
                                <td rowspan="1">
                                  <p>900000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.client.nodemanager-connect.retry-interval-ms</p>
                                </td>
                                <td rowspan="1">
                                  <p>10000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.node-labels.fs-store.retry-policy-spec</p>
                                </td>
                                <td rowspan="1">
                                  <p>2000, 500</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.node-labels.fs-store.root-dir</p>
                                </td>
                                <td rowspan="1">
                                  <p>/system/yarn/node-labels</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.node-labels.manager-class</p>
                                </td>
                                <td rowspan="1">
                                  <p>
                                    org.apache.hadoop.yarn.server.resourcemanager.nodelabels.MemoryRMNodeLabelsManager
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.bind-host</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.0.0.0</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>
                                    yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>90</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb</p>
                                </td>
                                <td rowspan="1">
                                  <p>1000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</p>
                                </td>
                                <td rowspan="1">
                                  <p>hadoop-yarn</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.linux-container-executor.cgroups.mount</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.linux-container-executor.resources-handler.class</p>
                                </td>
                                <td rowspan="1">
                                  <p>org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.log-aggregation.debug-enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.log-aggregation.num-log-files-per-app</p>
                                </td>
                                <td rowspan="1">
                                  <p>30</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds</p>
                                </td>
                                <td rowspan="1">
                                  <p>-1</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.recovery.dir</p>
                                </td>
                                <td rowspan="1">
                                  <p>/var/log/hadoop-yarn/nodemanager/recovery-state</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.recovery.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.resource.cpu-vcores</p>
                                </td>
                                <td rowspan="1">
                                  <p>1</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.nodemanager.resource.percentage-physical-cpu-limit</p>
                                </td>
                                <td rowspan="1">
                                  <p>100</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.bind-host</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.0.0.0</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.connect.max-wait.ms</p>
                                </td>
                                <td rowspan="1">
                                  <p>900000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.connect.retry-interval.ms</p>
                                </td>
                                <td rowspan="1">
                                  <p>30000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.fs.state-store.retry-policy-spec</p>
                                </td>
                                <td rowspan="1">
                                  <p>2000, 500</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.fs.state-store.uri</p>
                                </td>
                                <td rowspan="1">
                                  <p>  &lt;enter a "space" as the property value&gt;</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.ha.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.recovery.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.state-store.max-completed-applications</p>
                                </td>
                                <td rowspan="1">
                                  <p>${yarn.resourcemanager.max-completed-applications}</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.store.class</p>
                                </td>
                                <td rowspan="1">
                                  <p>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>10</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.system-metrics-publisher.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.work-preserving-recovery.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>false</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms</p>
                                </td>
                                <td rowspan="1">
                                  <p>10000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.zk-acl</p>
                                </td>
                                <td rowspan="1">
                                  <p>world:anyone:rwcda</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.zk-address</p>
                                </td>
                                <td rowspan="1">
                                  <p>localhost:2181</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.zk-num-retries</p>
                                </td>
                                <td rowspan="1">
                                  <p>1000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.zk-retry-interval-ms</p>
                                </td>
                                <td rowspan="1">
                                  <p>1000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.zk-state-store.parent-path</p>
                                </td>
                                <td rowspan="1">
                                  <p>/rmstore</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.resourcemanager.zk-timeout-ms</p>
                                </td>
                                <td rowspan="1">
                                  <p>10000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.timeline-service.bind-host</p>
                                </td>
                                <td rowspan="1">
                                  <p>0.0.0.0</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.timeline-service.client.max-retries</p>
                                </td>
                                <td rowspan="1">
                                  <p>30</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.timeline-service.client.retry-interval-ms</p>
                                </td>
                                <td rowspan="1">
                                  <p>1000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.timeline-service.enabled</p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.timeline-service.http-authentication.simple.anonymous.allowed
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>true</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.timeline-service.http-authentication.type</p>
                                </td>
                                <td rowspan="1">
                                  <p>simple</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.timeline-service.leveldb-timeline-store.read-cache-size</p>
                                </td>
                                <td rowspan="1">
                                  <p>104857600</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>10000</p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>10000</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;<code>Service Actions</code>, start YARN.
                  </p>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;<code>Service Actions</code>, start MapReduce2.
                  </p>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    <code>Service Actions,</code>
                    start HBase and ensure the service check passes.
                  </p>
                </li>
                <li>
                  <p>Using
                    <code>Ambari Web</code>
                    &gt;
                    <code>Services</code>
                    &gt;
                    <code>Service Actions</code>
                    <code>,</code>start the Hive service.
                  </p>
                </li>
                <li>
                  <p>Upgrade Oozie.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Perform the following preparation steps on each Oozie server host:</p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Note.png" width="50"></div>
                          <div class="simple-block">
                            <p>You must replace your Oozie configuration after upgrading.</p>
                          </div>
                        </aside>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Copy configurations from
                                <code>oozie-conf-bak</code>
                                to the
                                <code>/etc/oozie/conf</code>
                                directory on each Oozie server and client.
                              </p>
                            </li>
                            <li>
                              <p>Create
                                <code>/usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext-upgrade22</code>
                                directory.
                              </p>
                              <p>
                                <code>mkdir /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext-upgrade22
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Copy the JDBC jar of your Oozie database to both
                                <code>/usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext-upgrade22</code>
                                and<code>/usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libtools</code>.
                                For example, if you are using MySQL, copy your<code>
                                  mysql-connector-java.jar</code>.
                                <code>
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Copy these files to
                                <code>/usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext-upgrade22</code>
                                directory
                              </p>
                              <p>
                                <code>cp /usr/lib/hadoop/lib/hadoop-lzo*.jar /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext-upgrade22;
                                  cp /usr/share/HDP-oozie/ext-2.2.zip /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext-upgrade22;
                                  cp /usr/share/HDP-oozie/ext-2.2.zip /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Grant read/write access to the Oozie user.</p>
                              <p>
                                <code>chmod -R 777 /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext-upgrade22
                                </code>
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Upgrade steps:</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>On the Services view, make sure that YARN and MapReduce2 services are running.
                              </p>
                            </li>
                            <li>
                              <p>Make sure that the Oozie service is stopped.</p>
                            </li>
                            <li>
                              <p>In<code>oozie-env.sh</code>, comment out
                                <code>CATALINA_BASE</code>
                                property, also do the same using Ambari Web UI in
                                <code>Services</code>
                                &gt;
                                <code>Oozie</code>
                                &gt;
                                <code>Configs</code>
                                &gt;<code>Advanced oozie-env</code>.
                              </p>
                            </li>
                            <li>
                              <p>Upgrade Oozie.</p>
                              <p>
                                At the Oozie server host, as the Oozie service user:
                              </p>
                              <p>
                                <code>sudo su -l</code>
                                &lt;OOZIE_USER&gt;
                                <code>-c"/usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/bin/ooziedb.sh upgrade -run"
                                </code>
                                where
                                &lt;OOZIE_USER&gt;
                                is the Oozie service user. For example, oozie.
                              </p>
                              <p>
                                Make sure that the output contains the string "Oozie DB has been upgraded to Oozie
                                version&lt;OOZIE_Build_Version&gt;.
                              </p>
                            </li>
                            <li>
                              <p>Prepare the Oozie WAR file.</p>
                              <aside class="custom-note">
                                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                                <div class="simple-block">
                                  <p>The Oozie server must be
                                    <strong>not</strong>
                                    running for this step. If you get the message "ERROR: Stop Oozie first", it means
                                    the script still thinks it's running. Check, and if needed, remove the process id
                                    (pid) file indicated in the output.
                                  </p>
                                  <p></p>
                                </div>
                              </aside>
                              <p>
                                At the Oozie server, as the Oozie user
                                <code>
                                  sudo su -l
                                </code>
                                &lt;OOZIE_USER&gt;
                                <code>-c "/usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/bin/oozie-setup.sh
                                  prepare-war -d /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/libext-upgrade22"
                                </code>where
                                &lt;OOZIE_USER&gt;
                                is the Oozie service user. For example, oozie.
                              </p>
                              <p>
                                Make sure that the output contains the string "New Oozie WAR file added".
                              </p>
                            </li>
                            <li>
                              <p>Using<code>Ambari Web</code>, choose
                                <code>Services &gt; Oozie &gt; Configs, expand
                                  oozie-log4j</code>, then add the following property:
                              </p>
                              <p>
                                <code>log4j.appender.oozie.layout.ConversionPattern=%d{ISO8601} %5p %c{1}:%L -
                                  SERVER[
                                </code>
                                ${oozie.instance.id}
                                <code>] %m%n</code>
                                where
                                ${oozie.instance.id}
                                is determined by oozie, automatically.
                              </p>
                            </li>
                            <li>
                              <p>Using Ambari Web, choose
                                <code>Services</code>
                                &gt;
                                <code>Oozie</code>
                                &gt;
                                <code>Configs</code>
                                <code>,</code>expand<code>Advanced
                                  oozie-site</code>, then edit the following properties:
                              </p>
                              <ul class="UppercaseAlpha">
                                
                                  <li>
                                    <p>In<code>oozie.service.coord.push.check.requeue.interval</code>
                                      ,
                                      <i>
                                        <strong>replace</strong>
                                      </i>
                                      the existing property value with the following one:
                                    </p>
                                    <p>
                                      <code>30000</code>
                                    </p>
                                  </li>
                                  <li>
                                    <p>In<code>oozie.service.SchemaService.wf.ext.schemas</code>,
                                      <i>
                                        <strong>append</strong>
                                      </i>
                                      (using copy/paste) to the existing property value the following string, if is it
                                      is not already present:
                                    </p>
                                    <p>
                                      <code>
                                        shell-action-0.1.xsd,shell-action-0.2.xsd,shell-action-0.3.xsd,email-action-0.1.xsd,email-action-0.2.xsd,hive-action-0.2.xsd,hive-action-0.3.xsd,hive-action-0.4.xsd,hive-action-0.5.xsd,sqoop-action-0.2.xsd,sqoop-action-0.3.xsd,sqoop-action-0.4.xsd,ssh-action-0.1.xsd,ssh-action-0.2.xsd,distcp-action-0.1.xsd,distcp-action-0.2.xsd,oozie-sla-0.1.xsd,oozie-sla-0.2.xsd
                                      </code>
                                    </p>
                                    <aside class="custom-note">
                                      <div class="icon"><img src="Icons/Note.png" width="50"></div>
                                      <div class="simple-block">
                                        <p>If you have customized schemas, append this string to your custom
                                          schema name string.
                                        </p>
                                        <p>Do not overwrite custom schemas.</p>
                                        <p>If you have no customized schemas, you can replace the existing string
                                          with the following one:
                                        </p>
                                        <p>
                                          shell-action-0.1.xsd,email-action-0.1.xsd,hive-action-0.2.xsd,sqoop-action-0.2.xsd,ssh-action-0.1.xsd,distcp-action-0.1.xsd,shell-action-0.2.xsd,oozie-sla-0.1.xsd,oozie-sla-0.2.xsd,hive-action-0.3.xsd
                                        </p>
                                      </div>
                                    </aside>
                                  </li>
                                  <li>
                                    <p>In<code>oozie.service.URIHandlerService.uri.handlers</code>,
                                      <i>
                                        <strong>append</strong>
                                      </i>
                                      to the existing property value the following string, if is it is not already
                                      present:
                                    </p>
                                    <p>
                                      <code>
                                        org.apache.oozie.dependency.FSURIHandler,org.apache.oozie.dependency.HCatURIHandler
                                      </code>
                                    </p>
                                  </li>
                                  <li>
                                    <p>In<code>oozie.services</code>, make sure all the following
                                      properties are present:
                                    </p>
                                    <pre><code>org.apache.oozie.service.SchedulerService,
                                      org.apache.oozie.service.InstrumentationService,
                                      org.apache.oozie.service.MemoryLocksService,
                                      org.apache.oozie.service.UUIDService,
                                      org.apache.oozie.service.ELService,
                                      org.apache.oozie.service.AuthorizationService,
                                      org.apache.oozie.service.UserGroupInformationService,
                                      org.apache.oozie.service.HadoopAccessorService,
                                      org.apache.oozie.service.JobsConcurrencyService,
                                      org.apache.oozie.service.URIHandlerService,
                                      org.apache.oozie.service.DagXLogInfoService,
                                      org.apache.oozie.service.SchemaService,
                                      org.apache.oozie.service.LiteWorkflowAppService,
                                      org.apache.oozie.service.JPAService,
                                      org.apache.oozie.service.StoreService,
                                      org.apache.oozie.service.CoordinatorStoreService,
                                      org.apache.oozie.service.SLAStoreService,
                                      org.apache.oozie.service.DBLiteWorkflowStoreService,
                                      org.apache.oozie.service.CallbackService,
                                      org.apache.oozie.service.ActionService,
                                      org.apache.oozie.service.ShareLibService,
                                      org.apache.oozie.service.CallableQueueService,
                                      org.apache.oozie.service.ActionCheckerService,
                                      org.apache.oozie.service.RecoveryService,
                                      org.apache.oozie.service.PurgeService,
                                      org.apache.oozie.service.CoordinatorEngineService,
                                      org.apache.oozie.service.BundleEngineService,
                                      org.apache.oozie.service.DagEngineService,
                                      org.apache.oozie.service.CoordMaterializeTriggerService,
                                      org.apache.oozie.service.StatusTransitService,
                                      org.apache.oozie.service.PauseTransitService,
                                      org.apache.oozie.service.GroupsService,
                                      org.apache.oozie.service.ProxyUserService,
                                      org.apache.oozie.service.XLogStreamingService,
                                      org.apache.oozie.service.JvmPauseMonitorService
                                    </code></pre>
                                  </li>
                                  <li>
                                    <p>Add the<code>
                                      oozie.services.coord.check.maximum.frequency</code>property with the
                                      following property value:
                                      <code>false</code>
                                    </p>
                                    <p>
                                      If you set this property to true, Oozie rejects any coordinators with a frequency
                                      faster than 5 minutes. It is not recommended to disable this check or submit
                                      coordinators with frequencies faster than 5 minutes: doing so can cause unintended
                                      behavior and additional system stress.
                                    </p>
                                  </li>
                                  <li>
                                    <p>Add the
                                      <code>oozie.service.AuthorizationService.security.enabled
                                      </code>
                                      <code></code>property with the following property value:
                                      <code>false</code>
                                    </p>
                                    <p>

                                      Specifies whether security (user name/admin role) is enabled or not. If disabled
                                      any user can manage Oozie system and manage any job.
                                    </p>
                                  </li>
                                  <li>
                                    <p>Add the
                                      <code>oozie.service.HadoopAccessorService.kerberos.enabled
                                      </code>
                                      <code></code>property with the following property value:
                                      <code>false</code>
                                    </p>
                                    <p>

                                      Indicates if Oozie is configured to use Kerberos.
                                    </p>
                                  </li>
                                  <li>
                                    <p>Add the
                                      <code>oozie.authentication.simple.anonymous.allowed</code>
                                      <code></code>property with the following property value:
                                      <code>true</code>
                                    </p>
                                    <p>

                                      Indicates if anonymous requests are allowed. This setting is meaningful only when
                                      using 'simple' authentication.
                                    </p>
                                  </li>
                                  <li>
                                    <p>In<code>oozie.services.ext</code>,
                                      <i>
                                        <strong>append</strong>
                                      </i>
                                      to the existing property value the following string, if is it is not already
                                      present:
                                    </p>
                                    <p>
                                      <code>
                                        org.apache.oozie.service.PartitionDependencyManagerService,org.apache.oozie.service.HCatAccessorService
                                      </code>
                                    </p>
                                  </li>
                                  <li>
                                    <p>Update Oozie Configuration Properties for HDP 2.2</p>
                                    <p>
                                      Using<code>Ambari Web UI &gt; Services &gt; Oozie &gt; Configs &gt;
                                      oozie-site.xml</code>:
                                    </p>
                                    <ul class="Arrow">
                                      
                                        <li>
                                          <p>Add</p>
                                          <div class="xyleme-table"><table border="1">
                                            
                                              
                                              
                                              <thead>
                                                <tr>
                                                  <th rowspan="1">
                                                    <p>Name</p>
                                                  </th>
                                                  <th rowspan="1">
                                                    <p>Value</p>
                                                  </th>
                                                </tr>
                                              </thead>
                                              <tbody>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>oozie.authentication.simple.anonymous.allowed</p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>true</p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>oozie.service.coord.check.maximum.frequency</p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>false</p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>
                                                      oozie.service.ELService.ext.functions.coord-action-create
                                                    </p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>
                                                      now=org.apache.oozie.extensions.OozieELExtensions#ph2_now,
                                                    </p>
                                                    <p>
                                                      today=org.apache.oozie.extensions.OozieELExtensions#ph2_today,
                                                    </p>
                                                    <p>
                                                      yesterday=org.apache.oozie.extensions.OozieELExtensions#ph2_yesterday,
                                                    </p>
                                                    <p>
                                                      currentMonth=org.apache.oozie.extensions.OozieELExtensions#ph2_currentMonth,
                                                    </p>
                                                    <p>
                                                      lastMonth=org.apache.oozie.extensions.OozieELExtensions#ph2_lastMonth,
                                                    </p>
                                                    <p>
                                                      currentYear=org.apache.oozie.extensions.OozieELExtensions#ph2_currentYear,
                                                    </p>
                                                    <p>
                                                      lastYear=org.apache.oozie.extensions.OozieELExtensions#ph2_lastYear,
                                                    </p>
                                                    <p>
                                                      latest=org.apache.oozie.coord.CoordELFunctions#ph2_coord_latest_echo,
                                                    </p>
                                                    <p>
                                                      future=org.apache.oozie.coord.CoordELFunctions#ph2_coord_future_echo,
                                                    </p>
                                                    <p>
                                                      formatTime=org.apache.oozie.coord.CoordELFunctions#ph2_coord_formatTime,
                                                    </p>
                                                    <p>user=org.apache.oozie.coord.CoordELFunctions#coord_user
                                                    </p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>
                                                      oozie.service.ELService.ext.functions.coord-action-create-inst
                                                    </p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>
                                                      now=org.apache.oozie.extensions.OozieELExtensions#ph2_now_inst,
                                                    </p>
                                                    <p>
                                                      today=org.apache.oozie.extensions.OozieELExtensions#ph2_today_inst,
                                                    </p>
                                                    <p>
                                                      yesterday=org.apache.oozie.extensions.OozieELExtensions#ph2_yesterday_inst,
                                                    </p>
                                                    <p>
                                                      currentMonth=org.apache.oozie.extensions.OozieELExtensions#ph2_currentMonth_inst,
                                                    </p>
                                                    <p>
                                                      lastMonth=org.apache.oozie.extensions.OozieELExtensions#ph2_lastMonth_inst,
                                                    </p>
                                                    <p>
                                                      currentYear=org.apache.oozie.extensions.OozieELExtensions#ph2_currentYear_inst,
                                                    </p>
                                                    <p>
                                                      lastYear=org.apache.oozie.extensions.OozieELExtensions#ph2_lastYear_inst,
                                                    </p>
                                                    <p>
                                                      latest=org.apache.oozie.coord.CoordELFunctions#ph2_coord_latest_echo,
                                                    </p>
                                                    <p>
                                                      future=org.apache.oozie.coord.CoordELFunctions#ph2_coord_future_echo,
                                                    </p>
                                                    <p>
                                                      formatTime=org.apache.oozie.coord.CoordELFunctions#ph2_coord_formatTime,
                                                    </p>
                                                    <p>user=org.apache.oozie.coord.CoordELFunctions#coord_user
                                                    </p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>oozie.service.ELService.ext.functions.coord-action-start
                                                    </p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>
                                                      now=org.apache.oozie.extensions.OozieELExtensions#ph2_now,
                                                    </p>
                                                    <p>
                                                      today=org.apache.oozie.extensions.OozieELExtensions#ph2_today,
                                                    </p>
                                                    <p>
                                                      yesterday=org.apache.oozie.extensions.OozieELExtensions#ph2_yesterday,
                                                    </p>
                                                    <p>
                                                      currentMonth=org.apache.oozie.extensions.OozieELExtensions#ph2_currentMonth,
                                                    </p>
                                                    <p>
                                                      lastMonth=org.apache.oozie.extensions.OozieELExtensions#ph2_lastMonth,
                                                    </p>
                                                    <p>
                                                      currentYear=org.apache.oozie.extensions.OozieELExtensions#ph2_currentYear,
                                                    </p>
                                                    <p>
                                                      lastYear=org.apache.oozie.extensions.OozieELExtensions#ph2_lastYear,
                                                    </p>
                                                    <p>
                                                      latest=org.apache.oozie.coord.CoordELFunctions#ph3_coord_latest,
                                                    </p>
                                                    <p>
                                                      future=org.apache.oozie.coord.CoordELFunctions#ph3_coord_future,
                                                    </p>
                                                    <p>
                                                      dataIn=org.apache.oozie.extensions.OozieELExtensions#ph3_dataIn,
                                                    </p>
                                                    <p>
                                                      instanceTime=org.apache.oozie.coord.CoordELFunctions#ph3_coord_nominalTime,
                                                    </p>
                                                    <p>
                                                      dateOffset=org.apache.oozie.coord.CoordELFunctions#ph3_coord_dateOffset,
                                                    </p>
                                                    <p>
                                                      formatTime=org.apache.oozie.coord.CoordELFunctions#ph3_coord_formatTime,
                                                    </p>
                                                    <p>user=org.apache.oozie.coord.CoordELFunctions#coord_user
                                                    </p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>
                                                      oozie.service.ELService.ext.functions.coord-job-submit-data
                                                    </p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>
                                                      now=org.apache.oozie.extensions.OozieELExtensions#ph1_now_echo,
                                                    </p>
                                                    <p>
                                                      today=org.apache.oozie.extensions.OozieELExtensions#ph1_today_echo,
                                                    </p>
                                                    <p>
                                                      yesterday=org.apache.oozie.extensions.OozieELExtensions#ph1_yesterday_echo,
                                                    </p>
                                                    <p>
                                                      currentMonth=org.apache.oozie.extensions.OozieELExtensions#ph1_currentMonth_echo,
                                                    </p>
                                                    <p>
                                                      lastMonth=org.apache.oozie.extensions.OozieELExtensions#ph1_lastMonth_echo,
                                                    </p>
                                                    <p>
                                                      currentYear=org.apache.oozie.extensions.OozieELExtensions#ph1_currentYear_echo,
                                                    </p>
                                                    <p>
                                                      lastYear=org.apache.oozie.extensions.OozieELExtensions#ph1_lastYear_echo,
                                                    </p>
                                                    <p>
                                                      dataIn=org.apache.oozie.extensions.OozieELExtensions#ph1_dataIn_echo,
                                                    </p>
                                                    <p>
                                                      instanceTime=org.apache.oozie.coord.CoordELFunctions#ph1_coord_nominalTime_echo_wrap,
                                                    </p>
                                                    <p>
                                                      formatTime=org.apache.oozie.coord.CoordELFunctions#ph1_coord_formatTime_echo,
                                                    </p>
                                                    <p>
                                                      dateOffset=org.apache.oozie.coord.CoordELFunctions#ph1_coord_dateOffset_echo,
                                                    </p>
                                                    <p>user=org.apache.oozie.coord.CoordELFunctions#coord_user
                                                    </p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>
                                                      oozie.service.ELService.ext.functions.coord-job-submit-instances
                                                    </p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>
                                                      now=org.apache.oozie.extensions.OozieELExtensions#ph1_now_echo,
                                                    </p>
                                                    <p>
                                                      today=org.apache.oozie.extensions.OozieELExtensions#ph1_today_echo,
                                                    </p>
                                                    <p>
                                                      yesterday=org.apache.oozie.extensions.OozieELExtensions#ph1_yesterday_echo,
                                                    </p>
                                                    <p>
                                                      currentMonth=org.apache.oozie.extensions.OozieELExtensions#ph1_currentMonth_echo,
                                                    </p>
                                                    <p>
                                                      lastMonth=org.apache.oozie.extensions.OozieELExtensions#ph1_lastMonth_echo,
                                                    </p>
                                                    <p>
                                                      currentYear=org.apache.oozie.extensions.OozieELExtensions#ph1_currentYear_echo,
                                                    </p>
                                                    <p>
                                                      lastYear=org.apache.oozie.extensions.OozieELExtensions#ph1_lastYear_echo,
                                                    </p>
                                                    <p>
                                                      formatTime=org.apache.oozie.coord.CoordELFunctions#ph1_coord_formatTime_echo,
                                                    </p>
                                                    <p>
                                                      latest=org.apache.oozie.coord.CoordELFunctions#ph2_coord_latest_echo,
                                                    </p>
                                                    <p>
                                                      future=org.apache.oozie.coord.CoordELFunctions#ph2_coord_future_echo
                                                    </p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>oozie.service.ELService.ext.functions.coord-sla-create
                                                    </p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>
                                                      instanceTime=org.apache.oozie.coord.CoordELFunctions#ph2_coord_nominalTime,
                                                    </p>
                                                    <p>user=org.apache.oozie.coord.CoordELFunctions#coord_user
                                                    </p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>oozie.service.ELService.ext.functions.coord-sla-submit
                                                    </p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>
                                                      instanceTime=org.apache.oozie.coord.CoordELFunctions#ph1_coord_nominalTime_echo_fixed,
                                                    </p>
                                                    <p>user=org.apache.oozie.coord.CoordELFunctions#coord_user
                                                    </p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>oozie.service.HadoopAccessorService.kerberos.enabled
                                                    </p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>false</p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>
                                                      oozie.service.HadoopAccessorService.supported.filesystems
                                                    </p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>*</p>
                                                  </td>
                                                </tr>
                                              </tbody>
                                              
                                            
                                          </table></div>
                                        </li>
                                        <li>
                                          <p>Modify</p>
                                          <div class="xyleme-table"><table border="1">
                                            
                                              
                                              
                                              <thead>
                                                <tr>
                                                  <th rowspan="1">
                                                    <p>Name</p>
                                                  </th>
                                                  <th rowspan="1">
                                                    <p>Value</p>
                                                  </th>
                                                </tr>
                                              </thead>
                                              <tbody>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>oozie.service.SchemaService.wf.ext.schemas</p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>
                                                      shell-action-0.1.xsd,shell-action-0.2.xsd,shell-action-0.3.xsd,email-action-0.1.xsd,email-action-0.2.xsd,hive-action-0.2.xsd,hive-action-0.3.xsd,hive-action-0.4.xsd,hive-action-0.5.xsd,sqoop-action-0.2.xsd,sqoop-action-0.3.xsd,sqoop-action-0.4.xsd,ssh-action-0.1.xsd,ssh-action-0.2.xsd,distcp-action-0.1.xsd,distcp-action-0.2.xsd,oozie-sla-0.1.xsd,oozie-sla-0.2.xsd
                                                    </p>
                                                  </td>
                                                </tr>
                                                <tr>
                                                  <td rowspan="1">
                                                    <p>oozie.services.ext</p>
                                                  </td>
                                                  <td rowspan="1">
                                                    <p>
                                                      org.apache.oozie.service.JMSAccessorService,org.apache.oozie.service.PartitionDependencyManagerService,org.apache.oozie.service.HCatAccessorService
                                                    </p>
                                                  </td>
                                                </tr>
                                              </tbody>
                                              
                                            
                                          </table></div>
                                        </li>
                                      
                                    </ul>
                                  </li>
                                  <li>
                                    <p>After modifying all properties on the Oozie Configs page, choose
                                      <code>Save</code>
                                      to update<code>oozie.site.xml</code>, using the updated
                                      configurations.
                                    </p>
                                  </li>
                                
                              </ul>
                            </li>
                            <li>
                              <p>Replace the content of
                                <code>/usr/oozie/share</code>
                                in HDFS.
                                On the Oozie server host:
                              </p>
                              <ul class="Numeric">
                                
                                  <li>
                                    <p>Extract the Oozie sharelib into a
                                      <code>tmp</code>
                                      folder.
                                    </p>
                                    <p>
                                      <code>mkdir -p /tmp/oozie_tmp;
                                        cp /usr/hdp/2.2.0.0-&lt;$version&gt;/oozie/oozie-sharelib.tar.gz /tmp/oozie_tmp;
                                        cd /tmp/oozie_tmp;
                                        tar xzvf oozie-sharelib.tar.gz;
                                      </code>
                                    </p>
                                  </li>
                                  <li>
                                    <p>Back up the
                                      <code>/user/oozie/share</code>
                                      folder in HDFS and then delete it. If you have any custom files in this folder,
                                      back them up separately and then add them to the
                                      <code>/share</code>
                                      folder after updating it.
                                    </p>
                                    <p>
                                      <code>mkdir /tmp/oozie_tmp/oozie_share_backup;
                                        chmod 777 /tmp/oozie_tmp/oozie_share_backup;
                                      </code>
                                    </p>
                                    <p>
                                      <code>su -l</code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -copyToLocal /user/oozie/share
                                        /tmp/oozie_tmp/oozie_share_backup";
                                        su -l
                                      </code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -rm -r /user/oozie/share";
                                      </code>where
                                      &lt;HDFS_USER&gt;
                                      is the HDFS service user. For example, hdfs.
                                    </p>
                                  </li>
                                  <li>
                                    <p>Add the latest share libs that you extracted in step 1. After you have
                                      added the files, modify ownership and acl.
                                    </p>
                                    <p>
                                      <code>su -l</code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -copyFromLocal /tmp/oozie_tmp/share /user/oozie/.";
                                        su -l
                                      </code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -chown -R &lt;OOZIE_USER&gt;:&lt;HADOOP_GROUP&gt;
                                        /user/oozie";
                                        su -l
                                      </code>
                                      &lt;HDFS_USER&gt;
                                      <code>-c "hdfs dfs -chmod -R 755 /user/oozie";
                                      </code>where
                                      &lt;HDFS_USER&gt;
                                      is the HDFS service user. For example, hdfs.
                                    </p>
                                  </li>
                                
                              </ul>
                            </li>
                            <li>
                              <p>Use the
                                <code>Ambari Web UI</code>
                                &gt;
                                <code>Services</code>
                                view to start the Oozie service. Make sure that ServiceCheck passes for Oozie.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Update WebHCat.</p>
                  <ul class="UppercaseAlpha">
                    
                      <li>
                        <p>Modify the
                          <code>webhcat-site</code>
                          config type.
                        </p>
                        <p>Using<code>Ambari Web</code>, navigate to
                          <code>Services</code>
                          &gt;
                          <code>WebHCat</code>
                          and modify the following configuration:
                        </p>
                        <div class="xyleme-table"><table border="1">
                          
                            
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Action</p>
                                </th>
                                <th rowspan="1">
                                  <p>Property Name</p>
                                </th>
                                <th rowspan="1">
                                  <p>Property Value</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>Modify</p>
                                </td>
                                <td rowspan="1">
                                  <p>templeton.storage.class</p>
                                </td>
                                <td rowspan="1">
                                  <p>org.apache.hive.hcatalog.templeton.tool.ZooKeeperStorage</p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Expand
                          <code>Advanced</code>
                          &gt;<code>webhcat-site.xml</code>.
                        </p>
                        <p>
                          Check if property
                          <code>templeton.port</code>
                          exists. If not, then add it using the Custom webhcat-site panel. The default value for
                          templeton.port = 50111.
                        </p>
                      </li>
                      <li>
                        <p>On each WebHCat host, update the Pig and Hive tar bundles, by updating the following
                          files:
                        </p>
                        <ul class="Bullet">
                          
                            <li>
                              <p>
                                <code>/apps/webhcat/pig.tar.gz</code>
                              </p>
                            </li>
                            <li>
                              <p>
                                <code>/apps/webhcat/hive.tar.gz</code>
                              </p>
                              <aside class="custom-note">
                                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                                <div class="simple-block">
                                  <p>Find these files only on a host where WebHCat is installed.</p>
                                </div>
                              </aside>
                            </li>
                          
                        </ul>
                        <ul class="Numeric">
                          For example, to update a *.tar.gz file:
                          
                            <li>
                              <p>Move the file to a local directory.</p>
                              <p>
                                <code>su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hadoop --config /etc/hadoop/conf fs -copyToLocal
                                  /apps/webhcat/*.tar.gz
                                </code>
                                &lt;local_backup_dir&gt;
                                <code>"</code>
                              </p>
                            </li>
                            <li>
                              <p>Remove the old file.</p>
                              <p>
                                <code>su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hadoop --config /etc/hadoop/conf fs -rm /apps/webhcat/*.tar.gz"
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Copy the new file.</p>
                              <p>
                                <code>su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hdfs --config /etc/hadoop/conf dfs -copyFromLocal
                                  /usr/hdp/2.2.0.0-
                                </code>
                                &lt;$version&gt;
                                <code>/hive/hive.tar.gz /apps/webhcat/"; su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hdfs --config /etc/hadoop/conf dfs -copyFromLocal
                                  /usr/hdp/2.2.0.0-
                                </code>
                                &lt;$version&gt;
                                <code>/pig/pig.tar.gz /apps/webhcat/";
                                </code>where
                                &lt;HCAT_USER&gt;
                                is the HCatalog service user. For example, hcat.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>On each WebHCat host, update
                          <code>/app/webhcat/hadoop-streaming.jar</code>
                          file.
                        </p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Move the file to a local directory.</p>
                              <p>
                                <code>su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hadoop --config /etc/hadoop/conf fs -copyToLocal
                                  /apps/webhcat/hadoop-streaming*.jar &lt;local_backup_dir&gt;"
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Remove the old file.</p>
                              <p>
                                <code>su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hadoop --config /etc/hadoop/conf fs -rm
                                  /apps/webhcat/hadoop-streaming*.jar"
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Copy the new hadoop-streaming.jar file.</p>
                              <p>
                                <code>su -l</code>
                                &lt;HCAT_USER&gt;
                                <code>-c "hdfs --config /etc/hadoop/conf dfs -copyFromLocal /usr/hdp/2.2.0.0-&lt;$version&gt;/hadoop-mapreduce/hadoop-streaming*.jar
                                  /apps/webhcat"

                                </code>where
                                &lt;HCAT_USER&gt;
                                is the HCatalog service user. For example, hcat.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Prepare Tez for work.
                    Add the Tez service to your cluster using the Ambari Web UI, if Tez was not installed earlier.
                  </p>
                  <p>
                    Configure Tez.
                    <code>cd /var/lib/ambari-server/resources/scripts/;
                      ./configs.sh set localhost &lt;your-cluster-name&gt; cluster-env "tez_tar_source"
                      "/usr/hdp/current/tez-client/lib/tez.tar.gz";
                      ./configs.sh set localhost &lt;your-cluster-name&gt; cluster-env "tez_tar_destination_folder"
                      "hdfs:///hdp/apps/{{ hdp_stack_version }}/tez/"
                    </code>
                  </p>
                  <p>
                    If you use Tez as the Hive execution engine, and if the variable hive.server2.enabled.doAs is set to
                    true, you must create a scratch directory on the NameNode host for the username that will run the
                    HiveServer2 service. For example, use the following commands:

                    <code>sudo su -c "hdfs -makedir /tmp/hive-</code>
                    &lt;username&gt;
                    <code>"
                      sudo su -c "hdfs -chmod 777 /tmp/hive-
                    </code>
                    &lt;username&gt;
                    <code>"
                    </code>where&lt;username&gt; is the name of the user that runs the
                    HiveServer2 service.
                  </p>
                </li>
                <li>
                  <p>Using the<code>Ambari Web UI&gt; Services &gt; Hive</code>,
                    start the Hive service.
                  </p>
                </li>
                <li>
                  <p>If you use Tez as the Hive execution engine, and if the variable
                    <code>hive.server2.enabled.doAs</code>
                    is set to<code>true</code>, you must create a scratch directory on the NameNode host for
                    the username that will run the HiveServer2 service. For example, use the following commands:
                  </p>
                  <p>
                    <code>
                      sudo su -c "hdfs -makedir /tmp/hive-
                    </code>
                    &lt;username&gt;
                    <code>"</code>
                  </p>
                  <p>
                    <code>
                      sudo su -c "hdfs -chmod 777 /tmp/hive-
                    </code>
                    &lt;username&gt;
                    <code>"</code>
                  </p>
                  <p>
                    where
                    &lt;username&gt;
                    is the name of the user that runs the HiveServer2 service.
                  </p>
                </li>
                <li>
                  <p>Using<code>Ambari Web &gt; Services</code>, re-start the
                    remaining services.
                  </p>
                </li>
                <li>
                  <p>The upgrade is now fully functional but not yet finalized. Using the
                    <code>finalize</code>
                    command removes the previous version of the NameNode and DataNode storage directories.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>After the upgrade is finalized, the system cannot be rolled back. Usually this step is
                        not taken until a thorough testing of the upgrade has been performed.
                      </p>
                    </div>
                  </aside>
                  <p>
                    The upgrade must be finalized before another upgrade can be performed.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>Directories used by Hadoop 1 services set in /etc/hadoop/conf/taskcontroller.cfg are not
                        automatically deleted after upgrade. Administrators can choose to delete these directories after
                        the upgrade.
                      </p>
                    </div>
                  </aside>
                  <p>
                    To finalize the upgrade, execute the following command once, on the primary NameNode host in your
                    HDP cluster:
                    <code>sudo su -l</code>
                    &lt;HDFS_USER&gt;
                    <code>-c "hdfs dfsadmin -finalizeUpgrade"</code>
                  </p>
                </li>
              
            </ul>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-2c87cbec-f2e9-4c82-96c6-de295bbd589f">Upgrading the HDP Stack from 1.3 to 2.2</h3>
        
          <p>The Stack is the coordinated set of Hadoop components that you have installed. Use the following
            instructions to upgrade a current, Ambari-installed and managed instance of a version 1.3 Stack to a version
            2.2 Stack. This procedure causes the upgraded stack to be managed by Ambari.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>If your Stack has Kerberos Security turned on, you should turn it off before performing the
                upgrade. On
                <code>Ambari Web UI</code>
                &gt;
                <code>Admin</code>
                &gt;<code>Security</code>, click<code>Disable Security</code>.
                You can re-enable Security after performing the upgrade.
              </p>
            </div>
          </aside>
          <p>If you are upgrading from any other 1.x version of the stack, you must upgrade to 1.3 or later
            before you can upgrade to 2.2. Upgrades from previous 1.x versions are not supported.
          </p>
        
        
          <p>In preparation for future HDP 2.2 releases to support rolling upgrades, the HDP RPM package version
            naming convention has changed to include the HDP 2.2 product version in file and directory names. HDP 2.2
            marks the first release where HDP rpms, debs, and directories contain versions in the names to permit
            side-by-side installations of later HDP releases. To transition between previous releases and HDP 2.2,
            Pivotal provides hdp-select, a script that symlinks your directories to<code>
              hdp/current</code>and lets you maintain using the same binary and configuration paths that you were
            using before. The following instructions have you remove your old versions of HDP, install hdp-select, and
            install HDP 2.2 to prepare for rolling upgrade.
          </p>
        
        
          <h4 class="bold">Preparing the 1.3 Stack for the Upgrade to 2.2</h4>
          
            <p>To prepare for upgrading the HDP Stack, this section describes how to perform the following
              tasks:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>Checkpoint user metadata and capture the HDFS operational state.
                    This step supports rollback and restore of the original state of HDFS data, if necessary.
                  </p>
                </li>
                <li>
                  <p>Backup Hive and Oozie metastore databases.
                    This step supports rollback and restore of the original state of Hive and Oozie data, if necessary.
                  </p>
                </li>
                <li>
                  <p>Stop all HDP and Ambari services.</p>
                </li>
              
            </ul>
            <p>Perform steps 1 through 8 on the NameNode host. In a highly-available NameNode configuration, you
              should execute the following procedure on the primary NameNode.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>To locate the primary NameNode in an Ambari-managed HDP cluster, browse
                  <code>Ambari Web</code>
                  &gt;
                  <code>Services</code>
                  &gt;<code>HDFS</code>. In Summary, click NameNode.
                  <code>Hosts</code>
                  &gt;
                  <code>Summary</code>
                  displays the host name FQDN.
                </p>
              </div>
            </aside>
            <ul class="number-list">
              
                <li>
                  <p>Stop all services except HDFS and ZooKeeper. Also stop any client programs that access
                    HDFS.
                  </p>
                </li>
                <li>
                  <p>If HDFS is in a non-finalized state from a prior upgrade operation, you must finalize HDFS
                    before upgrading further. Finalizing HDFS will remove all links to the metadata of the prior HDFS
                    version - do this only if you do not want to rollback to that prior HDFS version.
                  </p>
                  <p>For example, as the HDFS user:
                    <code>sudo -u</code>
                    <code></code>
                    &lt;HDFS_USER&gt;
                    
                    <code>hadoop dfsadmin -finalizeUpgrade</code>
                  </p>
                  <p>You can check the namenode directory to ensure that there is no snapshot of any prior HDFS
                    upgrade. Specifically, examine the $dfs.namenode.name.dir (or $dfs.name.dir) on the NameNode. Make
                    sure that only a ‘current’, not a ‘previous’ directory exists.
                  </p>
                </li>
                <li>
                  <p>Create the following logs and other files.</p>
                  <p>Creating these logs lets you to check the integrity of the file system after upgrading.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Run
                          <code>fsck</code>
                          with the following flags and send the results to a log. The resulting file contains a complete
                          block map of the file system. You use this log later to confirm the upgrade.
                        </p>
                        <p>

                          <code>sudo -u</code>
                          &lt;HDFS_USER&gt;
                          <code>hadoop fsck / -files -blocks -locations &gt; dfs-old-fsck-1.log
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Optional: Capture the complete namespace of the filesystem. (The following command
                          does a recursive listing of the root file system.)
                        </p>
                        <p>
                          <code>
                            sudo -u
                          </code>
                          &lt;HDFS_USER&gt;
                          <code>hadoop dfs -lsr / &gt; dfs-old-lsr-1.log</code>
                        </p>
                      </li>
                      <li>
                        <p>Create a list of all the DataNodes in the cluster.</p>
                        <p>
                          <code>
                            sudo -u
                          </code>
                          &lt;HDFS_USER&gt;
                          <code>hadoop dfsadmin -report &gt; dfs-old-report-1.log</code>
                        </p>
                      </li>
                      <li>
                        <p>Optional: copy all or unrecoverable only data stored in HDFS to a local file system or
                          to a backup instance of HDFS.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p><strong>Save the namespace</strong>. You must be the HDFS service user to do this and you must
                    put the cluster in Safe Mode.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>This is a critical step. If you do not do this step before you do the upgrade, the
                        NameNode will not start afterwards.
                      </p>
                    </div>
                  </aside>
                  <p>
                    As the HDFS user:
                    <code>hadoop dfsadmin -safemode enter
                      hadoop dfsadmin -saveNamespace
                    </code>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>In a HA NameNode configuration, the command
                        <code>hdfs dfsadmin -saveNamespace</code>
                        does checkpoint in the first NameNode specified in the configuration, in<code>
                          dfs.ha.namenodes.[nameservice ID]</code>. You can also use the dfsadmin
                        <code>-fs</code>
                        option to specify which NameNode to connect. For example, to force a checkpoint in namenode 2:
                      </p>
                      <p>
                        <code>hdfs dfsadmin -fs hdfs://namenode2-hostname:namenode2-port -saveNamespace
                        </code>
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Copy the following checkpoint files into a backup directory. You can find the directory by
                    using the
                    <code>Services View</code>
                    in the Ambari Web UI. Select
                    <code>HDFS</code>
                    &gt;
                    <code>Configs</code>
                    <strong>.</strong>
                    In the Namenode section, look up the property
                    <strong>NameNode Directories</strong>
                    on your NameNode host.
                  </p>
                  <p>
                    &lt;dfs.name.dir&gt;
                    <code>/current</code>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>In a HA NameNode configuration, the location of the checkpoint depends on where the
                        saveNamespace command is sent, as defined in the preceding step.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>Store the layoutVersion for the NameNode. Make a copy of the file at
                    &lt;dfs.name.dir&gt;
                    <code>/current/VERSION</code>
                    where
                    &lt;dfs.name.dir&gt;
                    is the value of the config parameter<code>NameNode directories</code>. This file will be
                    used later to verify that the layout version is upgraded.
                  </p>
                </li>
                <li>
                  <p>Stop HDFS. Make sure all services in the cluster are completely stopped.</p>
                </li>
                <li>
                  <p>If you are upgrading Hive and Oozie, back up the Hive database and the Oozie database on the
                    Hive database host and Oozie database host machines, respectively.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Important.png" width="50"></div>
                    <div class="simple-block">
                      <p>Make sure that your Hive database is updated to the minimum recommended version.
                        <strong>If you are using Hive with MySQL, we recommend upgrading your MySQL database version to
                          5.6.21 before upgrading the HDP Stack to v2.2.
                        </strong>
                        For specific information, see<a href="#ref-f35b0203-6267-4533-9e88-652452ece5f5">
                          Database Requirements</a>.
                      </p>
                    </div>
                  </aside>
                  <ul class="LowercaseAlpha">
                    
                      <li>
                        <p>Optional - Backup the Hive Metastore database.</p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Note.png" width="50"></div>
                          <div class="simple-block">
                            <p>These instructions are provided for your convenience. Please check your database
                              documentation for the latest back up instructions.
                            </p>
                          </div>
                        </aside>
                        <div class="xyleme-table"><table border="1">
                          <p class="italic bold">Hive Metastore Database Backup and Restore</p>
                          
                            
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Database Type</p>
                                </th>
                                <th rowspan="1">
                                  <p>Backup</p>
                                </th>
                                <th rowspan="1">
                                  <p>Restore</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>MySQL</p>
                                </td>
                                <td rowspan="1">
                                  <p>mysqldump $dbname &gt; $outputfilename.sql For example: mysqldump hive &gt;
                                    /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>mysql $dbname &lt; $inputfilename.sql For example: mysql hive &lt;
                                    /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>Postgres</p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u $username pg_dump $databasename &gt; $outputfilename.sql For
                                    example: sudo -u postgres pg_dump hive &gt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u $username psql $databasename &lt; $inputfilename.sql For example:
                                    sudo -u postgres psql hive &lt; /tmp/mydir/backup_hive.sql
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>Oracle</p>
                                </td>
                                <td rowspan="1">
                                  <p>Connect to the Oracle database using sqlplus export the database: exp
                                    username/password@database full=yes file=output_file.dmp
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>Import the database: imp username/password@database ile=input_file.dmp
                                  </p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                      <li>
                        <p>Optional - Backup the Oozie Metastore database.</p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Note.png" width="50"></div>
                          <div class="simple-block">
                            <p>These instructions are provided for your convenience. Please check your database
                              documentation for the latest back up instructions.
                            </p>
                          </div>
                        </aside>
                        <div class="xyleme-table"><table border="1">
                          <p class="italic bold">Oozie Metastore Database Backup and Restore</p>
                          
                            
                            
                            
                            <thead>
                              <tr>
                                <th rowspan="1">
                                  <p>Database Type</p>
                                </th>
                                <th rowspan="1">
                                  <p>Backup</p>
                                </th>
                                <th rowspan="1">
                                  <p>Restore</p>
                                </th>
                              </tr>
                            </thead>
                            <tbody>
                              <tr>
                                <td rowspan="1">
                                  <p>MySQL</p>
                                </td>
                                <td rowspan="1">
                                  <p>mysqldump $dbname &gt; $outputfilename.sql For example: mysqldump oozie &gt;
                                    /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>mysql $dbname &lt; $inputfilename.sql For example: mysql oozie &lt;
                                    /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                              </tr>
                              <tr>
                                <td rowspan="1">
                                  <p>Postgres</p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u $username pg_dump $databasename &gt; $outputfilename.sql For
                                    example: sudo -u postgres pg_dump oozie &gt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                                <td rowspan="1">
                                  <p>sudo -u $username psql $databasename &lt; $inputfilename.sql For example:
                                    sudo -u postgres psql oozie &lt; /tmp/mydir/backup_oozie.sql
                                  </p>
                                </td>
                              </tr>
                            </tbody>
                            
                          
                        </table></div>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>On every host in your cluster known to Ambari, stop all Ambari Agents.</p>
                  <p>
                    <code>ambari-agent stop</code>
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Upgrading the 1.3 Stack to 2.2</h4>
          
            <p>This stack upgrade involves removing the HDP 1.x version of MapReduce and replacing it with the
              HDP 2.x YARN and MapReduce2 components. This process is somewhat long and complex. To help you, a Python
              script is provided to automate some of the upgrade steps.
            </p>
          
          
            <h4 class="bold">Prepare the 1.3 Stack for Upgrade to 2.2</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>Make sure that you completed the system preparation procedure; most importantly, save the
                      namespace.
                    </p>
                  </li>
                  <li>
                    <p>Stage the upgrade script:</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Create an "Upgrade Folder", for example<code>/work/upgrade_hdp_2</code>,
                            on a host that can communicate with Ambari Server. The Ambari Server host would be a
                            suitable candidate.
                          </p>
                        </li>
                        <li>
                          <p>Copy the upgrade script to the Upgrade Folder. The script is available here:
                            <code>/var/lib/ambari-server/resources/scripts/UpgradeHelper_HDP2.py</code>on
                            the Ambari Server host.
                          </p>
                        </li>
                        <li>
                          <p>Make sure that Python is available on the host and that the version is 2.6 or
                            higher:
                          </p>
                          <p>
                            <code>python --version</code>
                          </p>
                          <aside class="custom-note">
                            <div class="icon"><img src="Icons/Note.png" width="50"></div>
                            <div class="simple-block">
                              <p>For RHEL/Centos/Oracle Linux 5, you
                                <strong>must</strong>
                                use Python 2.6.
                              </p>
                            </div>
                          </aside>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Start the Ambari Server only if it is stopped. On the Ambari Server host:</p>
                    <p>
                      <code>ambari-server status</code>

                      If status is "stopped", then:

                      <code>ambari-server start</code>
                    </p>
                  </li>
                  <li>
                    <p>Back up current configuration settings and the component host mappings from MapReduce:
                    </p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Go to the Upgrade Folder.</p>
                        </li>
                        <li>
                          <p>Execute the
                            <code>backup-configs</code>
                            action:
                          </p>
                          <p>
                            <code>python UpgradeHelper_HDP2.py --hostname</code>
                            &lt;HOSTNAME&gt;
                            <code>--user</code>
                            &lt;USERNAME&gt;
                            <code>--password</code>
                            &lt;PASSWORD&gt;
                            <code>--clustername</code>
                            &lt;CLUSTERNAME&gt;
                            
                            <code>backup-configs</code>
                          </p>
                          <p>Where</p>
                          <ul class="Bullet">
                            
                              <li>
                                <p>
                                  &lt;HOSTNAME&gt;
                                  is the name of the Ambari Server host
                                </p>
                              </li>
                              <li>
                                <p>
                                  &lt;USERNAME&gt;
                                  is the admin user for Ambari Server
                                </p>
                              </li>
                              <li>
                                <p>
                                  &lt;PASSWORD&gt;
                                  is the password for the admin user
                                </p>
                              </li>
                              <li>
                                <p>
                                  &lt;CLUSTERNAME&gt;
                                  is the name of the cluster
                                </p>
                              </li>
                            
                          </ul>
                          <p>This step produces a set of files named TYPE_TAG, where TYPE is the configuration
                            type and TAG is the tag. These files contain copies of the various configuration settings
                            for the current (pre-upgrade) cluster. You can use these files as a reference later.
                          </p>
                        </li>
                        <li>
                          <p>Execute the<code>save-mr-mapping</code>action:
                          </p>
                          <p>
                            <code>
                              python UpgradeHelper_HDP2.py --hostname
                            </code>
                            &lt;HOSTNAME&gt;
                            <code>--user</code>
                            &lt;USERNAME&gt;
                            
                            <code>--password</code>
                            &lt;PASSWORD&gt;
                            <code>--clustername</code>
                            &lt;CLUSTERNAME&gt;
                            <code>save-mr-mapping</code>
                          </p>
                          <p>This step produces a file named
                            <code>mr_mapping</code>
                            that stores the host level mapping of MapReduce components such as MapReduce
                            JobTracker/TaskTracker/Client.
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Delete all the MapReduce server components installed on the cluster.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>If you are not already there, go to the Upgrade Folder.</p>
                        </li>
                        <li>
                          <p>Execute the
                            <code>delete-mr</code>
                            action.
                          </p>
                          <p>
                            <code>python UpgradeHelper_HDP2.py --hostname</code>
                            &lt;HOSTNAME&gt;
                            <code>--user</code>
                            &lt;USERNAME&gt;
                            <code>--password</code>
                            &lt;PASSWORD&gt;
                            <code>--clustername</code>
                            &lt;CLUSTERNAME&gt;
                            <code>delete-mr</code>
                          </p>
                          <p>Optionally, execute the delete script with the -n option to view, verify, and
                            validate API calls, if necessary.
                          </p>
                          <aside class="custom-note">
                            <div class="icon"><img src="Icons/Note.png" width="50"></div>
                            <div class="simple-block">
                              <p>Running the delete script with the -n option exposes API calls but does not
                                remove installed components. Use the -n option for validation purposes only.
                              </p>
                            </div>
                          </aside>
                        </li>
                        <li>
                          <p>The script asks you to confirm that you have executed the
                            <code>save-mr-mapping</code>
                            action and that you have a file named
                            <code>mr_mapping</code>
                            in the Upgrade Folder.
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>On the Ambari Server host, stop Ambari Server and confirm that it is stopped.</p>
                    <p>
                      <code>ambari-server stop</code>
                      <code>ambari-server status</code>
                    </p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Upgrade the 1.3 Stack to 2.2</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>Stop the Ambari Server only if it is started . On the Ambari Server host:</p>
                    <p>
                      <code>ambari-server status</code>

                      If status is "started", then:
                      <code>
                        ambari-server stop
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>Make sure that the old version of MapReduce deleted successfully.</p>
                  </li>
                  <li>
                    <p>Update the stack version in the Ambari Server database.
                      Use the command appropriate for a remote, or local repository, as follows:
                    </p>
                    <p>
                      <code>ambari-server upgradestack HDP-2.2</code>
                    </p>
                  </li>
                  <li>
                    <p>Upgrade the HDP repository on all hosts and replace the old repo file with the new file:
                    </p>
                    <p>The file you download is named<code>hdp.repo</code>. To function properly in
                      the system, it must be named<code>HDP.repo</code>. Once you have completed the "mv" of
                      the new repo file to the repos.d folder, make sure there is no file named
                      <code>hdp.repo</code>
                      anywhere in your repos.d folder.
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>For RHEL/CentOS/Oracle Linux 6:</p>
                          <p>
                            <code>wget -nv
                              http://public-repo-1.hortonworks.com/HDP/centos6/2.x/GA/2.2.0.0/hdp.repo -O
                              /etc/yum.repos.d/HDP.repo
                            </code>
                          </p>
                        </li>
                        <li>
                          <p>For SLES 11:</p>
                          <p>
                            <code>
                              wget -nv http://public-repo-1.hortonworks.com/HDP/centos5/2.x/GA/2.2.0.0/hdp.repo -O
                              /etc/yum.repos.d/HDP.repo
                            </code>
                          </p>
                        </li>
                        <li>
                          <p>For RHEL/CentOS/Oracle Linux 5: (DEPRECATED)</p>
                          <p>
                            <code>wget</code>
                            <code>-nv
                              http://public-repo-1.hortonworks.com/HDP-LABS/Projects/Champlain-Preview/2.2.0.0-9/centos5/hdp.repo
                              -O /etc/yum.repos.d/HDP.repo
                            </code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Back up the files in following directories on the Oozie server host and make sure that all
                      files, including *site.xml files are copied.
                      <code>mkdir oozie-conf-bak</code>
                      <code>
                      </code>
                      <code>cp -R /etc/oozie/conf/* oozie-conf-bak</code>
                    </p>
                  </li>
                  <li>
                    <p>Remove the old
                      <code>/oozie</code>
                      directories on all Oozie server and client hosts
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>
                            <code>rm -rf /etc/oozie/conf</code>
                          </p>
                        </li>
                        <li>
                          <p>
                            <code>rm -rf /usr/lib/oozie/</code>
                          </p>
                        </li>
                        <li>
                          <p>
                            <code>rm -rf /var/lib/oozie/</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Upgrade the stack on all Agent hosts. Skip any components your installation does not
                      use:
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>For RHEL/CentOS/Oracle Linux:</p>
                          <ul class="Numeric">
                            
                              <li>
                                <p>On all hosts, clean the yum repository.</p>
                                <p>
                                  <code>yum clean all</code>
                                </p>
                              </li>
                              <li>
                                <p>Remove remaining MapReduce, and WebHCat, HCatalog, and Oozie components on all
                                  hosts.
                                  This command uninstalls these HDP 1.3 component bits. It leaves the user data and
                                  metadata, but removes your configurations.
                                </p>
                                <p>
                                  <code>yum erase hadoop-pipes hadoop-sbin hadoop-native "webhcat*"
                                    "hcatalog*" "oozie*" "hadoop*" "hadoop-libhdfs*" "hbase*" "hcatalog*" "hive*"
                                    "oozie*" "oozie-client*" "pig*" "sqoop*" "webhcat-tar-hive*" "webhcat-tar-pig*"
                                    "zookeeper*"
                                  </code>
                                </p>
                              </li>
                              <li>
                                <p>Remove your old hdp.repo and hdp-utils repo files.</p>
                                <p>
                                  <code>rm etc/yum/repos.d/hdp.repo hdp-utils.repo</code>
                                </p>
                              </li>
                              <li>
                                <p>Install the following components:</p>
                                <p>
                                  <code>
                                    yum install "hadoop_2_2_0_0_*" "oozie_2_2_0_0_*" "pig_2_2_0_0_*" "sqoop_2_2_0_0_*"
                                    "zookeeper_2_2_0_0_*" "hbase_2_2_0_0_*" "hive_2_2_0_0_*"
                                  </code>
                                </p>
                              </li>
                              <li>
                                <p>Verify that the components were upgraded:</p>
                                <p>
                                  <code>yum list installed | grep HDP-$old-stack-version-number
                                  </code>
                                </p>
                                <p>
                                  No 1.3 components should appear in the returned list.
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                        <li>
                          <p>For SLES:</p>
                          <ul class="Numeric">
                            
                              <li>
                                <p>On all hosts, clean the zypper repository.</p>
                                <p>
                                  <code>zypper clean --all</code>
                                </p>
                              </li>
                              <li>
                                <p>Remove remaining MapReduce, and WebHCat, HCatalog, and Oozie components on all
                                  hosts.
                                  This command uninstalls these HDP 1.3 component bits. It leaves the user data and
                                  metadata, but removes your configurations.
                                </p>
                                <p>
                                  <code>zypper remove hadoop-pipes hadoop-sbin hadoop-native webhcat\*
                                    hcatalog\* oozie\*
                                  </code>
                                </p>
                              </li>
                              <li>
                                <p>Remove your old hdp.repo and hdp-utils repo files.</p>
                                <p>
                                  <code>rm etc/zypp/repos.d/hdp.repo hdp-utils.repo</code>
                                </p>
                              </li>
                              <li>
                                <p>Install the following components:</p>
                                <p>
                                  <code>zypper install "collectd*" "epel-release*" "gccxml*" "pig*" "hadoop*"
                                    "sqoop*" "zookeeper*" "hbase*" "hive*" hdp_mon_nagios_addons
                                  </code>
                                </p>
                                <p>
                                  <code>zypper install webhcat-tar-hive webhcat-tar-pig</code>
                                </p>
                                <p>
                                  <code>zypper install oozie oozie-client</code>
                                </p>
                              </li>
                              <li>
                                <p>Verify that the components were upgraded.</p>
                                <p>
                                  <code>rpm -qa | grep hadoop, rpm -qa | grep hive and rpm -qa | grep
                                    hcatalog
                                  </code>
                                </p>
                                <p>
                                  No 1.3 components should appear in the returned list.
                                </p>
                              </li>
                              <li>
                                <p>If components were not upgraded, upgrade them as follows:</p>
                                <p>
                                  <code>yast --update hadoop hcatalog hive</code>
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Symlink directories, using<code>hdp-select</code>.
                    </p>
                    <aside class="custom-note">
                      <div class="icon"><img src="Icons/Warning.png" width="50"></div>
                      <div class="simple-block">
                        <p>To prevent version-specific directory issues for your scripts and updates, Pivotal
                          provides<code>hdp-select</code>, a script that symlinks directories to hdp-current
                          and modifies paths for configuration directories.
                        </p>
                      </div>
                    </aside>
                    <p>Check that the
                      <code>hdp-select</code>
                      package installed:
                      <code>rpm -qa | grep hdp-select</code>

                      You should see:
                      <code>hdp-select-2.2.0.0-2041.el6.noarch</code>

                      If not, then run:
                      <code>
                        yum install hdp-select
                      </code>

                      Run
                      <code>hdp-select</code>
                      as root, on your NameNode(s) and all your DataNodes. In<code>/usr/bin</code>:
                      <code>
                        hdp-select set all 2.2.0.0-
                      </code>
                      &lt;$version&gt;
                      <code>
                      </code>where
                      &lt;$version&gt;
                      is the build number. For the HDP 2.2 release &lt;$version&gt; = 2041.
                      <code>
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>On the Hive Metastore database host, stop the Hive Metastore
                      <strong>
                        <i>service</i>
                      </strong>
                      , if you have not done so already. Make sure that the Hive Metastore
                      <strong>
                        <i>database</i>
                      </strong>
                      is running.
                    </p>
                  </li>
                  <li>
                    <p>Upgrade Hive v11 to v14 and upgrade the Hive metastore database schema, using the
                      following instructions:
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>Set java home:</p>
                          <p>
                            <code>export JAVA_HOME=/path/to/java</code>
                          </p>
                        </li>
                        <li>
                          <p>Copy old hive configurations to new conf dir:</p>
                          <p>
                            <code>cp -R /etc/hive/conf.server/* /etc/hive/conf/</code>
                          </p>
                        </li>
                        <li>
                          <p>
                            &lt;HIVE_HOME&gt; 
                            <code>/bin/schematool -upgradeSchemaFrom 0.11.0 -dbType</code>
                            &lt;databaseType&gt;
                            where
                            &lt;HIVE_HOME&gt;
                            is the Hive installation directory.
                          </p>
                          <p>
                            For example, on the Hive Metastore host:
                            <code>/usr/hdp/2.2.0.0-</code>
                            &lt;$version&gt;
                            <code>/hive/bin/schematool -upgradeSchemaFrom 0.11.0 -dbType</code>
                            &lt;databaseType&gt;
                            where
                            &lt;$version&gt;
                            is the 2.2.0 build number and
                            &lt;databaseType&gt;
                            is derby, mysql, oracle, or postgres.
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Complete Upgrade of the 1.3 Stack to 2.2</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>Start Ambari Server and Ambari Agents.</p>
                    <p>On the Server host:</p>
                    <p>
                      <code>ambari-server start</code>
                    </p>
                    <p>
                      On all of the Agent hosts:
                    </p>
                    <p>
                      <code>ambari-agent start</code>
                    </p>
                  </li>
                  <li>
                    <p>Update the repository Base URLs in Ambari Server for the HDP-2.2 stack. Browse to
                      <code>Ambari Web</code>
                      &gt;
                      <code>Admin</code>
                      &gt;
                      <code>Repositories</code>
                      and set the value of the HDP and HDP-UTILS repository Base URLs. For more information about
                      viewing and editing repository Base URLs, see<a href="#ref-0cf8106e-364a-46d5-85aa-38dd0476a7e2">Viewing Cluster Stack Version and
                        Repository URLs</a>.
                    </p>
                    <p>For a remote, accessible, public repository, the HDP and HDP-UTILS Base URLs are the same
                      as the baseurl=values in the HDP.repo file downloaded in Upgrade the Stack: Step 1 For a local
                      repository, use the local repository Base URL that you configured for the HDP Stack. For links to
                      download the HDP repository files for your version of the Stack, see<a href="#ref-3e43081a-a937-4d51-92cc-1fbf15645713">HDP Stack Repositories</a>.
                    </p>
                  </li>
                  <li>
                    <p>Add YARN and MapReduce2 services:</p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>If you are not already there, go to the Upgrade Folder.</p>
                        </li>
                        <li>
                          <p>Execute the add-yarn-mr2 action:</p>
                          <p>
                            <code>python UpgradeHelper_HDP2.py --hostname $HOSTNAME --user $USERNAME
                              --password $PASSWORD --clustername $CLUSTERNAME add-yarn-mr2
                            </code>
                          </p>
                        </li>
                      
                    </ul>
                    <aside class="custom-note">
                      <div class="simple-block">
                        <p>If desired, you can use the -n option to see the API calls as they are being made so
                          that you can verify them.
                        </p>
                      </div>
                    </aside>
                  </li>
                  <li>
                    <p>Update the respective configurations:</p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>If you are not already there, go to the Upgrade Folder.</p>
                        </li>
                        <li>
                          <p>Execute the update-configs action:</p>
                          <p>
                            <code>
                              python UpgradeHelper_HDP2.py --hostname $HOSTNAME --user
                            </code>
                            $USERNAME
                            <code>--password</code>
                            $PASSWORD
                            <code>--clustername</code>
                            $CLUSTERNAME
                            <code>update-configs</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Install the YARN and MapReduce2 services:</p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>If you are not already there, go to the Upgrade Folder.</p>
                        </li>
                        <li>
                          <p>Execute the install-yarn-mr2 action:</p>
                          <p>
                            <code>python UpgradeHelper_HDP2.py --hostname</code>
                            $HOSTNAME
                            <code>--user</code>
                            $USERNAME
                            <code>--password</code>
                            $PASSWORD
                            <code>--clustername</code>
                            $CLUSTERNAME
                            <code>install-yarn-mr2</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Using the Ambari Web UI, add the Tez service if if it has not been installed already. For
                      more information about adding a service, see<a href="#ref-19a49eb0-7d00-4f33-bb7b-ed805a5cd656">Adding a Service</a>.
                    </p>
                  </li>
                  <li>
                    <p>Using the Ambari Web UI, add any new services that you want to run on the HDP 2.2 stack.
                      You must add a Service before editing configuration properties necessary to complete the upgrade.
                    </p>
                  </li>
                  <li>
                    <p>Using the Ambari Web Services view, start the ZooKeeper service.</p>
                  </li>
                  <li>
                    <p>If you are upgrading from an HA NameNode configuration, start all JournalNodes. On each
                      JournalNode host, run the following command as the HDFS user:
                    </p>
                    <p>
                      <code>
                        su -l
                      </code>
                      &lt;HDFS_USER&gt;
                      <code>-c "/usr/hdp/2.2.0.0-&lt;$version&gt;/hadoop/sbin/hadoop-daemon.sh start
                        journalnode"
                      </code>
                    </p>
                    <p>All JournalNodes must be running when performing the upgrade, rollback, or finalization
                      operations. If any JournalNodes are down when running any such operation, the operation will fail.
                    </p>
                  </li>
                  <li>
                    <p>Because the file system version has now changed you must start the NameNode manually. On
                      the NameNode host, as the HDFS User:
                    </p>
                    <p>
                      <code></code>
                      <code>su -l -c "export HADOOP_LIBEXEC_DIR=/usr/hdp/2.2.0.0-</code>
                      &lt;$version&gt;
                      <code>/hadoop/libexec &amp;&amp; /usr/hdp/2.2.0.0-</code>
                      &lt;$version&gt;
                      <code>/hadoop/sbin/hadoop-daemon.sh start namenode -upgrade"</code>
                    </p>
                    <p>To check if the Upgrade is in progress, check that the "
                      <code>\previous</code>
                      " directory has been created in \NameNode and \JournalNode directories. The "
                      <code>\previous</code>
                      " directory contains a snapshot of the data before upgrade.
                    </p>
                    <aside class="custom-note">
                      <div class="icon"><img src="Icons/Note.png" width="50"></div>
                      <div class="simple-block">
                        <p>In a NameNode HA configuration, this NameNode will not enter the standby state as
                          usual. Rather, this NameNode will immediately enter the active state, perform an upgrade of
                          its local storage directories, and also perform an upgrade of the shared edit log. At this
                          point, the standby NameNode in the HA pair is still down. It will be out of sync with the
                          upgraded active NameNode.

                          To synchronize the active and standby NameNode, re-establishing HA, re-bootstrap the
                          standbyNameNode by running the NameNode with the '-bootstrapStandby' flag.
                          <strong>Do NOT</strong>
                          start this standby NameNode with the '-upgrade' flag.
                        </p>
                        <p>
                          <code>
                            su -l
                          </code>
                          &lt;HDFS_USER&gt;
                          <code>-c "hdfs namenode -bootstrapStandby -force"</code>
                        </p>
                        <p>
                          The bootstrapStandby command will download the most recent fsimage from the active NameNode
                          into the
                          <code>$dfs.name.dir</code>
                          directory of the standby NameNode. You can enter that directory to make sure the fsimage has
                          been successfully downloaded. After verifying, start the ZKFailoverController via Ambari, then
                          start the standby NameNode via Ambari. You can check the status of both NameNodes using the
                          Web UI.
                        </p>
                      </div>
                    </aside>
                  </li>
                  <li>
                    <p>Start all DataNodes.</p>
                    <p>
                      <code>
                        su -l
                      </code>
                       &lt;HDFS_USER&gt;
                      <code>-c "/usr/hdp/2.2.0.0-</code>
                      &lt;$version&gt;
                      <code>/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode"
                      </code>
                    </p>
                    <p>
                      The NameNode will send an upgrade command to DataNodes after receiving block reports.
                    </p>
                  </li>
                  <li>
                    <p>Prepare the NameNode to work with Ambari:</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Open the Ambari Web GUI. If it has been open throughout the process, do a hard reset
                            on your browser to force a reload.
                          </p>
                        </li>
                        <li>
                          <p>On the Services view, click
                            <strong>HDFS</strong>
                            to open the HDFS service.
                          </p>
                        </li>
                        <li>
                          <p>Click
                            <strong>View Host</strong>
                            to open the NameNode host details page.
                          </p>
                        </li>
                        <li>
                          <p>Use the drop-down menu to stop the NameNode.</p>
                        </li>
                        <li>
                          <p>On the Services view, restart the HDFS service. Make sure it passes the Service
                            Check. It is now under Ambari's control.
                          </p>
                          <aside class="custom-note">
                            <div class="icon"><img src="Icons/Important.png" width="50"></div>
                            <div class="simple-block">
                              <ul class="number-list">
                                In a cluster configured for NameNode High Availability, use the following
                                  procedure to restart NameNodes. Using the following procedure preserves HA when
                                  upgrading the cluster.
                                
                                
                                  <li>
                                    <p>Using Ambari Web &gt; Services &gt; HDFS, choose Active NameNode.
                                    </p>
                                    <p>This shows the host name of the current, active NameNode.</p>
                                  </li>
                                  <li>
                                    <p>Write down (or copy, or remember) the host name of the active NameNode.
                                    </p>
                                    <p>You need this host name for step 4.</p>
                                  </li>
                                  <li>
                                    <p>Using Ambari Web &gt; Services &gt; HDFS &gt; Service Actions &gt; choose
                                      Stop.
                                    </p>
                                    <p>This stops all of the HDFS Components, including both NameNodes.
                                    </p>
                                  </li>
                                  <li>
                                    <p>Using Ambari Web &gt; Hosts &gt; choose the host name you noted in Step 2,
                                      then start that NameNode component, using Host Actions &gt; Start.
                                    </p>
                                    <p>This causes the original, active NameNode to re-assume its role as the
                                      active NameNode.
                                    </p>
                                  </li>
                                  <li>
                                    <p>Using Ambari Web &gt; Services &gt; HDFS &gt; Service Actions, choose
                                      Re-Start All.
                                    </p>
                                  </li>
                                
                              </ul>
                            </div>
                          </aside>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>After the DataNodes are started, HDFS exits safemode. To monitor the status, run the
                      following command:
                    </p>
                    <p>
                      <code>sudo su -l</code>
                      &lt;HDFS_USER&gt;
                      <code>-c "hdfs dfsadmin -safemode get"</code>
                    </p>
                    <p>
                      Depending on the size of your system, a response may not display for up to 10 minutes. When HDFS
                      exits safemode, the following message displays:
                    </p>
                    <p>
                      <code>Safe mode is OFF</code>
                    </p>
                  </li>
                  <li>
                    <p>Make sure that the HDFS upgrade was successful. Execute step 3 in
                      <a href="#ref-2d16d77f-9eb4-485f-a3f9-daeb558a4b6b">Preparing for the Upgrade</a>
                      to create new versions of the logs and reports. Substitute "
                      <code>new</code>
                      " for "
                      <code>old</code>
                      " in the file names as necessary.
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>Compare the old and new versions of the following:</p>
                          <ul class="Bullet">
                            
                              <li>
                                <p>
                                  <code>dfs-old-fsck-1.log</code>
                                  versus<code>dfs-new-fsck-1.log</code>.
                                </p>
                                <p>
                                  The files should be identical unless the hadoop fsck reporting format has changed in
                                  the new version.
                                </p>
                              </li>
                              <li>
                                <p>
                                  <code>dfs-old-lsr-1.log</code>
                                  versus<code>dfs-new-lsr-1.log</code>.
                                </p>
                                <p>
                                  The files should be identical unless the format of hadoop fs -lsr reporting or the
                                  data structures have changed in the new version.
                                </p>
                              </li>
                              <li>
                                <p>
                                  <code>dfs-old-report-1.log</code>
                                  versus<code>fs-new-report-1.log</code>.
                                </p>
                                <p>
                                  Make sure all DataNodes previously belonging to the cluster are up and running.
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Update the configuration properties required for HDFS. Using Ambari Web, navigate to
                      <code>Services &gt; HDFS &gt; Configs</code>
                      and add/modify the following configurations:
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>Change the io.compression.codecs property to:</p>
                          <p>
                            <code>
                              org.apache.hadoop.io.compress.GzipCodec,com.hadoop.compression.lzo.LzoCodec,org.apache.hadoop.io
                            </code>
                          </p>
                        </li>
                        <li>
                          <p>Add to core-site.xml, the following property:</p>
                          <p>
                            <code>&lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt;
                              &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Using
                      <code>Ambari Web</code>
                      &gt;
                      <code>Services</code>
                      &gt;<code>Service Actions</code>, start YARN.
                    </p>
                  </li>
                  <li>
                    <p>Using
                      <code>Ambari Web</code>
                      &gt;
                      <code>Services</code>
                      &gt;<code>Service Actions</code>, start MapReduce2.
                    </p>
                  </li>
                  <li>
                    <p>Upgrade HBase.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Make sure that all HBase components - RegionServers and HBase Master - are
                            stopped.
                          </p>
                        </li>
                        <li>
                          <p>Using
                            <code>Ambari Web</code>
                            &gt;<code>Services</code>, start the ZooKeeper service. Wait until the
                            ZK service is up and running.
                          </p>
                        </li>
                        <li>
                          <p>On the HBase Master host, make these configuration changes:</p>
                          <ul class="Numeric">
                            
                              <li>
                                <p>In<code>HBASE_CONFDIR/hbase-site.xml</code>, set the property
                                  <code>dfs.client.read.shortcircuit</code>
                                  to<code>false</code>.
                                </p>
                              </li>
                              <li>
                                <p>In the configuration file, find the value of the
                                  <code>hbase.tmp.dir</code>
                                  property and make sure that the directory exists and is readable and writeable for the
                                  HBase service user and group.
                                </p>
                                <p>
                                  <code>
                                    chown -R
                                    &lt;HBASE_USER&gt;:&lt;HADOOP_GROUP&gt;&lt;HBASE.TMP.DIR&gt;</code>
                                </p>
                              </li>
                              <li>
                                <p>Go to the Upgrade Folder and check in the saved global configuration file
                                  named
                                  <code>global_&lt;$TAG&gt;</code>
                                  for the value of the property
                                  <code>hbase_pid_dir</code>
                                  and<code>hbase_log_dir</code>. Make sure that the directories are readable
                                  and writeable for the HBase service user and group.
                                </p>
                                <p>
                                  <code>chown -R &lt;HBASE_USER&gt;:&lt;HADOOP_GROUP&gt;&lt;hbase_pid_dir&gt;
                                    chown -R
                                    &lt;HBASE_USER&gt;:&lt;HADOOP_GROUP&gt;&lt;hbase_log_dir&gt;</code>
                                </p>
                                <p>Do this on
                                  <strong>every</strong>
                                  host where a RegionServer is installed as well as on the HBase Master host.
                                </p>
                              </li>
                              <li>
                                <p>Check for HFiles in V1 format. HBase 0.96.0 discontinues support for HFileV1.
                                  Before the actual upgrade, run the following command to check if there are HFiles in
                                  V1 format:
                                  <code>hbase upgrade -check</code>
                                  HFileV1 was a common format prior to HBase 0.94. You may see output similar to:
                                </p>
                                <p>
                                  <code>Tables Processed:

                                    hdfs://localhost:41020/myHBase/.META.
                                    hdfs://localhost:41020/myHBase/usertable
                                    hdfs://localhost:41020/myHBase/TestTable
                                    hdfs://localhost:41020/myHBase/t

                                    Count of HFileV1: 2
                                    HFileV1:
                                    hdfs://localhost:41020/myHBase/usertable/fa02dac1f38d03577bd0f7e666f12812/family/249450144068442524
                                    hdfs://localhost:41020/myHBase/usertable/ecdd3eaee2d2fcf8184ac025555bb2af/family/249450144068442512

                                    Count of corrupted files: 1
                                    Corrupted Files:
                                    hdfs://localhost:41020/myHBase/usertable/fa02dac1f38d03577bd0f7e666f12812/family/1
                                    Count of Regions with HFileV1: 2
                                    Regions to Major Compact:
                                    hdfs://localhost:41020/myHBase/usertable/fa02dac1f38d03577bd0f7e666f12812
                                    hdfs://localhost:41020/myHBase/usertable/ecdd3eaee2d2fcf8184ac025555bb2af
                                  </code>
                                </p>
                                <p>
                                  When you run the upgrade check, if "Count of HFileV1" returns any files, start the
                                  hbase shell to use major compaction for regions that have HFileV1 format. For example
                                  in the sample output above, you must compact the
                                  <code>fa02dac1f38d03577bd0f7e666f12812</code>
                                  and
                                  <code>ecdd3eaee2d2fcf8184ac025555bb2af</code>
                                  regions.
                                </p>
                              </li>
                              <li>
                                <p>Upgrade HBase. As the HBase service user:</p>
                                <p>
                                  <code>
                                    su -l &lt;HBASE_USER&gt; -c "hbase upgrade -execute"
                                  </code>
                                </p>
                                <p>
                                  Make sure that the output contains the string "Successfully completed Znode upgrade".
                                </p>
                              </li>
                              <li>
                                <p>Use the Services view to start the HBase service. Make sure that Service Check
                                  passes.
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Upgrade Oozie.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Perform the following preparation steps on each oozie server host:</p>
                          <aside class="custom-note">
                            <div class="icon"><img src="Icons/Note.png" width="50"></div>
                            <div class="simple-block">
                              <p>You must replace your Oozie configuration after upgrading.</p>
                            </div>
                          </aside>
                          <ul class="Numeric">
                            
                              <li>
                                <p>Copy
                                  <code>/etc/oozie/conf</code>
                                  from the template to the<code>/conf</code>directory on
                                  each Oozie server and client.
                                </p>
                              </li>
                              <li>
                                <p>Create
                                  <code>/usr/lib/oozie/libext-upgrade22</code>
                                  directory.
                                </p>
                                <p>
                                  <code>
                                    mkdir /usr/lib/oozie/libext-upgrade22
                                  </code>
                                </p>
                              </li>
                              <li>
                                <p>Copy the JDBC jar of your Oozie database to both
                                  <code>/usr/lib/oozie/libext-upgrade22</code>
                                  and<code>/usr/lib/oozie/libtools</code>.
                                </p>
                                <p>
                                  For example, if you are using MySQL, copy your<code>
                                  mysql-connector-java.jar</code>.
                                </p>
                              </li>
                              <li>
                                <p>Copy these files to
                                  <code>/usr/lib/oozie/libext-upgrade22</code>
                                  directory
                                </p>
                                <p>
                                  <code>cp /usr/lib/hadoop/lib/hadoop-lzo*.jar
                                    /usr/lib/oozie/libext-upgrade22
                                  </code>
                                </p>
                                <p>
                                  <code>cp /usr/share/HDP-oozie/ext-2.2.zip /usr/lib/oozie/libext-upgrade22
                                  </code>
                                </p>
                              </li>
                              <li>
                                <p>Grant read/write access to the Oozie user.</p>
                                <p>
                                  <code>chmod -R 777 /usr/lib/oozie/libext-upgrade22</code>
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                        <li>
                          <p>Upgrade steps:</p>
                          <ul class="Numeric">
                            
                              <li>
                                <p>On the Services view, make sure YARN and MapReduce2 are running.</p>
                              </li>
                              <li>
                                <p>Make sure that the Oozie service is stopped.</p>
                              </li>
                              <li>
                                <p>Upgrade Oozie. On the Oozie server host, as the Oozie service user:</p>
                                <p>
                                  <code>su -l</code>
                                  &lt;OOZIE_USER&gt;
                                  <code>-c "/usr/lib/oozie/bin/ooziedb.sh upgrade -run"</code>
                                </p>
                                <p>
                                  Make sure that the output contains the string "Oozie DB has been upgraded to Oozie
                                  version&lt;OOZIE_build_version&gt;.
                                </p>
                              </li>
                              <li>
                                <p>Prepare the Oozie WAR file.</p>
                                <aside class="custom-note">
                                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                                  <div class="simple-block">
                                    <p>The Oozie server must be
                                      <strong>not</strong>
                                      running for this step. If the message "ERROR: Stop Oozie first" displays, find and
                                      remove the process id (pid) file listed in the output. This prevent the script
                                      from "seeing" the (old) Oozie server process.
                                    </p>
                                  </div>
                                </aside>
                                <p>
                                  As the root user:
                                  <code>sudo su -l</code>
                                  &lt;OOZIE_USER&gt;
                                  <code>-c "/usr/lib/oozie/bin/oozie-setup.sh prepare-war -d
                                    /usr/lib/oozie/libext-upgrade22"
                                  </code>
                                </p>
                                <p>
                                  Make sure that the output contains the string "New Oozie WAR file added".
                                </p>
                              </li>
                              <li>
                                <p>Using Ambari Web UI
                                  <code>Services</code>
                                  &gt;
                                  <code>Oozie</code>
                                  &gt;<code>Configs</code>, edit the following configuration
                                  properties:
                                </p>
                                <ul class="Numeric">
                                  
                                    <li>
                                      <p>Add the following configuration properties in<code>
                                        oozie-site.xml</code>.
                                      </p>
                                      <div class="xyleme-table"><table border="1">
                                        
                                          
                                          
                                          
                                          <thead>
                                            <tr>
                                              <th rowspan="1">
                                                <p>Action</p>
                                              </th>
                                              <th rowspan="1">
                                                <p>Property Name</p>
                                              </th>
                                              <th rowspan="1">
                                                <p>Property Value</p>
                                              </th>
                                            </tr>
                                          </thead>
                                          <tbody>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>oozie.service.URIHandlerService.uri.handlers</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>
                                                  org.apache.oozie.dependency.FSURIHandler,org.apache.oozie.dependency.HCatURIHandler
                                                </p>
                                              </td>
                                            </tr>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>oozie.service.coord.push.check.requeue.interval</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>30000</p>
                                              </td>
                                            </tr>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>oozie.services</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>org.apache.oozie.service.SchedulerService,
                                                  org.apache.oozie.service.InstrumentationService,
                                                  org.apache.oozie.service.CallableQueueService,
                                                  org.apache.oozie.service.UUIDService,
                                                  org.apache.oozie.service.ELService,
                                                  org.apache.oozie.service.AuthorizationService,
                                                  org.apache.oozie.service.UserGroupInformationService,
                                                  org.apache.oozie.service.HadoopAccessorService,
                                                  org.apache.oozie.service.URIHandlerService,
                                                  org.apache.oozie.service.MemoryLocksService,
                                                  org.apache.oozie.service.DagXLogInfoService,
                                                  org.apache.oozie.service.SchemaService,
                                                  org.apache.oozie.service.LiteWorkflowAppService,
                                                  org.apache.oozie.service.JPAService,
                                                  org.apache.oozie.service.StoreService,
                                                  org.apache.oozie.service.CoordinatorStoreService,
                                                  org.apache.oozie.service.SLAStoreService,
                                                  org.apache.oozie.service.DBLiteWorkflowStoreService,
                                                  org.apache.oozie.service.CallbackService,
                                                  org.apache.oozie.service.ActionService,
                                                  org.apache.oozie.service.ActionCheckerService,
                                                  org.apache.oozie.service.RecoveryService,
                                                  org.apache.oozie.service.PurgeService,
                                                  org.apache.oozie.service.CoordinatorEngineService,
                                                  org.apache.oozie.service.BundleEngineService,
                                                  org.apache.oozie.service.DagEngineService,
                                                  org.apache.oozie.service.CoordMaterializeTriggerService,
                                                  org.apache.oozie.service.StatusTransitService,
                                                  org.apache.oozie.service.PauseTransitService,
                                                  org.apache.oozie.service.GroupsService,
                                                  org.apache.oozie.service.ProxyUserService,org.apache.oozie.service.XLogStreamingService,org.apache.oozie.service.JobsConcurrencyService
                                                </p>
                                              </td>
                                            </tr>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>oozie.services.ext</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>
                                                  org.apache.oozie.service.PartitionDependencyManagerService,org.apache.oozie.service.HCatAccessorService
                                                </p>
                                              </td>
                                            </tr>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>oozie.service.SchemaService.wf.ext.schemas</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>
                                                  shell-action-0.1.xsd,shell-action-0.2.xsd,shell-action-0.3.xsd,email-action-0.1.xsd,email-action-0.2.xsd,hive-action-0.2.xsd,hive-action-0.3.xsd,hive-action-0.4.xsd,hive-action-0.5.xsd,sqoop-action-0.2.xsd,sqoop-actio
                                                </p>
                                              </td>
                                            </tr>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>oozie.service.coord.check.maximum.frequency</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>false</p>
                                              </td>
                                            </tr>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>oozie.service.AuthorizationService.security.enabled</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>false</p>
                                              </td>
                                            </tr>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>oozie.service.HadoopAccessorService.kerberos.enabled
                                                </p>
                                              </td>
                                              <td rowspan="1">
                                                <p>false</p>
                                              </td>
                                            </tr>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>oozie.authentication.simple.anonymous.allowed</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>true</p>
                                              </td>
                                            </tr>
                                            <tr>
                                              <td rowspan="1">
                                                <p>Add</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>log4j.appender.oozie.layout.ConversionPattern</p>
                                              </td>
                                              <td rowspan="1">
                                                <p>%d{ISO8601} %5p %c{1}:%L - SERVER[${oozie.instance.id}] %m%n
                                                </p>
                                              </td>
                                            </tr>
                                          </tbody>
                                          
                                        
                                        Oozie-site.xml - Properties to Add
                                      </table></div>
                                      <aside class="custom-note">
                                        <div class="icon"><img src="Icons/Note.png" width="50"></div>
                                        <div class="simple-block">
                                          <p>Do not delete existing values from each property values list. IF you
                                            have customized schema or property values, make sure the customized values
                                            appear on Configs. Values in each property value list must be separated by
                                            commas, no spaces.
                                          </p>
                                        </div>
                                      </aside>
                                    </li>
                                    <li>
                                      <p>After modifying all properties on the Oozie Configs page, choose
                                        <code>Save</code>
                                        to update<code>oozie.site.xml</code>, using the modified
                                        configurations.
                                      </p>
                                    </li>
                                  
                                </ul>
                              </li>
                              <li>
                                <p>Replace the content of
                                  <code>/usr/oozie/share</code>
                                  in HDFS. On the Oozie server host:
                                </p>
                                <ul class="Numeric">
                                  
                                    <li>
                                      <p>Extract the Oozie sharelib into a
                                        <code>tmp</code>
                                        folder.
                                      </p>
                                      <p>
                                        <code>mkdir -p /tmp/oozie_tmp
                                          cp /usr/lib/oozie/oozie-sharelib.tar.gz /tmp/oozie_tmp
                                          cd /tmp/oozie_tmp
                                          tar xzvf oozie-sharelib.tar.gz
                                        </code>
                                      </p>
                                    </li>
                                    <li>
                                      <p>Back up the
                                        <code>/user/oozie/share</code>
                                        folder in HDFS and then delete it. If you have any custom files in this folder
                                        back them up separately and then add them back after the share folder is
                                        updated.
                                      </p>
                                      <p>
                                        <code>mkdir /tmp/oozie_tmp/oozie_share_backup
                                          chmod 777 /tmp/oozie_tmp/oozie_share_backup
                                        </code>
                                      </p>
                                      <p>
                                        As the Oozie user,

                                        <code>su -l</code>
                                        &lt;HDFS_USER&gt;
                                        <code>-c "hdfs dfs -copyToLocal /user/oozie/share
                                          /tmp/oozie_tmp/oozie_share_backup"
                                          su -l
                                        </code>
                                        &lt;HDFS_USER&gt;
                                        <code>-c "hdfs dfs -rm -r /user/oozie/share"</code>
                                      </p>
                                    </li>
                                    <li>
                                      <p>Add the latest share libs that you extracted in step 1. After you have
                                        added the files, modify ownership and acl.
                                      </p>
                                      <p>
                                        <code>
                                          su -l
                                        </code>
                                        &lt;HDFS_USER&gt;
                                        <code>-c "hdfs dfs -copyFromLocal /tmp/oozie_tmp/share /user/oozie/."
                                          su -l
                                        </code>
                                        &lt;HDFS_USER&gt; 
                                        <code>-c "hdfs dfs -chown -R &lt;OOZIE_USER&gt;:&lt;HADOOP_GROUP&gt;
                                          /user/oozie"
                                          su -l
                                        </code>
                                        &lt;HDFS_USER&gt;
                                        <code>-c "hdfs dfs -chmod -R 755 /user/oozie"</code>
                                      </p>
                                    </li>
                                  
                                </ul>
                              </li>
                              <li>
                                <p>Use the Services view to start the Oozie service. Make sure that ServiceCheck
                                  passes for Oozie.
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Update WebHCat.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Modify the
                            <code>webhcat-site</code>
                            config type.
                          </p>
                          <p>
                            Using the Ambari web UI, navigate to
                            <code>Services</code>
                            &gt;
                            <code>WebHCat</code>
                            and modify the following configuration:
                          </p>
                          <div class="xyleme-table"><table border="1">
                            
                              
                              
                              
                              <thead>
                                <tr>
                                  <th rowspan="1">
                                    <p>Action</p>
                                  </th>
                                  <th rowspan="1">
                                    <p>Property Name</p>
                                  </th>
                                  <th rowspan="1">
                                    <p>Property Value</p>
                                  </th>
                                </tr>
                              </thead>
                              <tbody>
                                <tr>
                                  <td rowspan="1">
                                    <p>Modify</p>
                                  </td>
                                  <td rowspan="1">
                                    <p>templeton.storage.class</p>
                                  </td>
                                  <td rowspan="1">
                                    <p>org.apache.hive.hcatalog.templeton.tool.ZooKeeperStorage</p>
                                  </td>
                                </tr>
                              </tbody>
                              
                            
                            WebHCat Properties to Modify
                          </table></div>
                        </li>
                        <li>
                          <p>On each WebHCat host, update the Pig and Hive tar bundles, by updating the following
                            files:
                          </p>
                          <ul class="Bullet">
                            
                              <li>
                                <p>
                                  <code>/apps/webhcat/pig.tar.gz</code>
                                </p>
                              </li>
                              <li>
                                <p>
                                  <code>/apps/webhcat/hive.tar.gz</code>
                                </p>
                                <aside class="custom-note">
                                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                                  <div class="simple-block">
                                    <p>You will find these files only on a host where webhcat is installed.
                                    </p>
                                  </div>
                                </aside>
                              </li>
                            
                          </ul>
                          <p>
                            For example, to update a *.tar.gz file:
                          </p>
                          <ul class="Numeric">
                            
                              <li>
                                <p>Move the file to a local directory. As the WebHCat user,</p>
                                <p>
                                  <code>su -l</code>
                                  &lt;HCAT_USER&gt;
                                  <code>-c "hadoop --config /etc/hadoop/conf fs -copyToLocal
                                    /apps/webhcat/*.tar.gz $&lt;local_backup_dir&gt;"
                                  </code>
                                </p>
                              </li>
                              <li>
                                <p>Remove the old file.</p>
                                <p>
                                  <code>su -l</code>
                                  &lt;HCAT_USER&gt;
                                  <code>-c "hadoop --config /etc/hadoop/conf fs -rm /apps/webhcat/*.tar.gz"
                                  </code>
                                </p>
                              </li>
                              <li>
                                <p>Copy the new file.</p>
                                <p>
                                  <code>su -l</code>
                                  &lt;HCAT_USER&gt;
                                  <code>-c "hdfs --config /etc/hadoop/conf dfs -copyFromLocal
                                    /usr/share/HDP-webhcat/*.tar.gz /apps/webhcat/"
                                  </code>
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                        <li>
                          <p>On each WebHCat host, update
                            <code>/app/webhcat/hadoop-streaming.jar</code>
                            file.
                          </p>
                          <ul class="Numeric">
                            
                              <li>
                                <p>Move the file to a local directory.</p>
                                <p>
                                  <code>
                                    su -l
                                  </code>
                                  &lt;HCAT_USER&gt;
                                  <code>-c "hadoop --config /etc/hadoop/conf fs -copyToLocal
                                    /apps/webhcat/hadoop-streaming*.jar $&lt;local_backup_dir&gt;"
                                  </code>
                                </p>
                              </li>
                              <li>
                                <p>Remove the old file.</p>
                                <p>
                                  <code>
                                    su -l
                                  </code>
                                  &lt;HCAT_USER&gt;
                                  <code>-c "hadoop --config /etc/hadoop/conf fs -rm
                                    /apps/webhcat/hadoop-streaming*.jar"
                                  </code>
                                </p>
                              </li>
                              <li>
                                <p>Copy the new hadoop-streaming.jar file.</p>
                                <p>
                                  <code>su -l</code>
                                  &lt;HCAT_USER&gt;
                                  <code>-c "hdfs --config /etc/hadoop/conf dfs -copyFromLocal
                                    /usr/lib/hadoop-mapreduce/hadoop-streaming*.jar /apps/webhcat"
                                  </code>
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Make sure Ganglia no longer attempts to monitor JobTracker.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Make sure Ganglia is stopped.</p>
                        </li>
                        <li>
                          <p>Log into the host where JobTracker was installed (and where ResourceManager is
                            installed after the upgrade).
                          </p>
                        </li>
                        <li>
                          <p>Backup the folder<code>/etc/ganglia/hdp/HDPJobTracker</code>.
                          </p>
                        </li>
                        <li>
                          <p>Remove the folder<code>/etc/ganglia/hdp/HDPJobTracker</code>.
                          </p>
                        </li>
                        <li>
                          <p>Remove the folder<code>$ganglia_runtime_dir/HDPJobTracker</code>.
                          </p>
                          <aside class="custom-note">
                            <div class="icon"><img src="Icons/Note.png" width="50"></div>
                            <div class="simple-block">
                              <p>For the value of<code>$ganglia_runtime_dir</code>, in the Upgrade
                                Folder, check the saved global configuration file<code>
                                  global_&lt;$TAG&gt;</code>.
                              </p>
                            </div>
                          </aside>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Use the Services view to start the remaining services back up.</p>
                  </li>
                  <li>
                    <p>The upgrade is now fully functional but not yet finalized. Using the
                      <code>finalize</code>
                      command removes the previous version of the NameNode and DataNode storage directories.
                    </p>
                    <p>
                      After the upgrade is finalized, the system cannot be rolled back. Usually this step is not taken
                      until a thorough testing of the upgrade has been performed.
                    </p>
                    <p>
                      The upgrade must be finalized before another upgrade can be performed.
                    </p>
                    <aside class="custom-note">
                      <div class="icon"><img src="Icons/Note.png" width="50"></div>
                      <div class="simple-block">
                        <p>Directories used by Hadoop 1 services set in /etc/hadoop/conf/taskcontroller.cfg are
                          not automatically deleted after upgrade. Administrators can choose to delete these directories
                          after the upgrade.
                        </p>
                      </div>
                    </aside>
                    <p>
                      To finalize the upgrade, execute the following command once, on the primary NamaNode host in your
                      HDP cluster, as the HDFS User:
                      <code>sudo su -l</code>
                      &lt;HDFS_USER&gt;
                      <code>-c "hadoop dfsadmin -finalizeUpgrade"</code>
                      where
                      &lt;HDFS_USER&gt;
                      is the HDFS Service user (by default,<code>hdfs</code>).
                    </p>
                  </li>
                
              </ul>
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-d7fe46ad-eac3-4a84-aed4-a26b902a9b27">Upgrading host server operating systems in an Ambari-managed Hadoop System</h3>
        
          <p>Ambari requires specific versions of the files for components that it uses. There are three steps
            you should take to make sure that these versions continue to be available:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>Disable automatic OS updates</p>
              </li>
              <li>
                <p>Do not update any HDP components such as MySQL, Ganglia, etc.</p>
              </li>
              <li>
                <p>If you must perform an OS update, do a manual kernel update only.</p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-3a224c6c-b15e-4318-b71e-68db9103ec5d">Upgrading an older Ambari Server version to 1.2.5</h3>
        
          <p>This 12-step, manual procedure upgrades an Ambari Server from an older, 1.x version to version
            1.2.5. Upgrading the Ambari Server version does not change the underlying Hadoop Stack version.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>You must know the location of the Nagios server for Step 9. Use the
                <code>Services View &gt; Summary</code>
                panel to locate the host on which the Nagios server is running.
              </p>
            </div>
          </aside>
          <ul class="number-list">
            
              <li>
                <p>Stop the Ambari Server and all Ambari Agents.</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>On the Ambari Server host:</p>
                      <p>
                        <code>ambari-server stop</code>
                      </p>
                    </li>
                    <li>
                      <p>On each Ambari Agent host:</p>
                      <p>
                        <code>ambari-agent stop</code>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Get the new Ambari bits.</p>
                <p>Using wget, fetch the repository file, then replace the old repository file with the new
                  repository file on every host.
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>Check your current directory before you download the new repository file to make sure that
                      no previous versions of the file exist. If a previous version exists, the new downloaded file will
                      be saved with a numeric extension such as ambari.repo.1. Make sure that the version you copy is
                      the new version.
                    </p>
                  </div>
                </aside>
                <ul class="Numeric">
                  
                    <li>
                      <p>Fetch the new repository file:</p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>For RHEL/CentOS 5/Oracle Linux 5:</p>
                            <p>
                              <code>wget
                                http://public-repo-1.hortonworks.com/ambari/centos5/1.x/updates/1.2.5.17/ambari.repo
                              </code>
                            </p>
                          </li>
                          <li>
                            <p>For RHEL/CentOS 6/Oracle Linux 6:</p>
                            <p>
                              <code>wget
                                http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.2.5.17/ambari.repo
                              </code>
                            </p>
                          </li>
                          <li>
                            <p>For SLES 11:</p>
                            <p>
                              <code>wget
                                http://public-repo-1.hortonworks.com/ambari/suse11/1.x/updates/1.2.5.17/ambari.repo
                              </code>
                            </p>
                          </li>
                        
                      </ul>
                    </li>
                    <li>
                      <p>Replace the old repository file with the new repository file.</p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>For RHEL/CentOS 5/Oracle Linux 5:</p>
                            <p>
                              <code>cp ambari.repo /etc/yum.repos.d/ambari.repo</code>
                            </p>
                          </li>
                          <li>
                            <p>For RHEL/CentOS 6/Oracle Linux 6:</p>
                            <p>
                              <code>cp ambari.repo /etc/yum.repos.d/ambari.repo</code>
                            </p>
                          </li>
                          <li>
                            <p>For SLES 11:</p>
                            <p>
                              <code>cp ambari.repo /etc/zypp/repos.d/ambari.repo</code>
                            </p>
                          </li>
                        
                      </ul>
                    </li>
                  
                </ul>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>If your cluster does not have access to the Internet, set up a local repository with this
                      data before you continue. See
                      <a href="#ref-28d7e1f2-0adb-436a-a4b1-65b522fdcdf2">Configure the Local Repositories
                      </a>
                      for more information.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Upgrade Ambari Server.</p>
                <p>On the Ambari Server host:</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>For RHEL/CentOS/Oracle Linux:</p>
                      <p>
                        <code>yum clean all
                          yum upgrade ambari-server-1.2.5.17 ambari-log4j-1.2.5.17
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>For SLES:</p>
                      <p>
                        <code>zypper clean
                          zypper up ambari-server-1.2.5.17 ambari-log4j-1.2.5.17
                        </code>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Check for upgrade success.</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>As the process runs, the console should produce output similar, although not identical,
                        to the following text:
                      </p>
                      <pre><code>Setting up Upgrade Process
                        Resolving Dependencies
                        --&gt; Running transaction check
                        ---&gt; Package ambari-agent.x86_64 0:1.2.2.3-1 will be updated
                        ---&gt; Package ambari-agent.x86_64 0:1.2.2.4-1 will be updated ...
                        ---&gt; Package ambari-agent.x86_64 0:1.2.2.5-1 will be an update ...
                      </code></pre>
                      <p>After the process is complete, check each host to make sure the new 1.2.4 files have
                        been installed.
                      </p>
                      <p>
                        <code>rpm -qa | grep ambari</code>
                      </p>
                    </li>
                    <li>
                      <p>If the upgrade fails, the console displays output similar to the following text:
                      </p>
                      <pre><code>Setting up Upgrade Process
                        No Packages marked for Update
                      </code></pre>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>On the Ambari Server host, check for a folder named<code>
                  /etc/ambari-server/conf.save</code>. If such a folder exists, rename it, using the following
                  command:
                </p>
                <p>
                  <code>mv /etc/ambari-server/conf.save /etc/ambari-server/conf</code>
                </p>
              </li>
              <li>
                <p>Upgrade the Ambari Server schema.</p>
                <p>On the Ambari Server host:
                  <code>
                    ambari-server upgrade
                  </code>
                </p>
              </li>
              <li>
                <p>Upgrade the Ambari Agent on all hosts.</p>
                <p>On each Ambari Agent host:</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>For RHEL/CentOS/Oracle Linux</p>
                      <p>
                        <code>yum upgrade ambari-agent ambari-log4j</code>
                      </p>
                    </li>
                    <li>
                      <p>For SLES</p>
                      <p>
                        <code>zypper up ambari-agent ambari-log4j</code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Note.png" width="50"></div>
                        <div class="simple-block">
                          <p>If a warning such as the following, "There are some running programs that use files
                            deleted by recent upgrade" appears, ignore it.
                          </p>
                        </div>
                      </aside>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>On each Agent host, check for a folder named<code>
                  /etc/ambari-agent/conf.save</code>. If such a folder exists, rename it, using the following
                  command:
                </p>
                <p>
                  <code>mv /etc/ambari-agent/conf.save /etc/ambari-agent/conf</code>
                </p>
              </li>
              <li>
                <p>Upgrade the Nagios and Ganglia add-ons package and restart.</p>
                <p>On the Nagios/Ganglia hosts:</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>For RHEL/CentOS/Oracle Linux:</p>
                      <p>
                        <code>yum upgrade hdp_mon_nagios_addons hdp_mon_ganglia_addons
                          service httpd restart
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>For SLES:</p>
                      <p>
                        <code>zypper up hdp_mon_nagios_addons hdp_mon_ganglia_addons
                          service apache2 restart
                        </code>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Start the Ambari Server and all Ambari Agents.</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>On the Ambari Server host:</p>
                      <p>
                        <code>ambari-server start</code>
                      </p>
                    </li>
                    <li>
                      <p>On each Ambari Agent host:</p>
                      <p>
                        <code>ambari-agent start</code>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Open<code>Ambari Web</code>. Point your browser to
                  <code>http://</code>
                  &lt;your.ambari.server&gt;
                  <code>:8080</code>
                </p>
                <p>Refresh your browser so that it loads the new version of the code. Hold the Shift key down
                  while clicking the refresh button on the browser. If you have problems, clear your browser cache
                  manually, then restart Ambari Server. Use the Ambari Admin name and password you have set up to log
                  in.
                </p>
              </li>
              <li>
                <p>Re-start the Ganglia, Nagios, and MapReduce services.</p>
                <p>In Ambari Web:</p>
                <ul class="Numeric">
                  
                    <li>
                      <p>Go to Services View, then choose each service.</p>
                    </li>
                    <li>
                      <p>Stop, then re-start each service, using the Management Header.</p>
                    </li>
                  
                </ul>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-c8dfb50f-1c9a-4028-96f8-5c2da4562b41">Troubleshooting an Ambari Server 1.x Upgrade</h3>
        
          <p>If upgrading Ambari Server 1.x fails, use the instructions in one of the following sections to fix
            the failed upgrade.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-4f73c195-4d9c-49be-8f27-6e62df06158f">Upgrade Failure with PostgreSQL</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-41c7d088-dfe4-489c-abe0-da71952d982e">Upgrade Failure with Oracle</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-072f8eea-b064-4950-a53e-311d36ee40c0">Upgrade Failure from a Local Repository
                  </a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Upgrade Failure with PostgreSQL</h4>
          
            <p>If you installed Ambari server with a PostgreSQL database and upgrading Ambari Server using a
              remote or public repository failed, use the following steps to fix the upgrade.
            </p>
            <ul class="number-list">
              
                <li>
                  <p>Upgrade the database schema.</p>
                  <p>
                    <code>/var/lib/ambari-server/resources/upgrade/ddl/AmbariRCA-DDL-Postgres-UPGRADE.sql
                    </code>
                  </p>
                </li>
                <li>
                  <p>Check database consistency.</p>
                  <p>
                    <code>
                      /var/lib/ambari-server/resources/upgrade/ddl/Ambari-DDL-Postgres-UPGRADE-1.3.0.Check.sql
                    </code>
                    with the following parameter:
                    <code>dbname = ambari</code>
                  </p>
                </li>
                <li>
                  <p>If you find an inconsistency, fix it using:</p>
                  <p>
                    <code>
                      /var/lib/ambari-server/resources/upgrade/ddl/Ambari-DDL-Postgres-UPGRADE-1.3.0.Fix.sql
                    </code>
                    with the following parameter:
                    <code>dbname = ambari</code>
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Upgrade Failure with Oracle</h4>
          
            <p>If you installed Ambari server with an Oracle database and upgrading Ambari Server using a remote
              or public repository failed, run the following script to upgrade the database schema.
              <code>
                /var/lib/ambari-server/resources/upgrade/ddl/AmbariRCA-DDL-Oracle-UPGRADE.sql
              </code>
            </p>
          
        
        
          <h4 class="bold">Upgrade Failure from a Local Repository</h4>
          
            <p>If you install and upgrade Ambari server using a local repository and upgrading Ambari Server
              using your local repository failed, find information necessary to fix the upgrade in the following
              locations:
            </p>
            <ul class="number-list">
              
                <li>
                  <p>Check for local repository version customized in<code>
                    /var/lib/ambari-server/resources/stacks/HDPLocal</code>.
                  </p>
                </li>
                <li>
                  <p>Check for the repository version used when creating the cluster, in<code>
                    repos/repoinfo.xml</code>.
                  </p>
                </li>
                <li>
                  <p>If local repository version is NOT the same as the NON-LOCAL repository version: Note the
                    os, version, repoid and baseurl, found in<code>repos/repoinfo.xml</code>.
                  </p>
                </li>
              
            </ul>
            <p>Then, choose the fix appropriate for your database version.</p>
            <ul class="bullet-list">
              
                <li>
                  <p>
                    <a href="#ref-4f73c195-4d9c-49be-8f27-6e62df06158f">PostgreSQL</a>
                  </p>
                </li>
                <li>
                  <p>
                    <a href="#ref-41c7d088-dfe4-489c-abe0-da71952d982e">Oracle</a>
                  </p>
                </li>
              
            </ul>
          
          
            <h4 class="bold">Ambari Server with PostgreSQL</h4>
            
              <p>To fix a local Ambari/PostgreSQL upgrade:</p>
              <ul class="number-list">
                
                  <li>
                    <p>Repair metadata information.</p>
                    <p>
                      <code>
                        /var/lib/ambari-server/resources/upgrade/dml/Ambari-DML-Postgres-INSERT_METAINFO.sql
                      </code>
                      with the following parameters:
                      <code>dbname = ambari
                        metainfo_key = repo:/HDP/
                      </code>
                      &lt;version&gt;
                      <code>/</code>
                      &lt;os&gt;
                      <code>/</code>
                      &lt;repoid&gt;
                      <code>:baseurl
                        metainfo_value =
                      </code>
                      &lt;baseurl&gt;
                    </p>
                  </li>
                  <li>
                    <p>Run the fix script.</p>
                    <p>
                      <code>
                        /var/lib/ambari-server/resources/upgrade/dml/Ambari-DML-Postgres-UPGRADE_STACK.sql
                      </code>
                      with the following parameters:
                      <code>dbname = ambari</code>
                    </p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Ambari Server with Oracle</h4>
            
              <p>To fix a local Ambari/PostgreSQL upgrade:</p>
              <ul class="number-list">
                
                  <li>
                    <p>Repair metadata information.</p>
                    <p>
                      <code>
                        /var/lib/ambari-server/resources/upgrade/dml/Ambari-DML-Oracle-INSERT_METAINFO.sql
                      </code>
                      with the following parameters:
                      <code>argument #1 = repo:/HDP/</code>
                      &lt;version&gt;
                      <code>/</code>
                      &lt;os&gt;
                      <code>/</code>
                      &lt;repoid&gt;
                      <code>:baseurl
                        argument #2 =
                      </code>
                      &lt;baseurl&gt;
                    </p>
                  </li>
                  <li>
                    <p>Run the fix script.</p>
                    <p>
                      <code>/var/lib/ambari-server/resources/upgrade/dml/Ambari-DML-Oracle-UPGRADE_STACK.sql
                      </code>
                    </p>
                  </li>
                
              </ul>
            
          
        
      
    
    
      <h2 class="horton-green bold">Administering Ambari</h2>
      
        
          <p>Apache Ambari is a system to help you provision, manage and monitor Hadoop clusters. This guide is
            intended for Cluster Operators and System Administrators responsible for installing and maintaining Ambari
            and the Hadoop clusters managed by Ambari. Installing Ambari creates a default user with "Admin Admin"
            privilege, with the following username/password:<code>admin/admin</code>.

            When you sign into Ambari as Ambari Admin, you can:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>Perform
                  <a href="#ref-5bc067b8-60d3-4360-a26c-3ffd680fa12b">Ambari Admin Tasks</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-c012fd89-584c-4539-a618-f0f8e6b45302">Create and Manage a Cluster</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-b61c95af-59c7-4714-8745-eabbbd3056c2">Manage Users and Groups</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-79e76a9f-830b-4acb-8f3b-3a0ada9484cf">Manage Views</a>
                </p>
              </li>
            
          </ul>
        
        
          <p>For specific information about provisioning an HDP cluster, see<a href="#ref-eb879df1-7042-4733-9221-4f2a7035d3e3">Install, Configure, and Deploy an HDP
            Cluster</a>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-5d8a4057-8871-4b0b-bffc-5ad0f6a654d6">Terms and Definitions</h3>
        
          <p>The following basic terms help describe the key concepts associated with Ambari Administration.
          </p>
          <div class="xyleme-table"><table border="1">
            
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>Term</p>
                  </th>
                  <th rowspan="1">
                    <p>Definition</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>Ambari Admin</p>
                  </td>
                  <td rowspan="1">
                    <p>Specific privilege granted to a user that enables the user to administer Ambari. The
                      default user
                      <code>admin</code>
                      created by Ambari is flagged as an “Ambari Admin”. Users with the Ambari Admin privilege can
                      grant, or revoke this privilege on other users.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Account</p>
                  </td>
                  <td rowspan="1">
                    <p>User name, password and privileges.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>User</p>
                  </td>
                  <td rowspan="1">
                    <p>Unique user in Ambari.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>User Type</p>
                  </td>
                  <td rowspan="1">
                    <p>Local and LDAP. Local users are maintained in the Ambari database and authentication is
                      performed against the Ambari database. LDAP users are imported (and synchronized) with an external
                      LDAP (if configured).
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Group</p>
                  </td>
                  <td rowspan="1">
                    <p>Unique group of users in Ambari.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Group Type</p>
                  </td>
                  <td rowspan="1">
                    <p>Local and LDAP. Local groups are maintained in the Ambari database. LDAP groups are
                      imported (and synchronized) with an external LDAP (if configured).
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Principal</p>
                  </td>
                  <td rowspan="1">
                    <p>User or group that can be authenticated by Ambari.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Cluster</p>
                  </td>
                  <td rowspan="1">
                    <p>Installation of a Hadoop cluster, based on a particular Stack, that is managed by
                      Ambari.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View</p>
                  </td>
                  <td rowspan="1">
                    <p>Defines a user interface component that is available to Ambari.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Resource</p>
                  </td>
                  <td rowspan="1">
                    <p>Represents the resource available and managed in Ambari. Ambari supports two types of
                      resources: cluster and view. An Ambari Admin assigns permissions for a resource for users and
                      groups.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Permissions</p>
                  </td>
                  <td rowspan="1">
                    <p>Represents the permission that can be granted to a principal (user or group) on a
                      particular resource.
                      For example, cluster resources support Operator and Read-Only permissions.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Privilege</p>
                  </td>
                  <td rowspan="1">
                    <p>Represents the mapping of a principal to a permission and a resource.
                      For example: the user
                      <code>admin</code>
                      is granted the permission Operator on cluster DevCluster.
                    </p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
        
      
      
        <h3 class="horton-blue bold" id="ref-84778cff-dd62-493a-90f9-13e1b37175a8">Logging in to Ambari</h3>
        
          <p>After installing Ambari, you can log in to Ambari as follows:</p>
          <ul class="number-list">
            
              <li>
                <p>Enter the following URL in a web browser:</p>
                <p>
                  <code>http://</code>
                  &lt;your.ambari.server&gt;
                  <code>:8080
                  </code>where
                  &lt;your.ambari.server&gt;
                  is the hostname for your Ambari server machine and
                  <code>8080</code>
                  is the default HTTP port.
                </p>
              </li>
              <li>
                <p>Enter the user account credentials for the default administrative user automatically created
                  during install:
                </p>
                <p>
                  <code>username/password = admin/admin</code>
                </p>
              </li>
              <li>
                <p>The
                  <a href="#ref-87a0227f-6727-47a8-a8f8-a28739ddf5ef">Ambari Administration</a>
                  web page displays. From this page you can<a href="#ref-b61c95af-59c7-4714-8745-eabbbd3056c2">
                    Manage Users and Groups</a>,<a href="#ref-80dcc1b2-6764-40e3-ae79-cd4e64c65530">Manage
                    Views</a>, and<a href="#ref-c012fd89-584c-4539-a618-f0f8e6b45302">Create a
                    Cluster</a>.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-87a0227f-6727-47a8-a8f8-a28739ddf5ef">About the Ambari Administration Interface</h3>
        
          <p>When you log in to the Ambari Administration interface with "Ambari Admin" privilege, a landing page
            displays links to the operations available. Plus, the operations are available from the left menu areas for
            clusters, views, users, and groups.
          </p>
          <div class="figure">
            
              
                
                <img src="System%20Admin%20Guides/Ambari/170_Ambari_Admin_page.png" width="50">
              
            
          </div>
        
        
          <ul class="bullet-list">
            
              <li>
                <p>Clusters displays a link to a cluster (if created) and links to manage access permissions for
                  that cluster.
                  See
                  <a href="#ref-c012fd89-584c-4539-a618-f0f8e6b45302">Creating and Managing a Cluster</a>
                  for more information.
                </p>
              </li>
              <li>
                <p>User and Group Management provides the ability create and edit users and groups.
                  See
                  <a href="#ref-b61c95af-59c7-4714-8745-eabbbd3056c2">Managing Users and Groups</a>
                  for more information.
                </p>
              </li>
              <li>
                <p>Views lets you to create and edit instances of deployed Views and manage access permissions
                  for those instances.
                  See
                  <a href="#ref-80dcc1b2-6764-40e3-ae79-cd4e64c65530">Managing Views</a>
                  for more information.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-5d62f7b0-7c24-404c-ba12-95b8a58fdc59">Changing the Administrator Account Password</h3>
        
          <p>During install and setup, the Cluster Installer wizard automatically creates a default user with
            "Ambari Admin" privilege. You can change the password for this user (or other Local users in the system)
            from the Ambari Administration interface. You can change the password for the default
            <code>admin</code>
            user to create a unique administrator credential for your system.

            To change the password for the default
            <code>admin</code>
            account:
          </p>
          <ul class="number-list">
            
              <li>
                <p>Browse to the Users section.</p>
              </li>
              <li>
                <p>Select the
                  <code>admin</code>
                  user.
                </p>
              </li>
              <li>
                <p>Click the Change Password button.</p>
              </li>
              <li>
                <p>Enter the current
                  <code>admin</code>
                  password and the new password twice.
                </p>
              </li>
              <li>
                <p>Click OK to save the new password.</p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-5bc067b8-60d3-4360-a26c-3ffd680fa12b">Ambari Admin Tasks</h3>
        
          <p>An "Ambari Admin" has administrator (or super-user) privilege. When logged into Ambari with the
            "Ambari Admin" privilege, you can:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-c012fd89-584c-4539-a618-f0f8e6b45302">Create a cluster</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-b8671a82-8833-4247-b96f-a0b7a81b7b7f">Set access permissions for an existing
                    cluster
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-534fc28f-9908-481e-ac5e-14de8d1a2709">Create, delete, and edit view instances
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-86d0b432-9bd5-4a98-8239-9f1a449217ed">Manage permissions for view instances
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-e87c8b71-e7a3-460e-a5c7-29b9c23e74ec">Create, edit, and delete users and user
                    groups
                  </a>
                </p>
              </li>
            
          </ul>
          <p>
            For more information about creating Ambari users locally and importing Ambari LDAP users, see<a href="#ref-b61c95af-59c7-4714-8745-eabbbd3056c2">Managing Users and Groups</a>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-c012fd89-584c-4539-a618-f0f8e6b45302">Creating a Cluster</h3>
        
          <p>As an Ambari Admin, you can launch the Cluster Install Wizard and create a cluster.
            To create a cluster, from the Ambari Administration interface:
          </p>
          <ul class="number-list">
            
              <li>
                <p>Click<code>Install Cluster</code>.
                  The Cluster Install Wizard displays.
                </p>
              </li>
              <li>
                <p>Follow the steps in the wizard to install your cluster.</p>
              </li>
            
          </ul>
          <p>For more information about prerequisites and system requirements, see<a href="#ref-4e6fd966-21d0-4dee-8175-06ba6c6ed517">Installing HDP using Ambari</a>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-b8671a82-8833-4247-b96f-a0b7a81b7b7f">Setting Cluster Permissions</h3>
        
          <p>After you create a cluster, users with Admin Admin privileges automatically get Operator permission
            on the cluster. By default, no users have access to the cluster. You can grant permissions on the cluster to
            other users and groups from the Ambari Administration interface.

            Ambari manages the following permissions for a cluster:
            <code>Operator</code>
            and<code>Read-Only</code>. Users and Groups with
            <code>Operator</code>
            permission are granted access to the cluster. Operator permission provides full control of the following
            services:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>Start</p>
              </li>
              <li>
                <p>Stop</p>
              </li>
              <li>
                <p>Restart</p>
              </li>
              <li>
                <p>Add New</p>
                <p>
                  And The Following Configurations:
                </p>
              </li>
              <li>
                <p>Modify</p>
              </li>
              <li>
                <p>Revert</p>
              </li>
            
          </ul>
          <p>Users and Groups with
            <code>Read-Only</code>
            permission can only view, not modify, services and configurations.

            Users with Ambari Admin privileges are implicitly granted
            <code>Operator</code>
            permission. Plus, Ambari Admin users have access to the Ambari Administration interface which allows them to
            control permissions for the cluster.
          </p>
          <p>To modify user and group permissions for a cluster:</p>
          <ul class="number-list">
            
              <li>
                <p>As an Ambari Admin, access the Ambari Administration interface.</p>
              </li>
              <li>
                <p>Click Permissions, displayed under the cluster name.</p>
              </li>
              <li>
                <p>The form showing the permissions
                  <code>Operator</code>
                  and
                  <code>Read-Only</code>
                  with users and groups is displayed.
                </p>
              </li>
              <li>
                <p>Modify the users and groups mapped to each permission and save.</p>
              </li>
            
          </ul>
          
            
            
            
          
          <p>For more information about managing users and groups, see<a href="#ref-b61c95af-59c7-4714-8745-eabbbd3056c2">Managing Users and Groups</a>.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Warning.png" width="50"></div>
            <div class="simple-block">
              <p>Assigning permissions to a group having
                <i>no</i>
                members is possible.
              </p>
            </div>
          </aside>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Tip%203d.png" width="50"></div>
            <div class="simple-block">
              <p>Verify user permissions, group membership, and group permissions to ensure that each user and
                group has appropriate permissions.
              </p>
            </div>
          </aside>
        
      
      
        <h3 class="horton-blue bold" id="ref-c19072ba-7515-4a25-855a-87f013ea337d">Viewing the Cluster Dashboard</h3>
        
          <p>After you have created a cluster, select
            <code>Clusters &gt; Go to Dashboard</code>
            to open the Dashboard view. For more information about using Ambari to monitor and manage your cluster, see
            <a href="#ref-09419997-e1b4-4788-a11a-5b02cdfedd90">Monitoring and Managing your HDP C</a>
            <a href="#ref-09419997-e1b4-4788-a11a-5b02cdfedd90">luster with Ambari</a>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-9a99a261-fcf2-49a8-b52e-dc0948dd30c2">Renaming a Cluster</h3>
        
          <p>A user with Admin Admin privileges can rename a cluster, using the Ambari Administration interface.

            To rename a cluster:
          </p>
          <ul class="number-list">
            
              <li>
                <p>In Clusters, click the Rename Cluster icon, next to the cluster name.</p>
                <div class="figure">
                  
                    
                      <img src="System%20Admin%20Guides/Ambari/Rename_cluster.png" width="50">
                    
                  
                </div>
                <p>The cluster name becomes write-able.</p>
              </li>
              <li>
                <p>Enter alphanumeric characters as a cluster name.</p>
              </li>
              <li>
                <p>Click the check mark.</p>
              </li>
              <li>
                <p>Confirm.</p>
              </li>
            
          </ul>
        
      
    
    
      <h2 class="horton-green bold">Managing Users and Groups</h2>
      
        
          <p>An "Ambari Admin" can create and manage users and groups available to Ambari. An Ambari Admin can
            also import user and group information into Ambari from external LDAP systems. This section describes the
            specific tasks you perform when managing users and groups in Ambari.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-7131cbf5-4ee7-4785-8a0c-37c7fe1d8828">Local and LDAP User Types</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-5bc067b8-60d3-4360-a26c-3ffd680fa12b">Ambari Admin Privileges</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-3de16e08-f9ed-4897-a067-c4ef341c4353">Creating a Local User</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-d52f3822-44fb-47d7-94d0-88f268930776">Setting User Status</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-36a632ca-a534-4edf-9759-89718b5a3722">Setting the Ambari Admin Flag</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-888694e6-b46a-47a1-aea4-b6a2545a4192">Changing the Password for a Local User
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-01e019e9-5336-4a57-b72b-5189c8c116f5">Deleting a Local User</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-5011c369-c25e-4ea1-a8ad-0e8b8f49f02a">Creating a Local Group</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-04303e51-d341-409f-8368-09fd41c4c1ae">Managing Group Membership</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-df29da7e-6549-4f2b-8e76-7c7aed29d48d">Deleting a Local Group</a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-b61c95af-59c7-4714-8745-eabbbd3056c2">Users and Groups Overview</h3>
        
          <p>Ambari supports two types of users and groups: Local and LDAP. The following topics describe how
            Ambari Administration supports managing Local and LDAP users and groups.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-7131cbf5-4ee7-4785-8a0c-37c7fe1d8828">Local and LDAP User and Group Types
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-5bc067b8-60d3-4360-a26c-3ffd680fa12b">Ambari Admin Privileges</a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Local and LDAP User and Group Types</h4>
          
            <p>Local users are stored in and authenticate against the Ambari database. LDAP users have basic
              account information stored in the Ambari database. Unlike Local users, LDAP users authenticate against an
              external LDAP system.

              Local groups are stored in the Ambari database. LDAP groups have basic information stored in the Ambari
              database, including group membership information. Unlike Local groups, LDAP groups are imported and
              synchronized from an external LDAP system.

              To use LDAP users and groups with Ambari, you must configure Ambari to authenticate against an external
              LDAP system. For more information about running ambari-server setup-ldap, see<a href="#ref-443fec0b-ef35-4829-bab9-14b83a416e4c">Configure Ambari to use LDAP Server</a>.
              A new Ambari user or group, created either locally or by synchronizing against LDAP, is granted no
              privileges by default. You, as an Ambari Admin, must explicitly grant each user permissions to access
              clusters or views.
            </p>
          
        
        
          <h4 class="bold">Ambari Admin Privileges</h4>
          
            <p>As an Ambari Admin, you can create new users, delete users, change user passwords and edit user
              settings. You can control certain privileges for Local and LDAP users. The following table lists the
              privileges available and those not available to the Ambari Admin for Local and LDAP Ambari users.
            </p>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">Ambari Administrator Privileges for Ambari Local and LDAP Users</p>
              
                
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Administrator User Privilege</p>
                    </th>
                    <th rowspan="1">
                      <p>Local User</p>
                    </th>
                    <th rowspan="1">
                      <p>LDAP User</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>Change Password</p>
                    </td>
                    <td rowspan="1">
                      <p>Available</p>
                    </td>
                    <td rowspan="1">
                      <p>Not Available</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Set Ambari Admin Flag</p>
                    </td>
                    <td rowspan="1">
                      <p>Available</p>
                    </td>
                    <td rowspan="1">
                      <p>Available</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Change Group Membership</p>
                    </td>
                    <td rowspan="1">
                      <p>Available</p>
                    </td>
                    <td rowspan="1">
                      <p>Not Available</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Delete User</p>
                    </td>
                    <td rowspan="1">
                      <p>Available</p>
                    </td>
                    <td rowspan="1">
                      <p>Not Available</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Set Active / Inactive</p>
                    </td>
                    <td rowspan="1">
                      <p>Available</p>
                    </td>
                    <td rowspan="1">
                      <p>Available</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-3de16e08-f9ed-4897-a067-c4ef341c4353">Creating a Local User</h3>
        
          <p>To create a local user:</p>
          <ul class="number-list">
            
              <li>
                <p>Browse to Users.</p>
              </li>
              <li>
                <p>Click Create Local User.</p>
              </li>
              <li>
                <p>Enter a unique user name.</p>
              </li>
              <li>
                <p>Enter a password, then confirm that password.</p>
              </li>
              <li>
                <p>Click Save.</p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-d52f3822-44fb-47d7-94d0-88f268930776">Setting User Status</h3>
        
          <p>User status indicates whether the user is active and should be allowed to log into Ambari or should
            be inactive and denied the ability to log in. By setting the Status flag as Active or Inactive, you can
            effectively "disable" user account access to Ambari while preserving the user account information related to
            permissions.
          </p>
          <p>To set user Status:</p>
          <ul class="number-list">
            
              <li>
                <p>On the Ambari Administration interface, browse to Users.</p>
              </li>
              <li>
                <p>Click the user name of the user to modify.</p>
              </li>
              <li>
                <p>Click the Status control to toggle between Active or Inactive.</p>
              </li>
              <li>
                <p>Choose OK to confirm the change.
                  The change is saved immediately.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-36a632ca-a534-4edf-9759-89718b5a3722">Setting the Ambari Admin Flag</h3>
        
          <p>You can elevate one or more users to have Ambari administrative privileges, by setting the Ambari
            Admin flag. You must be logged in as an account that is an Ambari Admin to set or remove the Ambari Admin
            flag.

            To set the Ambari Admin Flag:
          </p>
          <ul class="number-list">
            
              <li>
                <p>Browse to the Users section.</p>
              </li>
              <li>
                <p>Click the user name you wish to modify.</p>
              </li>
              <li>
                <p>Click on the Ambari Admin control.</p>
              </li>
              <li>
                <p>Switch Yes to set, or No to remove the Admin flag.</p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Important.png" width="50"></div>
            <div class="simple-block">
              <p>To prevent you from accidently locking yourself out of the Ambari Administration user interface,
                Ambari prevents setting the Ambari Admin flag for your own Ambari Admin account to No.
              </p>
            </div>
          </aside>
        
      
      
        <h3 class="horton-blue bold" id="ref-888694e6-b46a-47a1-aea4-b6a2545a4192">Changing the Password for a Local User</h3>
        
          <p>An Ambari Administrator can change local user passwords. LDAP passwords are not managed by Ambari
            since LDAP users authenticate to external LDAP. Therefore, LDAP user passwords cannot be changed from
            Ambari.

            To change the password for a local user:
          </p>
          <ul class="number-list">
            
              <li>
                <p>Browse to the user.</p>
              </li>
              <li>
                <p>Click<code>Change password</code>.
                </p>
              </li>
              <li>
                <p>Enter YOUR administrator password to confirm that you have privileges required to change a
                  local user password.
                </p>
              </li>
              <li>
                <p>Enter a password, then confirm that password.</p>
              </li>
              <li>
                <p>Click Save.</p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-01e019e9-5336-4a57-b72b-5189c8c116f5">Deleting a Local User</h3>
        
          <p>Deleting a local user removes the user account from the system, including all privileges associated
            with the user. You can reuse the name of a local user that has been deleted.
            To delete a local user:
          </p>
          <ul class="number-list">
            
              <li>
                <p>Browse to the User.</p>
              </li>
              <li>
                <p>Click<code>Delete User</code>.
                </p>
              </li>
              <li>
                <p>Confirm.</p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>If you want to disable user log in,
                <a href="#ref-d52f3822-44fb-47d7-94d0-88f268930776">set the user Status</a>
                to Inactive.
              </p>
            </div>
          </aside>
        
      
      
        <h3 class="horton-blue bold" id="ref-5011c369-c25e-4ea1-a8ad-0e8b8f49f02a">Creating a Local Group</h3>
        
          <p>To create a local group:</p>
          <ul class="number-list">
            
              <li>
                <p>Browse to Groups.</p>
              </li>
              <li>
                <p>Click Create Local Group.</p>
              </li>
              <li>
                <p>Enter a unique group name.</p>
              </li>
              <li>
                <p>Click Save.</p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-04303e51-d341-409f-8368-09fd41c4c1ae">Managing Group Membership</h3>
        
          <p>You can manage group membership of Local groups by adding or removing users from groups.</p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-dcd083b0-377a-4670-8d8d-3ff78dd5da3a">Adding a User to a Group</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-e0b6ef7c-639e-4cf8-a27f-22132a91072f">Modifying Group Membership</a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Adding a User to a Group</h4>
          
            <p>To add a user to group:</p>
            <ul class="number-list">
              
                <li>
                  <p>Browse to Groups.</p>
                </li>
                <li>
                  <p>Click a name in the Group Name list.</p>
                </li>
                <li>
                  <p>Choose the
                    <code>Local Members</code>
                    control to edit the member list.
                  </p>
                </li>
                <li>
                  <p>In the empty space, type the first character in an existing user name.</p>
                </li>
                <li>
                  <p>From the list of available user names, choose a user name.</p>
                </li>
                <li>
                  <p>Click the check mark to save the current, displayed members as group members.</p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Modifying Group Membership</h4>
          
            <p>To modify Local group membership:</p>
            <ul class="number-list">
              
                <li>
                  <p>In the Ambari Administration interface, browse to Groups.</p>
                </li>
                <li>
                  <p>Click the name of the Group to modify.</p>
                </li>
                <li>
                  <p>Choose the
                    <code>Local Members</code>
                    control to edit the member list.
                  </p>
                </li>
                <li>
                  <p>Click in the Local Members text area to modify the current membership.</p>
                </li>
                <li>
                  <p>Click the
                    <code>X</code>
                    to remove a user.
                  </p>
                </li>
                <li>
                  <p>To save your changes, click the checkmark. To discard your changes, click the
                    <code>x</code>.
                  </p>
                </li>
              
            </ul>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-df29da7e-6549-4f2b-8e76-7c7aed29d48d">Deleting a Local Group</h3>
        
          <p>Deleting a local group removes all privileges associated with the group.
            To delete a local group:
          </p>
          <ul class="number-list">
            
              <li>
                <p>Browse to the Group.</p>
              </li>
              <li>
                <p>Click<code>Delete Group</code>.
                </p>
              </li>
              <li>
                <p>Confirm. The group is deleted and the associated group membership information is removed.
                </p>
              </li>
            
          </ul>
        
      
    
    
      <h2 class="horton-green bold">Managing Views</h2>
      
        
          <p>The Ambari Views Framework offers a systematic way to plug in UI capabilities to surface custom
            visualization, management and monitoring features in Ambari Web. The development and use of Views allows you
            to extend and customize Ambari Web to meet your specific needs.

            A View extends Ambari to let third parties plug in new resource types along with APIs, providers, and UIs to
            support them. A View is deployed into the Ambari Server and Ambari Admins can create View instances and set
            the privileges on access to users and groups.

            The following sections cover the basics of Views and how to deploy and manage View instances in Ambari:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-80dcc1b2-6764-40e3-ae79-cd4e64c65530">Terminology</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-c4f9fe53-e036-4633-8414-0e1bd51b7610">Basic Concepts</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-e9380ee8-46f5-4ac7-8b67-d3586d0e6c0f">Deploying Views</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-534fc28f-9908-481e-ac5e-14de8d1a2709">Creating View Instances</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-86d0b432-9bd5-4a98-8239-9f1a449217ed">Setting View Permissions</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-0298b32c-3284-4e0b-8ab2-a894011fb638">Learn More</a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-80dcc1b2-6764-40e3-ae79-cd4e64c65530">Terminology</h3>
        
          <p>The following are Views terms and concepts you should be familiar with:</p>
          <div class="xyleme-table"><table border="1">
            
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>Term</p>
                  </th>
                  <th rowspan="1">
                    <p>Description</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>Views Framework</p>
                  </td>
                  <td rowspan="1">
                    <p>The core framework that is used to develop a View. This is very similar to a Java Web
                      App.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View Definition</p>
                  </td>
                  <td rowspan="1">
                    <p>Describes the View resources and core View properties such as name, version and any
                      necessary configuration properties. On deployment, the View definition is read by Ambari.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View Package</p>
                  </td>
                  <td rowspan="1">
                    <p>Packages the View client and server assets (and dependencies) into a bundle that is ready
                      to deploy into Ambari.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View Deployment</p>
                  </td>
                  <td rowspan="1">
                    <p>Deploying a View into Ambari. This makes the View available to Ambari Admins for creating
                      instances.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View Name</p>
                  </td>
                  <td rowspan="1">
                    <p>Unique identifier for a View. A View can have one or more versions of a View. The name is
                      defined in the View Definition (created by the View Developer) that is built into the View
                      Package.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View Version</p>
                  </td>
                  <td rowspan="1">
                    <p>Specific version of a View. Multiple versions of a View (uniquely identified by View name)
                      can be deployed into Ambari.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View Instance</p>
                  </td>
                  <td rowspan="1">
                    <p>Instantiation of a specific View version. Instances are created and configured by Ambari
                      Admins and must have a unique View instance name.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View Instance Name</p>
                  </td>
                  <td rowspan="1">
                    <p>Unique identifier of a specific instance of View.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Framework Services</p>
                  </td>
                  <td rowspan="1">
                    <p>View context, instance data, configuration properties and events are available from the
                      Views Framework.
                    </p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
        
      
      
        <h3 class="horton-blue bold" id="ref-c4f9fe53-e036-4633-8414-0e1bd51b7610">Basic Concepts</h3>
        
          <p>Views are basically Web applications that can be “plugged into” Ambari. Just like a typical web
            application, a View can include server-side resources and client-side assets. Server-side resources, which
            are written in Java, can integrate with external systems (such as cluster services) and expose REST
            end-points that are used by the view. Client-side assets, such as HTML/JavaScript/CSS, provide the UI for
            the view that is rendered in the Ambari Web interface.
          </p>
          
            Ambari Views Framework
            
            
          
        
        
          <p>Ambari exposes the Views Framework as the basis for View development. The Framework provides the
            following:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>Method for describing and packaging a View</p>
              </li>
              <li>
                <p>Method for deploying a View</p>
              </li>
              <li>
                <p>Framework services for a View to integrate with Ambari</p>
              </li>
              <li>
                <p>Method for managing View versions, instances, and permissions</p>
              </li>
            
          </ul>
          <p>The Views Framework is separate from Views themselves. The Framework is a core feature of Ambari and
            Views build on that Framework. Although Ambari does include some Views out-of-the-box, the feature of Ambari
            is the Framework to enable the development, deployment and creation of views.

            The development and delivery of a View follows this process flow:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>Develop the View (similar to how you would build a Web application)</p>
              </li>
              <li>
                <p>Package the View (similar to a WAR)</p>
              </li>
              <li>
                <p>Deploy the View into Ambari (using the Ambari Administration interface)</p>
              </li>
              <li>
                <p>Create and configure instances of the View (performed by Ambari Admins)</p>
              </li>
            
          </ul>
          
            
            
            
          
          <p>Considering the above, it is important to understand the different personas involved. The following
            table describes the three personas:
          </p>
          <div class="xyleme-table"><table border="1">
            
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>Persona</p>
                  </th>
                  <th rowspan="1">
                    <p>Description</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>View Developer</p>
                  </td>
                  <td rowspan="1">
                    <p>Person who builds the front-end and back-end of a View and uses the Framework services
                      available during development. The Developer created the View, resulting in a View Package that is
                      delivered to an Ambari Admin.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Ambari Admin</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari user that has Ambari Admin privilege and uses the Views Management section of the
                      Ambari Administration interface to create and managing instances of Views. Ambari Admin also
                      deploys the View Packages delivered by the View Developer.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View User</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari user that has access to one or more Views in Ambari Web. Basically, this is the end
                      user.
                    </p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
        
        
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Important.png" width="50"></div>
            <div class="simple-block">
              <p>This document covers the tasks related to an Ambari Admin using and making Views available to
                users in their Ambari deployment. This document does not cover View development and packaging. See
                <a href="#ref-0298b32c-3284-4e0b-8ab2-a894011fb638">Learn More</a>
                for more information on where to obtain information about developing Views.
              </p>
            </div>
          </aside>
          <p>After Views are developed, views are identified by unique a view name. Each View can have one or
            more View versions. Each View name + version combination is deployed as a single View package. Once a View
            package is deployed, the Ambari Admin can create View instances, where each instance is identified by a
            unique View instance name. The Ambari Admin can then set access permissions for each View instance.
          </p>
          
            Ambari Views Versions and Instances
            
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-e9380ee8-46f5-4ac7-8b67-d3586d0e6c0f">Deploying a View</h3>
        
          <p>Deploying a View involves obtaining the View Package and making the View available to the Ambari
            Server. Each View deployed has a unique name. Multiple versions of a View can be deployed at the same time.
            You can configure multiple versions of a View for your users, depending on their roles, and deploy these
            versions at the same time.

            For more information about building Views, see the<a href="https://cwiki.apache.org/confluence/display/AMBARI/Views">Apache Ambari Wiki page</a>.
          </p>
          <ul class="number-list">
            
              <li>
                <p>Obtain the View package. For example,<code>files-0.1.0.jar</code>.
                </p>
              </li>
              <li>
                <p>On the Ambari Server host, browse to the views directory.</p>
                <p>
                  <code>cd /var/lib/ambari-server/resources/views</code>
                </p>
              </li>
              <li>
                <p>Copy the View package into place.</p>
              </li>
              <li>
                <p>Restart Ambari Server.</p>
                <p>
                  <code>ambari-server restart</code>
                </p>
              </li>
              <li>
                <p>The View is extracted, registered with Ambari, and displays in the Ambari Administration
                  interface as available to create instances.
                </p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>
                <code>/var/lib/ambari-server/resources/views</code>
                is the default directory into which Views are deployed. You can change the default location by editing
                the
                <code>views.dir</code>
                property in<code>ambari.properties</code>.
              </p>
            </div>
          </aside>
        
      
      
        <h3 class="horton-blue bold" id="ref-534fc28f-9908-481e-ac5e-14de8d1a2709">Creating View Instances</h3>
        
          <p>To create a View instance:</p>
          <ul class="number-list">
            
              <li>
                <p>Browse to a View and expand.</p>
              </li>
              <li>
                <p>Click the “Create Instance” button.</p>
              </li>
              <li>
                <p>Provide the following information:</p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    
                    <thead>
                      <tr>
                        <th rowspan="1">
                          <p>Item</p>
                        </th>
                        <th rowspan="1">
                          <p>Required</p>
                        </th>
                        <th rowspan="1">
                          <p>Description</p>
                        </th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td rowspan="1">
                          <p>View Version</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Select the version of the View to instantiate.</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Instance Name</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Must be unique for a given View.</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Display Label</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Readable display name used for the View instance when shown in Ambari Web.
                          </p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Description</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Readable description used for the View instance when shown in Ambari Web.</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Visible</p>
                        </td>
                        <td rowspan="1">
                          <p>No</p>
                        </td>
                        <td rowspan="1">
                          <p>Designates whether the View is visible or not visible to the end-user in Ambari web.
                            Use this property to temporarily hide a view in Ambari Web from users.
                          </p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>Properties</p>
                        </td>
                        <td rowspan="1">
                          <p>Maybe</p>
                        </td>
                        <td rowspan="1">
                          <p>Depends on the View. If the View requires certain configuration properties, you are
                            prompted to provide the required information.
                          </p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-86d0b432-9bd5-4a98-8239-9f1a449217ed">Setting View Permissions</h3>
        
          <p>After a view instance has been created, an Ambari Admin can set which users and groups can access
            the view by setting the Use permission. By default, after view instance creation, no permissions are set on
            a view.

            To set permissions on a view:
          </p>
          <ul class="number-list">
            
              <li>
                <p>Browse to a view and expand. For example, browse to the Slider or Jobs view.</p>
              </li>
              <li>
                <p>Click on the view instance you want to modify.</p>
              </li>
              <li>
                <p>In the Permissions section, click the Users or Groups control.</p>
              </li>
              <li>
                <p>Modify the user and group lists as appropriate.</p>
              </li>
              <li>
                <p>Click the check mark to save changes.</p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>The Framework provides a way for view developers to specify custom permissions, beyond just the
                default Use permission. If custom permissions are are specified, they will show up in the Ambari
                Administration interface and the Ambari Admin can set users and groups on these permissions. See
                <a href="#ref-0298b32c-3284-4e0b-8ab2-a894011fb638">Additional Information</a>
                for more information on developing with the Views framework.
              </p>
            </div>
          </aside>
        
      
      
        <h3 class="horton-blue bold" id="ref-0298b32c-3284-4e0b-8ab2-a894011fb638">Additional Information</h3>
        
          <p>To learn more about developing views and the views framework itself, refer to the following
            resources:
          </p>
          <div class="xyleme-table"><table border="1">
            
              
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>Resource</p>
                  </th>
                  <th rowspan="1">
                    <p>Description</p>
                  </th>
                  <th rowspan="1">
                    <p>Link</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>Views Wiki</p>
                  </td>
                  <td rowspan="1">
                    <p>Learn about the Views Framework and Framework services available to views developers.
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>
                      <a href="https://cwiki.apache.org/confluence/display/AMBARI/Views">
                        https://cwiki.apache.org/confluence/display/AMBARI/Viewsche.org/confluence/display/AMBARI/Views
                      </a>
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Views API</p>
                  </td>
                  <td rowspan="1">
                    <p>Covers the Views REST API and associated framework Java classes.</p>
                  </td>
                  <td rowspan="1">
                    <p>
                      <a href="https://github.com/apache/ambari/blob/trunk/ambari-views/docs/index.md">
                        https://github.com/apache/ambari/blob/trunk/ambari-views/docs/index.md
                      </a>
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Views Examples</p>
                  </td>
                  <td rowspan="1">
                    <p>Code for example views that hover different areas of the framework and framework
                      services.
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>
                      <a href="https://github.com/apache/ambari/tree/trunk/ambari-views/examples">
                        https://github.com/apache/ambari/tree/trunk/ambari-views/examples
                      </a>
                    </p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>View Contributions</p>
                  </td>
                  <td rowspan="1">
                    <p>Views that are being developed and contributed to the Ambari community.
                      <a href="#footnote-4" class="footnote-anchor">[4]</a>
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>
                      <a href="https://github.com/apache/ambari/tree/trunk/contrib/views">
                        https://github.com/apache/ambari/tree/trunk/contrib/views
                      </a>
                    </p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
        
      
    
    
      <h2 class="horton-green bold">Ambari Security Guide</h2>
      
        
          <p>This section describes how to set up strong authentication for Hadoop users and hosts in an
            Ambari-installed HDP cluster, and provides information on advanced security options for Ambari.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-4a8722b7-505e-4aa1-9256-9fff03c0d000">Preparing Kerberos for Hadoop</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-36f47ef6-1164-49fd-8eca-9391317f73c9">Setting Up Hadoop Users</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-a9927c0e-595d-45b8-b574-a2d401685ccd">Setting up Ambari for Kerberos</a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-4a8722b7-505e-4aa1-9256-9fff03c0d000">Preparing Kerberos for Hadoop</h3>
        
          <p>This section describes how to set up the Kerberos components in your Hadoop cluster.</p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-c378bde5-ea90-4488-a3f9-2d25808f7f89">Kerberos Overview</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-d6ff1085-1c16-4ef0-aa3b-2ae5eac406c0">Installing and Configuring the KDC</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-1d3140b1-191c-49d2-af48-dfdb854a7a53">Creating the Kerberos Database</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-99390b40-9e5e-4ac6-97c7-e8347cbad6fb">Starting the KDC</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-c192db3c-487e-4503-8fb2-a1553cdfae75">Installing and Configuring the Kerberos
                    Clients
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-d0b2f2d1-904f-4982-8f83-26dc53d884bd">Creating Service Principals and Keytab
                    Files for Hadoop 2.x
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-f8683307-21bb-40ac-968f-7b810be76d58">Creating Service Principals and Keytab
                    Files for
                  </a>
                  <a href="#ref-f8683307-21bb-40ac-968f-7b810be76d58">HDP 1.x</a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Kerberos Overview</h4>
          
            <p>Establishing identity with strong authentication is the basis for secure access in Hadoop. Users
              need to be able to reliably “identify” themselves and then have that identity propagated throughout the
              Hadoop cluster. Once this is done those users can access resources (such as files or directories) or
              interact with the cluster (like running MapReduce jobs). As well, Hadoop cluster resources themselves
              (such as Hosts and Services) need to authenticate with each other to avoid potential malicious systems
              “posing as” part of the cluster to gain access to data.
            </p>
            <p>
              To create that secure communication among its various components, Hadoop uses Kerberos. Kerberos is a
              third party authentication mechanism, in which users and services that users want to access rely on a
              third party - the Kerberos server - to authenticate each to the other. The Kerberos server itself is known
              as the Key Distribution Center, or KDC. At a high level, it has three parts:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>A database of the users and services (known as<i>principals</i>) that it knows
                    about and their respective Kerberos passwords
                  </p>
                </li>
                <li>
                  <p>An
                    <i>authentication server</i>
                    (AS) which performs the initial authentication and issues a
                    <i>Ticket Granting Ticket</i>
                    (TGT)
                  </p>
                </li>
                <li>
                  <p>A
                    <i>Ticket Granting Server</i>
                    (TGS) that issues subsequent service tickets based on the initial TGT
                  </p>
                </li>
              
            </ul>
            <p>A user principal requests authentication from the AS. The AS returns a TGT that is encrypted using
              the user principal's Kerberos password, which is known only to the user principal and the AS. The user
              principal decrypts the TGT locally using its Kerberos password, and from that point forward, until the
              ticket expires, the user principal can use the TGT to get service tickets from the TGS. Service tickets
              are what allow a principal to access various services.
            </p>
            <p>
              Because cluster resources (hosts or services) cannot provide a password each time to decrypt the TGT, they
              use a special file, called a
              <i>keytab,</i>
              which contains the resource principal's authentication credentials.
            </p>
            <p>
              The set of hosts, users, and services over which the Kerberos server has control is called a<i>
              realm</i>.
            </p>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">Kerberos terminology</p>
              
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Term</p>
                    </th>
                    <th rowspan="1">
                      <p>Description</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>Key Distribution Center, or KDC</p>
                    </td>
                    <td rowspan="1">
                      <p>The trusted source for authentication in a Kerberos-enabled environment.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Kerberos KDC Server</p>
                    </td>
                    <td rowspan="1">
                      <p>The machine, or server, that serves as the Key Distribution Center.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Kerberos Client</p>
                    </td>
                    <td rowspan="1">
                      <p>Any machine in the cluster that authenticates against the KDC.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Principal</p>
                    </td>
                    <td rowspan="1">
                      <p>The unique name of a user or service that authenticates against the KDC.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Keytab</p>
                    </td>
                    <td rowspan="1">
                      <p>A file that includes one or more principals and their keys.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Realm</p>
                    </td>
                    <td rowspan="1">
                      <p>The Kerberos network that includes a KDC and a number of Clients.</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
        
        
          <h4 class="bold">Installing and Configuring the KDC</h4>
          
            <p>To use Kerberos with Hadoop you can either use an existing KDC or install a new one just for
              Hadoop's use. The following gives a very high level description of the installation process. To get more
              information see<a href="https://access.redhat.com/knowledge/docs/en-US/Red_Hat_Enterprise_Linux/6/html/Managing_Smart_Cards/installing-kerberos.html">
                RHEL documentation</a>,<a href="http://www.centos.org/docs/5/html/5.2/Deployment_Guide/s1-kerberos-server.html">CentOS
                documentation</a>, or
              <a href="http://doc.opensuse.org/products/draft/SLES/SLES-security_sd_draft/cha.net.kerberos.html">
                SLES documentation.
              </a>
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>Because Kerberos is a time-sensitive protocol, all hosts in the realm must be
                  time-synchronized, for example, by using the Network Time Protocol (NTP). If the local system time of
                  a client differs from that of the KDC by as little as 5 minutes (the default), the client will not be
                  able to authenticate.
                </p>
              </div>
            </aside>
            <ul class="number-list">
              
                <li>
                  <p>To install a new version of the server:</p>
                  <p>
                    <code>
                      For RHEL/CentOS/Oracle Linux
                    </code>
                    <code>yum install krb5-server krb5-libs krb5-auth-dialog krb5-workstation</code>
                    <code></code>
                  </p>
                  <p>
                    <code>
                      For SLES 11
                    </code>
                    <code>zypper install krb5 krb5-server krb5-client</code>
                  </p>
                  <p>
                    <code>For UBUNTU 12</code>
                    <code>apt-get install krb5 krb5-server krb5-client</code>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>The host on which you install the KDC must itself be secure.</p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>When the server is installed use a text editor to edit the configuration file, located by
                    default here:
                  </p>
                  <p>
                    <code>/etc/krb5.conf</code>
                  </p>
                  <p>Change the
                    <code>[realms]</code>
                    section of this file by replacing the default “kerberos.example.com” setting for the
                    <code>kdc</code>
                    and
                    <code>admin_server</code>
                    properties with the Fully Qualified Domain Name of the KDC server. In the following example,
                    “kerberos.example.com” has been replaced with “my.kdc.server”.
                  </p>
                  <p>
                    <code>[realms]
                      EXAMPLE.COM = {
                      kdc = my.kdc.server
                      admin_server = my.kdc.server
                      }
                    </code>
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Creating the Kerberos Database</h4>
          
            <p>Use the utility
              <code>kdb5_util</code>
              to create the Kerberos database.
            </p>
            <p>
              <code>
                For RHEL/CentOS/Oracle Linux 6
              </code>
              <code>/usr/sbin/kdb5_util create -s</code>
            </p>
            <p>
              <code>
                For SLES 11
              </code>
              <code>kdb5_util create -s</code>
            </p>
            <p>
              <code>For UBUNTU 12</code>
              <code>kdb5_util create -s</code>
            </p>
          
        
        
          <h4 class="bold">Starting the KDC</h4>
          
            <p>Start the KDC.

              <code>For RHEL/CentOS/Oracle Linux 5 (DEPRECATED)
              </code>
              <code>/etc/rc.d/init.d/krb5kdc start
                /etc/rc.d/init.d/kadmin start
              </code>
            </p>
            <p>
              <code>For SLES 11</code>
              <code>rckrb5kdc start
                rckadmind start
              </code>
            </p>
            <p>
              <code>For UBUNTU 12
              </code>
              <code>rckrb5kdc start
                rckadmind start
              </code>
            </p>
          
        
        
          <h4 class="bold">Installing and Configuring the Kerberos Clients</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>To install the Kerberos clients, on every server in the cluster:</p>
                  <p>
                    <code>
                      For RHEL/CentOS/Oracle Linux
                    </code>
                    <code>yum install krb5-workstation</code>
                  </p>
                  <p>
                    <code>
                      For SLES 11
                    </code>
                    <code>zypper install krb5-client</code>
                  </p>
                  <p>
                    <code>
                      For UBUNTU 12
                    </code>
                    <code>apt-get install krb5-client</code>
                  </p>
                </li>
                <li>
                  <p>Copy the
                    <code>krb5.conf</code>
                    file you modified in
                    <a href="#ref-d6ff1085-1c16-4ef0-aa3b-2ae5eac406c0">Installing and Configuring the KDC
                    </a>
                    to all the servers in the cluster.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Creating Service Principals and Keytab Files for HDP 2.x</h4>
          
            <p>Each service and sub-service in Hadoop must have its own principal. A principal name in a given
              realm consists of a primary name and an instance name, which in this case is the FQDN of the host that
              runs that service. As services do not log in with a password to acquire their tickets, their principal's
              authentication credentials are stored in a keytab file, which is extracted from the Kerberos database and
              stored locally with the service principal on the service component host.
            </p>
            <p>
              First you must create the principal, using mandatory naming conventions.
            </p>
            <p>
              Then you must create the keytab file with that principal's information and copy the file to the keytab
              directory on the appropriate service host.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>Principals can be created either on the KDC machine itself or through the network, using an
                  “admin” principal. The following instructions assume you are using the KDC machine and using the
                  <code>kadmin.local</code>
                  command line administration utility. Using
                  <code>kadmin.local</code>
                  on the KDC machine allows you to create principals without needing to create a separate "admin"
                  principal before you start.
                </p>
              </div>
            </aside>
            <ul class="number-list">
              
                <li>
                  <p>Open the
                    <code>kadmin.local</code>
                    utility on the KDC machine
                  </p>
                  <p>
                    <code>/usr/sbin/kadmin.local</code>
                  </p>
                </li>
                <li>
                  <p>Create the service principals:
                    <code>$kadmin.local
                      addprinc -randkey $primary_name/$fully.qualified.domain.name @EXAMPLE.COM
                    </code>
                  </p>
                  <p>
                    The
                    <code>-randkey</code>
                    option is used to generate the password.
                  </p>
                  <p>
                    Notice in the example that each service principal's primary name has appended to it the instance
                    name, the FQDN of the host on which it runs. This provides a unique principal name for services that
                    run on multiple hosts, like DataNodes and NodeManagers. The addition of the host name serves to
                    distinguish, for example, a request from DataNode A from a request from DataNode B. This is
                    important for the following reasons:
                  </p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>If the Kerberos credentials for one DataNode are compromised, it does not
                          automatically lead to all DataNodes being compromised
                        </p>
                      </li>
                      <li>
                        <p>If multiple DataNodes have exactly the same principal and are simultaneously
                          connecting to the NameNode, and if the Kerberos authenticator being sent happens to have same
                          timestamps, then the authentication would be rejected as a replay request.
                        </p>
                      </li>
                    
                  </ul>
                  <p>
                    The principal name must match the values in the table below:
                  </p>
                  <div class="xyleme-table"><table border="1">
                    <p class="italic bold">Service Principals</p>
                    
                      
                      
                      
                      <thead>
                        <tr>
                          <th rowspan="1">
                            <p>Service</p>
                          </th>
                          <th rowspan="1">
                            <p>Component</p>
                          </th>
                          <th rowspan="1">
                            <p>Mandatory Principal Name</p>
                          </th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>NameNode</p>
                          </td>
                          <td rowspan="1">
                            <p>nn/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>NameNode HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>SecondaryNameNode</p>
                          </td>
                          <td rowspan="1">
                            <p>nn/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>SecondaryNameNode HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>DataNode</p>
                          </td>
                          <td rowspan="1">
                            <p>dn/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>MR2</p>
                          </td>
                          <td rowspan="1">
                            <p>History Server</p>
                          </td>
                          <td rowspan="1">
                            <p>jhs/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>MR2</p>
                          </td>
                          <td rowspan="1">
                            <p>History Server HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>YARN</p>
                          </td>
                          <td rowspan="1">
                            <p>ResourceManager</p>
                          </td>
                          <td rowspan="1">
                            <p>rm/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>YARN</p>
                          </td>
                          <td rowspan="1">
                            <p>NodeManager</p>
                          </td>
                          <td rowspan="1">
                            <p>nm/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Oozie</p>
                          </td>
                          <td rowspan="1">
                            <p>Oozie Server</p>
                          </td>
                          <td rowspan="1">
                            <p>oozie/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Oozie</p>
                          </td>
                          <td rowspan="1">
                            <p>Oozie HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Hive</p>
                          </td>
                          <td rowspan="1">
                            <p>Hive Metastore HiveServer2</p>
                          </td>
                          <td rowspan="1">
                            <p>hive/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Hive</p>
                          </td>
                          <td rowspan="1">
                            <p>WebHCat</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HBase</p>
                          </td>
                          <td rowspan="1">
                            <p>MasterServer</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HBase</p>
                          </td>
                          <td rowspan="1">
                            <p>RegionServer</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>ZooKeeper</p>
                          </td>
                          <td rowspan="1">
                            <p>ZooKeeper</p>
                          </td>
                          <td rowspan="1">
                            <p>zookeeper/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Nagios Server</p>
                          </td>
                          <td rowspan="1">
                            <p>Nagios</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>JournalNode ServerOnly required if you are setting up NameNode HA.</p>
                          </td>
                          <td rowspan="1">
                            <p>JournalNode</p>
                          </td>
                          <td rowspan="1">
                            <p>jn/$FQDN</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                  <p>
                    For example, to create the principal for a DataNode service, issue the following command:
                    <code>$kadmin.local
                      addprinc -randkey dn/ $DataNode-Host @EXAMPLE.COM
                    </code>
                  </p>
                </li>
                <li>
                  <p>In addition you must create four special principals for Ambari's own use.</p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>The names in the following table can be customized in the Customize Services step of the
                        Ambari Install Wizard. If this is the case in your installation, the principal names should
                        match the customized names. For example, if the HDFS Service User has been set to<code>
                          hdfs1</code>, the respective principal for the Ambari HDFS User should also be created
                        as<code>hdfs1</code>.
                      </p>
                    </div>
                  </aside>
                  <p>
                    These principals do not have the FQDN appended to the primary name:
                  </p>
                  <div class="xyleme-table"><table border="1">
                    <p class="italic bold">Ambari Principals</p>
                    
                      
                      
                      <thead>
                        <tr>
                          <th rowspan="1">
                            <p>User</p>
                          </th>
                          <th rowspan="1">
                            <p>Mandatory Principal Name</p>
                          </th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari UserThis principal is used with the JAAS configuration. See Setting up JAAS
                              for Ambari for more information.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>ambari</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Smoke Test User</p>
                          </td>
                          <td rowspan="1">
                            <p>ambari-qa</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari HDFS User</p>
                          </td>
                          <td rowspan="1">
                            <p>hdfs</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari HBase User</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                </li>
                <li>
                  <p>After the principals are created in the database, you can extract the related keytab files
                    for transfer to the appropriate host:
                    <code>$kadmin.local
                      xst -norandkey -k $keytab_file_name $primary_name /fully.qualified.domain.name@EXAMPLE.COM
                    </code>
                  </p>
                  <p>
                    You must use the mandatory names for the
                    &lt;$keytab_file_name&gt;
                    variable shown in the preceding table.
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>
                        Some older versions of Kerberos do not support the xst
                        <code>-norandkey</code>
                        option. You can use the command without the
                        <code>-norandkey</code>
                        flag, except in cases where you need to copy a principal from one keytab file to another keytab
                        file on a host. This might be a requirement if the Hadoop configurations on a host have keytab
                        path properties that point to different keytab locations but have corresponding principal name
                        properties that have the same values.
                      </p>
                      <p>
                        In situations like this, you can use the two step
                        <code>kadmin</code>
                        /
                        <code>kutil</code>
                        procedure. This description assumes MIT Kerberos. If you are using another version, please check
                        the documentation for that version.
                      </p>
                    </div>
                  </aside>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Extract the keytab file information:</p>
                        <p>
                          <code>$kadmin
                            xst -k $keytab_file_name-temp1$primary_name /fully.qualified.domain.name@EXAMPLE.COM
                            xst -k $keytab_file_name-temp2$primary_name /fully.qualified.domain.name@EXAMPLE.COM
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Write the keytab to a file.</p>
                        <p>
                          <code>
                            $kutil
                            kutil: rkt $keytab_file_name-temp1
                            kutil: rkt $keytab_file_name-temp2
                            kutil: wkt $keytab_file_name
                            kutil: clear
                          </code>
                        </p>
                      </li>
                    
                  </ul>
                  <div class="xyleme-table"><table border="1">
                    <p class="italic bold">Service Keytab File Names</p>
                    
                      
                      
                      
                      <thead>
                        <tr>
                          <th rowspan="1">
                            <p>Component</p>
                          </th>
                          <th rowspan="1">
                            <p>Principal Name</p>
                          </th>
                          <th rowspan="1">
                            <p>Mandatory Keytab File Name</p>
                          </th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td rowspan="1">
                            <p>NameNode</p>
                          </td>
                          <td rowspan="1">
                            <p>nn/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>nn.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>NameNode HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>spnego.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>SecondaryNameNode</p>
                          </td>
                          <td rowspan="1">
                            <p>nn/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>nn.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>SecondaryNameNode HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>spnego.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>DataNode</p>
                          </td>
                          <td rowspan="1">
                            <p>dn/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>dn.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>MR2 History Server</p>
                          </td>
                          <td rowspan="1">
                            <p>jhs/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>jhs.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>MR2 History Server HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>spnego.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>YARN</p>
                          </td>
                          <td rowspan="1">
                            <p>rm/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>rm.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>YARN</p>
                          </td>
                          <td rowspan="1">
                            <p>nm/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>nm.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Oozie Server</p>
                          </td>
                          <td rowspan="1">
                            <p>oozie/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>oozie.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Oozie HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>spnego.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Hive Metastore HiveServer2</p>
                          </td>
                          <td rowspan="1">
                            <p>hive/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>hive.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>WebHCat</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>spnego.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HBase Master Server</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HBase RegionServer</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>ZooKeeper</p>
                          </td>
                          <td rowspan="1">
                            <p>zookeeper/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>zk.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Nagios Server</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Journal ServerOnly required if you are setting up NameNode HA.</p>
                          </td>
                          <td rowspan="1">
                            <p>jn/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>jn.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari UserThis principal is used with the JAAS configuration. See Setting up JAAS
                              for Ambari for more information.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>ambari</p>
                          </td>
                          <td rowspan="1">
                            <p>ambari.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Smoke Test User</p>
                          </td>
                          <td rowspan="1">
                            <p>ambari-qa</p>
                          </td>
                          <td rowspan="1">
                            <p>smokeuser.headless.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari HDFS User</p>
                          </td>
                          <td rowspan="1">
                            <p>hdfs</p>
                          </td>
                          <td rowspan="1">
                            <p>hdfs.headless.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari HBase User</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase.headless.keytab</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                  <p>For example, to create the keytab files for NameNode HTTP, issue the following command:
                  </p>
                  <p>
                    <code>$kadmin.local
                      xst -norandkey -k spnego.service.keytab HTTP/&lt;namenode-host&gt;</code>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>If you have a large cluster, you may want to create a script to automate creating your
                        principals and keytabs. To help with that, you can download a CSV-formatted file of all the
                        required principal names and keytab files from the Ambari Web GUI. Select
                        <code>Admin &gt; Security &gt; Enable Security</code>
                        <strong>,</strong>
                        then run the<code>Enable Security Wizard</code>, using the default
                        values. At the bottom of the third page, in<code>Create Principals and
                          Keytabs</code>, click<code>Download CSV</code>.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>When the keytab files have been created, on each host create a directory for them and set
                    appropriate permissions.
                  </p>
                  <p>
                    <code>mkdir -p /etc/security/keytabs/
                      chown root:hadoop /etc/security/keytabs
                      chmod 750 /etc/security/keytabs
                    </code>
                  </p>
                </li>
                <li>
                  <p>Copy the appropriate keytab file to each host. If a host runs more than one component (for
                    example, both NodeManager and DataNode), copy keytabs for both components. The Ambari Smoke Test
                    User, the Ambari HDFS User, and the Ambari HBase User keytabs should be copied to the all hosts on
                    the cluster.
                  </p>
                  <p>
                    If you have customized service user names, replace the default values below with your appropriate
                    service user, group, and keytab names.
                  </p>
                </li>
                <li>
                  <p>Set appropriate permissions for the keytabs.</p>
                  <p>
                    If you have customized service user names, replace the default values below with your appropriate
                    service user, group, and keytab names.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Optionally, if you have
                          <a href="#ref-04f03c43-badc-48ac-a335-0f44530b49bd">Set up JAAS</a>
                          on the Ambari server host:
                        </p>
                        <p>
                          <code>chown ambari:ambari /etc/security/keytabs/ambari.keytab
                            chmod 400 /etc/security/keytabs/ambari.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the HDFS NameNode and SecondaryNameNode hosts:</p>
                        <p>
                          <code>chown hdfs:hadoop /etc/security/keytabs/nn.service.keytab
                            chmod 400 /etc/security/keytabs/nn.service.keytab
                            chown root:hadoop /etc/security/keytabs/spnego.service.keytab
                            chmod 440 /etc/security/keytabs/spnego.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the HDFS NameNode host, for the Ambari Test Users:</p>
                        <p>
                          <code>chown ambari-qa:hadoop /etc/security/keytabs/smokeuser.headless.keytab
                            chmod 440 /etc/security/keytabs/smokeuser.headless.keytab
                            chown hdfs:hadoop /etc/security/keytabs/hdfs.headless.keytab
                            chmod 440 /etc/security/keytabs/hdfs.headless.keytab
                            chown hbase:hadoop /etc/security/keytabs/hbase.headless.keytab
                            chmod 440 /etc/security/keytabs/hbase.headless.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On each host that runs an HDFS DataNode:</p>
                        <p>
                          <code>chown hdfs:hadoop /etc/security/keytabs/dn.service.keytab
                            chmod 400 /etc/security/keytabs/dn.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the host that runs the MR2 History Server:</p>
                        <p>
                          <code>chown mapred:hadoop /etc/security/keytabs/jhs.service.keytab
                            chmod 400 /etc/security/keytabs/jhs.service.keytab
                            chown root:hadoop /etc/security/keytabs/spnego.service.keytab
                            chmod 440 /etc/security/keytabs/spnego.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the host that runs the YARN ResourceManager:</p>
                        <p>
                          <code>
                            chown yarn:hadoop /etc/security/keytabs/rm.service.keytab
                            chmod 400 /etc/security/keytabs/rm.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On each host that runs a YARN NodeManager:</p>
                        <p>
                          <code>
                          </code>
                          <code>chown yarn:hadoop /etc/security/keytabs/nm.service.keytab
                            chmod 400 /etc/security/keytabs/nm.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the host that runs the Oozie Server:</p>
                        <p>
                          <code>chown oozie:hadoop /etc/security/keytabs/oozie.service.keytab
                            chmod 400 /etc/security/keytabs/oozie.service.keytab
                            chown root:hadoop /etc/security/keytabs/spnego.service.keytab
                            chmod 440 /etc/security/keytabs/spnego.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the host that runs the Hive Metastore, HiveServer2 and WebHCat:</p>
                        <p>
                          <code>chown hive:hadoop /etc/security/keytabs/hive.service.keytab
                            chmod 400 /etc/security/keytabs/hive.service.keytab
                            chown root:hadoop /etc/security/keytabs/spnego.service.keytab
                            chmod 440 /etc/security/keytabs/spnego.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On hosts that run the HBase MasterServer, RegionServer and ZooKeeper:</p>
                        <p>
                          <code>chown hbase:hadoop /etc/security/keytabs/hbase.service.keytab
                            chmod 400 /etc/security/keytabs/hbase.service.keytab
                            chown zookeeper:hadoop /etc/security/keytabs/zk.service.keytab
                            chmod 400 /etc/security/keytabs/zk.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the host that runs the Nagios server:</p>
                        <p>
                          <code>chown nagios:nagios /etc/security/keytabs/nagios.service.keytab
                            chmod 400 /etc/security/keytabs/nagios.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On each host that runs a JournalNode, if you are setting up NameNode HA:</p>
                        <p>
                          <code>chown hdfs:hadoop /etc/security/keytabs/jn.service.keytab
                            chmod 400 /etc/security/keytabs/jn.service.keytab
                          </code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Verify that the correct keytab files and principals are associated with the correct service
                    using the
                    <code>klist</code>
                    command. For example, on the NameNode:
                    <code>klist –k -t /etc/security/keytabs/nn.service.keytab</code>
                    Do this on each respective service in your cluster.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Creating Service Principals and Keytab Files for HDP 1.x</h4>
          
            <p>Each service and sub-service in Hadoop must have its own principal. A principal name in a given
              realm consists of a primary name and an instance name, which in this case is the FQDN of the host that
              runs that service. As services do not log in with a password to acquire their tickets, their principal's
              authentication credentials are stored in a keytab file, which is extracted from the Kerberos database and
              stored locally with the service principal on the service component host.
            </p>
            <p>
              First, you must create the principal, using mandatory naming conventions. Then you must create the keytab
              file with that principal's information and copy the file to the keytab directory on the appropriate
              service host.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>Principals can be created either on the KDC machine itself or through the network, using an
                  “admin” principal. The following instructions assume you are using the KDC machine and using the
                  <code>kadmin.local</code>
                  command line administration utility. Using
                  <code>kadmin.local</code>
                  on the KDC machine allows you to create principals without needing to create a separate "admin"
                  principal before you start.
                </p>
              </div>
            </aside>
            <ul class="number-list">
              
                <li>
                  <p>Open the
                    <code>kadmin.local</code>
                    utility on the KDC machine
                  </p>
                  <p>
                    <code>
                    </code>
                    <code>/usr/sbin/kadmin.local</code>
                  </p>
                </li>
                <li>
                  <p>Create the service principals:
                    <code>$kadmin.local
                      addprinc -randkey $primary_name / $fully.qualified.domain.name @EXAMPLE.COM
                    </code>
                  </p>
                  <p>
                    The
                    <code>-randkey</code>
                    option is used to generate the password.
                  </p>
                  <p>
                    Notice in the example that each service principal's primary name has appended to it the instance
                    name, the FQDN of the host on which it runs. This provides a unique principal name for services that
                    run on multiple hosts, like DataNodes and TaskTrackers. The addition of the host name serves to
                    distinguish, for example, a request from DataNode A from a request from DataNode B. This is
                    important for the following reasons:
                  </p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>If the Kerberos credentials for one DataNode are compromised, it does not
                          automatically lead to all DataNodes being compromised
                        </p>
                      </li>
                      <li>
                        <p>If multiple DataNodes have exactly the same principal and are simultaneously
                          connecting to the NameNode, and if the Kerberos authenticator being sent happens to have same
                          time stamp, then the authentication would be rejected as a replay request.
                        </p>
                      </li>
                    
                  </ul>
                  <p>
                    The principal name must match the following values:
                  </p>
                  <div class="xyleme-table"><table border="1">
                    <p class="italic bold">Service Principals</p>
                    
                      
                      
                      
                      <thead>
                        <tr>
                          <th rowspan="1">
                            <p>Service</p>
                          </th>
                          <th rowspan="1">
                            <p>Component</p>
                          </th>
                          <th rowspan="1">
                            <p>Mandatory Principal Name</p>
                          </th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>NameNode</p>
                          </td>
                          <td rowspan="1">
                            <p>nn/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>NameNode HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>SecondaryNameNode</p>
                          </td>
                          <td rowspan="1">
                            <p>nn/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>SecondaryNameNode HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HDFS</p>
                          </td>
                          <td rowspan="1">
                            <p>DataNode</p>
                          </td>
                          <td rowspan="1">
                            <p>dn/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>MapReduce</p>
                          </td>
                          <td rowspan="1">
                            <p>JobTracker</p>
                          </td>
                          <td rowspan="1">
                            <p>jt/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>MapReduce</p>
                          </td>
                          <td rowspan="1">
                            <p>TaskTracker</p>
                          </td>
                          <td rowspan="1">
                            <p>tt/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Oozie</p>
                          </td>
                          <td rowspan="1">
                            <p>Oozie Server</p>
                          </td>
                          <td rowspan="1">
                            <p>oozie/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Oozie</p>
                          </td>
                          <td rowspan="1">
                            <p>Oozie HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Hive</p>
                          </td>
                          <td rowspan="1">
                            <p>Hive Metastore HiveServer2</p>
                          </td>
                          <td rowspan="1">
                            <p>hive/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Hive</p>
                          </td>
                          <td rowspan="1">
                            <p>WebHCat</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HBase</p>
                          </td>
                          <td rowspan="1">
                            <p>MasterServer</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HBase</p>
                          </td>
                          <td rowspan="1">
                            <p>RegionServer</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>ZooKeeper</p>
                          </td>
                          <td rowspan="1">
                            <p>ZooKeeper</p>
                          </td>
                          <td rowspan="1">
                            <p>zookeeper/$FQDN</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Nagios Server</p>
                          </td>
                          <td rowspan="1">
                            <p>Nagios</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios/$FQDN</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                  <p>
                    <strong>For example</strong>
                    : To create the principal for a DataNode service, issue the following command:
                    <code>$kadmin.local
                      addprinc -randkey dn/$DataNode-Host@EXAMPLE.COM
                    </code>
                  </p>
                </li>
                <li>
                  <p>In addition you must create four special principals for Ambari's own use.</p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>The names in the following table can be customized in the Customize Services step of the
                        Ambari Install Wizard. If this is the case in your installation, the principal names should
                        match the customized names. For example, if the HDFS Service User has been set to<code>
                          hdfs1</code>, the respective principal for the Ambari HDFS User should also be created
                        as<code>hdfs1</code>.
                      </p>
                    </div>
                  </aside>
                  <p>You do NOT need to append the FQDN to the primary name:</p>
                  <div class="xyleme-table"><table border="1">
                    <p class="italic bold">Ambari Principals</p>
                    
                      
                      
                      <thead>
                        <tr>
                          <th rowspan="1">
                            <p>User</p>
                          </th>
                          <th rowspan="1">
                            <p>Default Principal Name</p>
                          </th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari UserThis principal is used with the JAAS configuration. See Setting Up JAAS
                              for Ambari for more information.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>ambari</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Smoke Test User</p>
                          </td>
                          <td rowspan="1">
                            <p>ambari-qa</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari HDFS User</p>
                          </td>
                          <td rowspan="1">
                            <p>hdfs</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari HBase User</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                </li>
                <li>
                  <p>After the principals are created in the database, you can extract the related keytab files
                    for transfer to the appropriate host:
                    <code>$kadmin.local
                      xst -norandkey -k $keytab_file_name $primary_name/fully.qualified.domain.name@EXAMPLE.COM
                    </code>
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>Some older versions of Kerberos do not support the xst
                        <code>-norandkey</code>
                        option. You can use the command without the
                        <code>-norandkey</code>
                        flag, except in cases where you need to merge two principals with the same name into a single
                        keytab file for a single host. In this case, you can use the two step
                        <code>kadmin</code>
                        /
                        <code>ktutil</code>
                        procedure. This description assumes MIT Kerberos. If you are using another version, please check
                        the documentation for that version.
                      </p>
                      <ul class="number-list">
                        
                          <li>
                            <p>Extract the keytab file information.</p>
                            <p>
                              <code>$kadmin
                                xst -k $keytab_file_name-temp1$primary_name /fully.qualified.domain.name@EXAMPLE.COM
                                xst -k $keytab_file_name-temp2$primary_name /fully.qualified.domain.name@EXAMPLE.COM
                              </code>
                            </p>
                          </li>
                          <li>
                            <p>Merge the keytabs into a single file.</p>
                            <p>
                              <code>$kutil
                                rkt $keytab_file_name-temp1
                                rkt $keytab_file_name-temp2
                                wkt $keytab_file_name
                                clear
                              </code>
                              <code></code>
                            </p>
                          </li>
                        
                      </ul>
                    </div>
                  </aside>
                  <p>
                    You must use the mandatory names for the
                    &lt;keytab_file_name&gt;
                    variable shown in the following table. Adjust the principal names if necessary.
                  </p>
                  <div class="xyleme-table"><table border="1">
                    <p class="italic bold">Service Keytab File Names</p>
                    
                      
                      
                      
                      <thead>
                        <tr>
                          <th rowspan="1">
                            <p>Component</p>
                          </th>
                          <th rowspan="1">
                            <p>Principal Name</p>
                          </th>
                          <th rowspan="1">
                            <p>Mandatory Keytab File Name</p>
                          </th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td rowspan="1">
                            <p>NameNode</p>
                          </td>
                          <td rowspan="1">
                            <p>nn/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>nn.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>NameNode HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>spnego.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>SecondaryNameNode</p>
                          </td>
                          <td rowspan="1">
                            <p>nn/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>nn.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>SecondaryNameNode HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>spnego.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>DataNode</p>
                          </td>
                          <td rowspan="1">
                            <p>dn/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>dn.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>JobTracker</p>
                          </td>
                          <td rowspan="1">
                            <p>jt/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>jt.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>TaskTracker</p>
                          </td>
                          <td rowspan="1">
                            <p>tt/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>tt.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Oozie Server</p>
                          </td>
                          <td rowspan="1">
                            <p>oozie/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>oozie.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Oozie HTTP</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>spnego.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Hive Metastore HiveServer2</p>
                          </td>
                          <td rowspan="1">
                            <p>hive/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>hive.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>WebHCat</p>
                          </td>
                          <td rowspan="1">
                            <p>HTTP/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>spnego.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HBase Master Server</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>HBase RegionServer</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>ZooKeeper</p>
                          </td>
                          <td rowspan="1">
                            <p>zookeeper/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>zk.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Nagios Server</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios/$FQDN</p>
                          </td>
                          <td rowspan="1">
                            <p>nagios.service.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari UserThis principal is used with the JAAS configuration. See Setting Up JAAS
                              for Ambari for more information.
                            </p>
                          </td>
                          <td rowspan="1">
                            <p>ambari</p>
                          </td>
                          <td rowspan="1">
                            <p>ambari.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari Smoke Test User</p>
                          </td>
                          <td rowspan="1">
                            <p>ambari-qa</p>
                          </td>
                          <td rowspan="1">
                            <p>smokeuser.headless.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari HDFS User</p>
                          </td>
                          <td rowspan="1">
                            <p>hdfs</p>
                          </td>
                          <td rowspan="1">
                            <p>hdfs.headless.keytab</p>
                          </td>
                        </tr>
                        <tr>
                          <td rowspan="1">
                            <p>Ambari HBase User</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase</p>
                          </td>
                          <td rowspan="1">
                            <p>hbase.headless.keytab</p>
                          </td>
                        </tr>
                      </tbody>
                      
                    
                  </table></div>
                  <p>
                    <strong>For example</strong>
                    : To create the keytab files for NameNode HTTP, issue this command:
                  </p>
                  <p>
                    <code>xst -norandkey -k spnego.service.keytab HTTP/</code>
                    &lt;namenode-host&gt;
                  </p>
                  <aside class="custom-note">
                    <div class="icon"><img src="Icons/Note.png" width="50"></div>
                    <div class="simple-block">
                      <p>If you have a large cluster, you may want to create a script to automate creating your
                        principals and keytabs. The Ambari Web GUI can help. For further information see
                        <a href="#ref-d0b2f2d1-904f-4982-8f83-26dc53d884bd">Creating Service Principals and
                          Keytab Files for HDP 2.x
                        </a>
                        or<a href="#ref-f8683307-21bb-40ac-968f-7b810be76d58">Creating Service Principals and
                          Keytab Files for HDP 1.x</a>.
                      </p>
                    </div>
                  </aside>
                </li>
                <li>
                  <p>When the keytab files have been created, on each host create a directory for them and set
                    appropriate permissions.
                  </p>
                  <p>
                    <code>mkdir -p /etc/security/keytabs/
                      chown root:hadoop /etc/security/keytabs
                      chmod 750 /etc/security/keytabs
                    </code>
                  </p>
                </li>
                <li>
                  <p>Copy the appropriate keytab file to each host. If a host runs more than one component (for
                    example, both TaskTracker and DataNode), copy keytabs for both components. The Ambari Smoke Test
                    User, the Ambari HDFS User, and the Ambari HBase User keytabs should be copied to all hosts.
                  </p>
                </li>
                <li>
                  <p>Set appropriate permissions for the keytabs.</p>
                  <p>
                    If you have customized service user names, replace the default values below with your appropriate
                    service user, group, and keytab names.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Optionally, if you have
                          <a href="#ref-04f03c43-badc-48ac-a335-0f44530b49bd">Set up JAAS for Ambari</a>
                          on the Ambari server host:
                        </p>
                        <p>
                          <code>chown ambari:ambari /etc/security/keytabs/ambari.keytab
                            chmod 400 /etc/security/keytabs/ambari.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the HDFS NameNode and SecondaryNameNode hosts:</p>
                        <p>
                          <code>chown hdfs:hadoop /etc/security/keytabs/nn.service.keytab
                            chmod 400 /etc/security/keytabs/nn.service.keytab
                            chown root:hadoop /etc/security/keytabs/spnego.service.keytab
                            chmod 440 /etc/security/keytabs/spnego.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the HDFS NameNode host, for the Ambari Test Users:</p>
                        <p>
                          <code>
                            chown ambari-qa:hadoop /etc/security/keytabs/smokeuser.headless.keytab
                            chmod 440 /etc/security/keytabs/smokeuser.headless.keytab
                            chown hdfs:hadoop /etc/security/keytabs/hdfs.headless.keytab
                            chmod 440 /etc/security/keytabs/hdfs.headless.keytab
                            chown hbase:hadoop /etc/security/keytabs/hbase.headless.keytab
                            chmod 440 /etc/security/keytabs/hbase.headless.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On each host that runs an HDFS DataNode:</p>
                        <p>
                          <code>chown hdfs:hadoop /etc/security/keytabs/dn.service.keytab
                            chmod 400 /etc/security/keytabs/dn.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the host that runs the MapReduce JobTracker:</p>
                        <p>
                          <code>chown mapred:hadoop /etc/security/keytabs/jt.service.keytab
                            chmod 400 /etc/security/keytabs/jt.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On each host that runs a MapReduce TaskTracker:</p>
                        <p>
                          <code>chown mapred:hadoop /etc/security/keytabs/tt.service.keytab
                            chmod 400 /etc/security/keytabs/tt.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the host that runs the Oozie Server:</p>
                        <p>
                          <code>chown oozie:hadoop /etc/security/keytabs/oozie.service.keytab
                            chmod 400 /etc/security/keytabs/oozie.service.keytab
                            chown root:hadoop /etc/security/keytabs/spnego.service.keytab
                            chmod 440 /etc/security/keytabs/spnego.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the host that runs the Hive Metastore, HiveServer2 and WebHCat:</p>
                        <p>
                          <code>chown hive:hadoop /etc/security/keytabs/hive.service.keytab
                            chmod 400 /etc/security/keytabs/hive.service.keytab
                            chown root:hadoop /etc/security/keytabs/spnego.service.keytab
                            chmod 440 /etc/security/keytabs/spnego.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On hosts that run the HBase MasterServer, RegionServer and ZooKeeper:</p>
                        <p>
                          <code>chown hbase:hadoop /etc/security/keytabs/hbase.service.keytab
                            chmod 400 /etc/security/keytabs/hbase.service.keytab
                            chown zookeeper:hadoop /etc/security/keytabs/zk.service.keytab
                            chmod 400 /etc/security/keytabs/zk.service.keytab
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>On the host that runs the Nagios server:</p>
                        <p>
                          <code>chown nagios:nagios /etc/security/keytabs/nagios.service.keytab
                            chmod 400 /etc/security/keytabs/nagios.service.keytab
                          </code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Verify that the correct keytab files and principals are associated with the correct service
                    using the
                    <code>klist</code>
                    command. For example, on the NameNode:
                    <code>
                      klist –k -t /etc/security/keytabs/nn.service.keytab .
                    </code>
                    Do this on each respective service in your cluster.
                  </p>
                </li>
              
            </ul>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-36f47ef6-1164-49fd-8eca-9391317f73c9">Setting Up Hadoop Users</h3>
        
          <p>This section provides information on setting up Hadoop users for Kerberos.</p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-27d9fb8e-1c93-46a3-8be7-b6cd499a7125">Overview</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-cafd5dce-5ade-4651-82c5-dad6dad02fdc">Creating Mappings Between Principals and
                    UNIX Usernames
                  </a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Overview</h4>
          
            <p>Hadoop determines group file ownership and access control based on each user's group memberships.
              To configure Hadoop for use with Kerberos and Ambari you must create a mapping between service principals
              and these UNIX user names.
            </p>
            <p>
              A user is mapped to the groups in which it belongs using an implementation of the <code>
              GroupMappingServiceProviderinterface</code>. The implementation is pluggable and is configured in 
              <code>core-site.xml</code>.
            </p>
            <p>
              By default Hadoop uses <code>ShellBasedUnixGroupsMapping</code>, which is an implementation of
              <code>GroupMappingServiceProvider</code>. It fetches the group membership for a user name by
              executing a UNIX shell command. In secure clusters, since the user names are actually Kerberos
              principals, 
              <code>ShellBasedUnixGroupsMapping</code>
              will work only if the Kerberos principals map to valid UNIX user names. Hadoop provides a feature that
              lets administrators specify mapping rules to map a Kerberos principal to a local UNIX user name.
            </p>
          
        
        
          <h4 class="bold">Creating Mappings Between Principals and UNIX User names</h4>
          
            <p>Hadoop uses a rule-based system to create mappings between service principals and their related
              UNIX user names. The rules are specified in the
              <code>core-site.xml</code>
              configuration file as the value to the optional key<code>hadoop.security.auth_to_local</code>.
            </p>
            <p>
              The default rule is simply named<code>DEFAULT</code>. It translates all principals in your
              default domain to their first component. For example,
              <code>myusername@APACHE.ORG</code>
              and
              <code>myusername/admin@APACHE.ORG</code>
              both become<code>myusername</code>, assuming your default domain is APACHE.ORG.
            </p>
            <p>
              Use the following instructions to configure the mappings between principals and UNIX user names:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>
                    <a href="#ref-522eebb0-f10b-4f81-8e52-3cfe89234594">Creating Rules</a>
                  </p>
                </li>
                <li>
                  <p>
                    <a href="#ref-cafdcc6b-53ee-458c-8c43-35e43ff53544">Examples</a>
                  </p>
                </li>
              
            </ul>
          
          
            <h4 class="bold">Creating Rules</h4>
            
              <ul class="bullet-list">
                
                  <li>
                    <p>Simple Rules</p>
                    <p>
                      To make a simple map between principal names and UNIX users, you create a straightforward
                      substitution rule. For example, to map the ResourceManager(rm) and NodeManager(nm) principals in
                      the EXAMPLE.COM realm to the UNIX
                      $YARN_USER
                      user and the NameNode(nn) and DataNode(dn) principals to the UNIX
                      $HDFS_USER
                      user, you would make this the value for the
                      <code>hadoop.security.auth_to_local</code>
                      key in<code>core-site.xml</code>.
                    </p>
                    <p>
                      <code>RULE:[2:$1@$0]([jt]t@.*EXAMPLE.COM)s/.*/ $YARN_USER /
                        RULE:[2:$1@$0]([nd]n@.*EXAMPLE.COM)s/.*/ $HDFS_USER /
                        DEFAULT
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>Complex Rules</p>
                    <p>
                      To accommodate more complex translations, you create a hierarchical set of rules to add to the
                      default. Each rule is divided into three parts: base, filter, and substitution.
                    </p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>
                            <strong>The Base:</strong>
                          </p>
                          <p>
                            The base begins with the number of components in the principal name (excluding the realm),
                            followed by a colon, and the pattern for building the user name from the sections of the
                            principal name. In the pattern section
                            <code>$0</code>
                            translates to the realm,
                            <code>$1</code>
                            translates to the first component and
                            <code>$2</code>
                            to the second component.
                          </p>
                          <p>
                            For example:
                          </p>
                          <p>
                            <code>
                              [1:$1@$0]
                            </code>
                            translates
                            <code>myusername@APACHE.ORG</code>
                            to
                            <code>myusername@APACHE.ORG</code>
                          </p>
                          <p>
                            <code>[2:$1]</code>
                            translates
                            <code>myusername/admin@APACHE.ORG</code>
                            to
                            <code>myusername</code>
                          </p>
                          <p>
                            <code>[2:$1%$2]</code>
                            translates
                            <code>myusername/admin@APACHE.ORG</code>
                            to
                            <code>myusername%admin</code>
                          </p>
                        </li>
                        <li>
                          <p>
                            <strong>The Filter:</strong>
                          </p>
                          <p>
                            The filter consists of a regex in a parentheses that must match the generated string for the
                            rule to apply.
                          </p>
                          <p>
                            For example:
                          </p>
                          <p>
                            <code>(.*%admin)</code>
                            matches any string that ends in
                            <code>%admin</code>
                          </p>
                          <p>
                            <code>(.*@SOME.DOMAIN)</code>
                            matches any string that ends in
                            <code>@SOME.DOMAIN</code>
                          </p>
                        </li>
                        <li>
                          <p>
                            <strong>The Substitution:</strong>
                          </p>
                          <p>
                            The substitution is a sed rule that translates a regex into a fixed string.
                          </p>
                          <p>
                            For example:
                          </p>
                          <p>
                            <code>s/@ACME\.COM//</code>
                            removes the first instance of<code>@SOME.DOMAIN</code>.
                          </p>
                          <p>
                            <code>s/@[A-Z]*\.COM//</code>
                            removes the first instance of
                            <code>@</code>
                            followed by a name followed by<code>COM</code>.
                          </p>
                          <p>
                            <code>s/X/Y/g</code>
                            replaces all of the
                            <code>X</code>
                            in the name with
                            <code>Y</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Examples</h4>
            
              <ul class="bullet-list">
                
                  <li>
                    <p>If your default realm was<code>APACHE.ORG</code>, but you also wanted to take
                      all principals from
                      <code>ACME.COM</code>
                      that had a single component<code>joe@ACME.COM</code>, you would create this rule:
                    </p>
                    <p>
                      <code>RULE:[1:$1@$0](.*@ACME\.COM)s/@.*//
                        DEFAULT
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>To also translate names with a second component, you would use these rules:</p>
                    <p>
                      <code>RULE:[1:$1@$0](.*@ACME\.COM)s/@.*//
                        RULE:[2:$1@$0](.*@ACME\.COM)s/@.*//
                        DEFAULT
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>To treat all principals from
                      <code>APACHE.ORG</code>
                      with the extension
                      <code>/admin</code>
                      as<code>admin</code>, your rules would look like this:
                    </p>
                    <p>
                      <code>RULE[2:$1%$2@$0](.*%admin@APACHE\.ORG)s/.*/admin/
                        DEFAULT
                      </code>
                    </p>
                  </li>
                
              </ul>
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-a9927c0e-595d-45b8-b574-a2d401685ccd">Setting up Ambari for Kerberos</h3>
        
          <p>To turn on Kerberos-based security in the Ambari Web GUI you must:</p>
          <ul class="number-list">
            
              <li>
                <p>Have already set up Kerberos for your cluster.
                  For more information, see<a href="#ref-4a8722b7-505e-4aa1-9256-9fff03c0d000">Preparing
                    Kerberos for Hadoop</a>.
                </p>
              </li>
              <li>
                <p>Go to the
                  <code>Admin</code>
                  tab.
                </p>
              </li>
              <li>
                <p>Select<code>Security</code>.
                </p>
              </li>
              <li>
                <p>Click
                  <code>Enable Security</code>
                  and follow the steps in the<code>Enable Security Wizard</code>.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/newkerb_2x.png" width="50">
                    
                  
                </div>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Setting up JAAS for Ambari</h4>
          
            <p>If you want to set up Java Authentication and Authorization Services (JAAS) configurations for
              Ambari to provide independent, secure access to native Hadoop GUIs such as the NameName UI, use the Apache
              community documentation topic
              <a href="http://ambari.apache.org/1.2.5/installing-hadoop-using-ambari/content/ambari-kerb-2-3-2-2.html">
                Create the JAAS Configuration Files
              </a>
              to set up your configurations. Then, do the following:
            </p>
            <ul class="number-list">
              
                <li>
                  <p>Log into the Ambari server host.</p>
                  <p>
                    Ambari Server should not be running when you do this. Edit configuration files before you start
                    Ambari Server the first time or, stop the Ambari Server, edit the files, then re-start Ambari
                    Server.
                  </p>
                </li>
                <li>
                  <p>Run the following, specific setup-security command and answer the prompts:</p>
                  <p>
                    <code>ambari-server setup-security</code>
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Select 5 for<code>Setup Ambari kerberos JAAS
                          configuration</code>.
                        </p>
                      </li>
                      <li>
                        <p>Enter the Kerberos principal name for the Ambari server you set up earlier.</p>
                      </li>
                      <li>
                        <p>Enter the path to the keytab for the Ambari principal.</p>
                      </li>
                      <li>
                        <p>Restart Ambari Server:</p>
                        <p>
                          <code>ambari-server restart</code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Deploying JCE Policy Archives on the Ambari Server</h4>
          
            <p>On a secure cluster having no internet access, you must deploy the Java Cryptography Extension
              (JCE) security policy.jar files on the Ambari Server, before setting up your Ambari server with a custom
              JDK.
            </p>
            <p>
              When you<a href="#ref-a9927c0e-595d-45b8-b574-a2d401685ccd">enable security</a>, Ambari
              distributes the JCE.jars to all appropriate hosts in your cluster.
            </p>
            <p>
              To obtain and deploy the JCE.jar files appropriate for the JDK version in your cluster on your
              Ambari-server host,
            </p>
            <ul class="number-list">
              
                <li>
                  <p>Download the archive from one of the following locations</p>
                  <p>
                    <strong>For JDK 1.6</strong>
                    :
                    <a href="http://www.oracle.com/technetwork/java/javase/downloads/jce-6-download-429243.html">
                      http://www.oracle.com/technetwork/java/javase/downloads/jce-6-download-429243.html
                    </a>
                  </p>
                  <p>
                    <strong>For JDK 1.7</strong>
                    :
                    <a href="http://www.oracle.com/technetwork/java/javase/downloads/jce-7-download-432124.html">
                      http://www.oracle.com/technetwork/java/javase/downloads/jce-7-download-432124.html
                    </a>
                  </p>
                </li>
                <li>
                  <p>Save the archive in a temporary location.</p>
                </li>
                <li>
                  <p>Copy the archive to
                    <code>/var/lib/ambari-server/resources</code>
                    on the Ambari server.
                  </p>
                </li>
              
            </ul>
          
        
      
    
    
      <h2 class="horton-green bold">Advanced Security Options for Ambari</h2>
      
        
          <p>This section describes several security options for an Ambari-monitored-and-managed Hadoop
            cluster.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-59ed617d-03bc-4d41-964a-fec60deaa043">Setting Up LDAP or Active Directory
                    Authentication
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-a33359d6-2802-45a8-90c9-fc3fd20c9753">Encrypt Database and LDAP Passwords
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-2d711515-048d-4662-89ff-222d2ce3e1be">Set Up Security for Ambari</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-7ee44c15-f6a4-4a22-890c-442c5edde87c">Set Up Two-Way SSL Between Ambari Server
                    and Ambari Agents
                  </a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-b810db92-97de-4d4e-a905-239e2b8a2a04">Setting Up Ambari for LDAP or Active Directory Authentication</h3>
        
          <p>By default Ambari uses an internal database as the user store for authentication and authorization.
            If you want to configure LDAP or Active Directory (AD) external authentication, you need to
            <a href="#ref-59ed617d-03bc-4d41-964a-fec60deaa043">collect the following information</a>
            and<a href="#ref-443fec0b-ef35-4829-bab9-14b83a416e4c">run a setup command</a>.
          </p>
          <p>
            Also, you must synchronize your LDAP users and groups into the Ambari DB to be able to manage authorization
            and permissions against those users and groups.
          </p>
        
        
          <h4 class="bold">Setting Up LDAP User Authentication</h4>
          
            <p>The following table details the properties and values you need to know to set up LDAP
              authentication.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>
                  If you are going to set
                  <code>bindAnonymously</code>
                  to false (the default), you need to make sure you have an LDAP Manager name and password set up. If
                  you are going to use SSL, you need to make sure you have already set up your certificate and keys.
                </p>
              </div>
            </aside>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">Ambari Server LDAP Properties</p>
              
                
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Property</p>
                    </th>
                    <th rowspan="1">
                      <p>Values</p>
                    </th>
                    <th rowspan="1">
                      <p>Description</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.primaryUrl</p>
                    </td>
                    <td rowspan="1">
                      <p>server:port</p>
                    </td>
                    <td rowspan="1">
                      <p>The hostname and port for the LDAP or AD server. Example: my.ldap.server:389</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.secondaryUrl</p>
                    </td>
                    <td rowspan="1">
                      <p>server:port</p>
                    </td>
                    <td rowspan="1">
                      <p>The hostname and port for the secondary LDAP or AD server. Example:
                        my.secondary.ldap.server:389 This is an optional value.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.useSSL</p>
                    </td>
                    <td rowspan="1">
                      <p>true or false</p>
                    </td>
                    <td rowspan="1">
                      <p>If true, use SSL when connecting to the LDAP or AD server.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.usernameAttribute</p>
                    </td>
                    <td rowspan="1">
                      <p>[LDAP attribute]</p>
                    </td>
                    <td rowspan="1">
                      <p>The attribute for username. Example: uid</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.baseDn</p>
                    </td>
                    <td rowspan="1">
                      <p>[Distinguished Name]</p>
                    </td>
                    <td rowspan="1">
                      <p>The root Distinguished Name to search in the directory for users. Example:
                        ou=people,dc=hadoop,dc=apache,dc=org
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.bindAnonymously</p>
                    </td>
                    <td rowspan="1">
                      <p>true or false</p>
                    </td>
                    <td rowspan="1">
                      <p>If true, bind to the LDAP or AD server anonymously</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.managerDn</p>
                    </td>
                    <td rowspan="1">
                      <p>[Full Distinguished Name]</p>
                    </td>
                    <td rowspan="1">
                      <p>If Bind anonymous is set to false, the Distinguished Name (“DN”) for the manager.
                        Example: uid=hdfs,ou=people,dc=hadoop,dc=apache,dc=org
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.managerPassword</p>
                    </td>
                    <td rowspan="1">
                      <p>[password]</p>
                    </td>
                    <td rowspan="1">
                      <p>If Bind anonymous is set to false, the password for the manager</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.userObjectClass
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>[LDAP Object Class]
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>The object class that is used for users.
                        Example: organizationalPerson
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.groupObjectClass</p>
                    </td>
                    <td rowspan="1">
                      <p>[LDAP Object Class]</p>
                    </td>
                    <td rowspan="1">
                      <p>The object class that is used for groups.
                        Example: groupOfUniqueNames
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.groupMembershipAttr</p>
                    </td>
                    <td rowspan="1">
                      <p>[LDAP attribute]</p>
                    </td>
                    <td rowspan="1">
                      <p>The attribute for group membership.
                        Example: uniqueMember
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>authentication.ldap.groupNamingAttr</p>
                    </td>
                    <td rowspan="1">
                      <p>[LDAP attribute]</p>
                    </td>
                    <td rowspan="1">
                      <p>The attribute for group name.</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
          
            <h4 class="bold">Configure Ambari to use LDAP Server</h4>
            
              <p>If the LDAPS server certificate is signed by a trusted Certificate Authority, there is no need
                to import the certificate into Ambari so this section does not apply to you. If the LDAPS server
                certificate is self-signed, or is signed by an unrecognized certificate authority such as an internal
                certificate authority, you must import the certificate and create a keystore file. The following example
                creates a keystore file at /keys/ldaps-keystore.jks, but you can create it anywhere in the file system:

                Run the LDAP setup command on the Ambari server and answer the prompts, using the information you
                collected above:
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>
                      <code>mkdir /keys</code>
                    </p>
                  </li>
                  <li>
                    <p>
                      <code>$JAVA_HOME/bin/keytool -import -trustcacerts -alias root -file
                        $PATH_TO_YOUR_LDAPS_CERT -keystore /keys/ldaps-keystore.jks
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>Set a password when prompted. You will use this during ambari-server setup-ldap.
                    </p>
                  </li>
                
              </ul>
              <p>
                <code>
                  ambari-server setup-ldap
                </code>
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>At the
                      <code>Primary URL*</code>
                      prompt, enter the server URL and port you collected above. Prompts marked with an asterisk are
                      required values.
                    </p>
                  </li>
                  <li>
                    <p>At the
                      <code>Secondary URL</code>
                      prompt, enter the secondary server URL and port. This value is optional.
                    </p>
                  </li>
                  <li>
                    <p>At the
                      <code>Use SSL*</code>
                      prompt, enter your selection.
                      <strong>
                        <i>If using LDAPS</i>
                      </strong>
                      , enter<code>true</code>.
                    </p>
                  </li>
                  <li>
                    <p>At the
                      <code>User name attribute*</code>
                      prompt, enter your selection. The default value is<code>uid</code>.
                    </p>
                  </li>
                  <li>
                    <p>At the
                      <code>Base DN*</code>
                      prompt, enter your selection.
                    </p>
                  </li>
                  <li>
                    <p>At the
                      <code>Bind anonymously*</code>
                      prompt, enter your selection.
                    </p>
                  </li>
                  <li>
                    <p>At the
                      <code>Manager DN*</code>
                      prompt, enter your selection if you have set
                      <code>bind.Anonymously</code>
                      to false.
                    </p>
                  </li>
                  <li>
                    <p>At the<code>Enter the Manager Password*</code>prompt, enter
                      the password for your LDAP manager.
                    </p>
                  </li>
                  <li>
                    <p>At the Enter the
                      <code>userObjectClass*</code>
                      prompt, enter the object class that is used for users.
                    </p>
                  </li>
                  <li>
                    <p>At the Enter the
                      <code>groupObjectClass</code>
                      <code>*</code>
                      prompt, enter the object class that is used for groups.
                    </p>
                  </li>
                  <li>
                    <p>At the Enter the
                      <code>groupMembershipAttr</code>
                      <code>*</code>
                      prompt, enter the attribute for group membership.
                    </p>
                  </li>
                  <li>
                    <p>At the Enter the
                      <code>groupNamingAttr</code>
                      <code>*</code>
                      prompt, enter the attribute for group name.
                    </p>
                  </li>
                  <li>
                    <p>If you set
                      <code>Use SSL*</code>
                      = true in step 3, the following prompt appears:
                      <code>Do you want to provide custom TrustStore for Ambari?</code>
                    </p>
                    <p>Consider the following options and respond as appropriate.</p>
                    <ul class="Bullet">
                      
                        <li>
                          <p>
                            <strong>More secure option:</strong>
                            If using a self-signed certificate that you do not want imported to the existing JDK
                            keystore, enter<code>y</code>.
                          </p>
                          <p>
                            For example, you want this certificate used only by Ambari, not by any other applications
                            run by JDK on the same host.
                          </p>
                          <p>
                            If you choose this option, additional prompts appear. Respond to the additional prompts as
                            follows:
                          </p>
                          <ul class="Numeric">
                            
                              <li>
                                <p>At the
                                  <code>TrustStore type</code>
                                  prompt, enter<code>jks</code>.
                                </p>
                              </li>
                              <li>
                                <p>At the<code>Path to TrustStore file</code>
                                  prompt, enter
                                  <code>/keys/ldaps-keystore.jks</code>
                                  (or the actual path to your keystore file).
                                </p>
                              </li>
                              <li>
                                <p>At the
                                  <code>Password for TrustStore</code>
                                  prompt, enter the password that you defined for the keystore.
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                        <li>
                          <p>
                            <strong>Less secure option:</strong>
                            If using a self-signed certificate that you want to import and store in the existing,
                            default JDK keystore, enter<code>n</code>.
                          </p>
                          <ul class="Numeric">
                            
                              <li>
                                <p>Convert the SSL certificate to X.509 format, if necessary, by executing the
                                  following command:
                                </p>
                                <p>
                                  <code>openssl x509 -in slapd.pem -out</code>
                                  &lt;slapd.crt&gt;
                                </p>
                                <p>Where
                                  &lt;slapd.crt&gt;
                                  is the path to the X.509 certificate.
                                </p>
                              </li>
                              <li>
                                <p>Import the SSL certificate to the existing keystore, for example the default
                                  jre certificates storage, using the following instruction:
                                </p>
                                <p>
                                  <code>/usr/jdk64/jdk1.7.0_45/bin/keytool -import -trustcacerts -file
                                    slapd.crt -keystore /usr/jdk64/jdk1.7.0_45/jre/lib/security/cacerts
                                  </code>
                                </p>
                                <p>Where Ambari is set up to use JDK 1.7. Therefore, the certificate must be
                                  imported in the JDK 7 keystore.
                                </p>
                              </li>
                            
                          </ul>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>Review your settings and if they are correct, select<code>y</code>.
                    </p>
                  </li>
                  <li>
                    <p>Start or restart the Server</p>
                    <p>
                      <code>ambari-server restart</code>
                    </p>
                    <p>Initially the users you have enabled all have Ambari User privileges. Ambari Users can
                      read metrics, view service status and configuration, and browse job information. For these new
                      users to be able to start or stop services, modify configurations, and run smoke tests, they need
                      to be Admins. To make this change, as an Ambari Admin, use<code>Manage Ambari &gt;
                        Users &gt; Edit</code>. For instructions, see Managing Users and Groups.
                    </p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Synchronizing LDAP Users and Groups</h4>
            
              <p>Run the LDAP synchronize command and answer the prompts to initiate the sync:

                <code>ambari-server sync-ldap [option]</code>
              </p>
              <aside class="custom-note">
                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                <div class="simple-block">
                  <p>To perform this operation, your Ambari Server must be running and you must be an Ambari
                    Admin.
                  </p>
                </div>
              </aside>
              <p>The utility provides three options for synchronization:</p>
              <ul class="bullet-list">
                
                  <li>
                    <p>Specific set of users and groups, or</p>
                  </li>
                  <li>
                    <p>Synchronize the existing users and groups in Ambari with LDAP, or</p>
                  </li>
                  <li>
                    <p>All users and groups</p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Specific Set of Users and Groups</h4>
            
              <p><code>
                ambari-server sync-ldap --users users.txt --groups groups.txt

              </code>Use this option to synchronize a specific set of users and groups from LDAP into Ambari.
                Provide the command a text file of comma-separated users and groups, and those LDAP entities will be
                imported and synchronized with Ambari.
              </p>
              <aside class="custom-note">
                <div class="icon"><img src="Icons/Note.png" width="50"></div>
                <div class="simple-block">
                  <p>Group membership is determined using the Group Membership Attribute specified during
                    setup-ldap.
                  </p>
                </div>
              </aside>
            
            
              <h4 class="bold">Existing Users and Groups</h4>
              
                <p>
                  <code>ambari-server sync-ldap --existing</code>

                  After you have performed a synchronization of a<a href="#ref-0b1fad1b-bee7-45f2-84fc-31d112faae67">specific set of users and groups</a>,
                  you use this option to synchronize only those entities that are in Ambari with LDAP. Users will be
                  removed from Ambari if they no longer exist in LDAP, and group membership in Ambari will be updated to
                  match LDAP.
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>Group membership is determined using the Group Membership Attribute specified during
                      setup-ldap.
                    </p>
                  </div>
                </aside>
              
            
            
              <h4 class="bold">All Users and Groups
              </h4>
              
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Only use this option if you are sure you want to synchronize all users and groups from
                      LDAP into Ambari. If you only want to synchronize a subset of users and groups, use a
                      <a href="#ref-0b1fad1b-bee7-45f2-84fc-31d112faae67">specific set of users and groups
                      </a>
                      option.
                    </p>
                  </div>
                </aside>
                <p>
                  <code>
                    ambari-server sync-ldap --all
                  </code>

                  This will import all entities with matching LDAP user and group object classes into Ambari.
                </p>
              
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-a33359d6-2802-45a8-90c9-fc3fd20c9753">Optional: Encrypt Database and LDAP Passwords</h3>
        
          <p>By default the passwords to access the Ambari database and the LDAP server are stored in a plain
            text configuration file. To have those passwords encrypted, you need to run a special setup command.
          </p>
          <p>
            Ambari Server should not be running when you do this: either make the edits before you start Ambari Server
            the first time or bring the server down to make the edits.
          </p>
          <ul class="number-list">
            
              <li>
                <p>On the Ambari Server, run the special setup command and answer the prompts:</p>
                <p>
                  <code>ambari-server setup-security</code>
                </p>
                <ul class="Numeric">
                  
                    <li>
                      <p>Select
                        <code>4</code>
                        for<code>Encrypt passwords stored in ambari.properties file</code>
                        .
                      </p>
                    </li>
                    <li>
                      <p>Provide a master key for encrypting the passwords. You are prompted to enter the key
                        twice for accuracy.
                      </p>
                      <p>If your passwords are encrypted, you need access to the master key to start Ambari
                        Server.
                      </p>
                    </li>
                    <li>
                      <p>You have three options for maintaining the master key:</p>
                      <ul class="Bullet">
                        
                          <li>
                            <p>At the
                              <code>Persist</code>
                              prompt, select<code>y</code>. This stores the key in a file on the
                              server.
                            </p>
                          </li>
                          <li>
                            <p>Create an environment variable
                              AMBARI_SECURITY_MASTER_KEY
                              and set it to the key.
                            </p>
                          </li>
                          <li>
                            <p>Provide the key manually at the prompt on server start up.</p>
                          </li>
                        
                      </ul>
                    </li>
                    <li>
                      <p>Start or restart the Server</p>
                      <p>
                        <code>ambari-server restart</code>
                      </p>
                    </li>
                  
                </ul>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Reset Encryption</h4>
          
            <p>There may be situations in which you want to:</p>
            <ul class="bullet-list">
              
                <li>
                  <p>
                    <a href="#ref-b09964dd-afb4-4c0d-a237-92654fe0b269">Remove encryption entirely</a>
                  </p>
                </li>
                <li>
                  <p><a href="#ref-212003ef-107e-4e56-8f84-0388f8383175">Change the current master
                    key</a>, either because the key has been forgotten or because you want to change the current key
                    as a part of a security routine.
                  </p>
                  <p>Ambari Server should not be running when you do this.</p>
                </li>
              
            </ul>
          
          
            <h4 class="bold">Remove Encryption Entirely</h4>
            
              <p>To reset Ambari database and LDAP passwords to a completely unencrypted state:</p>
              <ul class="number-list">
                
                  <li>
                    <p>On the Ambari host, open
                      <code>/etc/ambari-server/conf/ambari.properties</code>
                      with a text editor and set this property
                    </p>
                    <p>
                      <code>security.passwords.encryption.enabled=false</code>
                    </p>
                  </li>
                  <li>
                    <p>Delete
                      <code>/var/lib/ambari-server/keys/credentials.jceks</code>
                    </p>
                  </li>
                  <li>
                    <p>Delete
                      <code>/var/lib/ambari-server/keys/master</code>
                    </p>
                  </li>
                  <li>
                    <p>You must now reset the database password and, if necessary, the LDAP password. Run
                      <a href="#ref-77031023-81db-4b1c-9434-2b68372a9920">ambari-server setup</a>
                      and
                      <a href="#ref-b810db92-97de-4d4e-a905-239e2b8a2a04">ambari-server setup-ldap</a>
                      again.
                    </p>
                  </li>
                
              </ul>
            
          
          
            <h4 class="bold">Change the Current Master Key</h4>
            
              <p>To change the master key:</p>
              <ul class="bullet-list">
                
                  <li>
                    <p>
                      <strong>If</strong>
                      you know the current master key or if the current master key has been persisted:
                    </p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Re-run the encryption setup command and follow the prompts.</p>
                          <p>
                            <code>ambari-server setup-security</code>
                          </p>
                          <ul class="Numeric">
                            
                              <li>
                                <p>Select
                                  <code>4</code>
                                  for<code>Encrypt passwords stored in ambari.properties
                                    file</code>.
                                </p>
                              </li>
                              <li>
                                <p>Enter the current master key when prompted if necessary (if it is not
                                  persisted or set as an environment variable).
                                </p>
                              </li>
                              <li>
                                <p>At the
                                  <code>Do you want to reset Master Key</code>
                                  prompt, enter<code>yes</code>.
                                </p>
                              </li>
                              <li>
                                <p>At the prompt, enter the new master key and confirm.</p>
                              </li>
                            
                          </ul>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>
                      <strong>If</strong>
                      you do
                      <strong>not</strong>
                      know the current master key:
                    </p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Remove encryption entirely, as described<a href="#ref-b09964dd-afb4-4c0d-a237-92654fe0b269">here</a>.
                          </p>
                        </li>
                        <li>
                          <p>Re-run
                            <code>ambari-server setup-security</code>
                            as described<a href="#ref-2d711515-048d-4662-89ff-222d2ce3e1be">here</a>.
                          </p>
                        </li>
                        <li>
                          <p>Start or restart the Ambari Server.</p>
                          <p>
                            <code>ambari-server restart</code>
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                
              </ul>
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-2d711515-048d-4662-89ff-222d2ce3e1be">Optional: Set Up Security for Ambari</h3>
        
          <p>There are four ways you can increase the security settings for your Ambari server installation.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>If you plan to configure your cluster for Kerberos, you may use the
                <strong>Setup Ambari kerberos JAAS configuration</strong>
                option, which is described in <a href="#ref-a9927c0e-595d-45b8-b574-a2d401685ccd">Setting up
                  Ambari for Kerberos</a>.
              </p>
            </div>
          </aside>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-ea066612-27fc-4721-b3cb-84dad66e9492">Set Up HTTPS for Ambari Server</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-499fc76f-c9c7-4e87-a7f5-9ae7f8e8399e">Set Up HTTPS for Ganglia</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-23ce2378-876a-43b5-a94d-aa8951b2c9d4">Set Up HTTPS for Nagios</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-a33359d6-2802-45a8-90c9-fc3fd20c9753">Encrypt Database and LDAP Passwords
                  </a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Set Up HTTPS for Ambari Server</h4>
          
            <p>If you want to limit access to the Ambari Server to HTTPS connections, you need to provide a
              certificate. While it is possible to use a self-signed certificate for initial trials, they are not
              suitable for production environments. After your certificate is in place, you must run a special setup
              command.
            </p>
            <p>
              Ambari Server should not be running when you do this. Either make these changes before you start Ambari
              the first time, or bring the server down before running the setup command.
            </p>
            <ul class="number-list">
              
                <li>
                  <p>Log into the Ambari Server host.</p>
                </li>
                <li>
                  <p>Locate your certificate. If you want to create a temporary self-signed certificate, use this
                    as an example:
                  </p>
                  <p>
                    <code>openssl genrsa -out $wserver.key 2048
                      openssl req -new -key $wserver.key -out $wserver.csr
                      openssl x509 -req -days 365 -in $wserver.csr -signkey $wserver.key -out $wserver.crt
                    </code>
                  </p>
                  <p>
                    Where
                    <code>$wserver</code>
                    is the Ambari Server host name.
                  </p>
                  <p>
                    The certificate you use must be PEM-encoded, not DER-encoded. If you attempt to use a DER-encoded
                    certificate, you see the following error:
                  </p>
                  <p>
                    <code>unable to load certificate
                      140109766494024:error:0906D06C:PEM routines:PEM_read_bio:no start line:pem_lib.c
                      :698:Expecting: TRUSTED CERTIFICATE
                    </code>
                  </p>
                  <p>
                    You can convert a DER-encoded certificate to a PEM-encoded certificate using the following command:
                  </p>
                  <p>
                    <code>openssl x509 -in cert.crt -inform der -outform pem -out cert.pem</code>
                  </p>
                  <p>
                    where
                    <code>cert.crt</code>
                    is the DER-encoded certificate and
                    <code>cert.pem</code>
                    is the resulting PEM-encoded certificate.
                  </p>
                </li>
                <li>
                  <p>Run the special setup command and answer the prompts</p>
                  <p>
                    <code>ambari-server setup-security</code>
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Select
                          <code>1</code>
                          for<code>Enable HTTPS for Ambari server</code>.
                        </p>
                      </li>
                      <li>
                        <p>Respond
                          <code>y</code>
                          to
                          <code>Do you want to configure HTTPS ?</code>
                        </p>
                      </li>
                      <li>
                        <p>Select the port you want to use for SSL. The default port number is 8443.</p>
                      </li>
                      <li>
                        <p>Provide the path to your certificate and your private key. For example, put your
                          certificate and private key in
                          <code>/etc/ambari-server/certs</code>
                          with root as the owner or the non-root user you designated during Ambari Server setup for the
                          ambari-server daemon.
                        </p>
                      </li>
                      <li>
                        <p>Provide the password for the private key.</p>
                      </li>
                      <li>
                        <p>Start or restart the Server</p>
                        <p>
                          <code>ambari-server restart</code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Set Up HTTPS for Ganglia</h4>
          
            <p>If you want Ganglia to use HTTPS instead of the default HTTP to communicate with Ambari Server,
              use the following instructions.
            </p>
            <p>
              The servers should not be running when you do this: either make the edits before you start Ambari Server
              the first time or bring the servers down to make the edits.
            </p>
            <ul class="number-list">
              
                <li>
                  <p>Set up the Ganglia server.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Log into the Ganglia server host.</p>
                      </li>
                      <li>
                        <p>Create a self-signed certificate on the Ganglia server host. For example:</p>
                        <p>
                          <code>openssl genrsa -out $gserver.key 2048
                            openssl req -new -key $gserver.key -out $gserver.csr
                            openssl x509 -req -days 365 -in $gserver.csr -signkey $gserver.key -out $gserver.crt
                          </code>
                        </p>
                        <p>Where
                          <code>$gserver</code>
                          is the Ganglia server host name.
                        </p>
                      </li>
                      <li>
                        <p>Install SSL on the Ganglia server host.</p>
                        <p>
                          <code>yum install mod_ssl</code>
                        </p>
                      </li>
                      <li>
                        <p>Edit the SSL configuration file on the Ganglia server host.</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Using a text editor, open:</p>
                              <p>
                                <code>
                                  /etc/httpd/conf.d/ssl.conf
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Add lines setting the certificate and key file names to the files you created
                                earlier in this procedure. For example:
                              </p>
                              <p>
                                <code>SSLCertificateFile $gserver.crt
                                  SSLCertificateKeyFile $gserver.key
                                </code>
                                <code>
                                </code>Where $gserver is the Ganglia server host name.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Disable HTTP access (optional).</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Using a text editor, open:</p>
                              <p>
                                <code>
                                  /etc/httpd/conf/httpd.conf
                                </code>
                              </p>
                            </li>
                            <li>
                              <p>Comment out the port 80 listener:</p>
                              <p>
                                <code>
                                  # Listen 80
                                </code>
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Restart the
                          <code>httpd</code>
                          service on the Ganglia server host.
                        </p>
                        <p>
                          <code>service httpd restart</code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Set up and restart the Ambari Server.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Log into the Ambari Server.</p>
                      </li>
                      <li>
                        <p>Run the special setup command and answer the prompts.</p>
                        <p>
                          <code>ambari-server setup-security</code>
                        </p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Select
                                <code>2</code>
                                for<code>Enable HTTPS for Ganglia service</code>.
                              </p>
                            </li>
                            <li>
                              <p>Respond
                                <code>y</code>
                                to
                                <code>Do you want to configure HTTPS for Ganglia
                                  service
                                </code>
                                <strong>.</strong>
                              </p>
                            </li>
                            <li>
                              <p>Enter your TrustStore type. Your options are<code>jks</code>,
                                <code>jceks</code>, or<code>pks12</code>.
                              </p>
                            </li>
                            <li>
                              <p>Enter the path to your TrustStore file.</p>
                            </li>
                            <li>
                              <p>Enter the password for your TrustStore and then re-enter to confirm. The
                                password must be at least 6 characters long.
                              </p>
                            </li>
                            <li>
                              <p>Enter the path to the Ganglia server certificate file.</p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Start or restart the Server</p>
                        <p>
                          <code>ambari-server restart</code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Set Up HTTPS for Nagios</h4>
          
            <p>
              If you want Nagios to use HTTPS instead of HTTP (the default), use the following instructions.
            </p>
            <p>
              The servers should not be running when you do this: either make the edits before you start Ambari Server
              the first time or bring the servers down to make the edits.
            </p>
            <ul class="number-list">
              
                <li>
                  <p>Set up the Nagios server.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Log into the Nagios server host.</p>
                      </li>
                      <li>
                        <p>Create a self-signed certificate on the Nagios server host. For example:</p>
                        <p>
                          <code>openssl genrsa -out $nserver.key 2048
                            openssl req -new -key $nserver.key -out $nserver.csr
                            openssl x509 -req -days 365 -in $nserver.csr -signkey $nserver.key -out $nserver.crt
                          </code>
                        </p>
                        <p>Where
                          <code>$nserver</code>
                          is the Nagios server host name.
                        </p>
                      </li>
                      <li>
                        <p>Install SSL on the Nagios server host.</p>
                        <p>
                          <code>yum install mod_ssl</code>
                        </p>
                      </li>
                      <li>
                        <p>Edit the SSL configuration file on the Nagios server host.</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Using a text editor, open:</p>
                              <p>
                                <code>/etc/httpd/conf.d/ssl.conf</code>
                              </p>
                            </li>
                            <li>
                              <p>Add lines setting the certificate and key file names to the files you created
                                previously in this procedure. For example:
                              </p>
                              <p>
                                <code>
                                </code>
                                <code>SSLCertificateFile $nserver.crt
                                  SSLCertificateKeyFile $nserver.key
                                </code>
                                <code>
                                </code>Where $nserver is the Nagios server host name.
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Disable HTTP access (optional)</p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Using a text editor, open:</p>
                              <p>
                                <code>/etc/httpd/conf/httpd.conf</code>
                              </p>
                            </li>
                            <li>
                              <p>Comment out the port 80 listener:</p>
                              <p>
                                <code># Listen 80</code>
                              </p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Restart the
                          <code>httpd</code>
                          service on the Nagios server host.
                        </p>
                        <p>
                          <code>service httpd restart</code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Set up and restart the Ambari Server.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Log into the Ambari Server.</p>
                      </li>
                      <li>
                        <p>Run the special setup command and answer the prompts.</p>
                        <p>
                          <code>ambari-server setup-security</code>
                        </p>
                        <ul class="Numeric">
                          
                            <li>
                              <p>Select
                                <code>2</code>
                                for<code>Enable HTTPS for Nagios service</code>.
                              </p>
                            </li>
                            <li>
                              <p>Respond
                                <code>y</code>
                                to<code>Do you want to configure HTTPS for Nagios?</code>.
                              </p>
                            </li>
                            <li>
                              <p>Enter your TrustStore type. Your options are<code>jks</code>,
                                <code>jceks</code>, or<code>pks12</code>.
                              </p>
                            </li>
                            <li>
                              <p>Enter the path to your TrustStore file.</p>
                            </li>
                            <li>
                              <p>Enter the password for your TrustStore and then re-enter to confirm. The
                                password must be at least 6 characters long.
                              </p>
                            </li>
                            <li>
                              <p>Enter the path to the Nagios server certificate file.</p>
                            </li>
                          
                        </ul>
                      </li>
                      <li>
                        <p>Start or restart the Server</p>
                        <p>
                          <code>ambari-server restart</code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-7ee44c15-f6a4-4a22-890c-442c5edde87c">Optional: Set Up Two-Way SSL Between Ambari Server and Ambari Agents</h3>
        
          <p>Two-way SSL provides a way to encrypt communication between Ambari Server and Ambari Agents. By
            default Ambari ships with Two-way SSL disabled. To enable Two-way SSL:
          </p>
          <p>
            Ambari Server should not be running when you do this: either make the edits before you start Ambari Server
            the first time or bring the server down to make the edits.
          </p>
          <ul class="number-list">
            
              <li>
                <p>On the Ambari Server host, open
                  <code>/etc/ambari-server/conf/ambari.properties</code>
                  with a text editor.
                </p>
              </li>
              <li>
                <p>Add the following property:</p>
                <p>
                  <code>security.server.two_way_ssl = true</code>
                </p>
              </li>
              <li>
                <p>Start or restart the Ambari Server.</p>
                <p>
                  <code>ambari-server restart</code>
                </p>
              </li>
            
          </ul>
          <p>The Agent certificates are downloaded automatically during Agent Registration.</p>
        
      
      
        <h3 class="horton-blue bold" id="ref-9b94686d-3bd8-4d8b-bb27-f0af1b546ccf">Optional: Configure Ciphers and Protocols for Ambari Server</h3>
        
          <p>Ambari provides control of ciphers and protocols that are exposed via Ambari Server.</p>
          <ul class="number-list">
            
              <li>
                <p>To disable specific ciphers, you can optionally add a list of the following format to
                  ambari.properties. If you specify multiple ciphers, separate each cipher using a vertical bar |.
                </p>
                <p>
                  <code>security.server.disabled.ciphers=TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA</code>
                </p>
              </li>
              <li>
                <p>To disable specific protocols, you can optionally add a list of the following format to
                  ambari.properties. If you specify multiple protocols, separate each protocol using a vertical bar |.
                </p>
                <p>
                  <code>security.server.disabled.protocols=SSL|SSLv2|SSLv3</code>
                </p>
              </li>
            
          </ul>
        
      
    
    
      <h2 class="horton-green bold">Troubleshooting Ambari Deployments</h2>
      
        <h3 class="horton-blue bold" id="ref-51adbb3c-07ba-479f-82e9-7eb9f0e2fe02">Introduction</h3>
        
          <p>The first step in troubleshooting any problem in an Ambari-deploying Hadoop cluster is<a href="#ref-523b3bb0-1633-41d0-800e-3e959e49dddf">Reviewing the Ambari Log Files</a>.
          </p>
          <p>Find a recommended solution to a troubleshooting problem in one of the following sections:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-4e0a7a1a-a1d8-4573-96b0-78bf29a2bb75">Resolving Ambari Installer Problems
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-4e0a7a1a-a1d8-4573-96b0-78bf29a2bb75">Resolving Cluster Deployment Problems
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-237d7afb-a37e-470b-b2ce-55ae739ac1ac">Resolving General Problems</a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-523b3bb0-1633-41d0-800e-3e959e49dddf">Reviewing Ambari Log Files</h3>
        
          <p>Find files that log activity on an Ambari host in the following locations:</p>
          <ul class="bullet-list">
            
              <li>
                <p>Ambari Server logs</p>
                <p>
                  <code>&lt;your.Ambari.server.host&gt;/var/log/ambari-server/ambari-server.log</code>
                </p>
              </li>
              <li>
                <p>Ambari Agent logs</p>
                <p>
                  <code>&lt;your.Ambari.agent.host&gt;/var/log/ambari-agent/ambari-agent.log</code>
                </p>
              </li>
              <li>
                <p>Ambari Action logs</p>
                <p>
                  <code>&lt;your.Ambari.agent.host&gt;/var/lib/ambari-agent/data/</code>
                </p>
                <p>
                  This location contains logs for all tasks executed on an Ambari agent host.
                  Each log name includes:
                </p>
                <ul class="Bullet">
                  
                    <li>
                      <p>commands-N.txt - the command file corresponding to a specific task.</p>
                    </li>
                    <li>
                      <p>output-N.txt - the output from the command execution.</p>
                    </li>
                    <li>
                      <p>errors-N.txt - error messages.</p>
                    </li>
                  
                </ul>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-4e0a7a1a-a1d8-4573-96b0-78bf29a2bb75">Resolving Ambari Installer Problems</h3>
        
          <p>Try the recommended solution for each of the following problems:</p>
        
        
          <h4 class="bold">Problem: Browser crashed before Install Wizard completes</h4>
          
            <p>Your browser crashes or you accidentally close your browser before the Install Wizard completes.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>The response to a browser closure depends on where you are in the process:</p>
              <ul class="bullet-list">
                
                  <li>
                    <p>The browser closes before you press the
                      <code>Deploy</code>
                      button.
                    </p>
                    <p>
                      Re-launch the same browser and continue the install process. Using a different browser forces you
                      to re-start the entire process.
                    </p>
                  </li>
                  <li>
                    <p>The browser closes after you press
                      <code>Deploy</code>
                      <strong>,</strong>
                      while or after the
                      <code>Install, Start, and Test</code>
                      screen opens.
                    </p>
                    <p>
                      Re-launch the same browser and continue the process, or log in again, using a different browser.
                      When the
                      <code>Install, Start, and Test</code>
                      displays, proceed.
                    </p>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Problem: Install Wizard reports that the cluster install has failed</h4>
          
            <p>The Install, Start, and Test screen reports that the cluster install has failed.</p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>The response to a report of install failure depends on the cause of the failure:</p>
              <ul class="bullet-list">
                
                  <li>
                    <p>The failure is due to intermittent network connection errors during software package
                      installs.
                    </p>
                    <p>
                      Use the
                      <strong></strong>
                      <code>Retry</code>
                      <strong></strong>button on the
                      <code>Install, Start, and Test</code>
                      screen.
                    </p>
                  </li>
                  <li>
                    <p>The failure is due to misconfiguration or other setup errors.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Use the left navigation bar to go back to the appropriate screen. For example,
                            <code>Customize Services</code>.
                          </p>
                        </li>
                        <li>
                          <p>Make your changes.</p>
                        </li>
                        <li>
                          <p>Continue in the normal way.</p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>The failure occurs during the start/test sequence.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Click
                            <code>Next</code>
                            and
                            <code>Complete,</code>
                            then proceed to the<code>Monitoring Dashboard</code>.
                          </p>
                        </li>
                        <li>
                          <p>Use the
                            <code>Services View</code>
                            to make your changes.
                          </p>
                        </li>
                        <li>
                          <p>Re-start the service using<code>Service Actions</code>
                            .
                          </p>
                        </li>
                      
                    </ul>
                  </li>
                  <li>
                    <p>The failure is due to something else.</p>
                    <ul class="Numeric">
                      
                        <li>
                          <p>Open an SSH connection to the Ambari Server host.</p>
                        </li>
                        <li>
                          <p>Clear the database. At the command line, type:</p>
                          <p>
                            <code></code>
                            <code>ambari-server reset</code>
                            <code></code>
                          </p>
                        </li>
                        <li>
                          <p>Clear your browser cache.</p>
                        </li>
                        <li>
                          <p>Re-run the Install Wizard.</p>
                        </li>
                      
                    </ul>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Problem: Ambari Agents May Fail to Register with Ambari Server.</h4>
          
            <p>When deploying HDP using Ambari 1.4.x or later on RHEL CentOS 6.5, click the “Failed” link on the
              Confirm Hosts page in the Cluster Install wizard to display the Agent logs. The following log entry
              indicates the SSL connection between the Agent and Server failed during registration:
            </p>
            <p>
              <code>
                INFO 2014-04-02 04:25:22,669 NetUtil.py:55 - Failed to connect to https://{ambari-server}:8440/cert/ca
                due to [Errno 1] _ssl.c:492: error:100AE081:elliptic curve routines:EC_GROUP_new_by_curve_name:unknown
                group
              </code>
            </p>
            <p>
              For more detailed information about this OpenSSL issue, see
              <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1025598">
                https://bugzilla.redhat.com/show_bug.cgi?id=1025598
              </a>
            </p>
          
          
            <h4 class="bold">Solution:</h4>
            
              <p>In certain recent Linux distributions, such as RHEL/Centos/Oracle Linux 6.x, the default value
                of
                <code>nproc</code>
                is lower than the value required to deploy the HBase service successfully. If you are deploying HBase,
                change the value of<code>nproc</code>:
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>Check the OpenSSL library version installed on your host(s):</p>
                    <p>
                      <code>rpm -qa | grepopenssl openssl-1.0.1e-15.el6.x86_64</code>
                    </p>
                  </li>
                  <li>
                    <p>If the output reads
                      <code>openssl-1.0.1e-15.x86_64 (1.0.1 build 15),</code>
                      you must upgrade the OpenSSL library. To upgrade the OpenSSL library, run the following command:
                    </p>
                    <p>
                      <code>yum upgrade openssl</code>
                    </p>
                  </li>
                  <li>
                    <p>Verify you have the newer version of OpenSSL (1.0.1 build 16):</p>
                    <p>
                      <code>rpm -qa | grep opensslopenssl-1.0.1e-16.el6.x86_64</code>
                    </p>
                  </li>
                  <li>
                    <p>Restart Ambari Agent(s) and click
                      <code>Retry -&gt; Failed</code>
                      in the wizard user interface.
                    </p>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Problem: The “yum install ambari-server” Command Fails</h4>
          
            <p>You are unable to get the initial install command to run.</p>
          
          
            <h4 class="bold">Solution:</h4>
            
              <p>You may have incompatible versions of some software components in your environment. See Meet
                Minimum System Requirements in Installing HDP Using Ambari for more information, then make any necessary
                changes.
              </p>
            
          
        
        
          <h4 class="bold">Problem: HDFS Smoke Test Fails</h4>
          
            <p>If your DataNodes are incorrectly configured, the smoke tests fail and you get this error message
              in the DataNode logs:
            </p>
            <p>
              <code>
                DisallowedDataNodeException
                org.apache.hadoop.hdfs.server.protocol.
                DisallowedDatanodeException
              </code>
            </p>
          
          
            <h4 class="bold">Solution:</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>Make sure that reverse DNS look-up is properly configured for all nodes in your cluster.
                    </p>
                  </li>
                  <li>
                    <p>Make sure you have the correct FQDNs when specifying the hosts for your cluster. Do not
                      use IP addresses - they are not supported.
                    </p>
                  </li>
                  <li>
                    <p>Restart the installation process.</p>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Problem: yum Fails on Free Disk Space Check</h4>
          
            <p>If you boot your Hadoop DataNodes with/as a ramdisk, you must disable the free space check for yum
              before doing the install. If you do not disable the free space check, yum will fail with the following
              error:
            </p>
            <p>
              <code>
                Fail: Execution of '/usr/bin/yum -d 0 -e 0 -y install unzip' returned 1. Error Downloading Packages:
                unzip-6.0-1.el6.x86_64: Insufficient space in download directory /var/cache/yum/x86_64/6/base/packages
                * free 0
                * needed 149 k
              </code>
            </p>
          
          
            <h4 class="bold">Solution:</h4>
            
              <p>To disable free space check, update the DataNode image with a directive in<code>
                /etc/yum.conf</code>:
              </p>
              <p>
                <code>
                  diskspacecheck=0
                </code>
              </p>
            
          
        
        
          <h4 class="bold">Problem: A service with a customized service user is not appearing properly in Ambari Web</h4>
          
            <p>You are unable to monitor or manage a service in Ambari Web when you have created a customized
              service user name with a hyphen, for example,<code>hdfs-user</code>.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>Hyphenated service user names are not supported. You must re-run the Ambari Install Wizard and
                create a different name.
              </p>
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-237d7afb-a37e-470b-b2ce-55ae739ac1ac">Resolving Cluster Deployment Problems</h3>
        
          <p>Try the recommended solution for each of the following problems:.</p>
        
        
          <h4 class="bold">Problem: Trouble Starting Ambari on System Reboot</h4>
          
            <p>If you reboot your cluster, you must restart the Ambari Server and all the Ambari Agents
              manually.
            </p>
          
          
            <h4 class="bold">Solution:</h4>
            
              <p>Log in to each machine in your cluster separately:</p>
              <ul class="number-list">
                
                  <li>
                    <p>On the Ambari Server host machine:</p>
                    <p>
                      <code>
                        ambari-server start
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>On each host in your cluster:</p>
                    <p>
                      <code>
                        ambari-agent start
                      </code>
                    </p>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Problem: Metrics and Host information display incorrectly in Ambari Web</h4>
          
            <p>Charts appear incorrectly or not at all despite being available in the native Ganglia interface or
              Host health status is displayed incorrectly.
            </p>
          
          
            <h4 class="bold">Solution:</h4>
            
              <p>All the hosts in your cluster and the machine from which you browse to Ambari Web must be in
                sync with each other. The easiest way to assure this is to enable NTP.
              </p>
            
          
        
        
          <h4 class="bold">Problem: On SUSE 11 Ambari Agent crashes within the first 24 hours</h4>
          
            <p>SUSE 11 ships with Python version 2.6.0-8.12.2 which contains a known defect that causes this
              crash.
            </p>
          
          
            <h4 class="bold">Solution:</h4>
            
              <p>Upgrade to Python version 2.6.8-0.15.1.</p>
            
          
        
        
          <h4 class="bold">Problem: Attempting to Start HBase REST server causes either REST server or Ambari Web to fail</h4>
          
            <p>
              As an option you can start the HBase REST server manually after the install process is complete. It can be
              started on any host that has the HBase Master or the Region Server installed. If you install the REST
              server on the same host as the Ambari server, the http ports will conflict.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>In starting the REST server, use the -p option to set a custom port.
                Use the following command to start the REST server.
                <code>/usr/lib/hbase/bin/hbase-daemon.sh start rest -p
                  &lt;custom_port_number&gt;</code>
              </p>
            
          
        
        
          <h4 class="bold">Problem: Multiple Ambari Agent processes are running, causing re-register</h4>
          
            <p>On a cluster host
              <code>ps aux | grep ambari-agent</code>
              shows more than one agent process running. This causes Ambari Server to get incorrect ids from the host
              and forces Agent to restart and re-register.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>On the affected host, kill the processes and restart.</p>
              <ul class="number-list">
                
                  <li>
                    <p>Kill the Agent processes and remove the Agent PID files found here:<code>
                      /var/run/ambari-agent/ambari-agent.pid</code>.
                    </p>
                  </li>
                  <li>
                    <p>Restart the Agent process:</p>
                    <p>
                      <code>ambari-agent start</code>
                    </p>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Problem: Some graphs do not show a complete hour of data until the cluster has been running for an
            hour
          </h4>
          
            <p>When you start a cluster for the first time, some graphs, such as
              <code>Services View &gt; HDFS</code>
              and<code>Services View &gt; MapReduce</code>, do not plot a complete hour of
              data. Instead, they show data only for the length of time the service has been running. Other graphs
              display the run of a complete hour.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>Let the cluster run. After an hour all graphs will show a complete hour of data.</p>
            
          
        
        
          <h4 class="bold">Problem: Ambari stops MySQL database during deployment, causing Ambari Server to crash.</h4>
          
            <p>The Hive Service uses MySQL Server by default. If you choose MySQL server as the database on the
              Ambari Server host as the managed server for Hive, Ambari stops this database during deployment and
              crashes.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>If you plan to use the default MySQL Server setup for Hive and use MySQL Server for Ambari -
                make sure that the two MySQL Server instances are different.
              </p>
              <p>If you plan to use the same MySQL Server for Hive and Ambari - make sure to choose the existing
                database option for Hive.
              </p>
            
          
        
        
          <h4 class="bold">Problem: Service Fails with Unknown Host Exception</h4>
          
            <p>JVM networkaddress.cache negative.ttl default setting of 10 (never cache) may result in DNS
              failure. Long, or multiple queries running on the JVM may fail. Occurs in Java 6,7, and 8.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>Appropriate values for networkaddress.cache negative ttl depend on various system factors,
                including network traffic, cluster size, and resource availability. You can set Java VM options in an
                Ambari-installed cluster using the following procedure:
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>Edit the template for hadoop-env.sh file. Ambari deploys the template file on your cluster
                      in the following location:
                    </p>
                    <p>
                      <code>
                        /var/lib/ambari-server/resources/stacks/
                      </code>
                      &lt;stack.Name&gt;
                      <code>/</code>
                      &lt;stack.Version&gt;
                      <code>/hooks/before-START/templates/hadoop-env.sh.j2</code>
                    </p>
                    <p>
                      where
                      &lt;stack.Name&gt;
                      and
                      &lt;stack.Version&gt;
                      refer to your specific stack name and version.
                    </p>
                  </li>
                  <li>
                    <p>Change the following line in the template to add options to all Hadoop processes, then
                      save the file.
                    </p>
                    <p>
                      <code>
                        export HADOOP_OPTS="-Djava.net.preferIPv4Stack=true ${HADOOP_OPTS}"
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>Restart Ambari server.</p>
                    <p>
                      <code>
                        ambari-server restart
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>Restart affected services, using the Ambari Web UI.</p>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Problem: Cluster Install Fails with Groupmod Error</h4>
          
            <p>
              The cluster fails to install with an error related to running<code>groupmod</code>. This can
              occur in environments where groups are managed in LDAP, and not on local Linux machines.
              You may see an error message similar to the following one:
            </p>
            <p>
              <code>
                Fail: Execution of 'groupmod hadoop' returned 10. groupmod: group 'hadoop' does not exist in /etc/group
              </code>
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>When installing the cluster using the Cluster Installer Wizard, at the
                <code>Customize Services</code>
                step, select the
                <code>Misc</code>
                tab and choose the
                <code>Skip group modifications during install</code>
                option.
              </p>
            
          
        
        
          <h4 class="bold">Problem: Host registration fails during Agent bootstrap on SLES due to timeout.</h4>
          
            <p>When using SLES and performing host registration using SSH, the Agent bootstrap may fail due to
              timeout when running the
              <code>setupAgent.py</code>
              script. The host on which the timeout occurs will show the following process hanging:
            </p>
            <p>
              <code>
                c6401.ambari.apache.org:/etc/ # ps -ef | grep zypper
                root 18318 18317 5 03:15 pts/1 00:00:00 zypper -q search -s --match-exact ambari-agent
              </code>
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <ul class="number-list">
                
                  <li>
                    <p>If you have a repository registered that is prompting to accept keys, via user
                      interaction, you may see the hang and timeout. In this case, run
                      <code>zypper refresh</code>
                      and confirm all repository keys are accepted for the zypper command to work without user
                      interaction.
                    </p>
                  </li>
                  <li>
                    <p>Another alternative is to perform manual Agent setup and not use SSH for host
                      registration. This option does not require that Ambari call zypper without user interaction.
                    </p>
                  </li>
                
              </ul>
            
          
        
        
          <h4 class="bold">Problem: Host Check Fails if Transparent Huge Pages (THP) is not disabled.</h4>
          
            <p>
              When installing Ambari on CentOS6.x using the Cluster Installer Wizard at the Host Checks step, one or
              more host checks may fail if you have not disabled Transparent Huge Pages on all hosts.
            </p>
            <p><code>
            </code>Host Checks will warn you when a failure occurs.
              <code>
              </code>
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>Disable THP.
                On all hosts,
              </p>
              <ul class="number-list">
                
                  <li>
                    <p>Add the following command to your
                      <code>/etc/rc.local</code>
                      file:
                    </p>
                    <p>
                      <code>if test -f /sys/kernel/mm/transparent_hugepage/defrag; then
                        echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag
                        fi
                      </code>
                    </p>
                  </li>
                  <li>
                    <p>To confirm, reboot the host then run the following command:</p>
                    <p>
                      <code>$ cat /sys/kernel/mm/transparent_hugepage/enabled
                        always madvise [never]
                      </code>
                    </p>
                  </li>
                
              </ul>
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-c5c5030a-ca27-4d81-99c0-ed74e60569c4">Resolving General Problems</h3>
        
          <h4 class="bold">Problem: Hive developers may encounter an exception error message during Hive Service Check</h4>
          
            <p>MySQL is the default database used by the Hive metastore. Depending on several factors, such as
              the version and configuration of MySQL, a Hive developer may see an exception message similar to the
              following one:
            </p>
            <p>
              <code>An exception was thrown while adding/validating classes) : Specified key was too
                long; max key length is 767 bytes
              </code>
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>Administrators can resolve this issue by altering the Hive metastore database to use the Latin1
                character set, as shown in the following example:
                <code>mysql&gt; ALTER DATABASE</code>
                &lt;metastore.database.name&gt;
                <code>character set latin1;</code>
              </p>
            
          
        
        
          <h4 class="bold">Problem: API calls for PUT, POST, DELETE respond with a "400 - Bad Request"</h4>
          
            <p>Removing a registered host not added to a cluster. curl command and REST API calls require a
              header element.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>Starting with Ambari 1.4.2, you must include the "X-Requested-By" header with the REST API
                calls.
              </p>
              <p>For example, if using curl, include the
                <code>-H "X-Requested-By: ambari"</code>
                option.
                <code>curl -u admin:admin -H "X-Requested-By: ambari" -X DELETE http://&lt;ambari-host&gt;:8080/api/v1/hosts/host1</code>
              </p>
            
          
        
        
          <h4 class="bold">Problem: Enabling NameNode HA wizard fails on the "Initialize JournalNode" step.</h4>
          
            <p>After upgrading to Ambari 1.6.1 and attempting to enable NameNode HA in a HDP 2.x Stack-based
              cluster, the HA wizard fails to complete with an error during the "Initialize JournalNode" step. This
              failure situation can also occur if your cluster was created using a Blueprint.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>Using the Ambari REST API, you need to create JournalNode and ZKFC service components. This API
                can also be called prior to launching the NameNode HA wizard to avoid the wizard failing.
              </p>
              <p>
                <code>
                  curl --user admin:admin -H "X-Requested-By: ambari" -i -X POST -d
                  '{"components":[{"ServiceComponentInfo":{"component_name":"JOURNALNODE"}},{"ServiceComponentInfo":{"component_name":"ZKFC"}}]}'
                  http://
                </code>
                &lt;ambari.server&gt;
                <code>:8080/api/v1/clusters/</code>
                &lt;c1.name&gt;
                <code>/services?ServiceInfo/service_name=HDFS</code>
              </p>
              <p>
                Replace
                &lt;ambari.server&gt;
                and
                &lt;c1.name&gt;
                with your Ambari Server hostname and cluster name respectively.
              </p>
            
          
        
        
          <h4 class="bold">Problem: When using HDP 1.3 Stack, alerts do not clear on TaskTracker decommission/recommission.
          </h4>
          
            <p>After decommissioning a TaskTracker, a host alert is shown as critical for the TaskTracker
              detecting the web UI is inaccessible. As part of decommissioning MapReduce shuts down the TaskTracker web
              UI but not the process.
            </p>
          
          
            <h4 class="bold">Solution</h4>
            
              <p>
                After decommissioning, the user must also stop the TaskTracker via Ambari. Now, on a recommission, the
                TaskTracker will be in the state, ready to start. When started, the TaskTracker web UI will come back
                up, and the alert will be dismissed.
              </p>
            
          
        
      
    
    
      <h2 class="horton-green bold">Installing Ambari Agents Manually</h2>
      
        <h3 class="horton-blue bold" id="ref-ff15b838-7902-4658-83f1-f53c9fe547c1">
          Download the Ambari Repo
        </h3>
        
          <p>Select the OS family running on your installation host.</p>
          <div class="tabs">
            
            <div class="tab">
              <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
              <div class="tab-content">
                <p>
                  On a server host that has Internet access, use a command line editor to perform the following steps:
                </p>
                <ul class="number-list">
                  
                    <strong>RHEL/CentOS/Oracle Linux 6</strong>
                  
                  
                    <li>
                      <p>Log in to your host as<code>root</code>. For example, type:
                      </p>
                      <p>
                        <code>ssh &lt;username&gt;@&lt;fqdn&gt;</code>
                        <code>sudo su -</code>
                        where
                        <code>&lt;username&gt;</code>
                        is your user name and
                        <code>&lt;fqdn&gt;</code>
                        is the fully qualified domain name of your server host.
                      </p>
                    </li>
                    <li>
                      <p>Download the Ambari repository file to a directory on your installation host.</p>
                      <p>
                        <code>wget -nv
                          http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.7.0/ambari.repo -O
                          /etc/yum.repos.d/ambari.repo
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Important.png" width="50"></div>
                        <div class="simple-block">
                          <p>Do not modify the
                            <code>ambari.repo</code>
                            file name. This file is expected to be available on the Ambari Server host during Agent
                            registration.
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>Confirm that the repository is configured by checking the repo list.</p>
                      <p>
                        <code>yum repolist</code>
                        You should see values similar to the following for Ambari repositories in the list.
                      </p>
                      <p>
                        Version values vary, depending on the installation.
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          
                          <thead></thead>
                          <tbody>
                            <tr>
                              <th rowspan="1">
                                <p>
                                  <strong>repo id</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>repo name</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>status</strong>
                                </p>
                              </th>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>AMBARI.1.7.0-1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Ambari 1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>5</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>base</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-6 - Base</p>
                              </td>
                              <td rowspan="1">
                                <p>6,518</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>extras</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-6 - Extras</p>
                              </td>
                              <td rowspan="1">
                                <p>15</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>updates</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-6 - Updates</p>
                              </td>
                              <td rowspan="1">
                                <p>209</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                    </li>
                    <li>
                      <p>Install the Ambari bits. This also installs the default PostgreSQL Ambari database.
                      </p>
                      <p>
                        <code>yum install ambari-server</code>
                      </p>
                    </li>
                    <li>
                      <p>Enter
                        <code>y</code>
                        when prompted to to confirm transaction and dependency checks.
                      </p>
                      <p>A successful installation displays output similar to the following:
                        <code>Installing : postgresql-libs-8.4.20-1.el6_5.x86_64 1/4
                          Installing : postgresql-8.4.20-1.el6_5.x86_64 2/4
                          Installing : postgresql-server-8.4.20-1.el6_5.x86_64 3/4
                          Installing : ambari-server-1.7.0-135.noarch 4/4
                          Verifying : postgresql-server-8.4.20-1.el6_5.x86_64 1/4
                          Verifying : postgresql-libs-8.4.20-1.el6_5.x86_64 2/4
                          Verifying : ambari-server-1.7.0-135.noarch 3/4
                          Verifying : postgresql-8.4.20-1.el6_5.x86_64 4/4

                          Installed:
                          ambari-server.noarch 0:1.7.0-135

                          Dependency Installed:
                          postgresql.x86_64 0:8.4.20-1.el6_5 postgresql-libs.x86_64 0:8.4.20-1.el6_5
                          postgresql-server.x86_64 0:8.4.20-1.el6_5

                          Complete!
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Note.png" width="50"></div>
                        <div class="simple-block">
                          <p>Accept the warning about trusting the Pivotal GPG Key. That key will be
                            automatically downloaded and used to validate packages from Pivotal. You will see the
                            following message:

                            <code>Importing GPG key 0x07513CAD:
                              Userid: "Jenkins (HDP Builds) &lt;jenkin@hortonworks.com&gt;"
                              From :
                              http://s3.amazonaws.com/dev.hortonworks.com/ambari/centos6/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
                            </code>
                          </p>
                        </div>
                      </aside>
                    </li>
                  
                </ul>
              </div>
            </div>
            <div class="tab">
              <p class="bold">SLES 11</p>
              <div class="tab-content">
                <p>On a server host that has Internet access, use a command line editor to perform the following
                  steps:
                </p>
                <ul class="number-list">
                  
                    <strong>SLES 11</strong>
                  
                  
                    <li>
                      <p>Log in to your host as<code>root</code>. For example, type:
                      </p>
                      <p>
                        <code>ssh &lt;username&gt;@&lt;fqdn&gt;</code>
                        <code>sudo su -</code>
                        where
                        <code>&lt;username&gt;</code>
                        is your user name and
                        <code>&lt;fqdn&gt;</code>
                        is the fully qualified domain name of your server host.
                      </p>
                    </li>
                    <li>
                      <p>Download the Ambari repository file to a directory on your installation host.
                        <code>wget -nv
                          http://public-repo-1.hortonworks.com/ambari/suse11/1.x/updates/1.7.0/ambari.repo -O
                          /etc/zypp/repos.d/ambari.repo
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Important.png" width="50"></div>
                        <div class="simple-block">
                          <p>Do not modify the
                            <code>ambari.repo</code>
                            file name. This file is expected to be available on the Ambari Server host during Agent
                            registration.
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>Confirm the downloaded repository is configured by checking the repo list.</p>
                      <p>
                        <code>zypper repos</code>
                        You should see the Ambari repositories in the list.
                      </p>
                      <p>
                        Version values vary, depending on the installation.
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          
                          
                          <thead></thead>
                          <tbody>
                            <tr>
                              <th rowspan="1">
                                <p>
                                  <strong>Alias</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>Name</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>Enabled</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>Refresh</strong>
                                </p>
                              </th>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>AMBARI.1.7.0-1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Ambari 1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                              <td rowspan="1">
                                <p>No</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>http-demeter.uni-regensburg.de-c997c8f9</p>
                              </td>
                              <td rowspan="1">
                                <p>SUSE-Linux-Enterprise-Software-Development-Kit-11-SP1 11.1.1-1.57</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>opensuse</p>
                              </td>
                              <td rowspan="1">
                                <p>OpenSuse</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                              <td rowspan="1">
                                <p>Yes</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                    </li>
                    <li>
                      <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                      <p>
                        <code>zypper install ambari-server</code>
                      </p>
                    </li>
                    <li>
                      <p>Enter
                        <code>y</code>
                        when prompted to to confirm transaction and dependency checks.
                      </p>
                      <p>
                        <code>A successful installation displays output similar to the following:
                          Retrieving package postgresql-libs-8.3.5-1.12.x86_64 (1/4), 172.0 KiB (571.0 KiB unpacked)
                          Retrieving: postgresql-libs-8.3.5-1.12.x86_64.rpm [done (47.3 KiB/s)]
                          Installing: postgresql-libs-8.3.5-1.12 [done]
                          Retrieving package postgresql-8.3.5-1.12.x86_64 (2/4), 1.0 MiB (4.2 MiB unpacked)
                          Retrieving: postgresql-8.3.5-1.12.x86_64.rpm [done (148.8 KiB/s)]
                          Installing: postgresql-8.3.5-1.12 [done]
                          Retrieving package postgresql-server-8.3.5-1.12.x86_64 (3/4), 3.0 MiB (12.6 MiB unpacked)
                          Retrieving: postgresql-server-8.3.5-1.12.x86_64.rpm [done (452.5 KiB/s)]
                          Installing: postgresql-server-8.3.5-1.12 [done]
                          Updating etc/sysconfig/postgresql...
                          Retrieving package ambari-server-1.7.0-135.noarch (4/4), 99.0 MiB (126.3 MiB unpacked)
                          Retrieving: ambari-server-1.7.0-135.noarch.rpm [done (3.0 MiB/s)]
                          Installing: ambari-server-1.7.0-135 [done]
                          ambari-server 0:off 1:off 2:off 3:on 4:off 5:on 6:off
                        </code>
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
            <div class="tab">
              <p class="bold">UBUNTU 12</p>
              <div class="tab-content">
                <p>On a server host that has Internet access, use a command line editor to perform the following
                  steps:
                </p>
                <ul class="number-list">
                  
                    <strong>UBUNTU 12</strong>
                  
                  
                    <li>
                      <p>Log in to your host as<code>root</code>. For example, type:
                      </p>
                      <p>
                        <code>ssh &lt;username&gt;@&lt;fqdn&gt;</code>
                        <code>sudo su -</code>
                        where
                        <code>&lt;username&gt;</code>
                        is your user name and
                        <code>&lt;fqdn&gt;</code>
                        is the fully qualified domain name of your server host.
                      </p>
                    </li>
                    <li>
                      <p>Download the Ambari repository file to a directory on your installation host.
                        <code>wget -nv
                          http://public-repo-1.hortonworks.com/ambari/ubuntu12/1.x/updates/1.7.0/ambari.list -O
                          /etc/apt/sources.list.d/ambari.list

                          apt-key adv --recv-keys --keyserver keyserver.ubuntu.com B9733A7A07513CAD

                          apt-get update
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Important.png" width="50"></div>
                        <div class="simple-block">
                          <p>Do not modify the
                            <code>ambari.list</code>
                            file name. This file is expected to be available on the Ambari Server host during Agent
                            registration.
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>Confirm that Ambari packages downloaded successfully by checking the package name
                        list.
                      </p>
                      <p>
                        <code>apt-cache pkgnames
                        </code>
                        You should see the Ambari packages in the list.
                      </p>
                      <p>
                        Version values vary, depending on the installation.
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          <thead></thead>
                          <tbody>
                            <tr>
                              <th rowspan="1">
                                <p>
                                  <strong>Alias</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>Name</strong>
                                </p>
                              </th>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>AMBARI-dev-2.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Ambari 2.x</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                    </li>
                    <li>
                      <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                      <p>
                        <code>apt-get install ambari-server</code>
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
            <div class="tab">
              <p class="bold">RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</p>
              <div class="tab-content">
                <p>
                  On a server host that has Internet access, use a command line editor to perform the following steps:
                </p>
                <ul class="number-list">
                  
                    <strong>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</strong>
                  
                  
                    <li>
                      <p>Log in to your host as<code>root</code>. For example, type:
                      </p>
                      <p>
                        <code>ssh &lt;username&gt;@&lt;fqdn&gt;</code>
                        <code>sudo su -</code>
                        where
                        <code>&lt;username&gt;</code>
                        is your user name and
                        <code>&lt;fqdn&gt;</code>
                        is the fully qualified domain name of your server host.
                      </p>
                    </li>
                    <li>
                      <p>Download the Ambari repository file to a directory on your installation host.
                        <code>
                          wget -nv http://public-repo-1.hortonworks.com/ambari/centos5/1.x/updates/1.7.0/ambari.repo -O
                          /etc/yum.repos.d/ambari.repo
                        </code>
                      </p>
                      <aside class="custom-note">
                        <div class="icon"><img src="Icons/Important.png" width="50"></div>
                        <div class="simple-block">
                          <p>Do not modify the
                            <code>ambari.repo</code>
                            file name. This file is expected to be available on the Ambari Server host during Agent
                            registration.
                          </p>
                        </div>
                      </aside>
                    </li>
                    <li>
                      <p>Confirm the repository is configured by checking the repo list.</p>
                      <p>
                        <code>yum repolist</code>
                        You should see the Ambari repositories in the list.
                      </p>
                      <p>
                        <code>AMBARI.1.7.0-1.x | 951 B 00:00
                          AMBARI.1.7.0-1.x/primary | 1.6 kB 00:00
                          AMBARI.1.7.0-1.x 5/5
                          epel | 3.7 kB 00:00
                          epel/primary_db | 3.9 MB 00:01
                        </code>
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          
                          <thead></thead>
                          <tbody>
                            <tr>
                              <th rowspan="1">
                                <p>
                                  <strong>repo Id</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>repo Name</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>status</strong>
                                </p>
                              </th>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>AMBARI.1.7.0-1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>Ambari 1.x</p>
                              </td>
                              <td rowspan="1">
                                <p>5</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>base</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-5 - Base</p>
                              </td>
                              <td rowspan="1">
                                <p>3,667</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>epel</p>
                              </td>
                              <td rowspan="1">
                                <p>Extra Packages for Enterprise Linux 5 - x86_64</p>
                              </td>
                              <td rowspan="1">
                                <p>7,614</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>puppet</p>
                              </td>
                              <td rowspan="1">
                                <p>Puppet</p>
                              </td>
                              <td rowspan="1">
                                <p>433</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>updates</p>
                              </td>
                              <td rowspan="1">
                                <p>CentOS-5 - Updates</p>
                              </td>
                              <td rowspan="1">
                                <p>118</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                    </li>
                    <li>
                      <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                      <p>
                        <code>yum install ambari-server</code>
                        <code></code>
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
          </div>
        
        
          <p>
            Follow instructions in the section for the operating system that runs on your installation host.
            Use a command line editor to perform each instruction.
          </p>
          <ul class="number-list">
            
              <strong>RHEL/CentOS/Oracle Linux 6</strong>
            
            
              <li>
                <p>Log in to your host as<code>root</code>. For example, type:
                </p>
                <p>
                  <code>ssh &lt;username&gt;@&lt;fqdn&gt;</code>
                  <code>sudo su -</code>
                  where
                  <code>&lt;username&gt;</code>
                  is your user name and
                  <code>&lt;fqdn&gt;</code>
                  is the fully qualified domain name of your server host.
                </p>
              </li>
              <li>
                <p>Download the Ambari repository file to a directory on your installation host.</p>
                <p>
                  <code>wget -nv
                    http://public-repo-1.hortonworks.com/ambari/centos6/1.x/updates/1.7.0/ambari.repo -O
                    /etc/yum.repos.d/ambari.repo
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Do not modify the
                      <code>ambari.repo</code>
                      file name. This file is expected to be available on the Ambari Server host during Agent
                      registration.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Confirm that the repository is configured by checking the repo list.</p>
                <p>
                  <code>yum repolist</code>
                  You should see values similar to the following for Ambari repositories in the list.
                </p>
                <p>
                  Version values vary, depending on the installation.
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    
                    <thead></thead>
                    <tbody>
                      <tr>
                        <th rowspan="1">
                          <p>
                            <strong>repo id</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>repo name</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>status</strong>
                          </p>
                        </th>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>AMBARI.1.7.0-1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Ambari 1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>5</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>base</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-6 - Base</p>
                        </td>
                        <td rowspan="1">
                          <p>6,518</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>extras</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-6 - Extras</p>
                        </td>
                        <td rowspan="1">
                          <p>15</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>updates</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-6 - Updates</p>
                        </td>
                        <td rowspan="1">
                          <p>209</p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
              <li>
                <p>Install the Ambari bits. This also installs the default PostgreSQL Ambari database.</p>
                <p>
                  <code>yum install ambari-server</code>
                </p>
              </li>
              <li>
                <p>Enter
                  <code>y</code>
                  when prompted to to confirm transaction and dependency checks.
                </p>
                <p>A successful installation displays output similar to the following:
                  <code>Installing : postgresql-libs-8.4.20-1.el6_5.x86_64 1/4
                    Installing : postgresql-8.4.20-1.el6_5.x86_64 2/4
                    Installing : postgresql-server-8.4.20-1.el6_5.x86_64 3/4
                    Installing : ambari-server-1.7.0-135.noarch 4/4
                    Verifying : postgresql-server-8.4.20-1.el6_5.x86_64 1/4
                    Verifying : postgresql-libs-8.4.20-1.el6_5.x86_64 2/4
                    Verifying : ambari-server-1.7.0-135.noarch 3/4
                    Verifying : postgresql-8.4.20-1.el6_5.x86_64 4/4

                    Installed:
                    ambari-server.noarch 0:1.7.0-135

                    Dependency Installed:
                    postgresql.x86_64 0:8.4.20-1.el6_5 postgresql-libs.x86_64 0:8.4.20-1.el6_5
                    postgresql-server.x86_64 0:8.4.20-1.el6_5

                    Complete!
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>Accept the warning about trusting the Pivotal GPG Key. That key will be automatically
                      downloaded and used to validate packages from Pivotal. You will see the following message:

                      <code>Importing GPG key 0x07513CAD:
                        Userid: "Jenkins (HDP Builds) &lt;jenkin@hortonworks.com&gt;"
                        From :
                        http://s3.amazonaws.com/dev.hortonworks.com/ambari/centos6/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins
                      </code>
                    </p>
                  </div>
                </aside>
              </li>
            
          </ul>
          <ul class="number-list">
            
              <strong>SLES 11</strong>
            
            
              <li>
                <p>Log in to your host as<code>root</code>. For example, type:
                </p>
                <p>
                  <code>ssh &lt;username&gt;@&lt;fqdn&gt;</code>
                  <code>sudo su -</code>
                  where
                  <code>&lt;username&gt;</code>
                  is your user name and
                  <code>&lt;fqdn&gt;</code>
                  is the fully qualified domain name of your server host.
                </p>
              </li>
              <li>
                <p>Download the Ambari repository file to a directory on your installation host.
                  <code>wget -nv
                    http://public-repo-1.hortonworks.com/ambari/suse11/1.x/updates/1.7.0/ambari.repo -O
                    /etc/zypp/repos.d/ambari.repo
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Do not modify the
                      <code>ambari.repo</code>
                      file name. This file is expected to be available on the Ambari Server host during Agent
                      registration.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Confirm the downloaded repository is configured by checking the repo list.</p>
                <p>
                  <code>zypper repos</code>
                  You should see the Ambari repositories in the list.
                </p>
                <p>
                  Version values vary, depending on the installation.
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    
                    
                    <thead></thead>
                    <tbody>
                      <tr>
                        <th rowspan="1">
                          <p>
                            <strong>Alias</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>Name</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>Enabled</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>Refresh</strong>
                          </p>
                        </th>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>AMBARI.1.7.0-1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Ambari 1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>No</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>http-demeter.uni-regensburg.de-c997c8f9</p>
                        </td>
                        <td rowspan="1">
                          <p>SUSE-Linux-Enterprise-Software-Development-Kit-11-SP1 11.1.1-1.57</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>opensuse</p>
                        </td>
                        <td rowspan="1">
                          <p>OpenSuse</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                        <td rowspan="1">
                          <p>Yes</p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
              <li>
                <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                <p>
                  <code>zypper install ambari-server</code>
                </p>
              </li>
              <li>
                <p>Enter
                  <code>y</code>
                  when prompted to to confirm transaction and dependency checks.
                </p>
                <p>
                  <code>A successful installation displays output similar to the following:
                    Retrieving package postgresql-libs-8.3.5-1.12.x86_64 (1/4), 172.0 KiB (571.0 KiB unpacked)
                    Retrieving: postgresql-libs-8.3.5-1.12.x86_64.rpm [done (47.3 KiB/s)]
                    Installing: postgresql-libs-8.3.5-1.12 [done]
                    Retrieving package postgresql-8.3.5-1.12.x86_64 (2/4), 1.0 MiB (4.2 MiB unpacked)
                    Retrieving: postgresql-8.3.5-1.12.x86_64.rpm [done (148.8 KiB/s)]
                    Installing: postgresql-8.3.5-1.12 [done]
                    Retrieving package postgresql-server-8.3.5-1.12.x86_64 (3/4), 3.0 MiB (12.6 MiB unpacked)
                    Retrieving: postgresql-server-8.3.5-1.12.x86_64.rpm [done (452.5 KiB/s)]
                    Installing: postgresql-server-8.3.5-1.12 [done]
                    Updating etc/sysconfig/postgresql...
                    Retrieving package ambari-server-1.7.0-135.noarch (4/4), 99.0 MiB (126.3 MiB unpacked)
                    Retrieving: ambari-server-1.7.0-135.noarch.rpm [done (3.0 MiB/s)]
                    Installing: ambari-server-1.7.0-135 [done]
                    ambari-server 0:off 1:off 2:off 3:on 4:off 5:on 6:off
                  </code>
                </p>
              </li>
            
          </ul>
          <ul class="number-list">
            
              <strong>UBUNTU 12</strong>
            
            
              <li>
                <p>Log in to your host as<code>root</code>. For example, type:
                </p>
                <p>
                  <code>ssh &lt;username&gt;@&lt;fqdn&gt;</code>
                  <code>sudo su -</code>
                  where
                  <code>&lt;username&gt;</code>
                  is your user name and
                  <code>&lt;fqdn&gt;</code>
                  is the fully qualified domain name of your server host.
                </p>
              </li>
              <li>
                <p>Download the Ambari repository file to a directory on your installation host.
                  <code>wget -nv
                    http://public-repo-1.hortonworks.com/ambari/ubuntu12/1.x/updates/1.7.0/ambari.list -O
                    /etc/apt/sources.list.d/ambari.list

                    apt-key adv --recv-keys --keyserver keyserver.ubuntu.com B9733A7A07513CAD

                    apt-get update
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Do not modify the
                      <code>ambari.list</code>
                      file name. This file is expected to be available on the Ambari Server host during Agent
                      registration.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Confirm that Ambari packages downloaded successfully by checking the package name list.
                </p>
                <p>
                  <code>apt-cache pkgnames
                  </code>
                  You should see the Ambari packages in the list.
                </p>
                <p>
                  Version values vary, depending on the installation.
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    <thead></thead>
                    <tbody>
                      <tr>
                        <th rowspan="1">
                          <p>
                            <strong>Alias</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>Name</strong>
                          </p>
                        </th>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>AMBARI-dev-2.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Ambari 2.x</p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
              <li>
                <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                <p>
                  <code>apt-get install ambari-server</code>
                </p>
              </li>
            
          </ul>
          <ul class="number-list">
            
              <strong>RHEL/CentOS/ORACLE Linux 5 (DEPRECATED)</strong>
            
            
              <li>
                <p>Log in to your host as<code>root</code>. For example, type:
                </p>
                <p>
                  <code>ssh &lt;username&gt;@&lt;fqdn&gt;</code>
                  <code>sudo su -</code>
                  where
                  <code>&lt;username&gt;</code>
                  is your user name and
                  <code>&lt;fqdn&gt;</code>
                  is the fully qualified domain name of your server host.
                </p>
              </li>
              <li>
                <p>Download the Ambari repository file to a directory on your installation host.
                  <code>
                    wget -nv http://public-repo-1.hortonworks.com/ambari/centos5/1.x/updates/1.7.0/ambari.repo -O
                    /etc/yum.repos.d/ambari.repo
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Important.png" width="50"></div>
                  <div class="simple-block">
                    <p>Do not modify the
                      <code>ambari.repo</code>
                      file name. This file is expected to be available on the Ambari Server host during Agent
                      registration.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Confirm the repository is configured by checking the repo list.</p>
                <p>
                  <code>yum repolist</code>
                  You should see the Ambari repositories in the list.
                </p>
                <p>
                  <code>AMBARI.1.7.0-1.x | 951 B 00:00
                    AMBARI.1.7.0-1.x/primary | 1.6 kB 00:00
                    AMBARI.1.7.0-1.x 5/5
                    epel | 3.7 kB 00:00
                    epel/primary_db | 3.9 MB 00:01
                  </code>
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    
                    <thead></thead>
                    <tbody>
                      <tr>
                        <th rowspan="1">
                          <p>
                            <strong>repo Id</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>repo Name</strong>
                          </p>
                        </th>
                        <th rowspan="1">
                          <p>
                            <strong>status</strong>
                          </p>
                        </th>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>AMBARI.1.7.0-1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>Ambari 1.x</p>
                        </td>
                        <td rowspan="1">
                          <p>5</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>base</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-5 - Base</p>
                        </td>
                        <td rowspan="1">
                          <p>3,667</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>epel</p>
                        </td>
                        <td rowspan="1">
                          <p>Extra Packages for Enterprise Linux 5 - x86_64</p>
                        </td>
                        <td rowspan="1">
                          <p>7,614</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>puppet</p>
                        </td>
                        <td rowspan="1">
                          <p>Puppet</p>
                        </td>
                        <td rowspan="1">
                          <p>433</p>
                        </td>
                      </tr>
                      <tr>
                        <td rowspan="1">
                          <p>updates</p>
                        </td>
                        <td rowspan="1">
                          <p>CentOS-5 - Updates</p>
                        </td>
                        <td rowspan="1">
                          <p>118</p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
              <li>
                <p>Install the Ambari bits. This also installs PostgreSQL.</p>
                <p>
                  <code>yum install ambari-server</code>
                  <code></code>
                </p>
              </li>
            
          </ul>
          
        
        
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>When deploying HDP on a cluster having limited or no Internet access, you should provide access
                to the bits using an alternative method.
              </p>
              <ul class="bullet-list">
                
                  <li>
                    <p>For more information about setting up local repositories, see<a href="#ref-28d7e1f2-0adb-436a-a4b1-65b522fdcdf2">Optional: Configure Local
                      Repositories</a>.
                    </p>
                  </li>
                  <li>
                    <p>For more information about obtaining JCE policy archives for secure authentication, see
                      <a href="#ref-ec1f472e-3232-4a81-acc5-b3ef236f4737">Deploying JCE Policy Archives on the
                        Ambari Server</a>.
                    </p>
                  </li>
                
              </ul>
              <p>Ambari Server by default uses an embedded PostgreSQL database. When you install the Ambari
                Server, the PostgreSQL packages and dependencies must be available for install. These packages are
                typically available as part of your Operating System repositories. Please confirm you have the
                appropriate repositories available for the postgresql-server packages.
              </p>
            </div>
          </aside>
        
      
      
        <h3 class="horton-blue bold" id="ref-ce168039-28fd-49cd-ba4b-455ce949b471">Install the Ambari Agents Manually</h3>
        
          <p>Use the instructions specific to the OS family running on your agent hosts.</p>
          <div class="tabs">
            
            <div class="tab">
              <p class="bold">RHEL/CentOS/Oracle Linux 6</p>
              <div class="tab-content">
                <ul class="number-list">
                  
                    <li>
                      <p>Install the Ambari Agent on every host in your cluster.</p>
                      <p>
                        <code></code>
                        <code>yum install ambari-agent</code>
                      </p>
                    </li>
                    <li>
                      <p>Using a text editor, configure the Ambari Agent by editing the
                        <code>ambari-agent.ini</code>
                        file as shown in the following example:
                      </p>
                      <p>
                        <code>vi /etc/ambari-agent/conf/ambari-agent.ini [server] hostname=&lt;your.ambari.server.hostname&gt;url_port=8440
                          secured_url_port=8441
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>Start the agent on every host in your cluster.</p>
                      <p>
                        <code>ambari-agent start</code>
                      </p>
                      <p>
                        The agent registers with the Server on start.
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
            <div class="tab">
              <p class="bold">SLES 11</p>
              <div class="tab-content">
                <ul class="number-list">
                  
                    <li>
                      <p>Install the Ambari Agent on every host in your cluster.</p>
                      <p>
                        <code>zypper install ambari-agent</code>
                      </p>
                    </li>
                    <li>
                      <p>Configure the Ambari Agent by editing the
                        <code>ambari-agent.ini</code>
                        file as shown in the following example:
                      </p>
                      <p>
                        <code>vi /etc/ambari-agent/conf/ambari-agent.ini [server]hostname=&lt;your.ambari.server.hostname&gt;url_port=8440secured_url_port=8441</code>
                      </p>
                    </li>
                    <li>
                      <p>Start the agent on every host in your cluster.</p>
                      <p>
                        <code>ambari-agent start</code>
                      </p>
                      <p>
                        The agent registers with the Server on start.
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
            <div class="tab">
              <p class="bold">UBUNTU 12</p>
              <div class="tab-content">
                <ul class="number-list">
                  
                    <li>
                      <p>Install the Ambari Agent on every host in your cluster.</p>
                      <p>
                        <code>apt-get install ambari-agent</code>
                      </p>
                    </li>
                    <li>
                      <p>Configure the Ambari Agent by editing the
                        <code>ambari-agent.ini</code>
                        file as shown in the following example:
                      </p>
                      <p>
                        <code>vi /etc/ambari-agent/conf/ambari-agent.ini [server]hostname=&lt;your.ambari.server.hostname&gt;url_port=8440secured_url_port=8441</code>
                      </p>
                    </li>
                    <li>
                      <p>Start the agent on every host in your cluster.</p>
                      <p>
                        <code>ambari-agent start</code>
                      </p>
                      <p>
                        The agent registers with the Server on start.
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
            <div class="tab">
              <p class="bold">RHEL/CentOS/Oracle Linux 5 (DEPRECATED)</p>
              <div class="tab-content">
                <ul class="number-list">
                  
                    <li>
                      <p>Install the Ambari Agent on every host in your cluster.</p>
                      <p>
                        <code></code>
                        <code>yum install ambari-agent</code>
                      </p>
                    </li>
                    <li>
                      <p>Using a text editor, configure the Ambari Agent by editing the
                        <code>ambari-agent.ini</code>
                        file as shown in the following example:
                      </p>
                      <p>
                        <code>vi /etc/ambari-agent/conf/ambari-agent.ini [server] hostname=&lt;your.ambari.server.hostname&gt;url_port=8440
                          secured_url_port=8441
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>Start the agent on every host in your cluster.</p>
                      <p>
                        <code>ambari-agent start</code>
                      </p>
                      <p>
                        The agent registers with the Server on start.
                      </p>
                    </li>
                  
                </ul>
              </div>
            </div>
          </div>
        
        
          <p>RHEL/CentOS/Oracle Linux 6</p>
          <ul class="number-list">
            
              <li>
                <p>Install the Ambari Agent on every host in your cluster.</p>
                <p>
                  <code></code>
                  <code>yum install ambari-agent</code>
                </p>
              </li>
              <li>
                <p>Using a text editor, configure the Ambari Agent by editing the
                  <code>ambari-agent.ini</code>
                  file as shown in the following example:
                </p>
                <p>
                  <code>vi /etc/ambari-agent/conf/ambari-agent.ini [server] hostname=&lt;your.ambari.server.hostname&gt;url_port=8440
                    secured_url_port=8441
                  </code>
                </p>
              </li>
              <li>
                <p>Start the agent on every host in your cluster.</p>
                <p>
                  <code>ambari-agent start</code>
                </p>
                <p>
                  The agent registers with the Server on start.
                </p>
              </li>
            
          </ul>
          <p>SLES 11</p>
          <ul class="number-list">
            
              <li>
                <p>Install the Ambari Agent on every host in your cluster.</p>
                <p>
                  <code></code>
                  <code>yum install ambari-agent</code>
                </p>
              </li>
              <li>
                <p>Using a text editor, configure the Ambari Agent by editing the
                  <code>ambari-agent.ini</code>
                  file as shown in the following example:
                </p>
                <p>
                  <code>vi /etc/ambari-agent/conf/ambari-agent.ini [server] hostname=&lt;your.ambari.server.hostname&gt;url_port=8440
                    secured_url_port=8441
                  </code>
                </p>
              </li>
              <li>
                <p>Start the agent on every host in your cluster.</p>
                <p>
                  <code>ambari-agent start</code>
                </p>
                <p>
                  The agent registers with the Server on start.
                </p>
              </li>
            
          </ul>
          <p>UBUNTU 12</p>
          <ul class="number-list">
            
              <li>
                <p>Install the Ambari Agent on every host in your cluster.</p>
                <p>
                  <code></code>
                  <code>yum install ambari-agent</code>
                </p>
              </li>
              <li>
                <p>Using a text editor, configure the Ambari Agent by editing the
                  <code>ambari-agent.ini</code>
                  file as shown in the following example:
                </p>
                <p>
                  <code>vi /etc/ambari-agent/conf/ambari-agent.ini [server] hostname=&lt;your.ambari.server.hostname&gt;url_port=8440
                    secured_url_port=8441
                  </code>
                </p>
              </li>
              <li>
                <p>Start the agent on every host in your cluster.</p>
                <p>
                  <code>ambari-agent start</code>
                </p>
                <p>
                  The agent registers with the Server on start.
                </p>
              </li>
            
          </ul>
          <p>RHEL/CentOS/Oracle Linux 5 (DEPRECATED)</p>
          <ul class="number-list">
            
              <li>
                <p>Install the Ambari Agent on every host in your cluster.</p>
                <p>
                  <code></code>
                  <code>yum install ambari-agent</code>
                </p>
              </li>
              <li>
                <p>Using a text editor, configure the Ambari Agent by editing the
                  <code>ambari-agent.ini</code>
                  file as shown in the following example:
                </p>
                <p>
                  <code>vi /etc/ambari-agent/conf/ambari-agent.ini [server] hostname=&lt;your.ambari.server.hostname&gt;url_port=8440
                    secured_url_port=8441
                  </code>
                </p>
              </li>
              <li>
                <p>Start the agent on every host in your cluster.</p>
                <p>
                  <code>ambari-agent start</code>
                </p>
                <p>
                  The agent registers with the Server on start.
                </p>
              </li>
            
          </ul>
          
        
      
    
    
      <h2 class="horton-green bold">Customizing HDP Services</h2>
      
        
          <p>You can override the default service settings established by the Ambari install wizard. For
            information about customizing service settings for your HDP Stack version, see one of the following topics:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-eeda7cc9-867e-4485-90cd-9d9c35001c55">Customizing Services for a HDP 2.x
                    Stack
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-6c6f06e3-5645-41fa-9d90-b081b0c7dd2f">Customizing Services for a HDP 1.x
                    Stack
                  </a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-eeda7cc9-867e-4485-90cd-9d9c35001c55">Customizing Services for a HDP 2.x Stack</h3>
        
          <p>Generally, you can customize services for the HDP 2.x Stack by overriding default settings that
            appear in
            <code>Services &gt; Configs</code>
            for each Service in the Ambari Web GUI.
          </p>
        
        
          <h4 class="bold">Defining Service Users and Groups for HDP 2.x</h4>
          
            <p>The individual services in Hadoop run under the ownership of their respective Unix accounts. These
              accounts are known as service users. These service users belong to a special Unix group. "Smoke Test" is a
              service user dedicated specifically for running smoke tests on components during installation using the
              <code>Services</code>
              View of the Ambari Web GUI. You can also run service checks as the "Smoke Test" user on-demand after
              installation. You can customize any of these users and groups using the
              <code>Misc</code>
              tab during the
              <code>Customize Services</code>
              installation step.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>Use the
                  <code>Skip Group Modifications</code>
                  option to not modify the Linux groups in the cluster. Choosing this option is typically required if
                  your environment manages groups using LDAP and not on the local Linux machines.
                </p>
              </div>
            </aside>
            <p>If you choose to customize names, Ambari checks to see if these custom accounts already exist. If
              they do not exist, Ambari creates them. The default accounts are always created during installation
              whether or not custom accounts are specified. These default accounts are not used and can be removed
              post-install.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>All new service user accounts, and any existing user accounts used as service users, must have
                  a UID &gt;= 1000.
                </p>
              </div>
            </aside>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">Service Users</p>
              
                
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Service*</p>
                    </th>
                    <th rowspan="1">
                      <p>Component</p>
                    </th>
                    <th rowspan="1">
                      <p>Default User Account</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>Knox</p>
                    </td>
                    <td rowspan="1">
                      <p>Knox Gateway</p>
                    </td>
                    <td rowspan="1">
                      <p>knox</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Kafka</p>
                    </td>
                    <td rowspan="1">
                      <p>Kafka Broker</p>
                    </td>
                    <td rowspan="1">
                      <p>kafka</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HDFS</p>
                    </td>
                    <td rowspan="1">
                      <p>NameNode SecondaryNameNode DataNode</p>
                    </td>
                    <td rowspan="1">
                      <p>hdfs</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>YARN</p>
                    </td>
                    <td rowspan="1">
                      <p>NodeManager ResourceManager</p>
                    </td>
                    <td rowspan="1">
                      <p>yarn</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>MapReduce2</p>
                    </td>
                    <td rowspan="1">
                      <p>HistoryServer</p>
                    </td>
                    <td rowspan="1">
                      <p>mapred</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Tez</p>
                    </td>
                    <td rowspan="1">
                      <p>Tez clients</p>
                    </td>
                    <td rowspan="1">
                      <p>tez
                        (Tez is available with HDP 2.1 or 2.2 Stack.)
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase</p>
                    </td>
                    <td rowspan="1">
                      <p>MasterServer RegionServer</p>
                    </td>
                    <td rowspan="1">
                      <p>hbase</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Hive</p>
                    </td>
                    <td rowspan="1">
                      <p>Hive Metastore, HiveServer2</p>
                    </td>
                    <td rowspan="1">
                      <p>hive</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HCat</p>
                    </td>
                    <td rowspan="1">
                      <p>HCatalog Client</p>
                    </td>
                    <td rowspan="1">
                      <p>hcat</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>WebHCat</p>
                    </td>
                    <td rowspan="1">
                      <p>WebHCat Server</p>
                    </td>
                    <td rowspan="1">
                      <p>hcat</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Falcon</p>
                    </td>
                    <td rowspan="1">
                      <p>Falcon Server</p>
                    </td>
                    <td rowspan="1">
                      <p>falcon
                        (Falcon is available with HDP 2.1 or 2.2 Stack.)
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Storm</p>
                    </td>
                    <td rowspan="1">
                      <p>Masters (Nimbus, DRPC Server, Storm REST API, Server, Storm UI Server) Slaves
                        (Supervisors, Logviewers)
                      </p>
                    </td>
                    <td rowspan="1">
                      <p>storm
                        (Storm is available with HDP 2.1 or 2.2 Stack.)
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Oozie</p>
                    </td>
                    <td rowspan="1">
                      <p>Oozie Server</p>
                    </td>
                    <td rowspan="1">
                      <p>oozie</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia</p>
                    </td>
                    <td rowspan="1">
                      <p>Ganglia Server Ganglia Monitors</p>
                    </td>
                    <td rowspan="1">
                      <p>nobody</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia</p>
                    </td>
                    <td rowspan="1">
                      <p>RRDTool (with Ganglia Server)</p>
                    </td>
                    <td rowspan="1">
                      <p>rrdcahed
                        (Created as part of installing RRDTool, which is used to store metrics data collected by
                        Ganglia.)
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia</p>
                    </td>
                    <td rowspan="1">
                      <p>Apache HTTP Server</p>
                    </td>
                    <td rowspan="1">
                      <p>apache
                        (Created as part of installing Apache HTTP Server, which is used to serve the Ganglia web UI.)
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>PostgreSQL</p>
                    </td>
                    <td rowspan="1">
                      <p>PostgreSQL (with Ambari Server)</p>
                    </td>
                    <td rowspan="1">
                      <p>postgres
                        (Created as part of installing the default PostgreSQL database with Ambari Server. If you are
                        not using the Ambari PostgreSQL database, this user is not needed.)
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Nagios</p>
                    </td>
                    <td rowspan="1">
                      <p>Nagios Server</p>
                    </td>
                    <td rowspan="1">
                      <p>nagios
                        (If you plan to use an existing user account named “nagios”, that “nagios” account must either
                        be in a group named “nagios” or you must customize the Nagios Group.)
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>ZooKeeper</p>
                    </td>
                    <td rowspan="1">
                      <p>ZooKeeper</p>
                    </td>
                    <td rowspan="1">
                      <p>zookeeper</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <p>
              *For all components, the Smoke Test user performs smoke tests against cluster services as part of the
              install process. It also can perform these on-demand, from the Ambari Web UI. The default user account for
              the smoke test user is ambari-qa.
            </p>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">Service Group</p>
              
                
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Service</p>
                    </th>
                    <th rowspan="1">
                      <p>Components</p>
                    </th>
                    <th rowspan="1">
                      <p>Default Group Account</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>All</p>
                    </td>
                    <td rowspan="1">
                      <p>All</p>
                    </td>
                    <td rowspan="1">
                      <p>hadoop</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Nagios</p>
                    </td>
                    <td rowspan="1">
                      <p>Nagios Server</p>
                    </td>
                    <td rowspan="1">
                      <p>nagios</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia</p>
                    </td>
                    <td rowspan="1">
                      <p>Ganglia Server Ganglia Monitor</p>
                    </td>
                    <td rowspan="1">
                      <p>nobody</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Knox</p>
                    </td>
                    <td rowspan="1">
                      <p>Knox Gateway</p>
                    </td>
                    <td rowspan="1">
                      <p>knox</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
        
        
          <h4 class="bold">Setting Properties That Depend on Service Usernames/Groups</h4>
          
            <p>Some properties must be set to match specific service user names or service groups. If you have
              set up non-default, customized service user names for the HDFS or HBase service or the Hadoop group name,
              you must edit the following properties, using<code>Services &gt; Service.Name &gt; Configs
                &gt; Advanced hdfs-ste</code>:
            </p>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">HDFS Settings: Advanced</p>
              
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Property Name</p>
                    </th>
                    <th rowspan="1">
                      <p>Value</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>dfs.permissions.superusergroup</p>
                    </td>
                    <td rowspan="1">
                      <p>The same as the HDFS username. The default is "hdfs"</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>dfs.cluster.administrators</p>
                    </td>
                    <td rowspan="1">
                      <p>A single space followed by the HDFS username.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>dfs.block.local-path-access.user</p>
                    </td>
                    <td rowspan="1">
                      <p>The HBase username. The default is "hbase".</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">MapReduce Settings: Advanced</p>
              
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Property Name</p>
                    </th>
                    <th rowspan="1">
                      <p>Value</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>mapreduce.cluster.administrators</p>
                    </td>
                    <td rowspan="1">
                      <p>A single space followed by the Hadoop group name.</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
        
      
      
        <h3 class="horton-blue bold" id="ref-6c6f06e3-5645-41fa-9d90-b081b0c7dd2f">Customizing Services for a HDP 1.x Stack</h3>
        
          <p>Generally, you can customize services for the HDP 1.x Stack by overriding default settings that
            appear in the Management Header for each Service in the Ambari Web GUI.
          </p>
        
        
          <h4 class="bold">Defining Service Users and Groups for HDP 1.x</h4>
          
            <p>The individual services in Hadoop run under the ownership of their respective Unix accounts. These
              accounts are known as service users. These service users belong to a special Unix group. "Smoke Test" is a
              service user dedicated specifically for running smoke tests on components during installation using the
              <code>Services</code>
              View of the Ambari Web GUI. You can also run service checks as the "Smoke Test" user on-demand after
              installation. You can customize any of these users and groups using the
              <code>Misc</code>
              tab during the
              <code>Customize Services</code>
              installation step.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>Use the
                  <code>Skip Group Modifications</code>
                  option to not modify the Linux groups in the cluster. Choosing this option is typically required if
                  your environment manages groups using LDAP and not on the local Linux machines.
                </p>
              </div>
            </aside>
            <p>If you choose to customize names, Ambari checks to see if these custom accounts already exist. If
              they do not exist, Ambari creates them. The default accounts are always created during installation
              whether or not custom accounts are specified. These default accounts are not used and can be removed
              post-install.
            </p>
            <aside class="custom-note">
              <div class="icon"><img src="Icons/Note.png" width="50"></div>
              <div class="simple-block">
                <p>All new service user accounts, and any existing user accounts used as service users, must have
                  a UID &gt;= 1000.
                </p>
              </div>
            </aside>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">Service Users</p>
              
                
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Service</p>
                    </th>
                    <th rowspan="1">
                      <p>Component</p>
                    </th>
                    <th rowspan="1">
                      <p>Default User Account</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>HDFS</p>
                    </td>
                    <td rowspan="1">
                      <p>NameNode SecondaryNameNode DataNode</p>
                    </td>
                    <td rowspan="1">
                      <p>hdfs</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>MapReduce</p>
                    </td>
                    <td rowspan="1">
                      <p>JobTracker HistoryServer TaskTracker</p>
                    </td>
                    <td rowspan="1">
                      <p>mapred</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Hive</p>
                    </td>
                    <td rowspan="1">
                      <p>Hive Metastore HiveServer2</p>
                    </td>
                    <td rowspan="1">
                      <p>hive</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HCat</p>
                    </td>
                    <td rowspan="1">
                      <p>HCatalog Server</p>
                    </td>
                    <td rowspan="1">
                      <p>hcat</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>WebHCat</p>
                    </td>
                    <td rowspan="1">
                      <p>WebHCat Server</p>
                    </td>
                    <td rowspan="1">
                      <p>hcat</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Oozie</p>
                    </td>
                    <td rowspan="1">
                      <p>Oozie Server</p>
                    </td>
                    <td rowspan="1">
                      <p>oozie</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>HBase</p>
                    </td>
                    <td rowspan="1">
                      <p>MasterServer RegionServer</p>
                    </td>
                    <td rowspan="1">
                      <p>hbase</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>ZooKeeper</p>
                    </td>
                    <td rowspan="1">
                      <p>ZooKeeper</p>
                    </td>
                    <td rowspan="1">
                      <p>zookeeper</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Ganglia</p>
                    </td>
                    <td rowspan="1">
                      <p>Ganglia Server Ganglia Collectors</p>
                    </td>
                    <td rowspan="1">
                      <p>nobody</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Nagios</p>
                    </td>
                    <td rowspan="1">
                      <p>Nagios Server</p>
                    </td>
                    <td rowspan="1">
                      <p>nagios

                        (If you plan to use an existing user account named "nagios", that "nagios" account must be in a
                        group named "nagios". If you customize this account, that account will be created and put in a
                        group "nagios".)
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>Smoke Test</p>
                    </td>
                    <td rowspan="1">
                      <p>All</p>
                    </td>
                    <td rowspan="1">
                      <p>ambari-qa

                        (The Smoke Test user performs smoke tests against cluster services as part of the install
                        process. It also can perform these on-demand from the Ambari Web GUI.)
                      </p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">Service Group</p>
              
                
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Service</p>
                    </th>
                    <th rowspan="1">
                      <p>Components</p>
                    </th>
                    <th rowspan="1">
                      <p>Default Group Account</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>All</p>
                    </td>
                    <td rowspan="1">
                      <p>All</p>
                    </td>
                    <td rowspan="1">
                      <p>hadoop</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
        
        
          <h4 class="bold">Setting Properties That Depend on Service Usernames/Groups</h4>
          
            <p>Some properties must be set to match specific service user names or service groups. If you have
              set up non-default, customized service user names for the HDFS or HBase service or the Hadoop group name,
              you must edit the following properties, using<code>Services &gt; Service.Name &gt; Configs
                &gt; Advanced</code>:
            </p>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">HDFS Settings: Advanced</p>
              
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Property Name</p>
                    </th>
                    <th rowspan="1">
                      <p>Value</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>dfs.permissions.supergroup</p>
                    </td>
                    <td rowspan="1">
                      <p>The same as the HDFS username. The default is "hdfs"</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>dfs.cluster.administrators</p>
                    </td>
                    <td rowspan="1">
                      <p>A single space followed by the HDFS username.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>dfs.block.local-path-access.user</p>
                    </td>
                    <td rowspan="1">
                      <p>The HBase username. The default is "hbase".</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <div class="xyleme-table"><table border="1">
              <p class="italic bold">MapReduce Settings: Advanced</p>
              
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Property Name</p>
                    </th>
                    <th rowspan="1">
                      <p>Value</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>mapreduce.tasktracker.group</p>
                    </td>
                    <td rowspan="1">
                      <p>The Hadoop group name. The default is "hadoop".</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>mapreduce.cluster.administrators</p>
                    </td>
                    <td rowspan="1">
                      <p>A single space followed by the Hadoop group name.</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
          
        
        
          <h4 class="bold">Recommended Memory Configurations for the MapReduce Service</h4>
          
            <p>The following recommendations can help you determine appropriate memory configurations based on
              your usage scenario:
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>Make sure that there is enough memory for all of the processes. Remember that system
                    processes take around 10% of the available memory.
                  </p>
                </li>
                <li>
                  <p>For co-deploying an HBase RegionServer and MapReduce service on the same node, reduce the
                    RegionServer's heap size (use the
                    <code>HBase Settings &gt; RegionServer &gt; HBase Region Servers maximum Java heap
                      size
                    </code>
                    property to modify the RegionServer heap size).
                  </p>
                </li>
                <li>
                  <p>For co-deploying an HBase RegionServer and the MapReduce service on the same node, or for
                    memory intensive MapReduce applications, modify the map and reduce slots as suggested in the
                    following example:
                  </p>
                </li>
              
            </ul>
            <p>
              <strong>EXAMPLE:</strong>
              For co-deploying an HBase RegionServer and the MapReduce service on a machine with 16GB of available
              memory, the following would be a recommended configuration:
            </p>
            <p>2 GB: system processes</p>
            <p>8 GB: MapReduce slots. 6 Map + 2 Reduce slots per 1 GB task</p>
            <p>4 GB: HBase RegionServer</p>
            <p>1 GB: TaskTracker</p>
            <p>1 GB: DataNode</p>
            <p>To change the number of Map and Reduce slots based on the memory requirements of your application,
              use the following properties:
            </p>
            <p>
              <strong>MapReduce Settings: TaskTracker</strong>
              :
              <code>Number of Map slots per node</code>
            </p>
            <p>
              <strong>MapReduce Settings: TaskTracker</strong>
              :
              <code>Number of Reduce slots per node</code>
            </p>
          
        
      
    
    
      <h2 class="horton-green bold">Using Custom Host Names</h2>
      
        
          <p>You can customize the agent registration host name and the public host name used for  each host in
            Ambari. Use this capability when "hostname" does not return the public network host name for your machines.
          </p>
          <p>
            <a href="#ref-37533a4c-11a5-4e86-9497-960caa65e3b2">How to Customize the name of a host</a>
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-37533a4c-11a5-4e86-9497-960caa65e3b2">How to Customize the name of a host</h3>
        
          <ul class="number-list">
            
              <li>
                <p>At the
                  <code>Install Options</code>
                  step in the Cluster Installer wizard, select<code>Perform Manual Registration for
                    Ambari Agents</code>.
                </p>
              </li>
              <li>
                <p>Install the Ambari Agents manually on each host, as described in<a href="#ref-ce168039-28fd-49cd-ba4b-455ce949b471">Install the Ambari Agents Manually</a>
                  .
                </p>
              </li>
              <li>
                <p>To echo the customized name of the host to which the Ambari agent registers, for every host,
                  create a script like the following example, named <code>
                    /var/lib/ambari-agent/hostname.sh</code>. Be sure to
                  <code>chmod</code>
                  the script so it is executable by the Agent.
                  <code>#!/bin/sh  echo
                  </code>
                  &lt;ambari_hostname&gt;
                </p>
                <p>
                  where
                  &lt;ambari_hostname&gt;
                  is the host name to use for Agent registration.
                </p>
              </li>
              <li>
                <p>Open
                  <code>/etc/ambari-agent/conf/ambari-agent.ini</code>
                  on every host, using a text editor.
                </p>
              </li>
              <li>
                <p>Add to the
                  <code>[agent]</code>
                  section the following line:
                </p>
                <p>
                  <code>
                    hostname_script=/var/lib/ambari-agent/hostname.sh
                  </code>
                </p>
                <p>
                  where
                  <code>/var/lib/ambari-agent/hostname.sh</code>
                  is the name of your custom echo script.
                </p>
              </li>
              <li>
                <p>To generate a public host name for every host, create a script like the following example,
                  named
                  <code>var/lib/ambari-agent/public_hostname.sh</code>
                  to show the name for that host in the UI. Be sure to
                  <code>chmod</code>
                  the script so it is executable by the Agent.
                  <code>#!/bin/sh</code>
                  &lt;hostname&gt;
                  <code>-f</code>
                </p>
                <p>
                  where
                   &lt;hostname&gt;
                  is the host name to use for Agent registration.
                </p>
              </li>
              <li>
                <p>Open
                  <code>/etc/ambari-agent/conf/ambari-agent.ini</code>
                  on every host, using a text editor.
                </p>
              </li>
              <li>
                <p>Add to the
                  <code>[agent]</code>
                  section the following line:
                </p>
                <p>
                  public_hostname_script=/var/lib/ambari-agent/public_hostname.sh
                </p>
              </li>
              <li>
                <p>If applicable, add the host names to
                  <code>/etc/hosts</code>
                  on every host.
                </p>
              </li>
              <li>
                <p>Restart the Agent on every host for these changes to take effect.</p>
                <p>
                  <code>ambari-agent restart</code>
                </p>
              </li>
            
          </ul>
        
      
    
    
      <h2 class="horton-green bold">Moving the Ambari Server</h2>
      
        
          <p>To transfer an Ambari Server that uses the default, PostgreSQL database to a new host, use the
            following instructions:
          </p>
          <ul class="number-list">
            
              <li>
                <p>
                  <a href="#ref-70abae27-19c7-49c2-a373-fadbed4d8d97">Back up all current data</a>
                  - from the original Ambari Server and MapReduce databases.
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-6b596c1a-a195-4164-9368-6a60ef5abda5">Update all Agents</a>
                  - to point to the new Ambari Server.
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-6fb36a70-54ef-4c39-9367-25a58968725d">Install the New Server</a>
                  - on a new host and populate databases with information from original Server.
                </p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>If your Ambari database is one of the non-default types, such as Oracle, adjust the database
                backup, restore, and stop/start procedures to match that database type.
              </p>
            </div>
          </aside>
        
      
      
        <h3 class="horton-blue bold" id="ref-70abae27-19c7-49c2-a373-fadbed4d8d97">Back up Current Data</h3>
        
          <ul class="number-list">
            
              <li>
                <p>Stop the original Ambari Server.</p>
                <p>
                  <code>ambari-server stop</code>
                </p>
              </li>
              <li>
                <p>Create a directory to hold the database backups.</p>
                <p>
                  <code>
                    cd /tmp
                    mkdir dbdumps
                    cd dbdumps/
                  </code>
                </p>
              </li>
              <li>
                <p>Create the database backups.</p>
                <p>
                  <code>pg_dump -U</code>
                  &lt;AMBARI.SERVER.USERNAME&gt;
                  <code>ambari &gt; ambari.sql Password:</code>
                  &lt;AMBARI.SERVER.PASSWORD&gt;
                  <code>
                    pg_dump -U
                  </code>
                  &lt;MAPRED.USERNAME&gt;
                  <code>ambarirca &gt; ambarirca.sql Password:</code>
                  &lt;MAPRED.PASSWORD&gt;
                </p>
                <p>
                  where&lt;AMBARI.SERVER.USERNAME&gt;,
                  &lt;MAPRED.USERNAME&gt;,&lt;AMBARI.SERVER.PASSWORD&gt;, and
                  &lt;MAPRED.PASSWORD&gt;
                  are the user names and passwords that you set up during installation. Default values are:
                  <code>ambari-server/bigdata</code>
                  and<code>mapred/mapred</code>.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-6b596c1a-a195-4164-9368-6a60ef5abda5">Update Agents</h3>
        
          <ul class="number-list">
            
              <li>
                <p>On each agent host, stop the agent.</p>
                <p>
                  <code>ambari-agent stop</code>
                </p>
              </li>
              <li>
                <p>Remove old agent certificates.</p>
                <p>
                  <code>rm /var/lib/ambari-agent/keys/*</code>
                </p>
              </li>
              <li>
                <p>Using a text editor, edit
                  <code>/etc/ambari-agent/conf/ambari-agent.ini</code>
                  to point to the new host.
                </p>
                <p>
                  [server]
                  hostname=&lt;NEW FULLY.QUALIFIED.DOMAIN.NAME&gt;
                url_port=8440
                  secured_url_port=8441
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-6fb36a70-54ef-4c39-9367-25a58968725d">Install the New Server and Populate the Databases</h3>
        
          <ul class="number-list">
            
              <li>
                <p>Install the Server on the new host.</p>
              </li>
              <li>
                <p>Stop the Server so that you can copy the old database data to the new Server.</p>
                <p>
                  <code>ambari-server stop</code>
                </p>
              </li>
              <li>
                <p>Restart the PostgreSQL instance.</p>
                <p>
                  <code>service postgresql restart</code>
                </p>
              </li>
              <li>
                <p>Open the PostgreSQL interactive terminal.</p>
                <p>
                  <code>su - postgres
                    psql
                  </code>
                </p>
              </li>
              <li>
                <p>Using the interactive terminal, drop the databases created by the fresh install.</p>
                <p>
                  <code>
                    drop database ambari;
                    drop database ambarirca;
                  </code>
                </p>
              </li>
              <li>
                <p>Check to make sure the databases have been dropped.</p>
                <p>
                  <code>/list</code>
                </p>
                <p>
                  The databases should not be listed.
                </p>
              </li>
              <li>
                <p>Create new databases to hold the transferred data.</p>
                <p>
                  <code>create database ambari;
                    create database ambarirca;
                  </code>
                </p>
              </li>
              <li>
                <p>Exit the interactive terminal.</p>
                <p>
                  <code>^d</code>
                </p>
              </li>
              <li>
                <p>Copy the saved data from
                  <a href="#ref-70abae27-19c7-49c2-a373-fadbed4d8d97">Back up Current Data</a>
                  to the new Server.
                </p>
                <p>
                  <code>cd /tmp
                    scp -i &lt;ssh-key&gt; root@
                  </code>
                  &lt;original.Ambari.Server&gt;
                  <code>/tmp/dbdumps/*.sql/tmp</code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>
                      <code>compress/transfer/uncompress</code>
                      as needed from source to dest
                    </p>
                  </div>
                </aside>
                <p>
                  <code>psql -d ambari -f /tmp/ambari.sql
                    psql -d ambarirca -f /tmp/ambarirca.sql
                  </code>
                </p>
              </li>
              <li>
                <p>Start the new Server.</p>
                <p>
                  <code>&lt;exit to root&gt;
                  </code>
                  <code>ambari-server start</code>
                </p>
              </li>
              <li>
                <p>On each Agent host, start the Agent.</p>
                <p>
                  <code>ambari-agent start</code>
                </p>
              </li>
              <li>
                <p>Open Ambari Web. Point your browser to:</p>
                <p>
                  &lt;new.Ambari.Server&gt;
                  <code>:8080</code>
                </p>
              </li>
              <li>
                <p>Go to
                  <code>Services &gt; MapReduce</code>
                  and use the Management Header to
                  <strong>Stop</strong>
                  and
                  <strong>Start</strong>
                  the MapReduce service.
                </p>
              </li>
              <li>
                <p>Start other services as necessary.</p>
              </li>
            
          </ul>
          <p>
            The new Server is ready to use.
          </p>
        
      
    
    
      <h2 class="horton-green bold">Configuring LZO Compression</h2>
      
        
          <p>LZO is a lossless data compression library that favors speed over compression ratio. Ambari does not
            install nor enable LZO Compression by default.
            To enable LZO compression in your HDP cluster, you must<a href="#ref-b53f37b7-389f-4781-8a2b-eeba4d9de123">Configure core-site.xml for LZO</a>.
          </p>
          <p>
            Optionally, you can implement LZO to optimize Hive queries in your cluster for speed.
            For more information about using LZO compression with Hive, see<a href="#ref-53d79874-3b82-4840-a56b-cc400eb9c98e">Running Compression with Hive Queries</a>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-b53f37b7-389f-4781-8a2b-eeba4d9de123">Configure core-site.xml for LZO</h3>
        
          <ul class="number-list">
            
              <li>
                <p>Browse to<code>Ambari Web &gt; Services &gt; HDFS &gt;
                  Configs</code>, then expand<code>Advanced
                  core-site</code>.
                </p>
              </li>
              <li>
                <p>Find the
                  <code>io.compression.codecs</code>
                  property key.
                </p>
              </li>
              <li>
                <p>Append to the
                  <code>io.compression.codecs</code>
                  property key, the following value:
                  <code>com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec
                  </code>
                </p>
              </li>
              <li>
                <p>Add a description of the config modification, then choose Save.</p>
              </li>
              <li>
                <p>Expand the
                  <code>Custom core-site.xml</code>
                  section.
                </p>
              </li>
              <li>
                <p>Select<code>Add Property</code>.
                </p>
              </li>
              <li>
                <p>Add to
                  <code>Custom core-site.xml</code>
                  the following property key and value
                </p>
                <div class="xyleme-table"><table border="1">
                  
                    
                    
                    <thead>
                      <tr>
                        <th rowspan="1">
                          <p>Property Key</p>
                        </th>
                        <th rowspan="1">
                          <p>Property Value</p>
                        </th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td rowspan="1">
                          <p>io.compression.codec.lzo.class</p>
                        </td>
                        <td rowspan="1">
                          <p>com.hadoop.compression.lzo.LzoCodec</p>
                        </td>
                      </tr>
                    </tbody>
                    
                  
                </table></div>
              </li>
              <li>
                <p>Choose<code>Save</code>.
                </p>
              </li>
              <li>
                <p>Add a description of the config modification, then choose Save.</p>
              </li>
              <li>
                <p>Restart the HDFS, MapReduce2 and YARN services.</p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>If performing a Restart or a Restart All does not start the required package install, you
                      may need to stop, then start the HDFS service to install the necessary LZO packages. Restart is
                      only available for a service in the "Runnning" or "Started" state.
                    </p>
                  </div>
                </aside>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-53d79874-3b82-4840-a56b-cc400eb9c98e">Running Compression with Hive Queries</h3>
        
          <p>Running Compression with Hive Queries requires creating LZO files. To create LZO files, use one of
            the following procedures:
          </p>
        
        
          <h4 class="bold">Create LZO Files</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>Create LZO files as the output of the Hive query.</p>
                </li>
                <li>
                  <p>Use
                    <code>lzop</code>
                    command utility or your custom Java to generate
                    <code>lzo.index</code>
                    for the
                    <code>.lzo</code>
                    files.
                  </p>
                </li>
              
            </ul>
            <p>
              <strong>Hive Query Parameters</strong>
            </p>
            <p>Prefix the query string with these parameters:</p>
            <pre><code>SET mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec
              SET hive.exec.compress.output=true
              SET mapreduce.output.fileoutputformat.compress=true
            </code></pre>
            <p>For example:</p>
            <p>
              <code>hive -e "SET
                mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec;SET
                hive.exec.compress.output=true;SET mapreduce.output.fileoutputformat.compress=true;"
              </code>
            </p>
          
        
        
          <h4 class="bold">Write Custom Java to Create LZO Files</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>Create text files as the output of the Hive query.</p>
                </li>
                <li>
                  <p>Write custom Java code to</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>convert Hive query generated text files to
                          <code>.lzo</code>
                          files
                        </p>
                      </li>
                      <li>
                        <p>generate
                          <code>lzo.index</code>
                          files for the
                          <code>.lzo</code>
                          files
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
            <p>
              <strong>Hive Query Parameters</strong>
            </p>
            <p>Prefix the query string with these parameters:</p>
            <pre><code>SET hive.exec.compress.output=false
              SET mapreduce.output.fileoutputformat.compress=false
            </code></pre>
            <p>For example:</p>
            <p>
              <code>hive -e "SET hive.exec.compress.output=false;SET
                mapreduce.output.fileoutputformat.compress=false;&lt;query-string&gt;"
              </code>
            </p>
          
        
      
    
    
      <h2 class="horton-green bold">Using Non-Default Databases</h2>
      
        
          <p>Use the following instructions to prepare a non-default database for Ambari, Hive/HCatalog, or
            Oozie. You must complete these instructions before you set up the Ambari Server by running<code>
              ambari-server setup</code>.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-6db1b3ae-7e80-4a7c-a73d-20f11379078f">Using Non-Default Databases - Ambari
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-5010f1c4-fc32-44cd-94f5-fe557eefcd6d">Using Non-Default Databases - Hive</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-b9803b8c-5f91-40d5-bdc4-da481581efbf">Using Non-Default Databases - Oozie
                  </a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-6db1b3ae-7e80-4a7c-a73d-20f11379078f">Using Non-Default Databases - Ambari</h3>
        
          <p>The following sections describe how to use Ambari with an existing database, other than the embedded
            PostgreSQL database instance that Ambari Server uses by default.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-e9b1e9fd-5904-46a7-a36c-3d3b96925f6a">Using Ambari with Oracle</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-826a906d-2ce7-4341-8a98-13ec519755de">Using Ambari with MySQL</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-7c4d2521-5377-468e-8e3d-93b5ea19cf46">Using Ambari with PostgreSQL</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-7774fa56-4fa8-4eb9-a973-9add77b8cfc1">Troubleshooting Non-Default Databases
                    with Ambari
                  </a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Using Ambari with Oracle</h4>
          
            <p>To set up Oracle for use with Ambari:</p>
            <ul class="number-list">
              
                <li>
                  <p>On the Ambari Server host, install the appropriate
                    <code>JDBC.jar</code>
                    file.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Download the Oracle JDBC (OJDBC) driver from<a href="http://www.oracle.com/technetwork/database/features/jdbc/index-091264.html">
                          http://www.oracle.com/technetwork/database/features/jdbc/index-091264.html</a>.
                        </p>
                      </li>
                      <li>
                        <p>Select<code>Oracle Database 11g Release 2 - ojdbc6.jar</code>.
                        </p>
                      </li>
                      <li>
                        <p>Copy the .jar file to the Java share directory.</p>
                        <p>
                          <code>cp ojdbc6.jar /usr/share/java</code>
                        </p>
                      </li>
                      <li>
                        <p>Make sure the .jar file has the appropriate permissions - 644.</p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create a user for Ambari and grant that user appropriate permissions.</p>
                  <p>For example, using the Oracle database admin utility, run the following commands:
                  </p>
                  <p>
                    <code># sqlplus sys/root as sysdba
                      CREATE USER &lt;AMBARIUSER&gt; IDENTIFIED BY &lt;AMBARIPASSWORD&gt; default tablespace
                      “USERS” temporary tablespace “TEMP”;
                      GRANT unlimited tablespace to &lt;AMBARIUSER&gt;;
                      GRANT create session to &lt;AMBARIUSER&gt;;
                      GRANT create TABLE to &lt;AMBARIUSER&gt;;
                      GRANT create SEQUENCE to &lt;AMBARIUSER&gt;;
                      QUIT;
                    </code>
                  </p>
                  <p>
                    Where
                    &lt;AMBARIUSER&gt;
                    is the Ambari user name and
                    &lt;AMBARIPASSWORD&gt;
                    is the Ambari user password.
                  </p>
                </li>
                <li>
                  <p>Load the Ambari Server database schema.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>You must pre-load the Ambari database schema into your Oracle database using the
                          schema script.
                        </p>
                        <p>
                          <code>sqlplus</code>
                          &lt;AMBARIUSER&gt;
                          <code>/</code>
                          &lt;AMBARIPASSWORD&gt;
                          <code> &lt; Ambari-DDL-Oracle-CREATE.sql</code>
                        </p>
                      </li>
                      <li>
                        <p>Find the Ambari-DDL-Oracle-CREATE.sql file in the
                          <code>/var/lib/ambari-server/resources/</code>
                          directory of the Ambari Server host after you have installed Ambari Server.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>When setting up the Ambari Server, select
                    <code>Advanced Database Configuration &gt; Option [2] Oracle</code>
                    and respond to the prompts using the username/password credentials you created in step 2.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Using Ambari with MySQL</h4>
          
            <p>To set up MySQL for use with Ambari:</p>
            <ul class="number-list">
              
                <li>
                  <p>On the Ambari Server host, install the connector.</p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Install the connector</p>
                        <p>
                          <strong>
                            RHEL/CentOS/Oracle Linux
                          </strong>
                          <code>yum install mysql-connector-java</code>
                        </p>
                        <p>
                          <strong>
                            SLES
                          </strong>
                          <code>zypper install mysql-connector-java</code>
                        </p>
                        <p>
                          <code>
                          </code>
                          <strong>UBUNTU</strong>
                          <code>
                          </code>
                          <code>apt-get install mysql-connector-java</code>
                        </p>
                      </li>
                      <li>
                        <p>Confirm that<code>.jar</code>is in the Java share directory.
                        </p>
                        <p>
                          <code>ls /usr/share/java/mysql-connector-java.jar</code>
                        </p>
                      </li>
                      <li>
                        <p>Make sure the .jar file has the appropriate permissions - 644.</p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create a user for Ambari and grant it permissions.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>For example, using the MySQL database admin utility:</p>
                        <p>
                          <code># mysql -u root -p
                            CREATE USER '
                          </code>
                          &lt;AMBARIUSER&gt;
                          <code>'@'%' IDENTIFIED BY '</code>
                          &lt;AMBARIPASSWORD&gt;
                          <code>';
                            GRANT ALL PRIVILEGES ON *.* TO '
                          </code>
                          &lt;AMBARIUSER&gt;
                          <code>'@'%';
                            CREATE USER '
                          </code>
                          &lt;AMBARIUSER&gt;
                          <code>'@'localhost' IDENTIFIED BY '</code>
                          &lt;AMBARIPASSWORD&gt;
                          <code>';
                            GRANT ALL PRIVILEGES ON *.* TO '
                          </code>
                          &lt;AMBARIUSER&gt;
                          <code>'@'localhost';
                            CREATE USER'
                          </code>
                          &lt;AMBARIUSER&gt;
                          <code>'@'</code>
                          &lt;AMBARISERVERFQDN&gt;
                          <code>' IDENTIFIED BY '</code>
                          &lt;AMBARIPASSWORD&gt;
                          <code>';
                            GRANT ALL PRIVILEGES ON *.* TO '
                          </code>
                          &lt;AMBARIUSER&gt;
                          <code>'@'</code>
                          &lt;AMBARISERVERFQDN&gt;
                          <code>';
                            FLUSH PRIVILEGES;
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Where&lt;AMBARIUSER&gt; is the Ambari user name,
                          &lt;AMBARIPASSWORD&gt;
                          is the Ambari user password and
                          &lt;AMBARISERVERFQDN&gt;
                          is the Fully Qualified Domain Name of the Ambari Server host.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Load the Ambari Server database schema.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>You must pre-load the Ambari database schema into your MySQL database using the schema
                          script.
                        </p>
                        <p>
                          <code>mysql -u</code>
                          &lt;AMBARIUSER&gt;
                          <code>-p CREATE DATABASE</code>
                          <code>&lt;AMBARIDATABASE&gt;</code>
                          <code>;
                            USE
                          </code>
                          &lt;AMBARIDATABASE&gt;
                          <code>;
                            SOURCE Ambari-DDL-MySQL-CREATE.sql;
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Where
                          &lt;AMBARIUSER&gt;
                          is the Ambari user name and
                          &lt;AMBARIDATABASE&gt;
                          is the Ambari database name.
                        </p>
                        <p>
                          Find the
                          <code>Ambari-DDL-MySQL-CREATE.sql</code>
                          file in the
                          <code>/var/lib/ambari-server/resources/</code>
                          directory of the Ambari Server host after you have installed Ambari Server.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>When setting up the Ambari Server, select
                    <code>Advanced Database Configuration &gt; Option [3] MySQL</code>
                    and enter the credentials you defined in Step 2. for user name, password and database name.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Using Ambari with PostgreSQL</h4>
          
            <p>To set up PostgreSQL for use with Ambari:</p>
            <ul class="number-list">
              
                <li>
                  <p>Create a user for Ambari and grant it permissions.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Using the PostgreSQL database admin utility:</p>
                        <p>
                          <code># sudo -u postgres psql
                            CREATE DATABASE
                          </code>
                          &lt;AMBARIDATABASE&gt;
                          <code>;
                            CREATE USER
                          </code>
                          &lt;AMBARIUSER&gt;
                          <code>WITH PASSWORD ‘</code>
                          &lt;AMBARIPASSWORD&gt;
                          <code>’;
                            GRANT ALL PRIVILEGES ON DATABASE
                          </code>
                          &lt;AMBARIDATABASE&gt;
                          <code>TO</code>
                          &lt;AMBARIUSER&gt;
                          <code>;
                            \connect
                          </code>
                          &lt;AMBARIDATABASE&gt;
                          <code>;
                            CREATE SCHEMA
                          </code>
                          &lt;AMBARISCHEMA&gt;
                          <code>AUTHORIZATION</code>
                          &lt;AMBARIUSER&gt;
                          <code>;
                            ALTER SCHEMA
                          </code>
                          &lt;AMBARISCHEMA&gt;
                          <code>OWNER TO</code>
                          &lt;AMBARIUSER&gt;
                          <code>;
                            ALTER ROLE
                          </code>
                          &lt;AMBARIUSER&gt;
                          <code>SET search_path to ‘</code>
                          &lt;AMBARISCHEMA&gt;
                          <code>’, 'public';</code>
                        </p>
                      </li>
                      <li>
                        <p>Where
                           &lt;AMBARIUSER&gt;
                          is the Ambari user name&lt;AMBARIPASSWORD&gt; is the Ambari user
                          password,
                          &lt;AMBARIDATABASE&gt;
                          is the Ambari database name and
                          &lt;AMBARISCHEMA&gt;
                          <code></code>is the Ambari schema name.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Load the Ambari Server database schema.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>You must pre-load the Ambari database schema into your PostgreSQL database using the
                          schema script.
                        </p>
                        <p>
                          <code># psql -U</code>
                          &lt;AMBARIUSER&gt;
                          <code>-d</code>
                          &lt;AMBARIDATABASE&gt;
                          <code>
                            \connect
                          </code>
                          &lt;AMBARIDATABASE&gt;
                          <code>;
                            \i Ambari-DDL-Postgres-CREATE.sql;
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Find the
                          <code>Ambari-DDL-Postgres-CREATE.sql</code>
                          file in the<code>/var/lib/ambari-server/resources/</code>directory of the Ambari
                          Server host after you have installed Ambari Server.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>When setting up the Ambari Server, select
                    <code>Advanced Database Configuration &gt; Option[4] PostgreSQL</code>
                    and enter the credentials you defined in Step 2. for user name, password, and database name.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Troubleshooting Ambari</h4>
          
            <p>Use these topics to help troubleshoot any issues you might have installing Ambari with an existing
              Oracle database.
            </p>
          
          
            <h4 class="bold">Problem: Ambari Server Fails to Start: No Driver</h4>
            
              <p>Check
                <code>/var/log/ambari-server/ambari-server.log</code>
                for the following error:
              </p>
              <p>
                <code>ExceptionDescription:Configurationerror.Class[oracle.jdbc.driver.OracleDriver]
                  not found.
                </code>
              </p>
              <p>The Oracle JDBC.jar file cannot be found.</p>
            
            
              <h4 class="bold">Solution</h4>
              
                <p>Make sure the file is in the appropriate directory on the Ambari server and re-run<code>
                  ambari-server setup</code>. Review the load database procedure appropriate for your database
                  type in<a href="#ref-6db1b3ae-7e80-4a7c-a73d-20f11379078f">Using Non-Default Databases -
                    Ambari</a>.
                </p>
              
            
          
          
            <h4 class="bold">Problem: Ambari Server Fails to Start: No Connection</h4>
            
              <p>Check<code>/var/log/ambari-server/ambari-server.log</code>for the following error:
              </p>
              <p>
                <code>The Network Adapter could not establish the connection Error Code: 17002
                </code>
              </p>
              <p>Ambari Server cannot connect to the database.</p>
            
            
              <h4 class="bold">Solution</h4>
              
                <p>Confirm that the database host is reachable from the Ambari Server and is correctly configured
                  by reading<code>/etc/ambari-server/conf/ambari.properties</code>.
                  <code>server.jdbc.url=jdbc:oracle:thin:@oracle.database.hostname:1521/ambaridb
                    server.jdbc.rca.url=jdbc:oracle:thin:@oracle.database.hostname:1521/ambari
                  </code>
                </p>
              
            
          
          
            <h4 class="bold">Problem: Ambari Server Fails to Start: Bad Username</h4>
            
              <p>Check
                <code>/var/log/ambari-server/ambari-server.log</code>
                for the following error:
              </p>
              <p>
                <code>Internal Exception: java.sql.SQLException:ORA­01017: invalid username/password;
                  logon denied
                </code>
              </p>
              <p>You are using an invalid username/password.</p>
            
            
              <h4 class="bold">Solution</h4>
              
                <p>Confirm the user account is set up in the database and has the correct privileges. See Step 3
                  above.
                </p>
              
            
          
          
            <h4 class="bold">Problem: Ambari Server Fails to Start: No Schema</h4>
            
              <p>Check
                <code>/var/log/ambari-server/ambari-server.log</code>
                for the following error:
              </p>
              <p>
                <code>Internal Exception: java.sql.SQLSyntaxErrorException: ORA­00942: table or view
                  does not exist
                </code>
              </p>
              <p>The schema has not been loaded.</p>
            
            
              <h4 class="bold">Solution</h4>
              
                <p>Confirm you have loaded the database schema. Review the load database schema procedure
                  appropriate for your database type in<a href="#ref-6db1b3ae-7e80-4a7c-a73d-20f11379078f">
                    Using Non-Default Databases - Ambari</a>.
                </p>
              
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-5010f1c4-fc32-44cd-94f5-fe557eefcd6d">Using Non-Default Databases - Hive</h3>
        
          <p>The following sections describe how to use Hive with an existing database, other than the MySQL
            database instance that Ambari installs by default.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-3e4391cf-499e-41c8-85cf-0d173c2b3360">Using Hive with Oracle</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-fe9e3437-a3f4-43b9-b2a2-4a323697dbfd">Using Hive with MySQL</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-a0442805-2765-4541-a76b-d13620359588">Using Hive with PostgreSQL</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-5f15a1bb-365a-4f1c-bcbf-3c195368d06f">Troubleshooting Non-Default Databases
                    with Hive
                  </a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Using Hive with Oracle</h4>
          
            <p>To set up Oracle for use with Hive:</p>
            <ul class="number-list">
              
                <li>
                  <p>On the Ambari Server host, stage the appropriate JDBC driver file for later deployment.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Download the Oracle JDBC (OJDBC) driver from<a href="http://www.oracle.com/technetwork/database/features/jdbc/index-091264.html">
                          http://www.oracle.com/technetwork/database/features/jdbc/index-091264.html</a>.
                        </p>
                      </li>
                      <li>
                        <p>Select
                          <code>Oracle Database 11g Release 2 - ojdbc6.jar</code>
                          and download the file.
                        </p>
                      </li>
                      <li>
                        <p>Make sure the .jar file has the appropriate permissions - 644.</p>
                      </li>
                      <li>
                        <p>Execute the following command, adding the path to the downloaded .jar file:</p>
                        <p>
                          <code>ambari-server setup --jdbc-db=oracle
                            --jdbc-driver=/path/to/downloaded/ojdbc6.jar
                          </code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create a user for Hive and grant it permissions.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Using the Oracle database admin utility:</p>
                        <p>
                          <code># sqlplus sys/root as sysdba
                            CREATE USER
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>IDENTIFIED BY</code>
                          &lt;HIVEPASSWORD&gt;
                          <code>;
                            GRANT SELECT_CATALOG_ROLE TO
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>;
                            GRANT CONNECT, RESOURCE TO
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>;
                            QUIT;
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Where
                          &lt;HIVEUSER&gt;
                          is the Hive user name and
                          &lt;HIVEPASSWORD&gt;
                          is the Hive user password.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Load the Hive database schema.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>For a
                          <strong>HDP 2.2 Stack</strong>
                        </p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Important.png" width="50"></div>
                          <div class="simple-block">
                            <p>
                              Ambari sets up the Hive Metastore database schemaautomatically.
                              You do not need to pre-load the Hive Metastore database schema into your Oracle database
                              for a HDP 2.2 Stack.
                            </p>
                          </div>
                        </aside>
                      </li>
                      <li>
                        <p>For a
                          <strong>HDP 2.1 Stack</strong>
                        </p>
                        <p>
                          You must pre-load the Hive database schema into your Oracle database using the schema script,
                          as follows:
                          sqlplus &lt;HIVEUSER&gt;/&lt;HIVEPASSWORD&gt; &lt; hive-schema-0.13.0.oracle.sql
                        </p>
                        <p>
                          Find the
                          <code>hive-schema-0.13.0.oracle.sql</code>
                          file in the
                          <code>/var/lib/ambari-server/resources/stacks/HDP/2.1/services/HIVE/etc/</code>
                          directory of the Ambari Server host after you have installed Ambari Server.
                        </p>
                      </li>
                      <li>
                        <p>For a
                          <strong>HDP 2.0 Stack</strong>
                        </p>
                        <p>
                          You must pre-load the Hive database schema into your Oracle database using the schema script,
                          as follows:
                          sqlplus &lt;HIVEUSER&gt;/&lt;HIVEPASSWORD&gt; &lt; hive-schema-0.12.0.oracle.sql
                        </p>
                        <p>
                          Find the
                          <code>hive-schema-0.12.0.oracle.sql</code>
                          file in the
                          <code>/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/HIVE/etc/</code>
                          directory of the Ambari Server host after you have installed Ambari Server.
                        </p>
                      </li>
                      <li>
                        <p>For a
                          <strong>HDP 1.3 Stack</strong>
                        </p>
                        <p>
                          You must pre-load the Hive database schema into your Oracle database using the schema script,
                          as follows:
                          sqlplus &lt;HIVEUSER&gt;/&lt;HIVEPASSWORD&gt; &lt; hive-schema-0.10.0.oracle.sql
                        </p>
                        <p>
                          Find the
                          <code>hive-schema-0.10.0.oracle.sql</code>
                          file in the
                          <code>/var/lib/ambari-server/resources/stacks/HDP/1.3.2/services/HIVE/etc/</code>
                          directory of the Ambari Server host after you have installed Ambari Server.
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Using Hive with MySQL</h4>
          
            <p>To set up MySQL for use with Hive:</p>
            <ul class="number-list">
              
                <li>
                  <p>On the Ambari Server host, stage the appropriate MySQL connector for later deployment.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Install the connector.</p>
                        <p>
                          <strong>RHEL/CentOS/Oracle Linux
                          </strong>
                          <code>yum install mysql-connector-java*</code>
                        </p>
                        <p>
                          <strong>SLES
                          </strong>
                          <code>zypper install mysql-connector-java*</code>
                        </p>
                        <p>
                          <strong>UBUNTU
                          </strong>
                          <code>apt-get install mysql-connector-java*</code>
                        </p>
                      </li>
                      <li>
                        <p>Confirm that
                          <code>mysql-connector-java.jar</code>
                          is in the Java share directory.
                        </p>
                        <p>
                          <code>ls /usr/share/java/mysql-connector-java.jar</code>
                        </p>
                      </li>
                      <li>
                        <p>Make sure the .jar file has the appropriate permissions - 644.</p>
                      </li>
                      <li>
                        <p>Execute the following command:</p>
                        <p>
                          <code>ambari-server setup --jdbc-db=mysql
                            --jdbc-driver=/usr/share/java/mysql-connector-java.jar
                          </code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create a user for Hive and grant it permissions.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Using the MySQL database admin utility:</p>
                        <p>
                          <code># mysql -u root -p
                            CREATE USER ‘
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>’@’localhost’ IDENTIFIED BY ‘</code>
                          &lt;HIVEPASSWORD&gt;
                          <code>’;
                            GRANT ALL PRIVILEGES ON *.* TO '
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>'@'localhost';
                            CREATE USER ‘
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>’@’%’ IDENTIFIED BY ‘</code>
                          &lt;HIVEPASSWORD&gt;
                          <code>’;
                            GRANT ALL PRIVILEGES ON *.* TO '
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>'@'%';
                            CREATE USER '
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>'@'</code>
                          &lt;HIVEMETASTOREFQDN&gt;
                          <code>'IDENTIFIED BY '</code>
                          &lt;HIVEPASSWORD&gt;
                          <code>';
                            GRANT ALL PRIVILEGES ON *.* TO '
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>'@'</code>
                          &lt;HIVEMETASTOREFQDN&gt;
                          <code>';
                            FLUSH PRIVILEGES;
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Where
                          &lt;HIVEUSER&gt;
                          is the Hive user name,
                          &lt;HIVEPASSWORD&gt;
                          is the Hive user password and&lt;HIVEMETASTOREFQDN&gt; is the Fully
                          Qualified Domain Name of the Hive Metastore host.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create the Hive database.</p>
                  <p>The Hive database must be created before loading the Hive database schema.

                    <code># mysql -u root -p CREATE DATABASE</code>
                    &lt;HIVEDATABASE&gt;

                    Where
                    &lt;HIVEDATABASE&gt;
                    is the Hive database name.
                  </p>
                </li>
                <li>
                  <p>Load the Hive database schema.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>For a<strong>HDP 2.2 Stack</strong>:
                        </p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Important.png" width="50"></div>
                          <div class="simple-block">
                            <p>
                              Ambari sets up the Hive Metastore database schemaautomatically.
                              You do not need to pre-load the Hive Metastore database schema into your MySQL database
                              for a HDP 2.2 Stack.
                            </p>
                          </div>
                        </aside>
                      </li>
                      <li>
                        <p>For a<strong>HDP 2.1 Stack</strong>:
                        </p>
                        <p>
                          You must pre-load the Hive database schema into your MySQL database using the schema script,
                          as follows.
                          <code>
                            mysql -u root -p
                          </code>
                          &lt;HIVEDATABASE&gt;
                          <code>hive-schema-0.13.0.mysql.sql</code>
                        </p>
                        <p>Find the
                          <code>hive-schema-0.13.0.mysql.sql</code>
                          file in the
                          <code>/var/lib/ambari-server/resources/stacks/HDP/2.1/services/HIVE/etc/</code>
                          directory of the Ambari Server host after you have installed Ambari Server.
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Using Hive with PostgreSQL</h4>
          
            <p>To set up PostgreSQL for use with Hive:</p>
            <ul class="number-list">
              
                <li>
                  <p>On the Ambari Server host, stage the appropriate PostgreSQL connector for later
                    deployment.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Install the connector.</p>
                        <p>
                          <strong>RHEL/CentOS/Oracle Linux
                          </strong>
                          <code>yum install postgresql-jdbc*</code>
                        </p>
                        <p>
                          <strong>SLES
                          </strong>
                          <code>zypper install -y postgresql-jdbc</code>
                        </p>
                      </li>
                      <li>
                        <p>Copy the connector.jar file to the Java share directory.</p>
                        <p>
                          <code>
                            cp /usr/share/pgsql/postgresql-*.jdbc3.jar /usr/share/java/postgresql-jdbc.jar
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Confirm that .jar is in the Java share directory.</p>
                        <p>
                          <code>
                            ls /usr/share/java/postgresql-jdbc.jar
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Change the access mode of the.jar file to 644.</p>
                        <p>
                          chmod 644 /usr/share/java/postgresql-jdbc.jar
                        </p>
                      </li>
                      <li>
                        <p>Execute the following command:</p>
                        <p>
                          <code>ambari-server setup --jdbc-db=postgres</code>
                          <code>--jdbc-driver=/usr/share/java/postgresql-connector-java.jar</code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create a user for Hive and grant it permissions.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Using the PostgreSQL database admin utility:</p>
                        <p>
                          <code>echo "CREATE DATABASE &lt;HIVEDATABASE&gt;;" | psql -U postgres
                            echo "CREATE USER
                          </code>
                          &lt;HIVEUSER&gt;
                          <code>WITH PASSWORD '</code>
                          &lt;HIVEPASSWORD&gt;
                          <code>';" | psql -U postgres
                            echo "GRANT ALL PRIVILEGES ON DATABASE
                          </code>
                          &lt;HIVEDATABASE&gt;
                          <code>TO</code>
                          &lt;HIVEUSER&gt;
                          <code>;" | psql -U postgres</code>
                        </p>
                      </li>
                      <li>
                        <p>Where&lt;HIVEUSER&gt; is the Hive user name,
                          &lt;HIVEPASSWORD&gt;
                          is the Hive user password and
                          &lt;HIVEDATABASE&gt;
                          is the Hive database name.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Load the Hive database schema.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>For a
                          <strong>HDP 2.2 Stack:</strong>
                        </p>
                        <aside class="custom-note">
                          <div class="icon"><img src="Icons/Important.png" width="50"></div>
                          <div class="simple-block">
                            <p>
                              Ambari sets up the Hive Metastore database schemaautomatically.
                              You do not need to pre-load the Hive Metastore database schema into your PostgreSQL
                              database for a HDP 2.2 Stack.
                            </p>
                          </div>
                        </aside>
                      </li>
                      <li>
                        <p>For a
                          <strong>HDP 2.1 Stack:</strong>
                        </p>
                        <p>
                          You must pre-load the Hive database schema into your PostgreSQL database using the schema
                          script, as follows:

                          <code># psql -U</code>
                          &lt;HIVEUSER&gt;
                          <code>-d</code>
                          &lt;HIVEDATABASE&gt;
                          <code>
                            \connect
                          </code>
                          &lt;HIVEDATABASE&gt;
                          <code>;
                            \i hive-schema-0.13.0.postgres.sql;
                          </code>
                        </p>
                        <p>Find the
                          <code>hive-schema-0.13.0.postgres.sql</code>
                          file in the
                          <code>/var/lib/ambari-server/resources/stacks/HDP/2.1/services/HIVE/etc/</code>
                          directory of the Ambari Server host after you have installed Ambari Server.
                        </p>
                      </li>
                      <li>
                        <p>For a
                          <strong>HDP 2.0 Stack:</strong>
                        </p>
                        <p>
                          You must pre-load the Hive database schema into your PostgreSQL database using the schema
                          script, as follows:

                          <code># sudo -u postgres psql
                            \connect
                          </code>
                          &lt;HIVEDATABASE&gt;
                          <code>;
                            \i hive-schema-0.12.0.postgres.sql;
                          </code>
                        </p>
                        <p>Find the
                          <code>hive-schema-0.12.0.postgres.sql</code>
                          file in the
                          <code>/var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/HIVE/etc/</code>
                          directory of the Ambari Server host after you have installed Ambari Server.
                        </p>
                      </li>
                      <li>
                        <p>For a
                          <strong>HDP 1.3 Stack:</strong>
                        </p>
                        <p>
                          You must pre-load the Hive database schema into your PostgreSQL database using the schema
                          script, as follows:

                          <code># sudo -u postgres psql
                            \connect
                          </code>
                          &lt;HIVEDATABASE&gt;
                          <code>;
                            \i hive-schema-0.10.0.postgres.sql;
                          </code>
                        </p>
                        <p>Find the
                          <code>hive-schema-0.10.0.postgres.sql</code>
                          file in the
                          <code>/var/lib/ambari-server/resources/stacks/HDP/1.3.2/services/HIVE/etc/</code>
                          directory of the Ambari Server host after you have installed Ambari Server.
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Troubleshooting Hive</h4>
          
            <p>Use these entries to help you troubleshoot any issues you might have installing Hive with
              non-default databases.
            </p>
          
          
            <h4 class="bold">Problem: Hive Metastore Install Fails Using Oracle</h4>
            
              <p>Check the install log:</p>
              <p>
                <code>cp /usr/share/java/${jdbc_jar_name} ${target}] has failures: true
                </code>
              </p>
              <p>The Oracle JDBC.jar file cannot be found.</p>
            
            
              <h4 class="bold">Solution</h4>
              
                <p>Make sure the file is in the appropriate directory on the Hive Metastore server and click
                  <strong>Retry</strong>.
                </p>
              
            
          
          
            <h4 class="bold">Problem: Install Warning when "Hive Check Execute" Fails Using Oracle</h4>
            
              <p>Check the install log:</p>
              <p>
                <code>java.sql.SQLSyntaxErrorException: ORA-01754:
                  a table may contain only one column of type LONG
                </code>
              </p>
              <p>The Hive Metastore schema was not properly loaded into the database.</p>
            
            
              <h4 class="bold">Solution</h4>
              
                <p>Ignore the warning, and complete the install. Check your database to confirm the Hive
                  Metastore schema is loaded. In the Ambari Web GUI, browse to
                  <strong>Services</strong>
                  &gt;<strong>Hive</strong>. Choose
                  <code>Service Actions &gt; Service Check</code>
                  to check that the schema is correctly in place.
                </p>
              
            
          
          
            <h4 class="bold">Problem: Hive Check Execute may fail after completing an Ambari upgrade to version 1.4.2</h4>
            
              <p>For secure and non-secure clusters, with Hive security authorization enabled, the Hive service
                check may fail. Hive security authorization may not be configured properly.
              </p>
            
            
              <h4 class="bold">Solution</h4>
              
                <p>Two workarounds are possible. Using Ambari Web, in<strong>HiveConfigsAdvanced</strong>:
                </p>
                <ul class="bullet-list">
                  
                    <li>
                      <p>Disable<code>hive.security.authorization</code>, by setting the
                        <code>hive.security.authorization.enabled</code>
                        value to false.
                      </p>
                      <p>
                        <strong></strong>
                        <strong>
                          <i>or</i>
                        </strong>
                        <strong></strong>
                      </p>
                    </li>
                    <li>
                      <p>Properly configure Hive security authorization. For example, set the following
                        properties:
                      </p>
                      <p>For more information about configuring Hive security, see
                        <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Authorization#LanguageManualAuthorization-MetastoreServerSecurity">
                          Metastore Server Security
                        </a>
                        in
                        <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Authorization">
                          Hive Authorization
                        </a>
                        and the HCatalog document<a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.0.9.1/bk_using_Ambari_book/content/ambari-chaplast-1-1.html">
                          Storage Based Authorization</a>.
                      </p>
                      <div class="xyleme-table"><table border="1">
                        <p class="italic bold">Hive Security Authorization
                          Settings
                        </p>
                        
                          
                          
                          <thead>
                            <tr>
                              <th rowspan="1">
                                <p>
                                  <strong>Property</strong>
                                </p>
                              </th>
                              <th rowspan="1">
                                <p>
                                  <strong>Value</strong>
                                </p>
                              </th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td rowspan="1">
                                <p>hive.security.authorization.manager</p>
                              </td>
                              <td rowspan="1">
                                <p>
                                  org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
                                </p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>hive.security.metastore.authorization.manager</p>
                              </td>
                              <td rowspan="1">
                                <p>
                                  org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
                                </p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>hive.security.authenticator.manager</p>
                              </td>
                              <td rowspan="1">
                                <p>org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                      <p>
                        <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Authorization#LanguageManualAuthorization-MetastoreServerSecurity">
                          Metastore Server Security
                        </a>
                        <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Authorization">
                          Hive Authorization
                        </a>
                        <a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.0.9.1/bk_using_Ambari_book/content/ambari-chaplast-1-1.html">
                          Storage Based Authorization
                        </a>
                      </p>
                    </li>
                  
                </ul>
              
            
          
        
      
      
        <h3 class="horton-blue bold" id="ref-b9803b8c-5f91-40d5-bdc4-da481581efbf">Using Non-Default Databases - Oozie</h3>
        
          <p>The following sections describe how to use Oozie with an existing database, other than the Derby
            database instance that Ambari installs by default.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-27b85ede-4fbe-4672-b771-2b3f02e5a2f9">Using Oozie with Oracle</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-b7328f97-8bd8-4936-a038-6289902a6029">Using Oozie with MySQL</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-168b712d-c256-466d-8ea2-d9f71150ef84">Using Oozie with PostgreSQL</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-22a77028-fd36-4976-ac14-ddd4e502f55a">Troubleshooting Non-Default Databases
                    with Oozie
                  </a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Using Oozie with Oracle</h4>
          
            <p>To set up Oracle for use with Oozie:</p>
            <ul class="number-list">
              
                <li>
                  <p>On the Ambari Server host, stage the appropriate JDBC driver file for later deployment.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Download the Oracle JDBC (OJDBC) driver from<a href="http://www.oracle.com/technetwork/database/features/jdbc/index-091264.html">
                          http://www.oracle.com/technetwork/database/features/jdbc/index-091264.html</a>.
                        </p>
                      </li>
                      <li>
                        <p>SelectOracle Database 11g Release 2 - ojdbc6.jar.
                        </p>
                      </li>
                      <li>
                        <p>Make sure the .jar file has the appropriate permissions - 644.</p>
                      </li>
                      <li>
                        <p>Execute the following command, adding the path to the downloaded.jar file:</p>
                        <p>
                          <code>ambari-server setup --jdbc-db=oracle
                            --jdbc-driver=/path/to/downloaded/ojdbc6.jar
                          </code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create a user for Oozie and grant it permissions.</p>
                  <p>Using the Oracle database admin utility, run the following commands:</p>
                  <p>
                    <code># sqlplus sys/root as sysdba
                      CREATE USER
                    </code>
                    &lt;OOZIEUSER&gt;
                    <code>IDENTIFIED BY</code>
                    &lt;OOZIEPASSWORD&gt;
                    <code>;
                      GRANT ALL PRIVILEGES TO
                    </code>
                    &lt;OOZIEUSER&gt;
                    <code>;
                      QUIT;
                    </code>
                  </p>
                  <p>Where
                    &lt;OOZIEUSER&gt;
                    is the Oozie user name and
                    &lt;OOZIEPASSWORD&gt;
                    is the Oozie user password.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Using Oozie with MySQL</h4>
          
            <p>To set up MySQL for use with Oozie:</p>
            <ul class="number-list">
              
                <li>
                  <p>On the Ambari Server host, stage the appropriate MySQL connector for later deployment.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Install the connector.</p>
                        <p>
                          <strong>RHEL/CentOS/Oracle Linux
                          </strong>
                          <code>yum install mysql-connector-java*</code>
                        </p>
                        <p>
                          <strong>SLES
                          </strong>
                          <code>zypper install mysql-connector-java*</code>
                        </p>
                        <p>
                          <strong>UBUNTU
                          </strong>
                          <code>apt-get install mysql-connector-java*</code>
                        </p>
                      </li>
                      <li>
                        <p>Confirm that
                          <code>mysql-connector-java.jar</code>
                          is in the Java share directory.
                        </p>
                        <p>
                          <code>ls /usr/share/java/mysql-connector-java.jar</code>
                        </p>
                      </li>
                      <li>
                        <p>Make sure the .jar file has the appropriate permissions - 644.</p>
                      </li>
                      <li>
                        <p>Execute the following command:</p>
                        <p>
                          <code>ambari-server setup --jdbc-db=mysql
                            --jdbc-driver=/usr/share/java/mysql-connector-java.jar
                          </code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create a user for Oozie and grant it permissions.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Using the MySQL database admin utility:</p>
                        <p>
                          <code># mysql -u root -p
                            CREATE USER ‘
                          </code>
                          &lt;OOZIEUSER&gt;
                          <code>’@’%’ IDENTIFIED BY ‘</code>
                          &lt;OOZIEPASSWORD&gt;
                          <code>’;
                            GRANT ALL PRIVILEGES ON *.* TO '&lt;OOZIEUSER&gt;'@'%';
                            FLUSH PRIVILEGES;
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Where
                          &lt;OOZIEUSER&gt;
                          is the Oozie user name and
                          &lt;OOZIEPASSWORD&gt;
                          is the Oozie user password.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create the Oozie database.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>The Oozie database must be created prior.</p>
                        <p>
                          <code># mysql -u root -p
                            CREATE DATABASE
                          </code>
                          &lt;OOZIEDATABASE&gt;
                        </p>
                      </li>
                      <li>
                        <p>Where
                          &lt;OOZIEDATABASE&gt;
                          is the Oozie database name.
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Using Oozie with PostgreSQL</h4>
          
            <p>To set up PostgreSQL for use with Oozie:</p>
            <ul class="number-list">
              
                <li>
                  <p>On the Ambari Server host, stage the appropriate PostgreSQL connector for later
                    deployment.
                  </p>
                  <ul class="Numeric">
                    
                      <li>
                        <p>Install the connector.</p>
                        <p>
                          <strong>
                            RHEL/CentOS/Oracle Linux
                          </strong>
                          <code>yum install postgresql-jdbc</code>
                        </p>
                        <p>
                          <strong>SLES
                          </strong>
                          <code>zypper install -y postgresql-jdbc</code>
                        </p>
                        <p>
                          <strong>UBUNTU
                          </strong>
                          <code>apt-get install -y postgresql-jdbc</code>
                        </p>
                      </li>
                      <li>
                        <p>Copy the connector.jar file to the Java share directory.</p>
                        <p>
                          <code>cp /usr/share/pgsql/postgresql-*.jdbc3.jar
                            /usr/share/java/postgresql-jdbc.jar
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Confirm that .jar is in the Java share directory.</p>
                        <p>
                          <code>ls /usr/share/java/postgresql-jdbc.jar</code>
                        </p>
                      </li>
                      <li>
                        <p>Change the access mode of the .jar file to 644.</p>
                        <p>
                          <code>chmod 644 /usr/share/java/postgresql-jdbc.jar</code>
                        </p>
                      </li>
                      <li>
                        <p>Execute the following command:</p>
                        <p>
                          <code>ambari-server setup --jdbc-db=postgres
                            --jdbc-driver=/usr/share/java/postgresql-connector-java.jar
                          </code>
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>Create a user for Oozie and grant it permissions.</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>Using the PostgreSQL database admin utility:</p>
                        <p>
                          <code>echo "CREATE DATABASE</code>
                          &lt;OOZIEDATABASE&gt;
                          <code>;" | psql -U postgres
                            echo "CREATE USER
                          </code>
                          &lt;OOZIEUSER&gt;
                          <code>WITH PASSWORD '</code>
                          &lt;OOZIEPASSWORD&gt;
                          <code>';" | psql -U postgres
                            echo "GRANT ALL PRIVILEGES ON DATABASE
                          </code>
                          &lt;OOZIEDATABASE&gt;
                          <code>TO</code>
                          &lt;OOZIEUSER&gt;
                          <code>;" | psql -U postgres
                          </code>
                        </p>
                      </li>
                      <li>
                        <p>Where
                          &lt;OOZIEUSER&gt;
                          is the Oozie user name,
                          &lt;OOZIEPASSWORD&gt;
                          is the Oozie user password and
                          &lt;OOZIEDATABASE&gt;
                          is the Oozieozie database name.
                        </p>
                      </li>
                    
                  </ul>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Troubleshooting Oozie</h4>
          
            <p>
              Use these entries to help you troubleshoot any issues you might have installing Oozie with non-default
              databases.
            </p>
          
          
            <h4 class="bold">Problem: Oozie Server Install Fails Using MySQL</h4>
            
              <p>Check the install log:</p>
              <p>
                <code>
                </code>
                <code>cp /usr/share/java/mysql-connector-java.jar
                  usr/lib/oozie/libext/mysql-connector-java.jar
                  has failures: true
                </code>
                <code>
                </code>
              </p>
              <p>
                The MySQL JDBC.jar file cannot be found.
              </p>
            
            
              <h4 class="bold">Solution</h4>
              
                <p>
                  Make sure the file is in the appropriate directory on the Oozie server and click<strong>Retry</strong>.
                </p>
              
            
          
          
            <h4 class="bold">Problem: Oozie Server Install Fails Using Oracle or MySQL</h4>
            
              <p>
                Check the install log:
              </p>
              <p>
                <code>
                  Exec[exec cd /var/tmp/oozie &amp;&amp;
                  /usr/lib/oozie/bin/ooziedb.sh create -sqlfile oozie.sql -run ]
                  has failures: true
                </code>
              </p>
              <p>
                Oozie was unable to connect to the database or was unable to successfully setup the schema for Oozie.
              </p>
            
            
              <h4 class="bold">Solution</h4>
              
                <p>
                  Check the database connection settings provided during the
                  <code>Customize Services</code>
                  step in the install wizard by browsing back to<code>Customize Services &gt;
                  Oozie</code>. After confirming and adjusting your database settings, proceed forward
                  with the install wizard.
                </p>
                <p>
                  If the Install Oozie Server wizard continues to fail, get more information by connecting directly to
                  the Oozie server and executing the following command as&lt;OOZIEUSER&gt;:
                </p>
                <p>
                  <code>su oozie /usr/lib/oozie/bin/ooziedb.sh create -sqlfile oozie.sql -run</code>
                </p>
              
            
          
        
      
    
    
      <h2 class="horton-green bold">Setting up an Internet Proxy Server for Ambari</h2>
      
        
          <p>If you plan to use the public repositories for installing the Stack, Ambari Server must have
            Internet access to confirm access to the repositories and validate the repositories. If your machine
            requires use of a proxy server for Internet access, you must configure Ambari Server to use the proxy
            server.
          </p>
          <p>
            <a href="#ref-0c356526-e74c-4420-a686-8b9bc17dd0c1">How To Set Up an Internet Proxy Server for
              Ambari
            </a>
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-0c356526-e74c-4420-a686-8b9bc17dd0c1">How To Set Up an Internet Proxy Server for Ambari</h3>
        
          <ul class="number-list">
            
              <li>
                <p>On the Ambari Server host, add proxy settings to the following script:
                  <code>/var/lib/ambari-server/ambari-env.sh.</code>
                </p>
                <p>
                  <code>-Dhttp.proxyHost=</code>
                  &lt;yourProxyHost&gt;
                  <code>-Dhttp.proxyPort=</code>
                  &lt;yourProxyPort&gt;
                </p>
              </li>
              <li>
                <p>Optionally, to prevent some host names from accessing the proxy server, define the list of
                  excluded hosts, as follows:
                </p>
                <p>
                  <code>-Dhttp.nonProxyHosts=</code>
                  &lt;pipe|separated|list|of|hosts&gt;
                </p>
              </li>
              <li>
                <p>If your proxy server requires authentication, add the user name and password, as follows:
                </p>
                <p>
                  <code>-Dhttp.proxyUser=</code>
                  &lt;username&gt;
                  <code>-Dhttp.proxyPassword=</code>
                  &lt;password&gt;
                </p>
              </li>
              <li>
                <p>Restart the Ambari Server to pick up this change.</p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>If you plan to use local repositories, see<a href="#ref-28d7e1f2-0adb-436a-a4b1-65b522fdcdf2">Optional: Configure Local
                Repositories</a>. Configuring Ambari to use a proxy server and have Internet access is not required.
                The Ambari Server must have access to your local repositories.
              </p>
            </div>
          </aside>
        
      
    
    
      <h2 class="horton-green bold">Configuring Network Port Numbers</h2>
      
        
          <p>This chapter lists port number assignments required to maintain communication between Ambari Server,
            Ambari Agents, Ambari Web UI, Ganglia, and Nagios components.
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-85947452-af53-46f1-96fa-133675313860">Default Network Port Numbers - Ambari
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-9635a415-5a72-4aca-9a13-f4acd6623f6d">Configuring Ganglia Ports</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-434dcc25-963d-4d73-8e3c-76a266860b2a">Configuring Nagios Ports</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-88b834bf-48d5-4bd9-9f66-4bc46533dd71">Optional: Changing the Default Ambari
                    Server Port
                  </a>
                </p>
                <p>
                  For more information about configuring port numbers for Stack components, see
                  <a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.0/HDP_Ref_Gd_v22/configuring_ports/index.html#Item1.1">
                    Configuring Ports
                  </a>
                  in the HDP Stack documentation.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-85947452-af53-46f1-96fa-133675313860">Default Network Port Numbers - Ambari</h3>
        
          <p>The following table lists the default ports used by Ambari Server and Ambari Agent services.
          </p>
          <div class="xyleme-table"><table border="1">
            
              
              
              
              
              
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>Service</p>
                  </th>
                  <th rowspan="1">
                    <p>Servers</p>
                  </th>
                  <th rowspan="1">
                    <p>Default Ports Used</p>
                  </th>
                  <th rowspan="1">
                    <p>Protocol</p>
                  </th>
                  <th rowspan="1">
                    <p>Description</p>
                  </th>
                  <th rowspan="1">
                    <p>Need End User Access?</p>
                  </th>
                  <th rowspan="1">
                    <p>Configuration Parameters</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>Ambari Server</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari Server host</p>
                  </td>
                  <td rowspan="1">
                    <p>8080 See Optional: Change the Ambari Server Port
                      for instructions on changing the default
                      port.
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>http See Optional: Set Up HTTPS for Ambari Server
                      for instructions on enabling HTTPS.
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>Interface to Ambari Web and Ambari REST
                      API
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>No</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Ambari Server</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari Server host</p>
                  </td>
                  <td rowspan="1">
                    <p>8440</p>
                  </td>
                  <td rowspan="1">
                    <p>https</p>
                  </td>
                  <td rowspan="1">
                    <p>Handshake Port for Ambari Agents to Ambari
                      Server
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>No</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Ambari Server</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari Server host</p>
                  </td>
                  <td rowspan="1">
                    <p>8441</p>
                  </td>
                  <td rowspan="1">
                    <p>https</p>
                  </td>
                  <td rowspan="1">
                    <p>Registration and Heartbeat Port for Ambari Agents
                      to Ambari Server
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>No</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Ambari Agent</p>
                  </td>
                  <td rowspan="1">
                    <p>All hosts running Ambari Agents</p>
                  </td>
                  <td rowspan="1">
                    <p>8670 You can change the Ambari Agent ping port in
                      the Ambari Agent configuration. If you change the port,
                      you must restart Nagios after making the
                      change.
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>tcp</p>
                  </td>
                  <td rowspan="1">
                    <p>Ping port used for Nagios Server to check the
                      health of the Ambari Agent
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>No</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
        
      
      
        <h3 class="horton-blue bold" id="ref-9635a415-5a72-4aca-9a13-f4acd6623f6d">Ganglia Ports</h3>
        
          <p>The following table lists the default ports used by the various Ganglia services.</p>
          <div class="xyleme-table"><table border="1">
            
              
              
              
              
              
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>Service</p>
                  </th>
                  <th rowspan="1">
                    <p>Servers</p>
                  </th>
                  <th rowspan="1">
                    <p>Default Ports Used</p>
                  </th>
                  <th rowspan="1">
                    <p>Protocol</p>
                  </th>
                  <th rowspan="1">
                    <p>Description</p>
                  </th>
                  <th rowspan="1">
                    <p>Need End User Access?</p>
                  </th>
                  <th rowspan="1">
                    <p>Configuration Parameters</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>Ganglia Server</p>
                  </td>
                  <td rowspan="1">
                    <p>Ganglia server host</p>
                  </td>
                  <td rowspan="1">
                    <p>8660/61/62/63</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>For metric (gmond) collectors</p>
                  </td>
                  <td rowspan="1">
                    <p>No</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Ganglia Monitor</p>
                  </td>
                  <td rowspan="1">
                    <p>All Slave Node hosts</p>
                  </td>
                  <td rowspan="1">
                    <p>8660</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>For monitoring (gmond) agents</p>
                  </td>
                  <td rowspan="1">
                    <p>No</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Ganglia Server</p>
                  </td>
                  <td rowspan="1">
                    <p>Ganglia server host</p>
                  </td>
                  <td rowspan="1">
                    <p>8651</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>For ganglia gmetad</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>Ganglia Web</p>
                  </td>
                  <td rowspan="1">
                    <p>Ganglia server host</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p>httpSee Optional: Set Up HTTPS for Ganglia for
                      instructions on enabling HTTPS.
                    </p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
        
      
      
        <h3 class="horton-blue bold" id="ref-434dcc25-963d-4d73-8e3c-76a266860b2a">Nagios Ports</h3>
        
          <p>The following table lists the default port used by the Nagios server.</p>
          <div class="xyleme-table"><table border="1">
            
              
              
              
              
              
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>Service</p>
                  </th>
                  <th rowspan="1">
                    <p>Servers</p>
                  </th>
                  <th rowspan="1">
                    <p>Default Ports Used</p>
                  </th>
                  <th rowspan="1">
                    <p>Protocol</p>
                  </th>
                  <th rowspan="1">
                    <p>Description</p>
                  </th>
                  <th rowspan="1">
                    <p>Need End User Access?</p>
                  </th>
                  <th rowspan="1">
                    <p>Configuration Parameters</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>Nagios Server</p>
                  </td>
                  <td rowspan="1">
                    <p>Nagios server host</p>
                  </td>
                  <td rowspan="1">
                    <p>80</p>
                  </td>
                  <td rowspan="1">
                    <p>httpSee Optional: Set Up HTTPS for Nagios for
                      instructions on enabling HTTPS.
                    </p>
                  </td>
                  <td rowspan="1">
                    <p>Nagios Web UI</p>
                  </td>
                  <td rowspan="1">
                    <p>No</p>
                  </td>
                  <td rowspan="1">
                    <p></p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
        
      
      
        <h3 class="horton-blue bold" id="ref-88b834bf-48d5-4bd9-9f66-4bc46533dd71">Optional: Changing the Default Ambari Server Port</h3>
        
          <p>By default, Ambari Server uses port 8080 to access the Ambari Web UI and the REST API. To change the
            port number, you must edit the Ambari properties file.
          </p>
          <p>Ambari Server should not be running when you change port numbers. Edit
            <code>ambari.properties</code>
            before you start Ambari Server the first time or stop Ambari Server before editing properties.
          </p>
          <ul class="number-list">
            
              <li>
                <p>On the Ambari Server host, open
                  <code>/etc/ambari-server/conf/ambari.properties</code>
                  with a text editor.
                </p>
              </li>
              <li>
                <p>Add the client API port property and set it to your desired port value:
                  <code>
                    client.api.port=
                  </code>
                  &lt;port_number&gt;
                </p>
              </li>
              <li>
                <p>Start or re-start the Ambari Server. Ambari Server now accesses Ambari Web via the newly
                  configured port:
                </p>
                <p>
                  <code>
                    http://
                  </code>
                  &lt;your.ambari.server&gt;
                  <code>:</code>
                  &lt;port_number&gt;  
                </p>
              </li>
            
          </ul>
        
      
    
    
      <h2 class="horton-green bold">Changing the JDK Version on an Existing Cluster</h2>
      
        
          <p>During your initial Ambari Server Setup, you selected the JDK to use or provided a path to a custom
            JDK already installed on your hosts. After setting up your cluster, you may change the JDK version using the
            following procedure.
          </p>
          <p>
            <a href="#ref-938c5120-aa38-4cc6-afc7-b7c18ce1f239">How to change the JDK Version for an Existing
              Cluster
            </a>
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-938c5120-aa38-4cc6-afc7-b7c18ce1f239">How to change the JDK Version for an Existing Cluster</h3>
        
          <ul class="number-list">
            
              <li>
                <p>Re-run Ambari Server Setup.</p>
                <p>
                  <code>
                    ambari-server setup
                  </code>
                </p>
              </li>
              <li>
                <p>At the prompt to change the JDK, Enter<strong>y</strong>.
                </p>
                <p>
                  <code>Do you want to change Oracle JDK [y/n] (n)?</code>
                  <code>y</code>
                </p>
              </li>
              <li>
                <p>At the prompt to choose a JDK, Enter
                  <code>1</code>
                  to change the JDK to v1.7.
                </p>
                <p>
                  <code>
                    [1] - Oracle JDK 1.7
                  </code>
                  <code>
                    [2] - Oracle JDK 1.6
                    [3] - Custom JDK Enter choice: 3
                  </code>
                </p>
                <p>
                  If you choose Oracle JDK 1.7 or Oracle JDK 1.6, the JDK you choose downloads and installs
                  automatically.
                </p>
              </li>
              <li>
                <p>If you choose<code>Custom JDK</code>, verify or add the custom
                  JDK path on all hosts in the cluster.
                </p>
              </li>
              <li>
                <p>After setup completes, you must restart each component for the new JDK to be used by the
                  Hadoop services.
                </p>
                <p>Using the Ambari Web UI, do the following tasks:</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>Restart each component</p>
                    </li>
                    <li>
                      <p>Restart each host</p>
                    </li>
                    <li>
                      <p>Restart all services</p>
                    </li>
                  
                </ul>
              </li>
            
          </ul>
          <p>
            For more information about managing services in your cluster, see<a href="#ref-a395d3b3-f835-4033-8176-d5ccee6830e5">Monitoring and Managing Services</a>.
          </p>
        
      
    
    
      <h2 class="horton-green bold">Configuring NameNode High Availability</h2>
      
        
          <p>Ambari sets up active and standby NameNode hosts on a new cluster, by default. Configuring NameNode
            High Availability (HA) sets the standby NameNode to handle the active NameNode workload in the event that
            the active NameNode fails.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>NameNode HA is available with HDP Stack v2.0 or later.</p>
            </div>
          </aside>
          <p>
            Following topics describe:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-96b6ea9c-9bf5-4a1b-a4fd-85eec215621e">How to Set Up NameNode HA</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-1143b7d0-5b4f-402c-8089-115017933ccd">How to Roll Back NameNode HA</a>
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-96b6ea9c-9bf5-4a1b-a4fd-85eec215621e">How To Set Up NameNode High Availability</h3>
        
          <ul class="number-list">
            
              <li>
                <p>Check to make sure you have at least three hosts in your cluster and are running at least
                  three ZooKeeper servers.
                </p>
              </li>
              <li>
                <p>In Ambari Web, select
                  <code>Services &gt; HDFS &gt; Summary. Select Service Actions and choose Enable
                    NameNode HA.
                  </code>
                </p>
              </li>
              <li>
                <p>The Enable HA Wizard launches. This wizard describes the set of automated and manual steps you
                  must take to set up NameNode high availability.
                </p>
              </li>
              <li>
                <p>
                  <strong>Get Started</strong>
                  : This step gives you an overview of the process and allows you to select a Nameservice ID. You use
                  this Nameservice ID instead of the NameNode FQDN once HA has been set up. Click
                  <code>Next</code>
                  to proceed.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/getstartedHA_2x.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p>
                  <strong>Select Hosts</strong>
                  : Select a host for the additional NameNode and the JournalNodes. The wizard suggest options that you
                  can adjust using the drop-down lists. Click
                  <code>Next</code>
                  to proceed.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/selecthostha_2x.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p>
                  <strong>Review</strong>
                  : Confirm your host selections and click<code>Next</code>.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/reviewha_2x.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p>
                  <strong>Create Checkpoints</strong>
                  : Follow the instructions in the step. You need to log in to your
                  <strong>current</strong>
                  NameNode host to run the commands to put your NameNode into safe mode and create a checkpoint. When
                  Ambari detects success, the message on the bottom of the window changes. Click<code>
                  Next</code>.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/checkpointsHA_2x.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p>
                  <strong>Configure Components</strong>
                  : The wizard configures your components, displaying progress bars to let you track the steps. Click
                  <code>Next</code>
                  to continue.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/configurecomponentsHA_2x.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p>
                  <strong>Initialize JournalNodes</strong>
                  : Follow the instructions in the step. You need to login to your
                  <strong>current</strong>
                  NameNode host to run the command to initialize the JournalNodes. When Ambari detects success, the
                  message on the bottom of the window changes. Click<strong>Next</strong>.
                </p>
                <p>
                  <i>
                    <strong>After upgrading to Ambari 1.6.1, or using a Blueprint to install your cluster,</strong>
                  </i>
                  initializing JournalNodes may fail. For information about how to work around this issue, see the the
                  following topic in the Ambari Troubleshooting Guide:

                  <a href="#ref-98fcd077-cf39-4075-ac30-264e3028fb49">Enabling NameNode HA wizard fails at the
                    Initialize JournalNode step
                  </a>
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/initializejournalnodesHA_2x.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p>
                  <strong>Start Components</strong>
                  : The wizard starts the ZooKeeper servers and the NameNode, displaying progress bars to let you track
                  the steps. Click
                  <code>Next</code>
                  to continue.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/startcomponentsHA_2x.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p>
                  <strong>Initialize Metadata</strong>
                  : Follow the instructions in the step. For this step you must log in to both the
                  <strong>current</strong>
                  NameNode and the
                  <strong>additional</strong>
                  NameNode. Make sure you are logged in to the correct host for each command. Click
                  <code>Next</code>
                  when you have completed the two commands. A
                  <strong>Confirmation</strong>
                  pop-up window displays, reminding you to do both steps. Click
                  <code>OK</code>
                  to confirm.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/initializemetadataHA_2x.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p>
                  <strong>Finalize HA Setup</strong>
                  : The wizard the setup, displaying progress bars to let you track the steps. Click
                  <code>Done</code>
                  to finish the wizard. After the Ambari Web GUI reloads, you may see some alert notifications. Wait a
                  few minutes until the services come back up. If necessary, restart any components using Ambari Web.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/finalizeHA_2x.png" width="50">
                    
                  
                </div>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>Choose Services, then start Nagios, after completing all steps in the HA wizard.
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>If you are using Hive, you must manually change the Hive Metastore FS root to point to the
                  Nameservice URI instead of the NameNode URI. You created the Nameservice ID in the Get Started step.
                </p>
                <ul class="Numeric">
                  
                    <li>
                      <p>Check the current FS root. On the Hive host:</p>
                      <p>
                        <code>
                          hive --config /etc/hive/conf.server --service metatool -listFSRoot
                        </code>
                      </p>
                      <p>
                        The output looks similar to the following:
                        <code>Listing FS Roots...
                          hdfs://&lt;namenode-host&gt;/apps/hive/warehouse
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>Use this command to change the FS root:</p>
                      <p>
                        <code>
                          $ hive --config /etc/hive/conf.server --service metatool -updateLocation
                        </code>
                        &lt;new-location&gt;&lt;old-location&gt;
                        <code>

                        </code>For example, where the Nameservice ID is mycluster:
                        <code>
                        </code>
                        <code>$ hive --config /etc/hive/conf.server --service metatool -updateLocation
                          hdfs://mycluster/apps/hive/warehouse hdfs://c6401.ambari.apache.org/apps/hive/warehouse
                        </code>
                      </p>
                      <p>
                        The output looks similar to the following:
                      </p>
                      <p>
                        <code>Successfully updated the following locations...
                        </code>
                        <code>Updated X records in SDS table</code>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>If you are using Oozie, you must use the Nameservice ID instead of the NameNode URI in your
                  workflow files. For example, where the Nameservice ID is<code>mycluster</code>:
                </p>
                <p>
                  <code>
                    &lt;workflow-app xmlns="uri:oozie:workflow:0.2" name="map-reduce-wf"&gt;
                    &lt;start to="mr-node"/&gt;
                    &lt;action name="mr-node"&gt;
                    &lt;map-reduce&gt;
                    &lt;job-tracker&gt;&lt;jobTracker&gt;&lt;/job-tracker&gt;
                    &lt;name-node&gt;hdfs://mycluster&lt;/name-node&gt;</code>
                </p>
              </li>
              <li>
                <p>If you are using Hue, to enable NameNode HighAvailability, you must use httpfs instead of
                  webhdfs to communicate with name nodes inside the cluster. After successfully setting up NameNode High
                  Availability:
                </p>
                <ul class="Numeric">
                  
                    <li>
                      <p>Install an httpfs server on any node in the cluster:</p>
                      <p>
                        <code>
                          yum install hadoop-httpfs
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>Ensure that Hue hosts and groups use the httpfs server.</p>
                      <p>
                        For example, on the httpfs server host, add to httpfs-site.xml the following lines:
                      </p>
                      <p>
                        <code>
                        </code>
                        <code>&lt;property&gt;
                          &lt;name&gt;httpfs.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt;
                          &lt;property&gt; &lt;name&gt;httpfs.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;
                          &lt;/property&gt;</code>
                      </p>
                    </li>
                    <li>
                      <p>Ensure that groups and hosts in the cluster use the httpfs server. For example, use
                        <strong>Services &gt; HDFS &gt; Configs</strong>
                        to add the following properties and values to<code>core-site.xml</code>.
                      </p>
                      <div class="xyleme-table"><table border="1">
                        
                          
                          
                          <thead>
                            <tr>
                              <th rowspan="1">
                                <p>Property</p>
                              </th>
                              <th rowspan="1">
                                <p>Value</p>
                              </th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td rowspan="1">
                                <p>hadoop.proxyuser.httpfs.groups</p>
                              </td>
                              <td rowspan="1">
                                <p>*</p>
                              </td>
                            </tr>
                            <tr>
                              <td rowspan="1">
                                <p>hadoop.proxyuser.httpfs.hosts</p>
                              </td>
                              <td rowspan="1">
                                <p>*</p>
                              </td>
                            </tr>
                          </tbody>
                          
                        
                      </table></div>
                    </li>
                    <li>
                      <p>Using Ambari, in
                        <code>Services &gt;HDFS</code>
                        restart the HDFS service in your cluster.
                      </p>
                    </li>
                    <li>
                      <p>On the Hue host, configure Hue to use the httpfs server by editing hue.ini to include
                        the following line:
                      </p>
                      <p>
                        <code>
                          webhdfs_url=http://
                        </code>
                        &lt;fqdn.of.httpfs.server&gt;
                        <code>:14000/webhdfs/v1/</code>
                      </p>
                    </li>
                    <li>
                      <p>Restart the Hue service.</p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Adjust the ZooKeeper Failover Controller retries setting for your environment.</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>Browse to
                        <code>Services &gt; HDFS &gt; Configs &gt;</code>
                        <code>core-site.</code>
                      </p>
                    </li>
                    <li>
                      <p>Set
                        <code>ha.failover-controller.active-standby-elector.zk.op.retries=120</code>
                      </p>
                    </li>
                  
                </ul>
              </li>
            
          </ul>
          <p></p>
        
      
      
        <h3 class="horton-blue bold" id="ref-1143b7d0-5b4f-402c-8089-115017933ccd">How to Roll Back NameNode HA</h3>
        
          <p>To roll back NameNode HA to the previous non-HA state use the following step-by-step manual process,
            depending on your installation.
          </p>
          <ul class="number-list">
            
              <li>
                <p>
                  <a href="#ref-da81d662-9713-4819-9cc6-6cff0136fb44">Stop HBase</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-1edc6678-2624-4180-9ed2-eec9b369b85a">Checkpoint the Active</a>
                  <a href="#ref-1edc6678-2624-4180-9ed2-eec9b369b85a">NameNode</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-d84d214b-90a8-4692-98b7-f4ad603a08d0">Stop All Services</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-7f2eb960-6285-425f-9422-2155c53941e6">Prepare the Ambari</a>
                  <a href="#ref-7f2eb960-6285-425f-9422-2155c53941e6">Host for Rollback</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-b9c0561a-dfdb-4695-b283-1ef5a5d0bd23">Restore the HBase Configuration</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-845625e1-fa42-425d-b60a-bcd347c3adaf">Delete ZooKeeper Failover Controllers
                  </a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-c38d1665-9d76-4270-b2de-7f21aa69f827">Modify HDFS Configurations</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-5eba614f-afb2-4fdd-a2f2-6aa64a91e98e">Recreate the</a>
                  <a href="#ref-5eba614f-afb2-4fdd-a2f2-6aa64a91e98e">standby NameNode</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-85ebe09e-eeca-462b-9784-d3df13d8d443">Re-enable the standby</a>
                  <a href="#ref-85ebe09e-eeca-462b-9784-d3df13d8d443">NameNode</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-dd4a088d-e577-4565-b178-46fbd428b68b">Delete All</a>
                  <a href="#ref-dd4a088d-e577-4565-b178-46fbd428b68b">JournalNodes</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-f922aff3-18bc-4bd9-b7c8-fcdce9b1ecd8">Delete the</a>
                  <a href="#ref-f922aff3-18bc-4bd9-b7c8-fcdce9b1ecd8">Additional NameNode</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-cdc37f56-735e-4422-bcc6-73225b8f50c9">Verify the HDFS Components</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-9c137931-2d46-48f0-8a6e-e6ba5331dc6a">Start HDFS</a>
                </p>
              </li>
            
          </ul>
        
        
          <h4 class="bold">Stop HBase</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>From Ambari Web, go to the Services view and select HBase.</p>
                </li>
                <li>
                  <p>Choose
                    <code>Service Actions &gt; Stop</code>
                    <strong>.</strong>
                  </p>
                </li>
                <li>
                  <p>Wait until HBase has stopped completely before continuing.</p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Checkpoint the Active NameNode</h4>
          
            <p>
              If HDFS has been in use
              <strong>after</strong>
              you enabled NameNode HA, but you wish to revert back to a non-HA state, you must checkpoint the HDFS state
              before proceeding with the rollback.
            </p>
            <p>
              If the
              <code>Enable NameNode HA</code>
              wizard failed and you need to revert back, you can skip this step and move on to<a href="#ref-d84d214b-90a8-4692-98b7-f4ad603a08d0">Stop All Services</a>.
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>If Kerberos security has
                    <strong>not</strong>
                    been enabled on the cluster:
                  </p>
                  <p>
                    On the Active NameNode host, execute the following commands to save the namespace. You must be the
                    HDFS service user to do this.
                  </p>
                  <p>
                    <code>sudo su -l</code>
                    &lt;HDFS_USER&gt;
                    <code>-c 'hdfs dfsadmin -safemode enter'
                      sudo su -l
                    </code>
                    &lt;HDFS_USER&gt;
                    <code>-c 'hdfs dfsadmin -saveNamespace'</code>
                  </p>
                </li>
                <li>
                  <p>If Kerberos security
                    <strong>has</strong>
                    been enabled on the cluster:
                  </p>
                  <p>
                    <code>sudo su -l</code>
                    &lt;HDFS_USER&gt;
                    <code>-c 'kinit -kt /etc/security/keytabs/nn.service.keytab nn/</code>
                    &lt;HDFS_USER&gt;
                    <code>@</code>
                    &lt;HDFS_USER&gt;
                    <code>;hdfs dfsadmin -safemode enter'
                      sudo su -l
                    </code>
                    &lt;HDFS_USER&gt;
                    <code>-c 'kinit -kt /etc/security/keytabs/nn.service.keytab nn/</code>
                    &lt;HDFS_USER&gt;
                    <code>@</code>
                    &lt;HDFS_USER&gt;
                    <code>;hdfs dfsadmin -saveNamespace'</code>
                  </p>
                  <p>
                    Where
                    &lt;HDFS_USER&gt;
                    is the HDFS service user; for example hdfs,
                    &lt;HOSTNAME&gt;
                    is the Active NameNode hostname, and&lt;REALM&gt; is your Kerberos realm.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Stop All Services</h4>
          
            <p>Browse to<code>Ambari Web &gt; Services</code>, then choose
              <code>Stop All</code>
              in the Services navigation panel. You must wait until all the services are completely stopped.
            </p>
          
        
        
          <h4 class="bold">Prepare the Ambari Server Host for Rollback</h4>
          
            <p>Log into the Ambari server host and set the following environment variables to prepare for the
              rollback procedure:
            </p>
            <div class="xyleme-table"><table border="1">
              
                
                
                <thead>
                  <tr>
                    <th rowspan="1">
                      <p>Variable</p>
                    </th>
                    <th rowspan="1">
                      <p>Value</p>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan="1">
                      <p>export AMBARI_USER=AMBARI_USERNAME</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the value of the administrative user for Ambari Web. The default value is
                        admin.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export AMBARI_PW=AMBARI_PASSWORD</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the value of the administrative password for Ambari Web. The default value is
                        admin.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export AMBARI_PORT=AMBARI_PORT</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the Ambari Web port. The default value is 8080.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export AMBARI_PROTO=AMBARI_PROTOCOL</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the value of the protocol for connecting to Ambari Web. Options are http or
                        https. The default value is http.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export CLUSTER_NAME=CLUSTER_NAME</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the name of your cluster, set during the Ambari Install Wizard process. For
                        example: mycluster.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export NAMENODE_HOSTNAME=NN_HOSTNAME</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the FQDN of the host for the non-HA NameNode. For example:
                        nn01.mycompany.com.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export ADDITIONAL_NAMENODE_HOSTNAME=ANN_HOSTNAME</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the FQDN of the host for the additional NameNode in your HA setup.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export SECONDARY_NAMENODE_HOSTNAME=SNN_HOSTNAME</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the FQDN of the host for the standby NameNode for the non-HA setup.
                      </p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export JOURNALNODE1_HOSTNAME=JOUR1_HOSTNAME</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the FQDN of the host for the first Journal Node.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export JOURNALNODE2_HOSTNAME=JOUR2_HOSTNAME</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the FQDN of the host for the second Journal Node.</p>
                    </td>
                  </tr>
                  <tr>
                    <td rowspan="1">
                      <p>export JOURNALNODE3_HOSTNAME=JOUR3_HOSTNAME</p>
                    </td>
                    <td rowspan="1">
                      <p>Substitute the FQDN of the host for the third Journal Node.</p>
                    </td>
                  </tr>
                </tbody>
                
              
            </table></div>
            <p>
              Double check that these environment variables are set correctly.
            </p>
          
        
        
          <h4 class="bold">Restore the HBase Configuration</h4>
          
            <p>If you have installed HBase, you may need to restore a configuration to its pre-HA state.
            </p>
            <ul class="number-list">
              
                <li>
                  <p>To check if your current HBase configuration needs to be restored, on the Ambari Server
                    host:
                  </p>
                  <p>
                    <code>
                      /var/lib/ambari-server/resources/scripts/configs.sh -u
                    </code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>get localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>hbase-site</code>
                  </p>
                  <p>
                    Where the environment variables you set up in
                    <a href="#ref-7f2eb960-6285-425f-9422-2155c53941e6">Prepare the Ambari Server Host for
                      Rollback
                    </a>
                    substitute for the variable names.
                  </p>
                  <p>
                    Look for the configuration property<code>hbase.rootdir</code>. If the value is set to
                    the NameService ID you set up using the
                    <code>Enable NameNode HA</code>
                    wizard, you need to revert the
                    <code>hbase-site</code>
                    configuration set up back to non-HA values. If it points instead to a specific NameNode host, it
                    does not need to be rolled back and you can go on to<a href="#ref-845625e1-fa42-425d-b60a-bcd347c3adaf">Delete ZooKeeper Failover
                    Controllers</a>.
                  </p>
                  <p>
                    For example:
                  </p>
                  <p>
                    <code>"hbase.rootdir":"hdfs://</code>
                    &lt;name-service-id&gt;
                    <code>:8020/apps/hbase/data"</code>
                    The hbase.rootdir property points to the NameService ID and the value needs to be rolled back

                    <code>"hbase.rootdir":"hdfs://</code>
                    &lt;nn01.mycompany.com&gt;
                    <code>:8020/apps/hbase/data"</code>
                    The hbase.rootdir property points to a specific NameNode host and not a NameService ID. This does
                    not need to be rolled back.
                  </p>
                </li>
                <li>
                  <p>If you need to roll back the
                    <code>hbase.rootdir</code>
                    value, on the Ambari Server host, use the
                    <code>config.sh</code>
                    script to make the necessary change:
                  </p>
                  <p>
                    <code>
                      /var/lib/ambari-server/resources/scripts/configs.sh -u
                    </code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>set localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>hbase-site hbase.rootdir hdfs://</code>
                    &lt;NAMENODE_HOSTNAME&gt;
                    <code>:8020/apps/hbase/data</code>
                  </p>
                  <p>
                    Where the environment variables you set up in
                    <a href="#ref-7f2eb960-6285-425f-9422-2155c53941e6">Prepare the Ambari Server Host for
                      Rollback
                    </a>
                    substitute for the variable names.
                  </p>
                </li>
                <li>
                  <p>Verify that the
                    <code>hbase.rootdir</code>
                    property has been restored properly. On the Ambari Server host:
                  </p>
                  <p>
                    <code>
                      /var/lib/ambari-server/resources/scripts/configs.sh -u
                    </code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>get localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>hbase-site</code>
                  </p>
                  <p>
                    The
                    <code>hbase.rootdir</code>
                    property should now be set to the NameNode hostname, not the NameService ID.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Delete ZooKeeper Failover Controllers</h4>
          
            <p>You may need to delete ZooKeeper (ZK) Failover Controllers.</p>
            <ul class="number-list">
              
                <li>
                  <p>To check if you need to delete ZK Failover Controllers, on the Ambari Server host:
                  </p>
                  <p>
                    <code>
                      curl -u
                    </code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/host_components?</code>
                    <code>HostRoles/component_name=ZKFC</code>
                  </p>
                  <p>
                    If this returns an empty
                    <code>items</code>
                    array, you may proceed to<a href="#ref-c38d1665-9d76-4270-b2de-7f21aa69f827">Modify HDFS
                    Configuration</a>.
                    Otherwise you must use the following DELETE commands:
                  </p>
                </li>
                <li>
                  <p>To delete all ZK Failover Controllers, on the Ambari Server host:</p>
                  <p>
                    <code>
                      curl -u
                    </code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X DELETE</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/hosts/</code>
                    &lt;NAMENODE_HOSTNAME&gt;
                    <code>/host_components/ZKFC

                      curl -u
                    </code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X DELETE</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/hosts/</code>
                    &lt;ADDITIONAL_NAMENODE_HOSTNAME&gt;
                    <code>/host_components/ZKFC</code>
                  </p>
                </li>
                <li>
                  <p>Verify that the ZK Failover Controllers have been deleted. On the Ambari Server host:
                  </p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/host_components?HostRoles/component_name=ZKFC</code>
                  </p>
                  <p>
                    This command should return an empty
                    <code>items</code>
                    array.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Modify HDFS Configurations</h4>
          
            <p>You may need to modify your
              <code>hdfs-site</code>
              configuration and/or your
              <code>core-site</code>
              configuration.
            </p>
            <ul class="number-list">
              
                <li>
                  <p>To check if you need to modify your
                    <code>hdfs-site</code>
                    configuration, on the Ambari Server host:
                  </p>
                  <p>
                    <code>
                      /var/lib/ambari-server/resources/scripts/configs.sh -u
                    </code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>get localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>hdfs-site</code>
                  </p>
                  <p>
                    If you see
                    <strong>any</strong>
                    of the following properties, you must delete them from your configuration.
                  </p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>
                          <code>dfs.nameservices</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.client.failover.proxy.provider.&lt;NAMESERVICE_ID&gt;</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.ha.namenodes.&lt;NAMESERVICE_ID&gt;</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.ha.fencing.methods</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.ha.automatic-failover.enabled</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.namenode.http-address.&lt;NAMESERVICE_ID&gt;.nn1</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.namenode.http-address.&lt;NAMESERVICE_ID&gt;.nn2</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.namenode.rpc-address.&lt;NAMESERVICE_ID&gt;.nn1</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.namenode.rpc-address.&lt;NAMESERVICE_ID&gt;.nn2</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.namenode.shared.edits.dir</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.journalnode.edits.dir</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.journalnode.http-address</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.journalnode.kerberos.internal.spnego.principal</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.journalnode.kerberos.principal</code>
                        </p>
                      </li>
                      <li>
                        <p>
                          <code>dfs.journalnode.keytab.file</code>
                        </p>
                        <p>
                          Where
                          <code>&lt;NAMESERVICE_ID&gt;</code>
                          is the NameService ID you created when you ran the
                          <strong>Enable NameNode HA</strong>
                          wizard.
                        </p>
                      </li>
                    
                  </ul>
                </li>
                <li>
                  <p>To delete these properties, execute the following
                    <strong>for each property</strong>
                    you found. On the Ambari Server host:
                  </p>
                  <p>
                    /
                    <code>var/lib/ambari-server/resources/scripts/configs.sh -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>delete localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>hdfs-site property_name</code>
                  </p>
                  <p>
                    Where you replace
                    <code>property_name</code>
                    with the name of
                    <strong>each</strong>
                    of the properties to be deleted.
                  </p>
                </li>
                <li>
                  <p>Verify that all of the properties have been deleted. On the Ambari Server host:
                    <code>/var/lib/ambari-server/resources/scripts/configs.sh -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>get localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>hdfs-site</code>
                  </p>
                  <p>
                    None of the properties listed above should be present.
                  </p>
                </li>
                <li>
                  <p>To check if you need to modify your
                    <code>core-site</code>
                    configuration, on the Ambari Server host:
                    <code>/var/lib/ambari-server/resources/scripts/configs.sh -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>get localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>core-site</code>
                  </p>
                </li>
                <li>
                  <p>If you see the property<code>ha.zookeeper.quorum</code>, it must be deleted. On
                    the Ambari Server host:
                  </p>
                  <p>
                    <code>/var/lib/ambari-server/resources/scripts/configs.sh -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>delete localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>core-site ha.zookeeper.quorum</code>
                  </p>
                </li>
                <li>
                  <p>If the property
                    <code>fs.defaultFS</code>
                    is set to the NameService ID, it must be reverted back to its non-HA value. For example:
                  </p>
                  <p>
                    <code>"fs.defaultFS":"hdfs://</code>
                    &lt;name-service-id&gt;
                    <code>"
                      The property fs.defaultFS needs to be modified as it points to a NameService ID
                      "fs.defaultFS":"hdfs://
                    </code>
                    &lt;nn01.mycompany.com&gt;
                    <code>"
                    </code>
                    The property
                    <code>fs.defaultFS</code>
                    does not need to be changed as it points to a specific NameNode, not to a NameService ID
                  </p>
                </li>
                <li>
                  <p>To revert the property
                    <code>fs.defaultFS</code>
                    to the NameNode host value, on the Ambari Server host:
                  </p>
                  <p>
                    <code>/var/lib/ambari-server/resources/scripts/configs.sh -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>set localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>core-site fs.defaultFS hdfs://</code>
                    &lt;NAMENODE_HOSTNAME&gt;
                  </p>
                </li>
                <li>
                  <p>Verify that the
                    <code>core-site</code>
                    properties are now properly set. On the Ambari Server host:
                  </p>
                  <p>
                    <code>/var/lib/ambari-server/resources/scripts/configs.sh -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>-p</code>
                    &lt;AMBARI_PW&gt;
                    <code>-port</code>
                    &lt;AMBARI_PORT&gt;
                    <code>get localhost</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>core-site</code>
                  </p>
                  <p>
                    The property
                    <code>fs.defaultFS</code>
                    should be set to point to the NameNode host and the property
                    <code>ha.zookeeper.quorum</code>
                    should not be there.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Recreate the Standby NameNode</h4>
          
            <p>You may need to recreate your standby NameNode.</p>
            <ul class="number-list">
              
                <li>
                  <p>To check to see if you need to recreate the standby NameNode, on the Ambari Server host:
                  </p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X GET</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/host_components?HostRoles/component_name=SECONDARY_NAMENODE</code>
                  </p>
                  <p>
                    If this returns an empty
                    <code>items</code>
                    array, you must recreate your standby NameNode. Otherwise you can go on to<a href="#ref-85ebe09e-eeca-462b-9784-d3df13d8d443">Re-enable Standby NameNode</a>.
                  </p>
                </li>
                <li>
                  <p>Recreate your standby NameNode. On the Ambari Server host:
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X POST -d '{"host_components" :
                      [{"HostRoles":{"component_name":"SECONDARY_NAMENODE"}] }'
                    </code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/hosts?Hosts/host_name=</code>
                    &lt;SECONDARY_NAMENODE_HOSTNAME&gt;
                  </p>
                </li>
                <li>
                  <p>Verify that the standby NameNode now exists. On the Ambari Server host:</p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X GET</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/host_components?HostRoles/component_name=SECONDARY_NAMENODE</code>
                  </p>
                  <p>
                    This should return a non-empty
                    <code>items</code>
                    array containing the standby NameNode.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Re-enable the Standby NameNode</h4>
          
            <p>To re-enable the standby NameNode, on the Ambari Server host:</p>
            <p>
              <code>curl -u</code>
              &lt;AMBARI_USER&gt;
              <code>:</code>
              &lt;AMBARI_PW&gt;
              <code>-H "X-Requested-By: ambari" -i -X '{"RequestInfo":{"context":"Enable Secondary
                NameNode"},"Body":{"HostRoles":{"state":"INSTALLED"}}}'
              </code>
              &lt;AMBARI_PROTO&gt;
              <code>://localhost:</code>
              &lt;AMBARI_PORT&gt;
              <code>/api/v1/clusters/</code>
              &lt;CLUSTER_NAME&gt;
              <code>/hosts/&lt;SECONDARY_NAMENODE_HOSTNAME}/host_components/SECONDARY_NAMENODE
              </code>
            </p>
            <ul class="bullet-list">
              
                <li>
                  <p>If this returns 200, go to<a href="#ref-dd4a088d-e577-4565-b178-46fbd428b68b">
                    Delete All JournalNodes</a>.
                  </p>
                </li>
                <li>
                  <p>If this returns 202, wait a few minutes and run the following on the Ambari Server host:
                  </p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:${AMBARI_PW -H "X-Requested-By: ambari" -i -X "</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/host_components?HostRoles/component_name=SECONDARY_NAMENODE&amp;fields=HostRoles/state"</code>
                  </p>
                  <p>
                    When
                    <code>"state" : "INSTALLED"</code>
                    is in the response, go on to the next step.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Delete All JournalNodes</h4>
          
            <p>
              You may need to delete any JournalNodes.
            </p>
            <ul class="number-list">
              
                <li>
                  <p>To check to see if you need to delete JournalNodes, on the Ambari Server host:</p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X GET</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/host_components?HostRoles/component_name=JOURNALNODE</code>
                  </p>
                  <p>
                    If this returns an empty
                    <code>items</code>
                    array, you can go on to<a href="#ref-f922aff3-18bc-4bd9-b7c8-fcdce9b1ecd8">Delete the
                    Additional NameNode</a>. Otherwise you must delete the JournalNodes.
                  </p>
                </li>
                <li>
                  <p>To delete the JournalNodes, on the Ambari Server host:</p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X DELETE</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/hosts/</code>
                    &lt;JOURNALNODE1_HOSTNAME&gt;
                    <code>/host_components/JOURNALNODE

                      curl -u
                    </code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X DELETE</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/hosts/</code>
                    &lt;JOURNALNODE2_HOSTNAME&gt;
                    <code>/host_components/JOURNALNODE 

                      curl -u
                    </code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X DELETE</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/hosts/</code>
                    &lt;JOURNALNODE3_HOSTNAME&gt;
                    <code>/host_components/JOURNALNODE</code>
                  </p>
                </li>
                <li>
                  <p>Verify that all the JournalNodes have been deleted. On the Ambari Server host:</p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X GET</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/host_components?HostRoles/component_name=JOURNALNODE</code>
                  </p>
                  <p>
                    This should return an empty
                    <code>items</code>
                    array.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Delete the Additional NameNode</h4>
          
            <p>
              You may need to delete your Additional NameNode.
            </p>
            <ul class="number-list">
              
                <li>
                  <p>To check to see if you need to delete your Additional NameNode, on the Ambari Server host:
                  </p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X GET</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/host_components?HostRoles/component_name=NAMENODE</code>
                  </p>
                  <p>
                    If the
                    <code>items</code>
                    array contains two NameNodes, the Additional NameNode must be deleted.
                  </p>
                </li>
                <li>
                  <p>To delete the Additional NameNode that was set up for HA, on the Ambari Server host:
                  </p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X DELETE</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/hosts/</code>
                    &lt;ADDITIONAL_NAMENODE_HOSTNAME&gt;
                    <code>/host_components/NAMENODE</code>
                  </p>
                </li>
                <li>
                  <p>Verify that the Additional NameNode has been deleted:</p>
                  <p>
                    <code>curl -u</code>
                    &lt;AMBARI_USER&gt;
                    <code>:</code>
                    &lt;AMBARI_PW&gt;
                    <code>-H "X-Requested-By: ambari" -i -X GET</code>
                    &lt;AMBARI_PROTO&gt;
                    <code>://localhost:</code>
                    &lt;AMBARI_PORT&gt;
                    <code>/api/v1/clusters/</code>
                    &lt;CLUSTER_NAME&gt;
                    <code>/host_components?HostRoles/component_name=NAMENODE</code>
                  </p>
                  <p>
                    This should return an
                    <code>items</code>
                    array that shows only one NameNode.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Verify the HDFS Components</h4>
          
            <p>Make sure you have the correct components showing in HDFS.</p>
            <ul class="number-list">
              
                <li>
                  <p>Go to<code>Ambari Web UI &gt; Services</code>, then select
                    <code>HDFS</code>.
                  </p>
                </li>
                <li>
                  <p>Check the Summary panel and make sure that the first three lines look like this:</p>
                  <ul class="Bullet">
                    
                      <li>
                        <p>NameNode</p>
                      </li>
                      <li>
                        <p>SNameNode</p>
                      </li>
                      <li>
                        <p>DataNodes</p>
                      </li>
                    
                  </ul>
                  <p>
                    You should
                    <strong>not</strong>
                    see any line for JournalNodes.
                  </p>
                </li>
              
            </ul>
          
        
        
          <h4 class="bold">Start HDFS</h4>
          
            <ul class="number-list">
              
                <li>
                  <p>In the<code>Ambari Web UI</code>, select<code>
                    Service Actions</code>, then choose
                    <code>Start</code>
                    <strong>.</strong>
                  </p>
                  <p>
                    Wait until the progress bar shows that the service has completely started and has passed the service
                    checks.

                    If HDFS does not start, you may need to repeat the previous step.
                  </p>
                </li>
                <li>
                  <p>To start all of the other services, select<code>Actions &gt; Start
                    All</code>in the
                    <code>Services</code>
                    navigation panel.
                  </p>
                </li>
              
            </ul>
          
        
      
    
    
      <h2 class="horton-green bold">Configuring ResourceManager High Availability</h2>
      
        
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>This feature is available with HDP Stack 2.2 or later.</p>
            </div>
          </aside>
          <p>The following topic explains<a href="#ref-edbf1cf0-b3cd-42fb-959c-fdb13bc5e02f">How to set
            up ResourceManager High Availability</a>.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-edbf1cf0-b3cd-42fb-959c-fdb13bc5e02f">How to Set Up ResourceManager High Availability</h3>
        
          <ul class="number-list">
            
              <li>
                <p>Check to make sure you have at least three hosts in your cluster and are running at least
                  three ZooKeeper servers.
                </p>
              </li>
              <li>
                <p>In Ambari Web, browse to<code>Services &gt; YARN &gt;
                  Summary</code>. Select
                  <code>Service Actions</code>
                  and choose<code>Enable ResourceManager HA</code>.
                </p>
              </li>
              <li>
                <p>The Enable ResourceManager HA Wizard launches. The wizard describes a set of automated and
                  manual steps you must take to set up ResourceManager High Availability.
                </p>
              </li>
              <li>
                <p><strong>Get Started</strong>: This step gives you an overview of enabling ResourceManager HA.
                  Click
                  <code>Next</code>
                  to proceed.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/RMHA-01_get_started.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p><strong>Select Host</strong>: The wizard shows you the host on which the current ResourceManager
                  is installed and suggests a default host on which to install an additional ResourceManager. Accept the
                  default selection, or choose an available host. Click
                  <code>Next</code>
                  to proceed.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/RMHA-02_Select_Host.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p><strong>Review Selections</strong>: The wizard shows you the host selections and configuration
                  changes that will occur to enable ResourceManager HA. Expand YARN, if necessary, to review all the
                  YARN configuration changes. Click<code>Next</code>to approve the changes
                  and start automatically configuring ResourceManager HA.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/RMHA-03_Review.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p><strong>Configure Components</strong>: The wizard configures your components automatically,
                  displaying progress bars to let you track the steps. After all progress bars complete, click
                  <code>Complete</code>to finish the wizard.
                </p>
                <div class="figure">
                  
                    
                      <img src="01-RawContent/Ambari/RMHA-04_Configure_Components.png" width="50">
                    
                  
                </div>
              </li>
            
          </ul>
        
      
    
    
      <h2 class="horton-green bold">Configuring RHEL HA for Hadoop 1.x</h2>
      
        
          <p>Ambari supports High Availability of components such as NameNode or JobTracker in a HDP 1.x cluster
            running RHEL HA. After installing NameNode monitoring components on hosts in an HA cluster, as described in
            <a href="http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-1.3.3/bk_hdp1-system-admin-guide/content/ch_ha-redhat-nn-config.html">
              HDP System Administration</a>, configure Ambari to reassign any component on a failover host in the
            cluster, using the host_relocate_component.py script.
          </p>
          <p>For example, if the host for the primary NameNode or JobTracker component fails, Ambari reassigns
            the primary NameNode or JobTracker component to the configured failover host, when you start or restart
            Ambari server.

            To configure RHEL HA for an Hadoop 1.x, do the following tasks:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <a href="#ref-7025de4e-976f-4e96-8874-5ce3370d62e7">Deploy the scripts</a>
                </p>
              </li>
              <li>
                <p>
                  <a href="#ref-67e6f971-18b4-45a1-a8f5-02651bc66683">Configure Ambari properties across the HA
                    cluster
                  </a>
                </p>
              </li>
              <li>
                <p><a href="#ref-bf4a0932-32e2-4d62-9196-ca244ab44255">Troublshoot RHEL HA</a>, if
                  necessary
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-7025de4e-976f-4e96-8874-5ce3370d62e7">Deploy the scripts</h3>
        
          <p>While the Ambari server and ambari agents are running on each host:</p>
          <ul class="number-list">
            
              <li>
                <p>Download relocate_host_component.py from
                  <code>/var/lib/ambari-server/resources/scripts</code>
                  on the Ambari server to
                  <code>/usr/bin/</code>
                  on each failover host.
                </p>
              </li>
              <li>
                <p>Download
                  <code>hadoop.sh</code>
                  from
                  <code>/var/lib/ambari-server/resources/scripts</code>
                  on the Ambari server and replace hadoop.sh in /usr/share/cluster/ on each failover host.
                </p>
              </li>
            
          </ul>
        
      
      
        <h3 class="horton-blue bold" id="ref-67e6f971-18b4-45a1-a8f5-02651bc66683">Configure Ambari properties across the HA cluster</h3>
        
          <p>To enable Ambari to run<code>relocate_host_component.py</code>, use a text editor to
            edit the cluster configuration file on each failover host in the HA cluster.
          </p>
          <p>
            In<code>/etc/cluster/cluster.conf</code>, set values for each of the following properties:
          </p>
          <ul class="bullet-list">
            
              <li>
                <p>
                  <code>&lt;server&gt;=&lt;ambari-hostname / ip&gt;</code>
                </p>
              </li>
              <li>
                <p>
                  <code>&lt;port&gt;=&lt;8080&gt;</code>
                </p>
              </li>
              <li>
                <p>
                  <code>&lt;protocol&gt;=&lt;http / https&gt;</code>
                </p>
              </li>
              <li>
                <p>
                  <code>&lt;user&gt;=&lt;admin&gt;</code>
                </p>
              </li>
              <li>
                <p>
                  <code>&lt;password&gt;=&lt;admin&gt;</code>
                </p>
              </li>
              <li>
                <p>
                  <code>&lt;cluster&gt;=&lt;cluster-name&gt;</code>
                </p>
              </li>
              <li>
                <p>
                  <code>&lt;output&gt;=&lt;/var/log/ambari_relocate.log&gt;</code>
                </p>
              </li>
            
          </ul>
          <p>
            For example, the Hadoop daemon section of
            <code>cluster.conf</code>
            on the NameNode localhost in an HA cluster will look like:
          </p>
          <p>
            <code>&lt;hadoop__independent_subtree="1" __max_restarts="10" __restart_expire_time="600"
              name="NameNode Process"
              daemon="namenode" boottime="10000" probetime="10000" stoptime="10000"
              url="http://10.0.0.30:50070/dfshealth.jsp"
              pid="/var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid" path="/"

              ambariproperties="server=localhost,port=8080,protocol=http,user=admin,password=admin,cluster=c1,output=/var/log/ambari_relocate.log"/&gt;</code>
          </p>
          <p>
            The
            <code>relocate_host_component.py</code>
            script reassigns components on failover of any host in the HA cluster, when you start or restart Ambari
            server.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-bf4a0932-32e2-4d62-9196-ca244ab44255">Troubleshooting RHEL HA</h3>
        
          <ul class="number-list">
            
              <li>
                <p>Review errors in<code>/var/log/messages/</code>.
                </p>
              </li>
              <li>
                <p>If the following error message appears:</p>
                <p>
                  <code>abrtd: Executable '/usr/bin/relocate_resources.py' doesn't belong to any
                    package and ProcessUnpackaged is set to 'no'
                  </code>
                </p>
                <p>
                  Set the following property, in<code>/etc/abrt/abrt-action-save-package-data.conf</code>,
                </p>
                <p>
                  <code>
                    set ProcessUnpackaged=Yes
                  </code>
                </p>
              </li>
              <li>
                <p>If the scripts return Error status=exit code 3, make sure the following are true:</p>
                <ul class="Bullet">
                  
                    <li>
                      <p>The ambari agent on the failover host is running.</p>
                    </li>
                    <li>
                      <p>Failover did not result from STOP HDFS or STOP NN/JT, using Ambari.</p>
                    </li>
                  
                </ul>
              </li>
            
          </ul>
          <p>
            The following table lists and describes parameters for<code>relocate_host_components.py</code>.
          </p>
          <div class="xyleme-table"><table border="1">
            
              
              
              
              
              <thead>
                <tr>
                  <th rowspan="1">
                    <p>Parameter</p>
                  </th>
                  <th rowspan="1">
                    <p>Value</p>
                  </th>
                  <th rowspan="1">
                    <p>Example</p>
                  </th>
                  <th rowspan="1">
                    <p>Description</p>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1">
                    <p>-h,</p>
                  </td>
                  <td rowspan="1">
                    <p>na</p>
                  </td>
                  <td rowspan="1">
                    <p>--help</p>
                  </td>
                  <td rowspan="1">
                    <p>Display all parameter options.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-v,</p>
                  </td>
                  <td rowspan="1">
                    <p>na</p>
                  </td>
                  <td rowspan="1">
                    <p>--verbose</p>
                  </td>
                  <td rowspan="1">
                    <p>Increases output verbosity.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-s,</p>
                  </td>
                  <td rowspan="1">
                    <p>SERVER_HOSTNAME,</p>
                  </td>
                  <td rowspan="1">
                    <p>--host=SERVER_HOSTNAME</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari server host name (FQDN)</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-p,</p>
                  </td>
                  <td rowspan="1">
                    <p>SERVER_PORT,</p>
                  </td>
                  <td rowspan="1">
                    <p>--port=SERVER_PORT</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari server port. [default: 8080]</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-r,</p>
                  </td>
                  <td rowspan="1">
                    <p>PROTOCOL,</p>
                  </td>
                  <td rowspan="1">
                    <p>--protocol=PROTOCOL</p>
                  </td>
                  <td rowspan="1">
                    <p>Protocol for communicating with Ambari server (http/https) [default: http]</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-c,</p>
                  </td>
                  <td rowspan="1">
                    <p>CLUSTER_NAME,</p>
                  </td>
                  <td rowspan="1">
                    <p>--cluster-name=CLUSTER_NAME</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari cluster to operate on.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-e,</p>
                  </td>
                  <td rowspan="1">
                    <p>SERVICE_NAME,</p>
                  </td>
                  <td rowspan="1">
                    <p>--service-name=SERVICE_NAME</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari Service to which the component belongs.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-m,</p>
                  </td>
                  <td rowspan="1">
                    <p>COMPONENT_NAME,</p>
                  </td>
                  <td rowspan="1">
                    <p>--component-name=COMPONENT_NAME</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari Service Component to operate on.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-n,</p>
                  </td>
                  <td rowspan="1">
                    <p>NEW_HOSTNAME,</p>
                  </td>
                  <td rowspan="1">
                    <p>--new-host=NEW_HOSTNAME</p>
                  </td>
                  <td rowspan="1">
                    <p>New host to relocate the component to.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-a,</p>
                  </td>
                  <td rowspan="1">
                    <p>ACTION,</p>
                  </td>
                  <td rowspan="1">
                    <p>--action=ACTION</p>
                  </td>
                  <td rowspan="1">
                    <p>Script action. [default: relocate]</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-o,</p>
                  </td>
                  <td rowspan="1">
                    <p>FILE,</p>
                  </td>
                  <td rowspan="1">
                    <p>--output-file=FILE</p>
                  </td>
                  <td rowspan="1">
                    <p>Output file. [default: /temp/ambari_reinstall_probe.out]</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-u,</p>
                  </td>
                  <td rowspan="1">
                    <p>USERNAME,</p>
                  </td>
                  <td rowspan="1">
                    <p>--username=USERNAME</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari server admin user. [default: admin]</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-w,</p>
                  </td>
                  <td rowspan="1">
                    <p>PASSWORD,</p>
                  </td>
                  <td rowspan="1">
                    <p>--password=PASSWORD</p>
                  </td>
                  <td rowspan="1">
                    <p>Ambari server admin password.</p>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1">
                    <p>-d,</p>
                  </td>
                  <td rowspan="1">
                    <p>COMPONENT_NAME,</p>
                  </td>
                  <td rowspan="1">
                    <p>--start-component</p>
                  </td>
                  <td rowspan="1">
                    <p>Start the component after reassignment.</p>
                  </td>
                </tr>
              </tbody>
              
            
          </table></div>
        
      
    
    
      <h2 class="horton-green bold">Using Ambari Blueprints</h2>
      
        
          <p>Ambari Blueprints provide an API to perform cluster installations. You can build a reusable
            “blueprint” that defines which Stack to use, how Service Components should be laid-out across a cluster, and
            what configurations to set.
          </p>
          <p>
            <a href="#ref-54188247-ac4b-47b4-a402-88bbf6687b74">Overview: Ambari Blueprints</a>
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-54188247-ac4b-47b4-a402-88bbf6687b74">Overview: Ambari Blueprints</h3>
        
          <p>
            Ambari Blueprints provide an API to perform cluster installations. You can build a reusable “blueprint” that
            defines which Stack to use, how Service Components should be laid-out across a cluster and what
            configurations to set.
          </p>
          <div class="figure">
            
              
                <img src="01-RawContent/Ambari/ambari_blueprint_concept.png" width="85">
              
            
          </div>
          <p>
            After setting up a blueprint, you can call the API to instantiate the cluster by providing the list of hosts
            to use. The Ambari Blueprint framework promotes reusability and facilitates automating cluster installations
            without UI interaction.
          </p>
          <p>
            Learn more about Ambari Blueprints API on the<a href="https://cwiki.apache.org/confluence/display/AMBARI/Blueprints">Ambari Wiki</a>.
          </p>
        
      
    
    
      <h2 class="horton-green bold">Configuring HDP Stack Repositories for Red Hat Satellite</h2>
      
        
          <p>As part of installing HDP Stack with Ambari,
            <code>HDP.repo</code>
            and
            <code>HDP-UTILS.repo</code>
            files are generated and distributed to the cluster hosts based on the Base URL user input from the Cluster
            Install Wizard during the Select Stack step. In cases where you are using Red Hat Satellite to manage your
            Linux infrastructure, you can disable the repositories defined in the HDP Stack .repo files and instead
            leverage Red Hat Satellite.
          </p>
          <p>
            <a href="#ref-43d025a3-bb9c-412a-8080-ae0b040fdbc2">How To Configure HDP Stack Repositories for Red
              Hat Satellite
            </a>
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-43d025a3-bb9c-412a-8080-ae0b040fdbc2">How To Configure HDP Stack Repositories for Red Hat Satellite</h3>
        
          <p>To disable the repositories defined in the HDP Stack.repo files:</p>
          <ul class="number-list">
            
              <li>
                <p>Before starting the Ambari Server and installing a cluster, on the Ambari Server browse to the
                  Stacks definition directory.
                </p>
                <p>
                  <code>
                    cd /var/lib/ambari-server/resources/stacks/
                  </code>
                </p>
              </li>
              <li>
                <p>Browse the install hook directory:</p>
                <p>
                  <strong>
                    For HDP 2.0 or HDP 2.1 Stack
                  </strong>
                  <code>cd HDP/2.0.6/hooks/before-INSTALL/templates</code>
                </p>
                <p>
                  <strong>For HDP 1.3 Stack
                  </strong>
                  <code>cd HDP/1.3.2/hooks/before-INSTALL/templates</code>
                </p>
              </li>
              <li>
                <p>Modify the.repo template file</p>
                <p>
                  <code>vi repo_suse_rhel.j2</code>
                </p>
              </li>
              <li>
                <p>Set the enabled property to 0 to disable the repository.</p>
                <p>
                  <code>enabled=0</code>
                </p>
              </li>
              <li>
                <p>Save and exit.</p>
              </li>
              <li>
                <p>Start the Ambari Server and proceed with your install.</p>
              </li>
            
          </ul>
          <p>The .repo files will still be generated and distributed during cluster install but the repositories
            defined in the .repo files will not be enabled.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Important.png" width="50"></div>
            <div class="simple-block">
              <p>You must configure Red Hat Satellite to define and enable the Stack repositories. Please refer
                to the Red Hat Satellite documentation for more information.
              </p>
            </div>
          </aside>
        
      
    
    
      <h2 class="horton-green bold">Configuring Storm for Supervision</h2>
      
        
          <p>Ambari administrators should install and configure a process controller to monitor and run Apache
            Storm under supervision. Storm is fail-fast application, meaning that it is designed to fail under certain
            circumstances, such as a runtime exception or a break in network connectivity. Without a watchdog process,
            these events can quickly take down an entire Storm cluster in production. A watchdog process prevents this
            by monitoring for failed Storm processes and restarting them when necessary. This topic describes how to
            configure 
            <code>supervisord</code>
            to manage the Storm processes, but you may choose to use another process controller, such as 
            <code>monit</code>
            or<code>daemontools</code>.
          </p>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Note.png" width="50"></div>
            <div class="simple-block">
              <p>Running Storm under supervision is only supported for Nimbus Server and Supervisors.</p>
            </div>
          </aside>
          <p>
            <a href="#ref-803898d1-8f94-4980-9b9f-9b110361a6a3">
            </a>
            <a href="#ref-803898d1-8f94-4980-9b9f-9b110361a6a3">How To Configure Storm for Supervision</a>
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-803898d1-8f94-4980-9b9f-9b110361a6a3">How To Configure Storm for Supervision</h3>
        
          <p>To configure Storm for operating under supervision:</p>
          <ul class="number-list">
            
              <li>
                <p>Stop all Storm components.</p>
                <p>
                  Using<code>Ambari Web Services &gt; Storm &gt; Service Actions</code>,
                  choose<code>Stop</code>, then wait until stop completes.
                </p>
              </li>
              <li>
                <p>Stop Ambari Server.</p>
                <p>
                  <code>
                    ambari-server stop
                  </code>
                </p>
              </li>
              <li>
                <p>Change Supervisor and Nimbus command scripts in the Stack definition.</p>
                <p>
                  On Ambari Server host, run:
                </p>
                <p>
                  <code>
                    sed -ir
                    "s/scripts\/supervisor.py/scripts\/supervisor_prod.py/g"/var/lib/ambari-server/resources/stacks/HDP/2.1/services/STORM/metainfo.xml
                    sed -ir "s/scripts\/nimbus.py/scripts\/nimbus_prod.py/g"
                    /var/lib/ambari-server/resources/stacks/HDP/2.1/services/STORM/metainfo.xml
                  </code>
                </p>
              </li>
              <li>
                <p>Install
                  <code>supervisord</code>
                  on all Nimbus and Supervisor hosts.
                </p>
                <ul class="Numeric">
                  
                    <li>
                      <p>Install EPEL repository.</p>
                      <p>
                        <code>
                          yum install epel-release -y
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>Install supervisor package for<code>supervisord</code>.
                      </p>
                      <p>
                        <code>
                          yum install supervisor -y
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>Enable
                        <code>supervisord</code>
                        on autostart.
                      </p>
                      <p>
                        <code>
                          chkconfig supervisord on
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>Change
                        <code>supervisord</code>
                        configuration file permissions.
                      </p>
                      <p>
                        <code>
                          chmod 600 /etc/supervisord.conf
                        </code>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Configure
                  <code>supervisord</code>
                  to supervise Nimbus Server and Supervisors.
                </p>
                <p>
                  Append the following to
                  <code>/etc/supervisord.conf</code>
                  on all Supervisor host and Nimbus hosts accordingly.
                </p>
                <p>
                  <code>
                    [program:storm-nimbus]
                    command=env PATH=$PATH:/bin:/usr/bin/:/usr/jdk64/jdk1.7.0_45/bin/ JAVA_HOME=/usr/jdk64/jdk1.7.0_45
                    /usr/hdp/current/storm-nimbus/bin/storm nimbus
                    user=storm
                    autostart=true
                    autorestart=true
                    startsecs=10
                    startretries=999
                    log_stdout=true
                    log_stderr=true
                    logfile=/var/log/storm/nimbus.out
                    logfile_maxbytes=20MB
                    logfile_backups=10
                  </code>
                </p>
                <p>
                  <code>
                    [program:storm-supervisor]
                    command=env PATH=$PATH:/bin:/usr/bin/:/usr/jdk64/jdk1.7.0_45/bin/ JAVA_HOME=/usr/jdk64/jdk1.7.0_45
                    /usr/hdp/current/storm-supervisor/bin/storm supervisor
                    user=storm
                    autostart=true
                    autorestart=true
                    startsecs=10
                    startretries=999
                    log_stdout=true
                    log_stderr=true
                    logfile=/var/log/storm/supervisor.out
                    logfile_maxbytes=20MB
                    logfile_backups=10
                  </code>
                </p>
                <aside class="custom-note">
                  <div class="icon"><img src="Icons/Note.png" width="50"></div>
                  <div class="simple-block">
                    <p>
                      Change /usr/jdk64/jdk1.7.0_45 accordingly to the location of the jdk for Ambari in your
                      environment
                    </p>
                  </div>
                </aside>
              </li>
              <li>
                <p>Start Ambari Server.</p>
                <p>
                  <code>
                    ambari-server start
                  </code>
                </p>
              </li>
            
          </ul>
        
      
    
    
      <h2 class="horton-green bold">Tuning Ambari Performance</h2>
      
        
          <p>For clusters larger than 200 nodes, calculate and set a larger task cache size on the Ambari server.
            Also, enable Nagios macros appropriate for the HDP Stack version.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-86a72931-b8b5-4925-b030-c561bce34a80">How To Tune Ambari Performance</h3>
        
          <p>For clusters larger than 200 nodes:</p>
          <ul class="number-list">
            
              <li>
                <p>Calculate the new, larger cache size, using the following relationship:</p>
                <p>
                  <code>ecCacheSizeValue=60*</code>
                  &lt;cluster_size&gt;
                  where
                  &lt;cluster_size&gt;
                  is the number of nodes in the cluster.
                </p>
              </li>
              <li>
                <p>On the Ambari Server host, in<code>etc/ambari-server/conf/ambari-properties</code>
                  , add the following property and value:
                </p>
                <p>
                  <code>server.ecCacheSize=&lt;ecCacheSizeValue&gt;
                  </code>where
                  &lt;ecCacheSizeValue&gt;
                  is the value calculated previously, based on the number of nodes in the cluster.
                </p>
              </li>
              <li>
                <p>On Ambari Server host, make the following changes:</p>
                <p>
                  <code>
                    -enable_environment_macros=1
                    +enable_environment_macros=0
                  </code>
                </p>
                <ul class="Bullet">
                  
                    <li>
                      <p>For HDP2, make this change in
                        <code>
                          /var/lib/ambari-server/resources/stacks/HDP/2.0.6/services/NAGIOS/package/templates/nagios.cfg.j2
                        </code>
                      </p>
                    </li>
                    <li>
                      <p>For HDP1, make this change in
                        <code>
                          /var/lib/ambari-server/resources/stacks/HDP/1.3.2/services/NAGIOS/package/templates/nagios.cfg.j2
                        </code>
                      </p>
                    </li>
                  
                </ul>
              </li>
              <li>
                <p>Restart Ambari Server.</p>
                <p>
                  <code>
                    ambari-server restart
                  </code>
                </p>
              </li>
              <li>
                <p>Restart Nagios.</p>
                <p>
                  Using<code>Ambari Web &gt; Services &gt; Nagios &gt; Service
                  Actions</code>, choose<code>Restart All</code>.
                </p>
              </li>
            
          </ul>
        
      
    
    
      <h2 class="horton-green bold">Refreshing YARN Capacity Scheduler</h2>
      
        
          <p>
            After you modify the Capacity Scheduler configuration, YARN supports refreshing the queues without requiring
            you to restart your ResourceManager. The “refresh” operation is valid if you have made no destructive
            changes to your configuration. Removing a queue is an example of a destructive change.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-6f5372a3-c2b7-42ed-9969-dc2ce0a9950f">How to refresh the YARN Capacity Scheduler</h3>
        
          <p>This topic describes how to refresh the Capacity Scheduler in cases where you have added or modified
            existing queues.
          </p>
        
        
          <ul class="bullet-list">
            
              <li>
                <p>In Ambari Web, browse to<code>Services &gt; YARN &gt;
                  Summary</code>.
                </p>
              </li>
              <li>
                <p>Select<code>Service Actions</code>, then choose
                  <code>Refresh YARN Capacity Scheduler</code>.
                </p>
              </li>
              <li>
                <p>Confirm you would like to perform this operation.</p>
                <p>
                  The refresh operation is submitted to the YARN ResourceManager.
                </p>
              </li>
            
          </ul>
          <aside class="custom-note">
            <div class="icon"><img src="Icons/Important.png" width="50"></div>
            <div class="simple-block">
              <p>The Refresh operation will fail with the following message: “Failed to re-init queues” if you
                attempt to refresh queues in a case where you performed a destructive change, such as removing a queue.
                In cases where you have made destructive changes, you must perform a ResourceManager restart for the
                capacity scheduler change to take effect.
              </p>
            </div>
          </aside>
        
      
    
    
      <h2 class="horton-green bold">Rebalancing HDFS</h2>
      
        
          <p>HDFS provides a “balancer” utility to help balance the blocks across DataNodes in the cluster.
          </p>
        
      
      
        <h3 class="horton-blue bold" id="ref-c6cd67d1-1c07-4505-8c20-b0f597f208f3">How to rebalance HDFS</h3>
        
          <p>This topic describes how you can initiate an HDFS rebalance from Ambari.</p>
        
        
          <ul class="number-list">
            
              <li>
                <p>. In Ambari Web, browse to<code>Services &gt; HDFS &gt;
                  Summary</code>.
                </p>
              </li>
              <li>
                <p>Select<code>Service Actions</code>, then choose
                  <code>Rebalance HDFS</code>.
                </p>
              </li>
              <li>
                <p>Enter the Balance Threshold value as a percentage of disk capacity.</p>
                <div class="figure">
                  
                    
                      <img src="System%20Admin%20Guides/Ambari/RebalanceHDFS.png" width="50">
                    
                  
                </div>
              </li>
              <li>
                <p>Click
                  <code>Start</code>
                  to begin the rebalance.
                </p>
              </li>
              <li>
                <p>You can check rebalance progress or cancel a rebalance in process by opening the Background
                  Operations dialog.
                </p>
              </li>
            
          </ul>
        
      
    
  </div></main>
</div>
<div class="container"><div class="footnotes">
<h2 class="horton-blue border-bottom">Footnotes</h2>
<ol>
<li id="footnote-1">
                        <p>Ambari 1.7x does not install Accumulo, Hue, Ranger, or Solr services for the HDP 2.2
                          Stack.
                        </p>
                      </li>
<li id="footnote-2">
                        <p>Ambari 1.7x does not install Accumulo, Hue, Knox, or Solr services for the HDP 2.1
                          Stack.
                        </p>
                      </li>
<li id="footnote-3">
                        <p>Ambari 1.7x does not install Hue for the HDP 2.0 Stack.</p>
                      </li>
<li id="footnote-4">
                        <p>The Views in the community are not supported by Pivotal.</p>
                      </li>
</ol>
</div></div>
<div class="container"><footer><h3 class="horton-blue border-bottom">About Pivotal Data Platform</h3>
      Copyright
      
        <p>This work by
          <a href="http://hortonworks.com">Pivotal, Inc.</a>
          is licensed under a<a href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons
            Attribution-ShareAlike 3.0 Unported License</a>.
        </p>
      
      
    <div class="copyright"><p>
    
      <p>The Pivotal Data Platform, powered by Apache Hadoop, is a massively scalable and 100% open source
        platform for storing, processing and analyzing large volumes of data. It is designed to deal with data from many
        sources and formats in a very quick, easy and cost-effective manner. The Pivotal Data Platform consists of
        the essential set of Apache Hadoop projects including MapReduce, Hadoop Distributed File System (HDFS),
        HCatalog, Pig, Hive, HBase, Zookeeper and Ambari. Pivotal is the major contributor of code and patches to
        many of these projects. These projects have been integrated and tested as part of the Pivotal Data Platform
        release process and installation and configuration tools have also been included.
      </p>
      <p>Unlike other providers of platforms built using Apache Hadoop, Pivotal contributes 100% of our code
        back to the Apache Software Foundation. The Pivotal Data Platform is Apache-licensed and completely open
        source. We sell only expert technical support,
        <a href="http://hortonworks.com/hadoop-training/">training</a>
        and partner enablement services.
        <strong>All of our technology is, and will remain, free and open source.
        </strong>
      </p>
      <p>For more information on Pivotal technology, Please visit the
        <a href="http://hortonworks.com/products/hdp/">Pivotal Data Platform</a>
        page. For more information on Pivotal services, please visit either the
        <a href="http://hortonworks.com/hadoop-support/">Support</a>
        or
        <a href="http://hortonworks.com/hadoop-training">Training</a>
        page. Feel free to
        <a href="http://hortonworks.com/about-us/contact-us/">Contact Us</a>
        directly to discuss your specific needs.
      </p>
    
    <span>© Copyright © 2012, 2014 Pivotal, Inc. Some rights reserved.</span>
  </p></div></footer></div>
</div></div></body>
</html>
